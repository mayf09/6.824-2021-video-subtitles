1
00:00:00,000 --> 00:00:02,010
0,90 90,150 150,480 480,960 1320,2010
We'll {} talking about {}
我们将谈论的是 Spark ，

2
00:00:02,010 --> 00:00:04,290
0,750 750,870 870,1440 1830,2160 2160,2280
is {} Spark,| and so
|所以这几乎可以追溯到学期开始，

3
00:00:04,290 --> 00:00:05,940
0,180 180,390 390,810 810,1230 1230,1650
this goes back to almost

4
00:00:05,940 --> 00:00:07,200
0,90 90,450 450,570 570,660 660,1260
the beginning of the semester,|
|

5
00:00:07,620 --> 00:00:09,420
0,780 780,1500 1500,1590 1590,1680 1680,1800
{} where you know we
我们在那里谈了很多关于 mapreduce 的事情，

6
00:00:09,420 --> 00:00:10,620
0,570 570,750 750,780 780,930 930,1200
talked quite a bit about

7
00:00:10,620 --> 00:00:12,420
0,150 150,510 510,630 630,960 960,1800
{mapreduce -},| in fact {you,know,lab,1}
|事实上，在实验 1 你实现了 mapreduce .

8
00:00:12,420 --> 00:00:14,130
0,180 180,270 270,810 810,1170 1170,1710
that you implemented {mapreduce -}.|
|

9
00:00:14,940 --> 00:00:17,550
0,600 780,1350 1470,1680 1680,2220 2250,2610
{} So {} and really
事实上，非正式的，

10
00:00:17,550 --> 00:00:19,050
0,360 360,450 450,900 1170,1410 1410,1500
what's you know sort of

11
00:00:19,050 --> 00:00:20,820
0,600 600,690 690,990 990,1440 1440,1770
informally,| you know the Spark
|Spark 是 Hadoop 的继任者，

12
00:00:20,820 --> 00:00:23,000
0,60 60,510 510,630 630,1380
is basically the successor

13
00:00:25,240 --> 00:00:27,540
0,120 120,810 810,1200 1200,1560
{you,know} to {Hadoop -},|
|

14
00:00:28,830 --> 00:00:29,910
0,420 420,540 540,720 720,930 930,1080
and {Hadoop - -} is
Hadoop 是 mapreduce 的开源版本。

15
00:00:29,910 --> 00:00:32,430
0,390 390,690 690,930 930,1650 1920,2520
the {open-source -} version of

16
00:00:33,270 --> 00:00:34,420
0,720
{}

17
00:00:35,000 --> 00:00:36,320
0,180 180,390 390,930
{} {mapreduce -}.|
|

18
00:00:38,610 --> 00:00:40,890
0,300 300,360 360,600 600,1320 1410,2280
So I think today, {}|
所以我认为今天，|

19
00:00:40,890 --> 00:00:42,270
0,180 180,450 480,870 870,1260 1260,1380
you know people typically will
人们通常会使用 Spark 而不是 Hadoop 。

20
00:00:42,270 --> 00:00:44,850
0,630 630,900 900,1650 1740,2070 2070,2580
use {} Spark {} instead

21
00:00:44,850 --> 00:00:46,300
0,300 330,630 630,780 780,1110
of {} {Hadoop -}.|
|

22
00:00:46,640 --> 00:00:47,960
0,270 270,390 390,480 480,870 870,1320
And so it's really widely
所以它有广泛的应用，

23
00:00:47,960 --> 00:00:50,080
0,660
used,|
|

24
00:00:52,860 --> 00:00:53,820
0,210 210,330 330,630 630,840 840,960
and it's widely used for
它被广泛用于数据科学计算，

25
00:00:53,820 --> 00:00:56,280
0,240 240,750 780,1560 1560,2130 2130,2460
data science {} computation,| so
|所以人们有大量的数据，

26
00:00:56,280 --> 00:00:58,050
0,300 300,630 630,840 840,1170 1170,1770
people that {you,know} have lots

27
00:00:58,050 --> 00:00:59,130
0,60 60,600 630,780 780,930 930,1080
of data,| that need to
|需要对其进行一些计算，

28
00:00:59,130 --> 00:01:00,660
0,240 240,480 480,1020 1020,1350 1350,1530
run some computation over it,|
|

29
00:01:00,840 --> 00:01:02,370
0,510 510,600 600,750 750,810 810,1530
require a ton of machines,|
需要大量的机器，|

30
00:01:02,550 --> 00:01:04,050
0,480 480,600 600,690 690,1290 1320,1500
{} you know Spark {}
Spark 是为这个特殊的情况而设计的，

31
00:01:04,050 --> 00:01:05,820
0,240 240,720 720,840 840,990 990,1770
is designed for that particular

32
00:01:05,820 --> 00:01:08,280
0,480 510,1050 1410,2010 2220,2370 2370,2460
{} case,| {} it is
|它由一家名为 Databricks 的公司商业化，

33
00:01:08,280 --> 00:01:09,570
0,630 630,720 720,780 780,1080 1080,1290
commercialized by a company called

34
00:01:09,570 --> 00:01:10,660
0,180 180,750
{Databricks -},|
|

35
00:01:12,250 --> 00:01:15,010
0,120 120,420 1740,2010 2010,2520 2520,2760
you know Matei Zaharia who
Matei Zaharia 是作者，

36
00:01:15,010 --> 00:01:16,030
0,90 90,420 420,900 900,960 960,1020
is the author,| of the
|这篇论文的主要作者，他的博士论文，

37
00:01:16,030 --> 00:01:17,080
0,240 240,450 450,540 540,660 660,1050
main author of this paper,

38
00:01:17,110 --> 00:01:19,840
0,840 840,960 960,1350 1350,1950 2070,2730
his {} PhD thesis,| started
|和其他一些人一起开始，

39
00:01:19,840 --> 00:01:20,710
0,180 180,270 270,660 660,720 720,870
with a number of other

40
00:01:20,710 --> 00:01:22,180
0,270 270,390 390,720 720,930 930,1470
people,| this company {Databricks -}
|Databricks 公司将 Spark 商业化，

41
00:01:22,390 --> 00:01:25,510
0,510 510,1080 1080,1890 1890,2250 2250,3120
{} which {commercializes -} Spark,|
|

42
00:01:25,540 --> 00:01:27,670
0,450 450,570 570,810 810,1260 1260,2130
but it also supports the
但它也支持 Apache 开源 Spark 版本，

43
00:01:27,730 --> 00:01:32,280
0,390 390,1260 2130,2580 2580,3030
Apache open-source Spark version,|
|

44
00:01:33,010 --> 00:01:34,540
0,180 180,300 300,600 630,990 990,1530
it's {} a pretty popular
它是一个很流行的开源项目，

45
00:01:34,540 --> 00:01:36,760
0,210 210,510 510,1050 1770,1950 1950,2220
{open-source -} project| or very
|或非常流行的开源项目。

46
00:01:36,760 --> 00:01:39,220
0,330 330,540 540,780 780,1380 1860,2460
popular {open-source -} project. {}|
|

47
00:01:39,400 --> 00:01:41,140
0,210 210,810 840,1290 1290,1680 1680,1740
It is one reason as
它取代 Hadoop 的一个原因是，

48
00:01:41,140 --> 00:01:42,760
0,210 210,390 420,1440 1440,1530 1530,1620
sort of replaced you know

49
00:01:42,760 --> 00:01:44,020
0,120 120,360 360,480 480,870 870,1260
the use of {Hadoop -}

50
00:01:44,080 --> 00:01:45,370
0,150 150,450 450,510 510,780 780,1290
is,| because it actually supports
|因为它支持更广泛的，

51
00:01:45,370 --> 00:01:46,800
0,90 90,450 450,1110
{} wider range,|
|

52
00:01:47,610 --> 00:01:49,530
0,690 690,930 930,1020 1020,1740 1740,1920
wider range of applications than
比 mapreduce 更广泛的应用程序，

53
00:01:49,530 --> 00:01:51,000
0,90 90,240 240,540 540,840
{mapreduce - -} can,|
|

54
00:01:52,410 --> 00:01:54,270
0,180 180,870 870,1110 1110,1410 1410,1860
in particular {you,know} very good
尤其是非常擅长这些迭代。

55
00:01:54,510 --> 00:01:55,860
0,210 210,420 420,1080
at these iterative.|
|

56
00:01:57,070 --> 00:01:58,160
0,180 180,450 450,510 510,840
{Oops\,,what} happened {there -},|
糟糕，发生了什么，|

57
00:02:00,800 --> 00:02:02,450
0,210 210,300 300,570 570,1110 1110,1650
let me see, something {}
一些东西可能崩溃了，

58
00:02:02,690 --> 00:02:04,610
0,510 510,780 780,1050 1050,1590 1620,1920
maybe {external -} crash,| hold
|稍等一下。

59
00:02:04,610 --> 00:02:05,620
0,90 90,180 180,570
on a second.|
|

60
00:02:27,180 --> 00:02:28,340
0,870

61
00:02:36,270 --> 00:02:39,810
0,660 870,1500 2280,2880 2880,3120 3120,3540
Okay, {} fortunately {having -}
好的，幸运的是[状态很好]。

62
00:02:39,810 --> 00:02:42,000
0,240 240,720 750,1410
good shape. {}|
|

63
00:02:42,340 --> 00:02:43,120
0,210 210,360 360,420 420,720 720,780
Okay, so it supports a
好的，所以它支持广泛的应用，

64
00:02:43,120 --> 00:02:45,580
0,210 210,420 420,510 510,1410 1770,2460
wide range of applications, {}|
|

65
00:02:45,700 --> 00:02:46,720
0,270 270,630 630,720 720,900 900,1020
in particular is good at
尤其擅长迭代应用，

66
00:02:46,720 --> 00:02:48,880
0,300 300,660 660,1290 1290,1470 1470,2160
these iterative applications,| so applications
|所以，如果应用程序需要执行多轮 mapreduce 操作，

67
00:02:48,880 --> 00:02:50,620
0,600 660,810 810,1320 1320,1620 1620,1740
where {} multiple rounds of

68
00:02:50,620 --> 00:02:52,030
0,210 210,510 510,990 990,1200 1200,1410
{mapreduce -} operations,| so if
|如果你有一个应用程序，

69
00:02:52,030 --> 00:02:53,140
0,210 210,360 360,450 450,960 960,1110
you have an application,| that
|需要先执行一轮 mapreduce ，

70
00:02:53,140 --> 00:02:54,520
0,390 390,780 780,1110 1110,1170 1170,1380
requires one set of {mapreduce

71
00:02:54,520 --> 00:02:55,690
0,330 330,660 660,750 750,1020 1020,1170
-}| followed by another set
|然后再执行一轮 mapreduce 计算，

72
00:02:55,690 --> 00:02:56,620
0,60 60,270 270,570 570,840 840,930
of {mapreduce -}, followed by

73
00:02:56,620 --> 00:02:59,290
0,240 240,450 450,840 840,1860 2280,2670
another {mapreduce -} computation,| Spark
|Spark 很适合它，

74
00:02:59,290 --> 00:03:00,130
0,90 90,330 330,510 510,630 630,840
is really good at it,|
|

75
00:03:00,400 --> 00:03:01,000
0,120 120,180 180,420 420,510 510,600
and the reason is so
它很擅长的原因是，

76
00:03:01,000 --> 00:03:02,290
0,180 180,330 330,600 600,870 870,1290
good at {it,is},| because basically
|因为它将中间结果保存在内存中，

77
00:03:02,290 --> 00:03:04,000
0,150 150,510 510,720 720,1320 1320,1710
it keeps the intermediate results

78
00:03:04,000 --> 00:03:05,020
0,120 120,510 510,600 600,780 780,1020
in memory,| and that's really
|这是很好编程支持。

79
00:03:05,020 --> 00:03:06,880
0,180 180,600 600,1020 1020,1470 1470,1860
good support, programming support for

80
00:03:07,420 --> 00:03:08,320
0,480 480,780
doing so.|
|

81
00:03:09,140 --> 00:03:12,140
0,600 1500,1980 1980,2250 2250,2430 2430,3000
{ -} In some ways,
在某些方面，

82
00:03:12,170 --> 00:03:14,000
0,600 840,1020 1020,1380 1380,1560 1560,1830
{} you know,| so if
|如果之前的论文和这篇论文之间有任何联系，

83
00:03:14,000 --> 00:03:15,620
0,150 150,690 750,1290 1290,1410 1410,1620
there's any connection at all

84
00:03:15,620 --> 00:03:16,640
0,240 240,300 300,630 630,930 930,1020
between the previous paper and

85
00:03:16,640 --> 00:03:17,930
0,150 150,540 540,780 810,1200 1200,1290
this paper,| which basically is
|基本上没有，

86
00:03:17,930 --> 00:03:20,000
0,420 570,1170 1200,1560 1560,1650 1650,2070
not,| {} but you know
|但它们都是针对内存计算的，

87
00:03:20,120 --> 00:03:21,950
0,300 300,600 600,900 900,1530 1590,1830
they're all both targeted to

88
00:03:21,950 --> 00:03:23,760
0,240 240,450 450,720 720,1470
{sort,of} {in-memory -} computations,|
|

89
00:03:28,000 --> 00:03:29,470
0,330 330,480 480,1050 1050,1140 1140,1470
{you,know} for datasets that basically
对于可以存储在内存中的数据集，

90
00:03:29,470 --> 00:03:31,090
0,240 240,420 420,810 1380,1560 1560,1620
fit {in-memory -},| in the
|在之前的论文和 FaRM 论文中，

91
00:03:31,090 --> 00:03:32,710
0,270 270,750 750,1080 1080,1350 1350,1620
previous paper and FaRM paper|
|

92
00:03:32,710 --> 00:03:33,460
0,120 120,240 240,540 540,630 630,750
is all about you know
|是关于在内存中的数据库，

93
00:03:33,460 --> 00:03:35,260
0,330 390,960 960,1170 1170,1290 1290,1800
the database fit {in-memory -},|
|

94
00:03:35,290 --> 00:03:37,000
0,570 570,660 660,900 900,1290 1290,1710
here's the {dataset -} the
这里是数据科学计算的数据集，

95
00:03:37,030 --> 00:03:38,800
0,270 270,660 660,1380 1380,1500 1500,1770
data science computation,| for data
|用于你想做的数据科学计算。

96
00:03:38,800 --> 00:03:39,880
0,270 270,750 750,840 840,930 930,1080
science computation that you want

97
00:03:39,880 --> 00:03:40,400
0,60 60,270
to do.|
|

98
00:03:41,420 --> 00:03:42,660
0,570

99
00:03:42,860 --> 00:03:43,820
0,300 300,630 630,690 690,780 780,960
Of course, you know since
当然，自从 2012 年这篇论文发表以来，

100
00:03:43,820 --> 00:03:46,040
0,810 810,1500 1500,1980 1980,2100 2100,2220
{2012\,,when} {this,paper,was} published,| a lot
|发生了很多事情，

101
00:03:46,040 --> 00:03:48,200
0,60 60,270 270,390 390,930 1260,2160
of things have happened, {}|
|

102
00:03:48,230 --> 00:03:49,280
0,660
the
Spark 并不是与 Scala 捆绑在一起，

103
00:03:49,500 --> 00:03:51,210
0,570 870,1050 1050,1290 1290,1350 1350,1710
{} {Spark -} is not

104
00:03:51,210 --> 00:03:53,340
0,210 210,540 540,930 930,1500 1530,2130
really tied to {} Scala,|
|

105
00:03:53,340 --> 00:03:54,960
0,120 120,420 420,780 780,1440 1440,1620
sort of described {in,the,paper},| but
像论文中描述的那样，|比如，还有其他语言前端，

106
00:03:54,960 --> 00:03:55,950
0,90 90,150 150,330 330,690 690,990
there are other language front

107
00:03:55,950 --> 00:03:57,930
0,210 210,270 270,810 1290,1680 1680,1980
ends, for example,| but probably
|但更重要的是，

108
00:03:57,930 --> 00:04:00,510
0,180 180,930 930,1050 1050,1770 2070,2580
more importantly,| you know {}
|在这篇论文中定义的 RDD 有点过时了，

109
00:04:01,320 --> 00:04:03,390
0,240 240,810 810,1020 1020,1440 1440,2070
the RDD has defined {in,this,paper}

110
00:04:03,390 --> 00:04:05,280
0,180 180,510 510,1020 1020,1320 1320,1890
{slightly -} {deprecated -}, {}|
|

111
00:04:05,280 --> 00:04:09,630
0,390 390,840 2040,2280 2280,3630 3720,4350
and replace by {} {dataframes
被数据帧所取代，

112
00:04:09,630 --> 00:04:11,730
0,690 810,1230 1230,1410 1410,1650 1650,2100
-},| {} but {dataframes -}
|但是考虑数据帧的方式，

113
00:04:11,730 --> 00:04:12,510
0,90 90,240 240,330 330,510 510,780
the way to think about

114
00:04:12,510 --> 00:04:13,500
0,90 90,540 540,690 690,810 810,990
it,| the way I think
|在我看来，

115
00:04:13,500 --> 00:04:14,520
0,270 270,330 330,510 510,600 600,1020
about it,| this is basically
|这是带有显示列的 RDD ，

116
00:04:14,520 --> 00:04:16,680
0,540 570,990 990,1380 1380,1650 1650,2160
column, is {} {RDD -}

117
00:04:16,680 --> 00:04:18,900
0,120 120,330 360,840 840,1500 1860,2220
{with -} explicit columns,| and
|RDD 的所有好想法也适用于数据帧。

118
00:04:18,900 --> 00:04:20,040
0,180 180,270 270,480 480,960 960,1140
all the good ideas of

119
00:04:20,040 --> 00:04:21,840
0,120 120,600 600,930 930,1410 1410,1800
{RDDs -} are also true

120
00:04:21,840 --> 00:04:23,760
0,660 780,1170 1170,1410 1410,1860
for {} {dataframes -}.|
|

121
00:04:24,480 --> 00:04:25,740
0,480 480,690 690,900 900,1170 1170,1260
{} And so for the
所以这节课剩下的部分，

122
00:04:25,740 --> 00:04:26,460
0,120 120,210 210,270 270,570 570,720
rest of the lecture,| I'm
|我只想谈谈 RDD ，

123
00:04:26,460 --> 00:04:27,810
0,120 120,270 270,480 480,750 750,1350
just gonna talk about {RDDs

124
00:04:28,230 --> 00:04:32,340
0,150 150,2610 3030,3750 3750,3960 3960,4110
-},| and think about them
|并将它们等同于数据帧。

125
00:04:32,340 --> 00:04:33,660
0,210 210,660 660,780 780,1140 1140,1320
as equivalently as to {}

126
00:04:33,660 --> 00:04:34,560
0,150 150,240 240,750
{dataframes - -}.|
|

127
00:04:36,540 --> 00:04:38,460
0,210 210,630 630,1140 1140,1380 1410,1920
Any questions before I proceed?|
在我继续之前，有什么问题吗？|

128
00:04:46,200 --> 00:04:47,910
0,360 360,510 510,1230 1290,1560 1560,1710
{} And then quick other
然后快速提出另一点，

129
00:04:47,910 --> 00:04:49,620
0,150 150,510 510,1350 1350,1620 1620,1710
point,| maybe this research is
|也许这项研究真的很成功，

130
00:04:49,620 --> 00:04:52,830
0,450 450,690 690,900 900,1560 2760,3210
really {} quite successful,| widely
|被广泛应用，

131
00:04:52,830 --> 00:04:55,980
0,510 750,1200 1200,1920 1980,2550 2580,3150
used,| also {} Matei {}
|Matei 也获得了 ACM 博士论文奖，

132
00:04:55,980 --> 00:04:58,140
0,120 120,570 570,1260 1290,1710 1710,2160
{you,know} received the ACM doctoral

133
00:04:58,140 --> 00:04:59,910
0,480 570,960 960,1410 1410,1590 1590,1770
thesis {} award,| for this
|对于这篇论文，都是关于 Spark 的。

134
00:04:59,910 --> 00:05:02,070
0,180 180,930 1140,1560 1560,1710 1710,2160
for this thesis, that basically

135
00:05:02,070 --> 00:05:03,260
0,180 180,330 330,540 540,990
is all about Spark.|
|

136
00:05:04,300 --> 00:05:05,680
0,270 270,390 390,600 600,1020 1020,1380
So it's quite unusual actually
对于一篇博士论文来说，这是相当不寻常的，

137
00:05:05,680 --> 00:05:07,960
0,540 960,1170 1170,1650 1650,1980 1980,2280
for a doctoral thesis,| that
|产生这样的影响。

138
00:05:07,960 --> 00:05:08,530
0,90 90,210 210,360 360,510 510,570
to have that kind of

139
00:05:08,530 --> 00:05:09,320
0,510
impact.|
|

140
00:05:16,470 --> 00:05:17,320
0,570
Okay?|
好的?|

141
00:05:18,580 --> 00:05:20,800
0,600 720,960 960,1110 1110,1800 1800,2220
{} So the way I
所以我想讨论 Spark ，

142
00:05:20,800 --> 00:05:21,940
0,180 180,240 240,420 420,660 660,1140
want to talk about Spark|
|

143
00:05:21,940 --> 00:05:23,680
0,180 180,390 390,750 750,990 990,1740
by just looking at the
通过查看一些示例，

144
00:05:23,770 --> 00:05:25,630
0,210 210,360 360,510 510,1140 1170,1860
{} some of examples,| because
|因为我觉得最好，

145
00:05:25,840 --> 00:05:26,860
0,270 270,510 510,810 810,960 960,1020
I think you get the

146
00:05:26,860 --> 00:05:29,530
0,510 510,1260 1260,1590 1590,2040 2100,2670
best,| {} you, you understand
|你了解编程模型，

147
00:05:29,530 --> 00:05:31,460
0,210 210,630 630,1170
the programming model,|
|

148
00:05:31,960 --> 00:05:32,830
0,180 180,360 360,450 450,750 750,870
but that is based on
这是基于 RDD 的，

149
00:05:32,830 --> 00:05:35,020
0,150 150,930 1410,1770 1770,2070 2070,2190
{RDDs -},| {} best by
|我想最好是查看示例，

150
00:05:35,020 --> 00:05:36,100
0,210 210,330 330,600 600,960 960,1080
this I think looking at

151
00:05:36,100 --> 00:05:37,440
0,810
examples,|
|

152
00:05:40,330 --> 00:05:41,500
0,360 360,450 450,600 600,930 930,1170
and you get the best
你能最好的了解 RDD 。

153
00:05:41,500 --> 00:05:42,580
0,240 240,360 360,630 630,810 810,1080
idea {of -} what actually

154
00:05:42,580 --> 00:05:44,320
0,90 90,210 210,1020 1470,1620 1620,1740
in {RDD,is -}.| And so
|所以让我举一些例子，

155
00:05:44,320 --> 00:05:45,070
0,120 120,300 300,510 510,600 600,750
let me pull up some

156
00:05:45,070 --> 00:05:46,510
0,90 90,420 420,1080 1080,1230 1230,1440
of the examples,| that were
|在论文中的，

157
00:05:46,510 --> 00:05:47,440
0,60 60,120 120,690
in the paper,|
|

158
00:05:48,070 --> 00:05:49,870
0,180 180,420 420,600 600,1200 1200,1800
then we'll walk through those.|
然后我们走一遍。|

159
00:05:51,260 --> 00:05:53,700
0,960 1260,1650 1650,2100
{} {Take,this} one,|
拿出这个，|

160
00:05:53,960 --> 00:05:55,260
0,210 210,360 360,630 630,990
so let's start here,
让我们从这里开始，一个非常简单的例子。

161
00:05:55,870 --> 00:05:58,090
0,240 240,570 570,1200 1200,1560 1560,2220
a very simple {} example.|
|

162
00:05:58,600 --> 00:06:01,360
0,330 330,780 990,1290 1290,1800 2100,2760
And so {you,know} the idea
所以想法是，

163
00:06:01,360 --> 00:06:02,420
0,120 120,750
is that,|
|

164
00:06:02,720 --> 00:06:04,460
0,780 780,960 960,1080 1080,1500 1500,1740
{} in this example is
在这个例子中，

165
00:06:04,460 --> 00:06:05,630
0,210 210,300 300,840 870,1110 1110,1170
that,| you know first of
|首先，你可以互动地使用 Spark ，

166
00:06:05,630 --> 00:06:06,500
0,90 90,210 210,420 420,690 690,870
all, you can sort of

167
00:06:06,500 --> 00:06:09,230
0,630 630,1440 1470,1890 1890,2640 2670,2730
use {} spark interactively,| so
|你可以在工作站或笔记本电脑上开始 Spark ，

168
00:06:09,230 --> 00:06:10,670
0,150 150,240 240,390 390,570 1020,1440
you can see that {start,of}

169
00:06:10,670 --> 00:06:12,380
0,360 360,420 420,510 510,1320 1560,1710
Spark at the workstation or

170
00:06:12,380 --> 00:06:15,920
0,600 900,1380 1380,1680 1680,2460 2460,3540
laptop,| and start interacting {}
|开始与 Spark 互动，

171
00:06:16,010 --> 00:06:18,440
0,660 930,1560 1620,1920 1920,2310 2310,2430
{with,Spark},| {} you know the
|使用输入命令的方式。

172
00:06:18,440 --> 00:06:20,120
0,360 360,1110 1110,1230 1230,1590 1590,1680
way {you,know} you type in

173
00:06:20,120 --> 00:06:21,100
0,300 300,420 420,870
commands like this.|
|

174
00:06:21,480 --> 00:06:22,620
0,240 240,600 660,900 900,1050 1050,1140
And so now what does
那么现在这个命令做了什么，

175
00:06:22,620 --> 00:06:23,790
0,180 180,480 480,930 960,1080 1080,1170
this command do,| you know
|这会创建一个 RDD ，

176
00:06:23,790 --> 00:06:26,010
0,180 180,870 1080,1560 1590,2160 2160,2220
this basically {} creates {an,RDD

177
00:06:26,010 --> 00:06:28,140
0,600 600,750 750,1260 1590,2010 2010,2130
-},| {you,know} called this {}
|称这个为 RDD ， lines 是 RDD ，

178
00:06:28,140 --> 00:06:29,100
0,480
RDDs,

179
00:06:29,400 --> 00:06:31,470
0,390 390,570 570,690 690,1290 1590,2070
lines is {an,RDD -},| and
|我这里表示 RDD 存储在 HDFS 中，

180
00:06:31,470 --> 00:06:33,300
0,90 90,300 300,1140 1140,1830 1830,1830
I just represents {you,know,the} {}

181
00:06:33,300 --> 00:06:34,740
0,300 300,630 630,810 810,1110 1110,1440
{RDD -} that actually stored

182
00:06:34,740 --> 00:06:36,810
0,90 90,450 450,960 1200,1860 1860,2070
in {HDFS -},| and {you,know}
|HDFS 可能有许多分区

183
00:06:36,810 --> 00:06:37,680
0,450
the

184
00:06:38,500 --> 00:06:40,420
0,810 810,930 930,1290 1290,1620 1620,1920
HDFS {you,know} might be have

185
00:06:40,420 --> 00:06:41,800
0,330 330,990 990,1080 1080,1200 1200,1380
many partitions| you know for
|对于这个文件，

186
00:06:41,800 --> 00:06:43,210
0,120 120,510 510,1050 1080,1260 1260,1410
this particular file,| {} so
|例如，第一个 1000 或 100 万条记录在分区 1 上，

187
00:06:43,210 --> 00:06:45,250
0,60 60,600 870,1080 1080,1590 1590,2040
for example the first thousand

188
00:06:45,250 --> 00:06:46,270
0,90 90,120 120,420 420,810 810,1020
or {} million records live

189
00:06:46,270 --> 00:06:48,100
0,540 540,900 900,1290 1290,1530 1530,1830
{on,like} partition 1,| there's next
|下一个 100 万在分区 2 ，

190
00:06:48,100 --> 00:06:50,170
0,1050 1050,1230 1230,1320 1320,1680 1680,2070
million live in partition 2,|
|

191
00:06:50,170 --> 00:06:51,790
0,390 390,630 630,900 900,1230 1230,1620
{and,the,next} million live to partition
接下来的 100 万在分区 3 ，

192
00:06:51,790 --> 00:06:54,160
0,300 840,1050 1050,1200 1200,1980 1980,2370
3,| then this RDD {}
|这个 RDD lines 代表了这组分区，

193
00:06:54,160 --> 00:06:55,990
0,240 240,420 420,780 780,1680 1680,1830
{lines -} basically represents you

194
00:06:55,990 --> 00:06:57,550
0,120 120,660 690,900 900,1380 1380,1560
know that {} that set

195
00:06:57,550 --> 00:06:58,720
0,210 210,1080
of partitions,|
|

196
00:07:00,070 --> 00:07:02,470
0,780 780,1440 1470,2010 2010,2190 2190,2400
when you run this line
当运行这行或输入这行并回车，

197
00:07:02,470 --> 00:07:03,100
0,90 90,180 180,420 420,480 480,630
or you type in this

198
00:07:03,100 --> 00:07:05,380
0,270 270,420 420,1260 1260,1860 1890,2280
line in return, {hit,return},| basically
|什么都不会发生，

199
00:07:05,380 --> 00:07:07,570
0,270 270,480 480,1080 1200,2010 2010,2190
nothing really happens,| {} and
|这就是论文所说的懒惰计算，

200
00:07:07,570 --> 00:07:09,010
0,120 120,240 240,300 300,450 450,1440
so this is what the

201
00:07:09,100 --> 00:07:10,690
0,660 660,1020 1020,1140 1140,1320 1320,1590
paper refers to as lazy

202
00:07:10,690 --> 00:07:13,960
0,810 1320,2070 2070,2490 2490,2790 2790,3270
computations,| {in,fact\,,computations} executed {some,point} later,|
|事实上，计算在稍晚一些执行，|

203
00:07:13,960 --> 00:07:14,920
0,300 300,390 390,570 570,750 750,960
and we'll see {} in
我们稍后会看到什么时候，

204
00:07:14,920 --> 00:07:16,390
0,30 30,300 300,630 960,1380 1380,1470
a second when,| but at
|但在这个特定的点上，

205
00:07:16,390 --> 00:07:17,650
0,150 150,450 450,750 750,810 810,1260
this particular point { -},|
|

206
00:07:17,740 --> 00:07:18,730
0,150 150,360 360,450 450,690 690,990
the only thing that's actually
唯一发生的事情是，

207
00:07:18,730 --> 00:07:20,080
0,390 390,660 660,930 930,1200 1200,1350
happened is that,| there is
|RDD 中有一个 lines 对象。

208
00:07:20,080 --> 00:07:22,330
0,270 420,1140 1140,1410 1410,1950 1950,2250
a lines lines {object -}

209
00:07:22,330 --> 00:07:23,020
0,120 120,420 420,480 480,600 600,690
that happens to be in

210
00:07:23,020 --> 00:07:23,740
0,120 120,630
{RDD -}.|
|

211
00:07:24,640 --> 00:07:26,980
0,570 780,1320 1320,2130 2130,2220 2220,2340
And {} RDD you know
而且 RDD 支持广泛的操作，

212
00:07:26,980 --> 00:07:28,930
0,540 540,1080 1080,1410 1410,1770 1770,1950
supports a wide range of

213
00:07:28,930 --> 00:07:30,880
0,930 1140,1410 1410,1530 1530,1650 1650,1950
operations,| {} we can actually
|我们可以看一下它支持的一些操作。

214
00:07:30,880 --> 00:07:31,750
0,180 180,270 270,450 450,720 720,870
look a little bit with

215
00:07:31,750 --> 00:07:33,460
0,180 180,780 780,930 930,990 990,1710
some operations that it supports.|
|

216
00:07:34,480 --> 00:07:35,780
0,990

217
00:07:37,440 --> 00:07:39,270
0,420 450,870 870,1140 1140,1350 1350,1830
Yeah, so {it's,has -}, an
是的，它有， RDD 有一个 API ，

218
00:07:39,420 --> 00:07:41,610
0,390 390,540 540,630 630,1410 1560,2190
RDD has an API {},|
|

219
00:07:41,610 --> 00:07:42,510
0,270 270,360 360,540 540,690 690,900
and it turns out that
事实证明， API 的方法

220
00:07:42,510 --> 00:07:44,070
0,90 90,450 450,570 570,720 720,1560
the methods of the API|
|

221
00:07:44,100 --> 00:07:45,300
0,540 540,630 630,900 900,1020 1020,1200
or the methods on {RDD
或者 RDD 上的方法在两个类中，

222
00:07:45,300 --> 00:07:46,980
0,330 330,570 570,750 750,930 930,1680
-} {fail,in -} two classes,|
|

223
00:07:47,340 --> 00:07:49,650
0,480 480,1080 1080,1380 1380,1800 2040,2310
{} one are the, are
一个是 Actions ，

224
00:07:49,650 --> 00:07:50,480
0,690
Actions,|
|

225
00:07:50,770 --> 00:07:52,330
0,360 360,780 780,900 900,1440 1440,1560
and Actions are really the
Actions 是会导致计算发生的操作，

226
00:07:52,330 --> 00:07:54,490
0,720 720,870 870,1230 1230,1590 1620,2160
operations that will actually cause

227
00:07:54,490 --> 00:07:56,800
0,570 570,630 630,1050 1890,2100 2100,2310
computation to happen,| so all
|所以，所有懒惰的构建计算

228
00:07:56,800 --> 00:07:58,210
0,120 120,600 600,810 810,960 960,1410
the lazily sort of {build,up}

229
00:07:58,210 --> 00:07:59,890
0,840 930,1200 1200,1530 1530,1590 1590,1680
computation| really happens at the
|都发生在你运行 Action 的时间点，

230
00:07:59,890 --> 00:08:01,060
0,330 330,450 450,660 660,810 810,1170
point that {you're,run} an Action,|
|

231
00:08:01,210 --> 00:08:02,200
0,270 270,420 420,510 510,870 870,990
and so for example, you
比如，你运行 count 或 collect ，

232
00:08:02,200 --> 00:08:04,840
0,210 210,750 750,870 870,1440 1650,2640
run count or collect,| then,
|然后， Spark 计算将被执行。

233
00:08:04,840 --> 00:08:07,990
0,0 0,930 1800,2250 2250,2790 2790,3150
{} the Spark computation actually

234
00:08:07,990 --> 00:08:08,840
0,600
{is,executed}.|
|

235
00:08:09,780 --> 00:08:12,390
0,330 330,450 450,1410 1410,1920 1920,2610
All the other {API,or} methods
所有其他 API 或方法都是 Transformations ，

236
00:08:12,540 --> 00:08:15,510
0,690 690,1710 2040,2430 2430,2610 2610,2970
are Transformations,| and they basically
|它们把一个 RDD 变成另一个 RDD ，

237
00:08:15,510 --> 00:08:16,980
0,210 210,480 480,600 600,1170 1290,1470
take one {RDD -} and

238
00:08:16,980 --> 00:08:18,210
0,180 180,300 300,510 510,1050 1050,1230
turn it into another {RDD

239
00:08:18,210 --> 00:08:19,440
0,420 570,810 810,1020 1020,1140 1140,1230
-},| it turns out that
|每个 RDD 都是只读的或不可变的，

240
00:08:19,440 --> 00:08:21,990
0,960 1110,1320 1320,1830 1860,2130 2130,2550
{every,RDD} is actually {read-only -}

241
00:08:22,020 --> 00:08:23,200
0,300 300,960
or immutable,|
|

242
00:08:23,470 --> 00:08:25,380
0,210 210,330 330,750 750,1620
so you can't modify
所以，你不能修改 RDD ，

243
00:08:25,640 --> 00:08:27,470
0,180 180,300 300,840 960,1200 1200,1830
an {RDD -},| can only
|只能从现有的 RDD 生成新的 RDD 。

244
00:08:27,620 --> 00:08:29,930
0,1050 1050,1530 1530,1800 1800,1920 1920,2310
basically generate new {RDDs -}

245
00:08:29,930 --> 00:08:32,060
0,390 390,870 870,1290 1290,1590 1980,2130
form an existing one.| And
|所以如果我们看第二行，

246
00:08:32,060 --> 00:08:32,540
0,90 90,180 180,240 240,390 390,480
so if we look at

247
00:08:32,540 --> 00:08:34,310
0,60 60,420 420,900 990,1380 1380,1770
the second line,| this basically
|这创建了第二个 RDD ， RDD errors ，

248
00:08:34,310 --> 00:08:35,990
0,270 270,330 330,660 660,900 900,1680
creates a second {RDD -},

249
00:08:35,990 --> 00:08:37,240
0,150 150,480 480,1080
{RDD -} errors,|
|

250
00:08:37,550 --> 00:08:39,350
0,570 570,780 780,990 990,1140 1140,1800
and that one is created
这是通过在 lines RDD 上运行过滤器创建的，

251
00:08:39,500 --> 00:08:42,350
0,900 930,1440 1440,1530 1530,2220 2400,2850
by running a filter on

252
00:08:42,350 --> 00:08:43,800
0,120 120,450 450,600 600,1080
the lines {RDD -},|
|

253
00:08:44,240 --> 00:08:45,140
0,270 270,420 420,510 510,780 780,900
{} so the lines {RDD
所以 lines RDD 只读，

254
00:08:45,140 --> 00:08:47,570
0,420 630,840 840,1170 1170,2070 2070,2430
-} {read-only -}, {} {read-only

255
00:08:47,570 --> 00:08:50,150
0,180 180,630 1650,2130 2130,2310 2310,2580
- -},| {you,can,run} this method
|你可以对它运行 filter 方法，

256
00:08:50,150 --> 00:08:51,320
0,90 90,450 450,600 600,930 930,1170
the filter on it,| which
|在这种情况下，

257
00:08:51,320 --> 00:08:52,550
0,120 120,270 270,510 510,840 840,1230
in this case,| basically filters
|过滤出所有记录，

258
00:08:52,550 --> 00:08:54,260
0,450 600,870 870,990 990,1290 1290,1710
out all the records {}

259
00:08:54,260 --> 00:08:55,700
0,390 390,660 660,990 990,1110 1110,1440
start with,| all the lines
|所以以消息 ERROR 或字符串 ERROR 开头的行，

260
00:08:55,700 --> 00:08:57,290
0,120 120,390 390,570 570,1170 1200,1590
that start with the message

261
00:08:57,290 --> 00:08:59,180
0,450 450,720 720,1200 1440,1590 1590,1890
{ERROR,or} string ERROR,| and that
|这代表一个新的 RDD ，

262
00:08:59,180 --> 00:09:00,560
0,450 450,570 570,870 870,990 990,1380
represents a new {RDD -},|
|

263
00:09:00,800 --> 00:09:02,540
0,210 210,780 840,1020 1020,1170 1170,1740
and again at this point,
同样，在这一点上，并没有计算出任何东西，

264
00:09:02,750 --> 00:09:04,490
0,420 420,810 810,1080 1080,1260 1260,1740
nothing actually really being computed,|
|

265
00:09:04,490 --> 00:09:06,080
0,90 90,420 420,510 510,1260 1260,1590
is {just,like} a recipe or
只是一个[配方]或创建一个数据流，

266
00:09:06,080 --> 00:09:07,430
0,300 300,540 540,870 870,1170 1170,1350
{you,know} built some almost a

267
00:09:07,430 --> 00:09:10,100
0,330 330,870 960,1590 1590,2100 2280,2670
{dataflow -}| {} or what
|或者论文中所说的计算迭代图。

268
00:09:10,100 --> 00:09:10,910
0,60 60,240 240,450 450,510 510,810
the paper calls {} iterative

269
00:09:10,910 --> 00:09:12,600
0,540 600,810 810,900 900,1560
graph of the computation.|
|

270
00:09:14,180 --> 00:09:15,140
0,660

271
00:09:19,870 --> 00:09:20,720
0,660

272
00:09:22,040 --> 00:09:24,350
0,780 780,1050 1050,1680 1680,1800 1800,2310
Also, {} when the computation
此外，当计算开始运行时，

273
00:09:24,350 --> 00:09:26,000
0,270 270,660 660,1110 1200,1380 1380,1650
actually starts running,| it hasn't
|它还没有运行，

274
00:09:26,000 --> 00:09:27,050
0,150 150,420 420,630 630,930 930,1050
run yet,| but when it
|但当它开始运行时，

275
00:09:27,050 --> 00:09:28,760
0,180 180,510 510,930 1110,1470 1470,1710
will start running,| {} these
|这些操作是流水线的，

276
00:09:28,760 --> 00:09:31,100
0,480 480,690 690,1020 1020,1530 1860,2340
operations are {pipelined - -},|
|

277
00:09:31,100 --> 00:09:33,260
0,150 150,330 330,480 480,1290 1560,2160
with that, they mean, {}|
这个的意思是，|

278
00:09:33,260 --> 00:09:34,820
0,150 150,240 240,930 930,1290 1290,1560
so for example in stage
比如，在第一阶段，计算这个 lines ，

279
00:09:34,820 --> 00:09:36,500
0,480 480,570 570,750 750,1410 1440,1680
one you know the this

280
00:09:36,500 --> 00:09:38,660
0,510 510,600 600,690 690,1230 1380,2160
computation of the lines,| the
|第一阶段将读取一些记录，

281
00:09:38,960 --> 00:09:40,280
0,360 360,630 630,840 840,1020 1020,1320
stage one will read some

282
00:09:40,280 --> 00:09:41,390
0,180 180,300 300,870 870,990 990,1110
set of records,| you know
|例如，从第一个分区，

283
00:09:41,390 --> 00:09:43,340
0,510 510,960 990,1440 1440,1650 1650,1950
from {for,example -} this first

284
00:09:43,340 --> 00:09:44,100
0,600
partition,|
|

285
00:09:44,410 --> 00:09:46,480
0,570 630,810 810,1440 1500,1860 1860,2070
{} and then, {} do
然后，对它进行处理，

286
00:09:46,480 --> 00:09:47,920
0,180 180,720 720,930 930,1260 1350,1440
its processing on it, {}|
|

287
00:09:47,920 --> 00:09:49,000
0,270 270,450 450,780 780,900 900,1080
if there's anything and then
如果有什么东西，然后移交给第二阶段，

288
00:09:49,000 --> 00:09:50,410
0,330 330,480 480,570 570,870 870,1410
handed off to stage two,|
|

289
00:09:50,530 --> 00:09:52,420
0,360 360,630 630,960 960,1620 1740,1890
{you,know,what} stage two basically you
第二阶段会做这个 filter ，

290
00:09:52,420 --> 00:09:53,600
0,90 90,270 270,420 420,930
know doing this filter,|
|

291
00:09:53,890 --> 00:09:55,000
0,240 240,390 390,510 510,750 750,1110
and so in stage two,
所以在第二阶段，这个 filter 将运行，

292
00:09:55,000 --> 00:09:57,700
0,60 60,240 240,780 1020,1620 1950,2700
you know the, { -}

293
00:09:57,730 --> 00:10:00,130
0,600 1110,1410 1410,1920 1920,2220 2220,2400
the, {} this filter will

294
00:10:00,130 --> 00:10:01,720
0,420 540,690 690,870 870,930 930,1590
run,| and sort of {grab,out}
|找出 lines 中匹配的，

295
00:10:01,720 --> 00:10:03,940
0,270 270,870 870,1080 1080,1500 1500,2220
the lines that actually are

296
00:10:04,090 --> 00:10:05,620
0,540 660,1350
{} match,|
|

297
00:10:05,770 --> 00:10:07,510
0,420 420,540 540,840 840,1320 1320,1740
and you know basically produce
用它产生新的 RDD ，

298
00:10:07,510 --> 00:10:09,520
0,300 300,660 660,840 840,1320 1320,2010
with that {} new RDD,|
|

299
00:10:09,610 --> 00:10:11,470
0,300 300,540 540,1350 1590,1710 1710,1860
that just contains you know
只包含以（ERROR）开头的 lines ，

300
00:10:11,470 --> 00:10:12,970
0,180 180,630 630,750 750,1350 1350,1500
the lines {you,know} strings that

301
00:10:12,970 --> 00:10:14,350
0,330 330,570 630,990 990,1110 1110,1380
start with,| lines that start
|以字符串 ERROR 开头的 lines 。

302
00:10:14,350 --> 00:10:15,380
0,90 90,180 180,450 450,810
with the string ERROR.|
|

303
00:10:16,670 --> 00:10:19,040
0,450 450,1380 1560,2040 2040,2220 2220,2370
And while {} this sort
当第二个 RDD ，第二个阶段运行，

304
00:10:19,040 --> 00:10:20,360
0,60 60,420 420,780 780,1020 1020,1320
of second RDD, second stage

305
00:10:20,360 --> 00:10:21,320
0,360 360,450 450,570 570,690 690,960
runs,| you know the first
|第一阶段从文件系统中获取下一组记录，

306
00:10:21,320 --> 00:10:22,460
0,330 330,510 510,780 780,870 870,1140
stage {you,know} grab the next

307
00:10:22,460 --> 00:10:23,900
0,180 180,300 480,1140 1140,1350 1350,1440
set of records from the

308
00:10:23,900 --> 00:10:25,520
0,270 270,720 1050,1260 1260,1560 1560,1620
file system,| and then you
|然后再把它们带到第二阶段，

309
00:10:25,520 --> 00:10:26,480
0,210 210,390 390,630 630,870 870,960
know fetch them again to

310
00:10:26,480 --> 00:10:28,340
0,330 330,660 690,870 870,1230 1380,1860
stage two,| and so as
|随着你越走越远，

311
00:10:28,340 --> 00:10:29,870
0,90 90,480 480,1320 1320,1380 1380,1530
you go {further,and,further},| you have
|你有越来越多的阶段在你的管道中，

312
00:10:29,870 --> 00:10:31,130
0,270 270,360 360,510 510,1050 1050,1260
more and more stages in

313
00:10:31,130 --> 00:10:33,380
0,240 240,840 840,1050 1050,1770 1770,2250
your pipeline,| or your {}
|或者你的迭代图，

314
00:10:33,740 --> 00:10:35,630
0,630 630,1230 1320,1470 1470,1680 1680,1890
iterative graph,| and all those
|所有这些阶段将会并行运行，

315
00:10:35,630 --> 00:10:36,770
0,660 690,840 840,960 960,1020 1020,1140
stages are going to be

316
00:10:36,770 --> 00:10:38,620
0,390 390,600 600,660 660,1710
running sort of {in,parallel},|
|

317
00:10:38,850 --> 00:10:40,170
0,420 420,720 720,900 900,930 930,1320
and that's what I mean
这就是我所说的流水线转换。

318
00:10:40,170 --> 00:10:41,880
0,150 150,480 480,810 810,1350 1470,1710
with [] {pipelining -} {}

319
00:10:41,980 --> 00:10:43,300
0,120 120,1050
the transformations.|
|

320
00:10:45,990 --> 00:10:47,860
0,330 330,870 900,1560
Okay, so, {}
好的，所以，这行描述了，

321
00:10:48,080 --> 00:10:49,580
0,180 180,480 480,720 720,1380 1410,1500
so here this this you

322
00:10:49,580 --> 00:10:51,830
0,660 690,1020 1020,1320 1320,1620 1620,2250
know this line basically describes,|
|

323
00:10:51,830 --> 00:10:53,390
0,270 270,390 390,960 1020,1320 1320,1560
how to create {} {RDD
如何创建 errors RDD ，

324
00:10:53,390 --> 00:10:55,580
0,330 330,960 1110,1590 1590,1740 1740,2190
-} error, {} {RDD -},

325
00:10:55,640 --> 00:10:57,470
0,360 360,510 510,1080 1230,1440 1440,1830
errors {RDD -},| and then
|然后这一行，

326
00:10:57,470 --> 00:10:59,930
0,180 180,330 330,870 870,2070 2100,2460
this lines basically [],| tells
|告诉 Spark 在内存中保留这个 RDD 的复制，

327
00:10:59,930 --> 00:11:02,060
0,1050 1080,1320 1320,1710 1710,2040 2040,2130
Spark to basically keep a

328
00:11:02,060 --> 00:11:03,620
0,510 510,660 660,840 840,1440 1440,1560
copy of this RDD in

329
00:11:03,620 --> 00:11:04,240
0,390
memory,|
|

330
00:11:04,500 --> 00:11:07,710
0,330 330,600 600,1470 1740,2970 2970,3210
so if subsequent { -}
如果后续计算运行，使用 errors 做更多，

331
00:11:08,130 --> 00:11:09,960
0,990 990,1260 1260,1440 1440,1590 1590,1830
{computation,run} that you do more

332
00:11:09,960 --> 00:11:12,600
0,480 480,690 690,1230 1470,2160 2160,2640
stuff with errors,| {} Spark
|Spark 会将原始的 RDD 保存在内存中，

333
00:11:12,600 --> 00:11:14,220
0,120 120,330 330,960 960,1080 1080,1620
will actually keep the original

334
00:11:14,220 --> 00:11:17,070
0,780 780,1050 1050,1230 1230,1710 1980,2850
RDD actually in memory, {}|
|

335
00:11:17,070 --> 00:11:18,150
0,180 180,540 540,780 780,960 960,1080
so that, {} it can
这样，它可以与以后的计算共享，

336
00:11:18,150 --> 00:11:19,830
0,90 90,630 630,780 780,1080 1080,1680
be shared with later computation,|
|

337
00:11:19,830 --> 00:11:21,390
0,180 180,630 630,960 960,1080 1080,1560
so {for,example,if,you} wanted to reuse
例如，如果你想要重用错误文件，

338
00:11:21,390 --> 00:11:23,340
0,120 120,360 360,840 1140,1410 1410,1950
the error file,| {} then
|那么错误文件将存储在内存中，

339
00:11:23,430 --> 00:11:24,660
0,360 360,510 510,750 750,870 870,1230
that error file will be

340
00:11:24,660 --> 00:11:25,800
0,180 180,570 570,930 930,1080 1080,1140
in memory,| doesn't have to
|不需要从文件中重建，

341
00:11:25,800 --> 00:11:27,600
0,180 180,990 990,1320 1320,1410 1410,1800
be reconstructed from the files,|
|

342
00:11:27,600 --> 00:11:29,640
0,300 300,870 870,1050 1050,1920 1920,2040
actually represent the {maybe,HDFS -
从 HDFS 中，

343
00:11:29,640 --> 00:11:32,130
0,390 480,720 720,1200 1470,1950 1980,2490
-}| {} and {} allows
|允许你运行第二次计算。

344
00:11:32,130 --> 00:11:33,120
0,240 240,480 480,660 660,750 750,990
you to run the second

345
00:11:33,120 --> 00:11:33,800
0,570
computation.|
|

346
00:11:34,920 --> 00:11:36,600
0,300 300,360 360,720 720,1080 1080,1680
{And,here} for example one already,
即使在这个简单的例子中，

347
00:11:36,660 --> 00:11:37,620
0,180 180,480 480,570 570,690 690,960
{you,know} even in this simple

348
00:11:37,620 --> 00:11:39,060
0,480 480,600 600,780 780,990 990,1440
example,| you'll see there's a
|你会发现这和 mapreduce 有很大的不同，

349
00:11:39,060 --> 00:11:40,380
0,180 180,510 510,930 930,1230 1230,1320
big difference between this and

350
00:11:40,380 --> 00:11:41,760
0,210 210,750 1020,1200 1200,1320 1320,1380
{mapreduce -},| where at the
|在 mapreduce 作业中，你运行计算，它结束，

351
00:11:41,760 --> 00:11:43,290
0,210 210,510 510,1110 1230,1410 1410,1530
{mapreduce -} job and you

352
00:11:43,290 --> 00:11:44,940
0,150 150,240 240,930 930,1080 1080,1650
run the computation, it ends,|
|

353
00:11:45,150 --> 00:11:46,230
0,210 210,630 630,630 630,990 990,1080
and then, {} if you
然后，如果你想对数据重新做一些事情，

354
00:11:46,230 --> 00:11:48,000
0,180 180,660 750,1410 1410,1650 1650,1770
want to redo something with

355
00:11:48,000 --> 00:11:49,050
0,90 90,630 720,840 840,930 930,1050
the data,| you have to
|你必须从文件系统重新读取它，

356
00:11:49,050 --> 00:11:50,580
0,390 390,510 510,840 1200,1440 1440,1530
reread it in from the

357
00:11:50,580 --> 00:11:52,560
0,240 240,630 630,1110 1260,1800 1800,1980
file system,| and using this
|而使用这个 persist 方法，

358
00:11:52,560 --> 00:11:54,540
0,150 150,360 360,600 600,1170 1170,1980
sort of {} persist method,|
|

359
00:11:54,750 --> 00:11:57,090
0,780 780,1290 1290,1500 1500,2220 2250,2340
{} Spark can avoid you
Spark 可以避免必须从磁盘重新读取数据，

360
00:11:57,090 --> 00:11:58,830
0,120 120,360 360,480 480,1170 1320,1740
know having to reread {}

361
00:11:58,830 --> 00:12:00,090
0,240 240,540 540,780 780,960 960,1260
that data from the disk,|
|

362
00:12:00,090 --> 00:12:00,870
0,210 210,360 360,600 600,630 630,780
and {you,know} save a lot
节省了很多时间。

363
00:12:00,870 --> 00:12:01,400
0,60 60,360
of time.|
|

364
00:12:06,110 --> 00:12:07,480
0,240 240,540 540,660 660,1080
Any questions so far?|
到目前为止，有什么问题吗？|

365
00:12:08,480 --> 00:12:09,380
0,240 240,360 360,570 570,690 690,900
And so when the error
所以，当错误文件从 P1 中提取出来时，

366
00:12:09,380 --> 00:12:11,660
0,660 690,1080 1080,1710 1710,2130 2160,2280
file gets extracted from {P1

367
00:12:11,660 --> 00:12:12,890
0,210 210,450 450,750 750,900 900,1230
-}, let's say,| and then
|然后另一个错误文件从 P2 中提取出来，

368
00:12:12,890 --> 00:12:14,840
0,540 540,1230 1260,1560 1560,1800 1800,1950
there's another error file that

369
00:12:14,840 --> 00:12:16,640
0,270 270,750 750,900 900,1470 1560,1800
gets extracted from P2,| so
|所以我的理解是，这是并行发生的？

370
00:12:16,640 --> 00:12:17,720
0,120 120,660 660,750 750,930 930,1080
my understanding is that, this

371
00:12:17,720 --> 00:12:19,910
0,360 360,480 480,1170 1200,1710 1980,2190
happened in parallel?| Yes, so
|是的，所以你可以考虑它，

372
00:12:19,910 --> 00:12:20,600
0,150 150,240 240,390 390,600 600,690
you can think about it,|
|

373
00:12:20,600 --> 00:12:21,680
0,480 570,750 750,840 840,960 960,1080
like you know they're going
就像在 mapreduce 中，有很多 worker ，

374
00:12:21,680 --> 00:12:23,330
0,60 60,180 180,390 390,1020 1050,1650
to be many worker, like

375
00:12:23,330 --> 00:12:25,040
0,120 120,390 390,960 1290,1620 1620,1710
in {mapreduce -},| and the
|worker 在每个分区上工作，

376
00:12:25,040 --> 00:12:26,750
0,360 360,750 750,1110 1110,1230 1230,1710
workers work on each partition,|
|

377
00:12:27,940 --> 00:12:29,680
0,780 780,900 900,1020 1020,1230 1230,1740
basically, you know the scheduler
调度者会发送工作

378
00:12:29,680 --> 00:12:31,510
0,120 120,690 930,1290 1290,1770 1770,1830
will sent a job| you
|给每个 worker ，

379
00:12:31,510 --> 00:12:32,110
0,90 90,240 240,390 390,510 510,600
know to each of the

380
00:12:32,110 --> 00:12:35,110
0,660 750,1260 1260,1980 2010,2610 2610,3000
workers,| {} and a job
|作业是一个属于分区的任务，

381
00:12:35,110 --> 00:12:36,310
0,150 150,300 300,780 780,870 870,1200
is a task you know

382
00:12:36,340 --> 00:12:38,050
0,600 600,720 720,780 780,1140 1140,1710
pertains to a particular partition,|
|

383
00:12:38,230 --> 00:12:41,140
0,570 570,1290 1290,2130 2190,2700 2700,2910
{} and {} workers start
worker 开始获取一个任务，

384
00:12:41,140 --> 00:12:43,660
0,420 420,750 750,1890 2100,2400 2400,2520
working on {} get one

385
00:12:43,660 --> 00:12:44,650
0,90 90,210 210,630 630,720 720,990
of these tasks| and basically
|然后开始运行。

386
00:12:44,650 --> 00:12:45,340
0,270 270,450
start running.|
|

387
00:12:45,710 --> 00:12:47,180
0,240 240,390 390,540 540,1080 1080,1470
So you get parallelism between
所以，你可以在分区之间获得并行性，

388
00:12:47,180 --> 00:12:48,710
0,210 210,930 1140,1320 1320,1410 1410,1530
the partitions,| and you get
|你也会得到流水线中的各个阶段之间的并行性。

389
00:12:48,710 --> 00:12:50,180
0,540 540,840 840,900 900,1380 1380,1470
parallelism between the stages in

390
00:12:50,180 --> 00:12:51,060
0,60 60,570
the pipeline.|
|

391
00:12:52,580 --> 00:12:53,800
0,150 150,300 300,510 510,960
I see, thank you.|
我明白了，谢谢。|

392
00:12:55,550 --> 00:12:57,000
0,270 270,1110

393
00:12:57,220 --> 00:12:59,290
0,360 420,810 810,870 1050,1530 1680,2070
{What's,the}.| Sorry.| {Can,you} {hear,me}.| What's
是什么。|抱歉。|你能听见我说话吗？|lineage 和事务日志有什么不同，

394
00:12:59,290 --> 00:13:01,960
0,90 90,480 480,1350 1470,2340 2370,2670
the difference between lineage and

395
00:13:01,960 --> 00:13:03,760
0,150 150,660 1020,1440 1440,1530 1530,1800
the like just the log

396
00:13:03,760 --> 00:13:04,930
0,60 60,720 720,810 810,960 960,1170
of transactions,| that we've seen
|我们之前看到的，

397
00:13:04,930 --> 00:13:05,920
0,420 420,570 570,660 660,750 750,990
before,| like is it just
|它是否只是操作的粒度？

398
00:13:05,920 --> 00:13:08,260
0,180 180,810 810,960 960,1440 1470,2340
the granularity of the operations?|
|

399
00:13:09,000 --> 00:13:11,310
0,390 390,510 510,930 930,1890 1890,2310
As we see, lineage, log
正如我们看到的，日志是严格的线性的，

400
00:13:11,310 --> 00:13:13,290
0,120 120,600 600,1110 1170,1620 1620,1980
is strictly linear, right,| and
|到目前为止我们看到的例子，

401
00:13:13,290 --> 00:13:14,160
0,60 60,480 480,570 570,720 720,870
the examples that we've seen

402
00:13:14,160 --> 00:13:17,250
0,180 180,510 510,1350 2220,2970 2970,3090
so far,| the lineage is
|lineage 也是线性的，

403
00:13:17,250 --> 00:13:18,240
0,210 210,570 570,720 720,840 840,990
also linear,| but we'll see
|但我们稍后会看到使用 fork 的例子，

404
00:13:18,240 --> 00:13:20,610
0,300 300,750 750,1200 1320,1740 1740,2370
later examples where with forks,|
|

405
00:13:21,200 --> 00:13:23,090
0,450 450,780 780,1050 1050,1470 1470,1890
{} where one stage depends
其中一个阶段依赖于多个不同的 RDD ，

406
00:13:23,090 --> 00:13:26,870
0,120 120,930 1020,2520 2640,3150 3150,3780
on multiple {} different RDDs,|
|

407
00:13:26,870 --> 00:13:27,980
0,330 330,450 450,540 540,900 900,1110
and you know that's not
这在日志中不具有代表性。

408
00:13:27,980 --> 00:13:29,820
0,600 600,660 660,780 780,1200
representative in the log.|
|

409
00:13:31,350 --> 00:13:32,610
0,480 510,660 660,750 750,960 960,1260
{} You know there share
它们有一些相似之处，

410
00:13:32,610 --> 00:13:33,810
0,150 150,780 780,840 840,900 900,1200
some similarities in the sense,|
|

411
00:13:33,810 --> 00:13:35,010
0,210 210,360 360,450 450,810 810,1200
that like you're starting the
比如你从开始状态开始，

412
00:13:35,100 --> 00:13:37,020
0,690 690,1170 1170,1290 1290,1380 1380,1920
beginning state,| all the operations
|所有的操作都是确定性的，

413
00:13:37,020 --> 00:13:38,520
0,90 90,1020 1020,1140 1140,1320 1320,1500
are deterministic,| and then you'll
|然后，你会得到，

414
00:13:38,520 --> 00:13:39,900
0,210 210,480 480,660 660,1020 1140,1380
end up in some,| if
|如果你应用所有这些操作，

415
00:13:39,900 --> 00:13:41,100
0,90 90,390 390,540 540,690 690,1200
you apply all those operations,|
|

416
00:13:41,100 --> 00:13:43,320
0,120 120,330 330,450 450,810 1560,2220
will end in some deterministic
将得到某种确定性的结束状态，

417
00:13:43,320 --> 00:13:45,180
0,390 390,720 1050,1380 1380,1680 1680,1860
end state,| {} so in
|所以在这个意义上，有一些相似之处，

418
00:13:45,180 --> 00:13:46,800
0,210 210,480 480,870 870,1020 1020,1620
that sense, there's some similarity,|
|

419
00:13:46,800 --> 00:13:48,480
0,180 180,540 540,660 660,1530 1530,1680
but {you,know} I think they're
但是，我觉得它们很不一样。

420
00:13:48,480 --> 00:13:49,400
0,360 360,750
quite different.|
|

421
00:13:51,870 --> 00:13:52,830
0,300 300,510 510,750 750,870 870,960
{} I also have a
我也有一个问题，

422
00:13:52,830 --> 00:13:55,860
0,570 570,720 720,780 1050,2250 2400,3030
question,| in this {case,filter} {},|
|在这个 filter 的例子中，|

423
00:13:56,910 --> 00:13:58,440
0,270 270,570 570,960 960,1230 1230,1530
so it works by just
它只需在每个分区上应用 filter ，

424
00:13:58,440 --> 00:14:00,030
0,420 420,750 750,900 900,1050 1050,1590
applying filter on each partition,|
|

425
00:14:00,030 --> 00:14:01,320
0,180 180,780 780,990 990,1110 1110,1290
but sometimes, like I see
但有时，比如我看到 transformation 也包含 join 或 sort 。

426
00:14:01,320 --> 00:14:03,480
0,120 120,900 900,1200 1200,1680 1680,2160
the transformation also contain join

427
00:14:03,510 --> 00:14:07,960
0,210 210,660 660,2430
or sort.| {Yeah\,,let's,talk,about,a,little,bit\,,I,will,talk,about,sort,and,join,in,a,second},|
|好的，让我们稍微谈一下，我稍后会谈到 sort 和 join ，|

428
00:14:09,700 --> 00:14:12,520
0,420 420,690 690,840 840,1140 2040,2820
they're clearly much more complicated.|
它们显然要复杂得多。|

429
00:14:13,620 --> 00:14:15,450
0,450 450,930 960,1230 1230,1440 1440,1830
So is, {} do we,
所以，这个 persist 是不是我们开始计算的时候？

430
00:14:15,450 --> 00:14:17,220
0,180 180,480 510,840 840,1590 1590,1770
but like this persist is

431
00:14:17,220 --> 00:14:20,490
0,390 390,600 600,1140 1140,2070 2310,3270
when we start computing?| No,
|不，没有东西计算出来，仍然是所有的描述，

432
00:14:20,490 --> 00:14:21,690
0,330 330,450 450,570 570,900 900,1200
nothing has been computed yet,

433
00:14:21,690 --> 00:14:23,160
0,390 390,660 660,1140 1140,1290 1290,1470
still all descriptions,| so let's
|让我们进一步讨论一下。

434
00:14:23,160 --> 00:14:24,000
0,180 180,210 210,360 360,480 480,840
talk a little bit further.|
|

435
00:14:24,880 --> 00:14:26,890
0,660 690,1260 1260,1560 1560,1710 1710,2010
{} Let's look at actually
让我们来看看产生计算的东西。

436
00:14:26,890 --> 00:14:28,420
0,330 330,510 510,720 720,1350 1350,1530
something that actually generates the

437
00:14:28,420 --> 00:14:29,580
0,750
computation.|
|

438
00:14:29,920 --> 00:14:31,740
0,660 690,1560

439
00:14:32,730 --> 00:14:34,530
0,150 150,420 420,510 510,1050 1050,1800
So, here are two commands
所以，这是两个导致计算的命令，

440
00:14:35,010 --> 00:14:37,440
0,510 510,810 810,1110 1110,1710 1710,2430
{} that actually result in

441
00:14:37,470 --> 00:14:39,990
0,450 480,1260 1260,1500 1500,1980 1980,2520
{} computation,| so this command
|所以这个命令将导致计算，

442
00:14:39,990 --> 00:14:41,370
0,180 180,540 540,600 600,1110 1110,1380
will result in computation,| because
|因为它包含 count ，这是一个操作，

443
00:14:41,370 --> 00:14:43,230
0,120 120,630 630,1140 1560,1770 1770,1860
it contains count, which is

444
00:14:43,230 --> 00:14:45,180
0,90 90,690 840,1110 1110,1560 1620,1950
an action,| and this command
|这个命令将导致计算， collect 是一个操作。

445
00:14:45,180 --> 00:14:47,040
0,300 300,720 720,810 810,930 930,1860
will result in a computation,

446
00:14:47,040 --> 00:14:48,460
0,420 450,630 630,750 750,1200
collect is an action.|
|

447
00:14:50,210 --> 00:14:53,420
0,210 210,780 870,2700 2700,3000 3000,3210
And so yeah and so
所以你可以，

448
00:14:53,420 --> 00:14:55,790
0,390 390,720 1140,1350 1350,1770 1770,2370
you can,| so we look
|所以我们看，

449
00:14:55,790 --> 00:14:57,110
0,330 330,450 450,870 870,1170 1170,1320
like,| so the reason that
|所以它们显示两个命令的原因，

450
00:14:57,110 --> 00:14:58,220
0,90 90,270 270,390 390,810 810,1110
they show two commands,| because
|因为它们证明了你可以重复使用 errors ，

451
00:14:58,220 --> 00:14:59,450
0,60 60,600 600,690 690,1110 1110,1230
they demonstrate that basically you

452
00:14:59,450 --> 00:15:01,820
0,150 150,570 570,1050 1350,2070 2130,2370
can reuse errors,| {} and
|所以，如果你看一下这个计算，

453
00:15:01,820 --> 00:15:02,600
0,150 150,240 240,330 330,540 540,780
so if you look at

454
00:15:02,660 --> 00:15:06,110
0,180 180,330 330,960 1200,2730 3060,3450
you know this computation,| {you,know}
|然后你可以画出谱系图，

455
00:15:06,110 --> 00:15:07,280
0,300 300,420 420,510 510,690 690,1170
then you can draw the

456
00:15:07,310 --> 00:15:10,070
0,510 510,1230 1290,1620 1620,2130 2160,2760
lineage graph, right,| so start
|开始是 lines ，

457
00:15:10,070 --> 00:15:11,620
0,180 180,870
with lines,|
|

458
00:15:12,510 --> 00:15:15,180
0,630 870,1110 1110,1170 1170,1890 2490,2670
{} {there,was} a filter that
我们运行了一个 filter ，

459
00:15:15,180 --> 00:15:16,320
0,150 150,690
we ran,|
|

460
00:15:18,450 --> 00:15:20,430
0,750 750,1110 1170,1560 1590,1740 1740,1980
{} oops, sorry,| let me
糟糕，抱歉，|让我写的稍微不同一点，

461
00:15:20,430 --> 00:15:22,170
0,270 540,840 840,1170 1170,1620 1620,1740
{write -} slightly differently,| there
|在 lines 上有一个 filter ，

462
00:15:22,170 --> 00:15:23,460
0,120 120,180 180,540 540,660 660,1290
was a filter on lines,|
|

463
00:15:24,260 --> 00:15:25,130
0,150 150,240 240,450 450,720 720,870
that we just saw that
我们看到产生 errors ，

464
00:15:25,130 --> 00:15:26,820
0,420 420,900
produces errors,|
|

465
00:15:28,630 --> 00:15:29,620
0,210 210,300 300,750 750,900 900,990
{or,that's} a description, how to
或者这是一种描述，如何获得 errors ，

466
00:15:29,620 --> 00:15:31,540
0,240 240,780 1080,1500 1500,1710 1710,1920
get errors,| {} then there's
|然后在这种情况下，还有另一个 filter ，

467
00:15:31,540 --> 00:15:33,070
0,330 360,720 720,1080 1080,1260 1260,1530
in this case, there's another

468
00:15:33,070 --> 00:15:34,140
0,600
filter,|
|

469
00:15:34,580 --> 00:15:35,780
0,150 150,270 270,690 690,810 810,1200
it's the filter of {HDFS
它是 HDFS 的 filter ，

470
00:15:35,780 --> 00:15:36,680
0,600
-},|
|

471
00:15:37,400 --> 00:15:38,870
0,210 210,390 390,690 690,1080 1080,1470
and that basically produces another
这会产生另一个 RDD ，

472
00:15:38,870 --> 00:15:40,010
0,570 600,690 690,810 810,1020 1020,1140
RDD,| you know that {RDD
|RDD 在这里并没有明确的名称，

473
00:15:40,010 --> 00:15:41,390
0,240 240,330 330,480 480,1020 1020,1380
-} is not explicitly named

474
00:15:41,390 --> 00:15:43,250
0,420 630,1140 1140,1410 1410,1650 1650,1860
here,| {} but it does
|但它产生了另一个 RDD ，

475
00:15:43,250 --> 00:15:44,750
0,300 300,930 930,1050 1050,1380 1380,1500
produce another {RDD -},| so
|所以我打算把它叫做 HDFS ，

476
00:15:44,750 --> 00:15:45,470
0,90 90,240 240,390 390,450 450,720
I was going to call

477
00:15:45,470 --> 00:15:47,280
0,240 480,1020 1020,1530
it {hdfs -},|
|

478
00:15:47,750 --> 00:15:49,100
0,420 420,510 510,930 930,1200 1200,1350
because the filter on {HDFS
因为 filter 在 HDFS 上，

479
00:15:49,100 --> 00:15:49,900
0,540
-},|
|

480
00:15:50,210 --> 00:15:52,010
0,180 180,660 660,660 660,1140 1140,1800
and then {} we see
然后，我们看到有一个 map ，

481
00:15:52,040 --> 00:15:53,480
0,240 240,480 480,540 540,1140
{} there's a map,|
|

482
00:15:53,820 --> 00:15:54,930
0,210 210,390 390,510 510,900 900,1110
{} and that produces yet
这又产生了另一个 RDD ，

483
00:15:54,930 --> 00:15:57,150
0,390 390,510 510,1020 1050,2010 2010,2220
another {RDD -},| again this
|再次，这个 RDD 在这里没有名字，它是匿名的，

484
00:15:57,150 --> 00:15:58,230
0,360 360,600 600,810 810,1050 1050,1080
RDD doesn't really have a

485
00:15:58,230 --> 00:16:02,040
0,330 330,1080 1080,1500 1920,2730 3180,3810
name here, but {so,it's,anonymous}, {}|
|

486
00:16:02,070 --> 00:16:02,880
0,300 300,420 420,570 570,720 720,810
I'm just gonna give it
我要给它起个名字，就是 time ，

487
00:16:02,880 --> 00:16:04,520
0,30 30,480 480,780 810,1380
a name, that's time,|
|

488
00:16:05,760 --> 00:16:09,510
0,330 330,990 1140,1830 2040,2610 2610,3750
because basically {} splits the
因为把每一个行分为三部分，

489
00:16:09,540 --> 00:16:11,520
0,870 870,1110 1110,1320 1320,1500 1500,1980
{one,either} line into three pieces|
|

490
00:16:11,520 --> 00:16:12,930
0,270 270,660 660,930 930,1260 1260,1410
and grabs {the,third} piece out
从中拿出第三部分，

491
00:16:12,930 --> 00:16:13,950
0,60 60,240 240,540 540,660 660,1020
of that line| and that
|那正好就是 time ，

492
00:16:13,950 --> 00:16:15,150
0,360 360,450 450,600 600,690 690,1200
happens to be the time,|
|

493
00:16:15,740 --> 00:16:17,240
0,150 150,690 690,690 690,1440 1440,1500
and then, {} there's a
然后，有一个最后的操作，就是 collect ，

494
00:16:17,240 --> 00:16:21,080
0,720 1080,1200 1200,1620 1650,2460 3600,3840
final you know operation and

495
00:16:21,080 --> 00:16:23,150
0,210 210,840 1110,1320 1320,1590 1590,2070
that's collect,| {} which actually
|它统计所有的 time 出现的次数，

496
00:16:23,150 --> 00:16:25,070
0,360 360,690 720,1080 1080,1620 1650,1920
counts up {all,the}, the number

497
00:16:25,070 --> 00:16:26,120
0,60 60,300 300,510 510,720 720,1050
of times, that time actually

498
00:16:26,120 --> 00:16:27,170
0,510 540,720 720,780 780,990 990,1050
appears| or the number of
|或者在 time RDD 产生的条目的数量。

499
00:16:27,170 --> 00:16:28,490
0,330 330,690 690,780 780,1170 1170,1320
entries basically {} result of

500
00:16:28,490 --> 00:16:30,890
0,420 780,1080 1080,1260 1260,1710 1710,2400
the in the RDD produced,

501
00:16:31,190 --> 00:16:32,180
0,360 360,510 510,600 600,870 870,990
{} in the time {RDD

502
00:16:32,180 --> 00:16:32,800
0,420
-}.|
|

503
00:16:33,470 --> 00:16:36,140
0,600 930,1350 1380,2040 2340,2520 2520,2670
Okay?| So this, so this
好的?|所以这就是这一点，

504
00:16:36,140 --> 00:16:37,820
0,120 120,750 750,990 990,1410 1410,1680
is actually this point,| when
|在这里返回，

505
00:16:37,820 --> 00:16:39,800
0,120 120,300 300,930 1260,1890 1890,1980
you know the return {

506
00:16:39,800 --> 00:16:40,700
0,180 180,510 510,750 750,840 840,900
-} return here,| in the
|在用户界面或交互用户界面中，

507
00:16:40,700 --> 00:16:41,870
0,330 330,840 840,1110 1110,1170 1170,1170
user interface or in the

508
00:16:43,310 --> 00:16:45,800
0,630 660,1320 1320,1710 1950,2250 2250,2490
interactive user interface {} it

509
00:16:45,800 --> 00:16:47,240
0,180 180,600 720,840 840,1080 1080,1440
is,| and at that point,|
|在这一点上，|

510
00:16:47,240 --> 00:16:50,360
0,690 870,1350 1350,2130 2160,2310 2310,3120
basically {} Spark {you,know} will
Spark 会收集很多 worker ，

511
00:16:50,840 --> 00:16:52,280
0,540 540,600 600,720 720,1200 1200,1440
collect you know a lot

512
00:16:52,280 --> 00:16:53,570
0,90 90,360 360,540 540,630 630,1290
of a set of workers,|
|

513
00:16:53,870 --> 00:16:55,850
0,600 600,1140 1140,1290 1290,1470 1470,1980
{} split you know send
给它们发送工作，

514
00:16:55,850 --> 00:16:57,620
0,300 300,420 420,990 990,1260 1260,1770
them the jobs,| or basically
|或者通知调度器需要执行作业，

515
00:16:57,620 --> 00:17:00,230
0,420 420,1020 1020,1560 1620,2430 2430,2610
{inform,the} scheduler {} {that,job} needs

516
00:17:00,230 --> 00:17:02,450
0,90 90,210 210,930 1200,1680 1680,2220
to be executed,| {} and
|这个谱系图中需要执行的任务的描述。

517
00:17:02,450 --> 00:17:03,800
0,90 90,720 720,930 930,1020 1020,1350
the description of the task

518
00:17:03,800 --> 00:17:05,120
0,120 120,300 300,360 360,510 510,1320
that needs to be executed

519
00:17:05,120 --> 00:17:06,260
0,300 300,660 660,1080
this lineage graph.|
|

520
00:17:13,400 --> 00:17:14,210
0,150 150,300 300,450 450,660 660,810
And so we can sort
所以我们可以稍微思考一下是如何执行的，

521
00:17:14,210 --> 00:17:14,840
0,60 60,240 240,300 300,480 480,630
of think a little bit

522
00:17:14,840 --> 00:17:16,160
0,240 240,600 600,780 780,870 870,1320
about exactly how the execution

523
00:17:16,160 --> 00:17:17,120
0,390 390,570 570,690 690,750 750,960
happens,| so let me draw
|所以让我画一张图，

524
00:17:17,120 --> 00:17:18,400
0,90 90,600
a picture,|
|

525
00:17:22,190 --> 00:17:23,540
0,210 210,300 300,840 840,1260 1260,1350
so the {picture,as} follows,| we
图片如下所示，|这就是所谓的驱动，这是很常见的事情，

526
00:17:23,540 --> 00:17:24,470
0,180 180,420 420,690 690,870 870,930
got there's what's called the

527
00:17:24,470 --> 00:17:25,820
0,420 420,630 630,720 720,1020 1020,1350
driver, that's the usual thing,|
|

528
00:17:26,790 --> 00:17:27,870
0,120 120,270 270,540 540,780 930,1080
you know {where -} the
用户输入的程序，

529
00:17:27,870 --> 00:17:29,100
0,420 420,540 540,630 630,930 930,1230
program that the user typed

530
00:17:29,100 --> 00:17:33,450
0,510 900,1590 1740,2310 2340,3060 3930,4350
into,| {} it {} start
|它从收集很多 worker ，很多机器开始，

531
00:17:33,450 --> 00:17:34,440
0,210 210,630 630,690 690,900 900,990
of collecting a bunch of

532
00:17:34,440 --> 00:17:36,390
0,630 1320,1560 1560,1680 1680,1890 1890,1950
workers, {you,know} a bunch of

533
00:17:36,390 --> 00:17:38,730
0,690 1410,1950 1950,2040 2040,2100 2100,2340
machines,| {almost -} the same
|几乎与 mapreduce 中的一样。

534
00:17:38,730 --> 00:17:40,440
0,210 210,420 420,630 630,990 1080,1710
way like as in {mapreduce

535
00:17:40,440 --> 00:17:41,360
0,720
-}.|
|

536
00:17:42,460 --> 00:17:44,020
0,810 840,990 990,1110 1110,1410 1410,1560
And you know there's gonna
这里会有 HDFS ，

537
00:17:44,020 --> 00:17:46,120
0,240 240,420 450,870 870,1320 1470,2100
be a {HDFS -},| there's
|lines 文件，

538
00:17:46,120 --> 00:17:48,280
0,600 810,1290 1290,1440 1440,1740 1740,2160
lines file,| that actually has
|有分区， P1 P2 之类，等等。

539
00:17:48,340 --> 00:17:50,470
0,630 630,810 810,990 990,1440 1440,2130
partitions are {P1 -}, P2

540
00:17:50,470 --> 00:17:51,560
0,660
whatever,

541
00:17:54,950 --> 00:17:56,840
0,810 840,1080 1080,1470 1470,1590 1590,1890
{blah,blah,blah}.| And typically the number
|通常分区的数量大于 worker 的数量，

542
00:17:56,840 --> 00:17:57,890
0,90 90,480 480,600 600,900 900,1050
of partitions is larger than

543
00:17:57,890 --> 00:17:59,660
0,60 60,270 270,330 330,960 1350,1770
the number of workers, {}|
|

544
00:17:59,660 --> 00:18:01,610
0,300 330,750 750,930 1530,1890 1890,1950
sorry, number of,| {yes\,,number} of
抱歉，数量，|是的，分区的数量大于 worker 的数量 ，

545
00:18:01,610 --> 00:18:02,600
0,390 390,480 480,810 810,930 930,990
partitions is larger than the

546
00:18:02,600 --> 00:18:04,460
0,210 210,270 270,630 630,1710 1710,1860
number of workers,| {you,know} get
|有负载平衡，

547
00:18:04,460 --> 00:18:06,680
0,270 270,840 1560,1800 1800,2070 2070,2220
load balance,| {} is like
|比如一个分区很小，而另一个分区很大，

548
00:18:06,680 --> 00:18:07,700
0,150 150,480 480,540 540,930 930,1020
one partition is small and

549
00:18:07,700 --> 00:18:08,600
0,60 60,210 210,330 330,420 420,900
the other one is big,|
|

550
00:18:08,630 --> 00:18:10,040
0,420 420,570 570,930 930,1080 1080,1410
and you {don't,want,to} have workers
你不想让 worker 无所事事。

551
00:18:10,040 --> 00:18:11,330
0,60 60,330 330,570 570,810 810,1290
are relying sitting around idle.|
|

552
00:18:11,940 --> 00:18:13,500
0,450 450,750 750,1110 1110,1200 1200,1560
{} And basically the {scheduler
基本上调度器，

553
00:18:13,500 --> 00:18:16,110
0,420 900,1050 1050,1680 2310,2550 2550,2610
-},| you know there's a
|有一个调度器运行计算，

554
00:18:16,110 --> 00:18:20,130
0,720 2580,3390 3390,3540 3540,3660 3660,4020
scheduler runs you know basically

555
00:18:20,130 --> 00:18:22,050
0,90 90,780 780,930 930,1140 1140,1920
the computation,| and it has
|它有谱系图的信息。

556
00:18:22,080 --> 00:18:23,280
0,150 150,810 810,900 900,1080 1080,1200
{you,know,the} information that has the

557
00:18:23,280 --> 00:18:24,660
0,360 360,930
lineage graphs.|
|

558
00:18:25,820 --> 00:18:26,840
0,180 180,360 360,570 570,660 660,1020
And so worker is basically
所以 worker 加入，

559
00:18:26,840 --> 00:18:28,100
0,210 210,660 750,840 840,1020 1020,1260
check in,| you know the
|driver 分发代码， Spark 程序，

560
00:18:28,130 --> 00:18:30,500
0,510 510,1020 1020,1110 1110,1710
driver [exercising] the code,

561
00:18:31,260 --> 00:18:33,630
0,420 420,1110 1290,1470 1470,1680 1680,2370
Spark program,| and we just
|我们刚刚构建的，

562
00:18:33,630 --> 00:18:35,370
0,630 870,1080 1080,1170 1170,1470 1470,1740
constructed,| and the worker should
|worker 去找调度者，

563
00:18:35,370 --> 00:18:36,450
0,180 180,570 570,660 660,750 750,1080
go basically to the scheduler,|
|

564
00:18:36,450 --> 00:18:37,620
0,240 240,570 570,630 630,870 870,1170
say, please you know which
说，我应该在哪个分区工作。

565
00:18:37,620 --> 00:18:38,880
0,330 330,510 510,570 570,990
partition should I work.|
|

566
00:18:39,240 --> 00:18:41,490
0,750 750,1260 1260,1440 1440,1740 1740,2250
And, {} then they run
然后，它们作为流水线的一部分运行，

567
00:18:41,640 --> 00:18:43,280
0,450 450,1320
{} basically

568
00:18:43,610 --> 00:18:45,110
0,540 540,690 690,1080 1080,1320 1320,1500
{ -} part of the

569
00:18:45,110 --> 00:18:46,080
0,750
pipeline,|
|

570
00:18:46,780 --> 00:18:47,590
0,270 270,420 420,540 540,720 720,810
and so we look at
所以我们看看这个，

571
00:18:47,590 --> 00:18:48,610
0,300 300,420 420,540 540,810 810,1020
this,| let me actually draw
|让我把这个画得稍有不同，

572
00:18:48,610 --> 00:18:49,660
0,150 150,480 480,750 750,930 930,1050
this slightly different,| {so,I,have} a
|所以我在这里有更多的空间。

573
00:18:49,660 --> 00:18:50,830
0,210 210,330 330,450 450,780 780,1170
little bit more space here.|
|

574
00:18:51,070 --> 00:18:52,060
0,570

575
00:18:52,600 --> 00:18:53,380
0,150 150,270 270,540 540,690 690,780
So we saw there was
所以我们看到有很多阶段，

576
00:18:53,380 --> 00:18:54,580
0,30 30,150 150,390 390,510 510,1200
a whole bunch of stages,|
|

577
00:18:54,970 --> 00:18:56,020
0,180 180,360 360,450 450,750 750,1050
and then the last stage
然后最后一个阶段是，

578
00:18:56,020 --> 00:18:59,110
0,780 1230,2040 2070,2580 2580,2940 2940,3090
was,| the last operate was
|最后一个操作是 collect 阶段。

579
00:18:59,110 --> 00:19:01,120
0,90 90,450 450,1200
to collect stage.|
|

580
00:19:02,560 --> 00:19:05,080
0,870 870,1080 1080,1710 1770,2460 2460,2520
So in this {}, in
所以在我们刚才看到的这个场景中，

581
00:19:05,380 --> 00:19:07,480
0,690 780,1410 1410,1440 1440,1980 1980,2100
this { -} scenario that

582
00:19:07,480 --> 00:19:08,860
0,120 120,360 360,570 570,870 960,1380
we just looked at,| the
|collect 阶段当然需要从所有分区收集数据，

583
00:19:08,860 --> 00:19:09,970
0,300 300,510 510,600 600,900 900,1110
collect stage, of course, needs

584
00:19:09,970 --> 00:19:12,820
0,120 120,840 840,1290 1290,1980 1980,2850
to collect data from {}

585
00:19:13,000 --> 00:19:14,980
0,480 480,1110 1140,1410 1410,1800 1800,1980
{all,the} partitions, right,| so in
|所以原则上，

586
00:19:15,220 --> 00:19:17,440
0,720 900,1200 1200,1530 1530,2160 2190,2220
principle,| {you,know} let's draw a
|我们画一条绿线，

587
00:19:17,470 --> 00:19:19,570
0,360 360,840 1050,1680 1680,2010 2010,2100
green line,| basically everything of
|基本上这一切，

588
00:19:19,570 --> 00:19:20,240
0,570
this,|
|

589
00:19:20,600 --> 00:19:22,190
0,150 150,450 450,1110 1110,1500 1500,1590
it was executed on an
都是在一个独立的分区上执行的，

590
00:19:22,190 --> 00:19:23,820
0,660 660,1320
independent partition,|
|

591
00:19:24,100 --> 00:19:25,930
0,360 360,570 570,1260 1350,1680 1680,1830
so every worker gets one
所以每个 worker 会从调度器得到这些任务中的一个，

592
00:19:25,930 --> 00:19:27,490
0,60 60,240 240,840 840,1260 1260,1560
of these tasks from the

593
00:19:27,490 --> 00:19:30,010
0,660 690,1350 1350,1470 1470,1650 1650,2520
scheduler,| runs you know the
|运行东西，

594
00:19:30,100 --> 00:19:31,960
0,480 480,630 630,1260 1260,1560 1560,1860
thing| and produces in the
|最后产生一个 time RDD ，

595
00:19:31,960 --> 00:19:34,500
0,390 420,870 870,1320 1650,2310
end {} a time

596
00:19:35,290 --> 00:19:36,760
0,360 360,540 540,720 720,1110
{} {RDD - -},|
|

597
00:19:37,270 --> 00:19:38,830
0,660 780,1050 1050,1260 1260,1320 1320,1560
and {} when the {scheduler
当调度者确定所有 time ，

598
00:19:38,830 --> 00:19:40,750
0,150 150,600 600,690 690,1260 1290,1920
- -} you know determines

599
00:19:40,750 --> 00:19:43,420
0,150 150,570 600,1290 1290,1740 1860,2670
that basically all the time,|
|

600
00:19:43,660 --> 00:19:44,620
0,300 300,390 390,540 540,750 750,960
you know like all these
所有这些阶段，

601
00:19:44,620 --> 00:19:45,700
0,540 540,720 720,810 810,1020 1020,1080
stages,| this is called the
|这被称为阶段，

602
00:19:45,700 --> 00:19:46,740
0,570
stage,|
|

603
00:19:48,080 --> 00:19:49,250
0,360 360,600 600,660 660,990 990,1170
if all the stages have
如果所有阶段都已完成，

604
00:19:49,250 --> 00:19:50,690
0,630 660,870 870,1050 1050,1260 1260,1440
completed,| and so all the
|所有区间产生了 time ，

605
00:19:50,690 --> 00:19:52,160
0,600 600,780 780,1170 1170,1320 1320,1470
time {} partitions have been

606
00:19:52,160 --> 00:19:54,350
0,690 810,1560 1560,1680 1680,2040 2040,2190
produced,| then it actually will
|然后它会运行 collect 操作做加法，

607
00:19:54,350 --> 00:19:56,270
0,540 690,840 840,990 990,1320 1350,1920
run you know the collect

608
00:19:56,270 --> 00:19:57,980
0,600 780,1020 1020,1200 1200,1560 1560,1710
action {} to basically do

609
00:19:57,980 --> 00:20:01,070
0,180 180,720 960,1470 1530,2370 2370,3090
the addition| and retrieve information
|从每个分区获取信息，

610
00:20:01,070 --> 00:20:03,410
0,420 420,810 810,1410 1620,1890 1890,2340
from every partition,| {} to
|用来计算 collect ，

611
00:20:03,410 --> 00:20:05,600
0,390 390,750 750,1440 1470,1920 1920,2190
actually compute the collect,| or
|这不是 collect ，

612
00:20:05,660 --> 00:20:07,370
0,570 660,1050 1050,1170 1170,1380 1380,1710
actually this is not collect,|
|

613
00:20:07,370 --> 00:20:08,580
0,180 180,450 450,1020
it was {a,count},
这是 count ，很抱歉。

614
00:20:10,710 --> 00:20:12,480
0,270 270,420 420,810
sorry about that.|
|

615
00:20:15,500 --> 00:20:17,300
0,300 300,720 750,1170 1170,1650 1650,1800
And so {} one sort
所以，思考这个问题的一种方式是，

616
00:20:17,300 --> 00:20:18,140
0,60 60,330 330,420 420,600 600,840
of way to think about

617
00:20:18,140 --> 00:20:18,950
0,180 180,300 300,510 510,720 720,810
this is,| that this is
|这有点像 mapreduce ，

618
00:20:18,950 --> 00:20:20,840
0,180 180,270 270,900 1080,1560 1560,1890
sort of like {} almost

619
00:20:20,840 --> 00:20:22,040
0,150 150,180 180,390 390,840 840,1200
like a {mapreduce -},| where
|其中有 map 阶段，

620
00:20:22,040 --> 00:20:22,970
0,120 120,240 240,300 300,570 570,930
you have the map phase,|
|

621
00:20:22,970 --> 00:20:24,410
0,90 90,540 720,900 900,1110 1110,1440
and then you have a
然后你有 shuffle ，

622
00:20:24,410 --> 00:20:26,000
0,660 810,1200 1200,1320 1320,1440 1440,1590
shuffle,| and then you run
|然后运行 reduce 阶段，

623
00:20:26,000 --> 00:20:28,340
0,120 120,450 450,960 960,1470 1650,2340
the reduce phase,| and {}
|而 count 在这种方式上几乎是一样的，

624
00:20:28,400 --> 00:20:30,680
0,540 540,630 630,1140 1170,1560 1560,2280
{the,count} is almost {} similar

625
00:20:30,770 --> 00:20:32,630
0,270 270,420 420,660 660,1290 1410,1860
{} in that fashion,| and
|在论文中，他们提到这一点的方式是，

626
00:20:32,630 --> 00:20:33,650
0,450 450,540 540,780 780,870 870,1020
in the paper, the way

627
00:20:33,650 --> 00:20:34,670
0,90 90,420 420,540 540,780 780,1020
they refer to this is,|
|

628
00:20:34,790 --> 00:20:37,100
0,330 330,1140 1380,1800 1800,2010 2010,2310
this dependency, {they,call} this a
这个依赖关系称为宽依赖，

629
00:20:37,100 --> 00:20:40,190
0,450 450,1230 2130,2520 2520,2640 2640,3090
wide dependency,| because the action
|因为 action 或 transformation 依赖多个分区，

630
00:20:40,190 --> 00:20:41,900
0,180 180,270 270,900 900,990 990,1710
or the transformation is dependent

631
00:20:41,960 --> 00:20:44,090
0,660 660,750 750,1260 1260,1380 1380,2130
on a number of partitions,|
|

632
00:20:44,540 --> 00:20:46,190
0,600 600,840 840,960 960,1260 1260,1650
and these are called narrow
这些称为窄依赖，

633
00:20:46,190 --> 00:20:46,820
0,480
{},

634
00:20:47,120 --> 00:20:50,160
0,270 270,390 390,1350 1620,2490
{narrow -} dependencies,| because,
|因为这个 RDD ，

635
00:20:51,290 --> 00:20:53,990
0,570 930,1800 1830,2070 2070,2520 2550,2700
this {} {RDD -} {},|
|

636
00:20:53,990 --> 00:20:55,100
0,210 210,510 510,720 720,810 810,1110
to make that {RDD -}
为了制作这个 RDD ，只依赖于另一个，

637
00:20:55,100 --> 00:20:56,450
0,90 90,360 360,930 930,1080 1080,1350
is only dependent on one

638
00:20:56,450 --> 00:20:58,910
0,570 870,1230 1230,1590 1590,2130 2130,2460
another,| {} only {at,the}, only
|只依赖于父分区，

639
00:20:58,910 --> 00:21:00,890
0,360 360,450 450,510 510,1200 1500,1980
dependent on the parent {}

640
00:21:00,890 --> 00:21:03,260
0,690 780,1200 1200,1470 1470,1800 1800,2370
partition,| only one parent partition
|只需一个父分区就能计算它。

641
00:21:03,470 --> 00:21:04,220
0,210 210,420 420,540 540,690 690,750
to actually be able to

642
00:21:04,220 --> 00:21:04,920
0,300 300,510
compute it.|
|

643
00:21:05,970 --> 00:21:07,710
0,420 510,1170 1170,1500 1500,1620 1620,1740
So generally you you would
一般来说，你会希望计算有窄依赖，

644
00:21:07,710 --> 00:21:09,300
0,330 330,420 420,1050 1170,1350 1350,1590
prefer {} computation have narrow

645
00:21:09,300 --> 00:21:10,650
0,720 720,960 960,1080 1080,1230 1230,1350
dependencies,| because they can just
|因为它们可以在没有任何通信的情况下在本地运行，

646
00:21:10,650 --> 00:21:12,600
0,240 240,690 690,1020 1020,1200 1200,1950
run locally without any communication,|
|

647
00:21:12,960 --> 00:21:14,910
0,510 510,810 810,1560 1590,1770 1770,1950
before wide dependency, you might
在宽依赖之前，你可能需要 collect ，

648
00:21:14,910 --> 00:21:17,010
0,120 120,210 210,750 780,2070 2070,2100
have to collect, { -}|
|

649
00:21:17,010 --> 00:21:18,270
0,480 480,630 630,720 720,780 780,1260
you might have to collect
你可能需要从父分区收集，

650
00:21:18,300 --> 00:21:20,670
0,540 630,1350 1350,1800 1800,1950 1950,2370
{} partitions from the parent,|
|

651
00:21:20,670 --> 00:21:21,210
0,90 90,210 210,330 330,480 480,540
or you may have to
或者你可能必须从所有机器的父 RDD 收集分区。

652
00:21:21,210 --> 00:21:22,800
0,420 420,810 810,1020 1020,1110 1110,1590
collect partitions from the parent

653
00:21:22,920 --> 00:21:25,350
0,690 720,990 990,1560 1740,1860 1860,2430
RDD from all the machines.|
|

654
00:21:25,840 --> 00:21:29,080
0,420 690,1530 1560,2370 2400,2640 2640,3240
{} Professor.| Yeah.| I had
教授。|嗯。|我有个问题，

655
00:21:29,080 --> 00:21:31,270
0,60 60,540 540,1140 1500,2010 2010,2190
a question,| so {} in
|所以在论文中，它说窄依赖，

656
00:21:31,270 --> 00:21:33,910
0,120 120,900 1290,1500 1500,2190 2220,2640
the paper, it says narrow

657
00:21:33,910 --> 00:21:37,540
0,990 1560,2040 2070,2340 2340,3150 3300,3630
dependencies,| where each partition of
|父 RDD 的每个分区，

658
00:21:37,540 --> 00:21:39,130
0,150 150,720 720,900 900,1080 1080,1590
the parent {RDD - -}|
|

659
00:21:39,490 --> 00:21:41,110
0,270 270,750 750,930 930,1080 1080,1620
is used by at most
用作最多是子 RDD 的一个分区，

660
00:21:41,110 --> 00:21:42,790
0,330 330,960 960,1110 1110,1230 1230,1680
one partition of the child

661
00:21:42,790 --> 00:21:45,520
0,150 150,660 1080,1770 1860,2640 2640,2730
{RDD -},| {} but it
|但它没有说任何关于控制的事情，

662
00:21:45,520 --> 00:21:47,620
0,270 270,600 600,1020 1020,1440 1440,2100
doesn't say anything about the

663
00:21:47,740 --> 00:21:48,960
0,210 210,990
the control,|
|

664
00:21:49,300 --> 00:21:51,430
0,150 150,510 510,690 690,1500 1950,2130
the [] is like,| it
比如，|它没有说子分区最多只使用一个父分区。

665
00:21:51,430 --> 00:21:53,710
0,270 270,960 1230,1530 1530,1860 1860,2280
doesn't say like a child

666
00:21:53,710 --> 00:21:55,060
0,540 540,810 810,900 900,1230 1230,1350
partition needs to use at

667
00:21:55,060 --> 00:21:57,300
0,750 1050,1980
most one,

668
00:21:58,000 --> 00:22:01,180
0,600 990,1410 1410,2280 2550,3060 3060,3180
{} one parent.| {} Yeah,
|是的，没错，因为。

669
00:22:01,180 --> 00:22:03,280
0,210 210,450 450,660 660,1110 1110,2100
that's correct, because then.| Yeah,
|是的，如果一个子分区使用多个父分区，

670
00:22:03,280 --> 00:22:04,930
0,180 180,600 600,960 960,1200 1200,1650
if a child uses multiple

671
00:22:04,930 --> 00:22:06,070
0,360 360,750 750,930 930,1080 1080,1140
parent partition,| then it's a
|那么它就是一个宽依赖。

672
00:22:06,070 --> 00:22:07,260
0,390 390,990
wide dependency.|
|

673
00:22:08,310 --> 00:22:11,160
0,180 180,330 330,750 870,1410 1890,2850
If a parent, sorry.| If,
如果一个父分区，抱歉。|如果子分区使用分区，

674
00:22:11,730 --> 00:22:14,100
0,330 330,630 660,1320 1440,1770 1770,2370
if the child meets the

675
00:22:14,190 --> 00:22:16,440
0,600 600,990 1020,1290 1290,1620 1620,2250
partition,| if the partition for
|如果多个父分区，

676
00:22:16,470 --> 00:22:18,780
0,390 390,690 690,1350 1560,2070 2070,2310
multiple parent partitions,| then it's
|那么它就是一个宽依赖。

677
00:22:18,780 --> 00:22:20,260
0,180 180,630 630,1200
a wide dependency.|
|

678
00:22:20,750 --> 00:22:22,430
0,570 1050,1230 1230,1290 1290,1620 1620,1680
{} So, for example in
例如在 count 的情况下，

679
00:22:22,430 --> 00:22:23,960
0,90 90,390 390,630 630,1050 1080,1530
the count case, correct,| {you,know,you}
|你有 time 分区。

680
00:22:23,960 --> 00:22:28,580
0,750 1350,2250 2820,3630 3630,4350
have time, time partitions.|
|

681
00:22:29,100 --> 00:22:29,940
0,480
Right.|
是的。|

682
00:22:30,770 --> 00:22:33,170
0,420 420,480 480,990 1020,1860 2190,2400
And the count operation is
count 操作将收集所有来自它们的数据。

683
00:22:33,170 --> 00:22:34,520
0,120 120,180 180,720 750,1200 1200,1350
going to collect {you,know,data} from

684
00:22:34,520 --> 00:22:37,010
0,180 180,240 240,510 1200,1860 2280,2490
all of them.| Right.| So
|是的。|所以如果 count RDD ，

685
00:22:37,010 --> 00:22:37,970
0,240 240,600 600,780 780,870 870,960
if count where at {RDD

686
00:22:37,970 --> 00:22:40,160
0,600 1140,1350 1350,1710 1710,2040 2040,2190
-},| it isn't like, it's
|它不是，这只是一个 action ，

687
00:22:40,160 --> 00:22:41,480
0,210 210,270 270,780 930,1110 1110,1320
just an action,| but even
|但即使是我们在 RDD ，

688
00:22:41,480 --> 00:22:42,410
0,150 150,240 240,330 330,690 690,930
we're in {RDD -},| then
|那么这将需要与所有的父分区交互。

689
00:22:42,410 --> 00:22:43,610
0,540 540,660 660,810 810,1020 1020,1200
basically you know that would

690
00:22:43,610 --> 00:22:45,590
0,840 930,1170 1170,1710 1710,1860 1860,1980
require {} interaction with all

691
00:22:45,590 --> 00:22:46,320
0,90 90,630
the parents.|
|

692
00:22:46,780 --> 00:22:48,220
0,300 300,870 870,960 960,1320 1320,1440
{} What I'm saying is,|
我的意思是，|

693
00:22:48,220 --> 00:22:49,240
0,120 120,510 570,720 720,900 900,1020
I think I think it's
我想恰恰相反，

694
00:22:49,240 --> 00:22:51,840
0,210 210,360 360,1170 1620,2280
just the opposite, right,|
|

695
00:22:52,020 --> 00:22:53,910
0,480 690,870 870,1110 1110,1380 1380,1890
I I think this might
我想这可能像是，

696
00:22:53,940 --> 00:22:54,920
0,660
like,|
|

697
00:22:55,600 --> 00:22:57,160
0,150 150,570 570,900 900,1230 1260,1560
I mean I I I
我是说，我真的很困惑，

698
00:22:57,160 --> 00:22:59,560
0,600 600,750 750,1080 1080,1710 1830,2400
I was actually confused, {}|
|

699
00:23:00,700 --> 00:23:02,470
0,390 570,810 810,900 900,1500 1530,1770
like with the paper, on
在论文中，在这个特定的问题上，

700
00:23:02,470 --> 00:23:04,750
0,210 210,990 990,1410 1410,1770 1950,2280
this specific issue,| but as
|但正如上面所说，

701
00:23:04,750 --> 00:23:07,570
0,210 210,870 930,1440 1860,2280 2280,2820
it says,| like each partition
|父 RDD 的每个分区至多由一个子分区使用，

702
00:23:07,570 --> 00:23:08,890
0,120 120,210 210,750 750,1200 1200,1320
of the parent RDD is

703
00:23:08,890 --> 00:23:09,910
0,240 240,330 330,510 510,810 810,1020
used by at most one

704
00:23:09,910 --> 00:23:12,940
0,570 570,690 690,840 840,1560 2850,3030
partition of the child,| but
|但它没有说子分区使用最多。

705
00:23:12,940 --> 00:23:15,040
0,120 120,360 360,930 1200,1620 1620,2100
it doesn't say one partition

706
00:23:15,040 --> 00:23:16,030
0,60 60,180 180,600 600,870 870,990
of the child uses it

707
00:23:16,030 --> 00:23:19,270
0,540 1890,2220 2220,2490 2520,2850 2850,3240
most.| {I'm,not} {actually -} sure
|我不确定你为什么会对此感到困惑，

708
00:23:19,300 --> 00:23:21,100
0,90 90,360 450,1230 1230,1590 1590,1800
you know exactly why you're

709
00:23:21,100 --> 00:23:22,150
0,420 420,510 510,690 690,870 870,1050
confused with this,| so let
|所以，我们可以推迟这件事，然后回来讨论它。

710
00:23:22,150 --> 00:23:23,380
0,630 630,690 870,990 990,1110 1110,1230
me know when we can

711
00:23:23,380 --> 00:23:24,400
0,420 420,600 600,720 720,810 810,1020
postpone this and come back

712
00:23:24,400 --> 00:23:25,420
0,120 120,690
to it.|
|

713
00:23:25,740 --> 00:23:27,780
0,690 690,1380 1380,1560 1560,1740 1740,2040
Sure.| I think the {key,thing}
好的。|我认为关键的是观察到有两种依赖，

714
00:23:27,780 --> 00:23:29,190
0,480 480,900 900,1050 1050,1350 1350,1410
observes basically two types of

715
00:23:29,190 --> 00:23:30,660
0,480 480,810 810,1080 1080,1170 1170,1470
dependency,| wide ones and narrow
|宽的和窄的，

716
00:23:30,660 --> 00:23:32,760
0,480 750,1020 1020,1320 1320,1530 1530,2100
ones,| and wide ones basically
|宽的涉及到通信，

717
00:23:32,760 --> 00:23:34,770
0,90 90,390 420,1110 1110,1440 1440,2010
you know basically involve communication,|
|

718
00:23:34,770 --> 00:23:37,200
0,240 240,450 450,720 720,1170 1440,2430
because they have to {}
因为它们必须，

719
00:23:37,260 --> 00:23:40,620
0,510 510,750 750,1200 1560,2370 2700,3360
talk to the, { -}|
|

720
00:23:41,010 --> 00:23:42,510
0,420 420,630 630,1080 1080,1320 1320,1500
collect the information from the
从父分区收集信息。

721
00:23:42,510 --> 00:23:44,310
0,360 360,510 510,570 570,1080 1080,1800
{} from the parent partitions.|
|

722
00:23:45,990 --> 00:23:48,220
0,1050 1440,1920
Okay?| Thanks.|
好的?|谢谢。|

723
00:23:50,100 --> 00:23:51,030
0,120 120,390 390,540 540,600 600,930
I actually have a question
我有一个关于接口的问题，

724
00:23:51,030 --> 00:23:54,270
0,150 150,990 2250,2610 2610,2730 2730,3240
on interface,| like the previous
|在前面一两张幻灯片上，

725
00:23:54,270 --> 00:23:55,530
0,240 240,360 360,510 510,990 990,1260
one or two slides,| what
|如果我们不调用 errors.persist ，会发生什么？

726
00:23:55,530 --> 00:23:56,730
0,390 390,510 510,630 630,870 870,1200
happens, if we don't call

727
00:23:56,730 --> 00:23:58,480
0,270 270,720 750,1470
{errors.persist - -}?|
|

728
00:23:59,610 --> 00:24:01,560
0,1050 1050,1320 1320,1440 1440,1590 1590,1950
{} If you do not,
如果你没有，那么，

729
00:24:01,560 --> 00:24:04,590
0,540 540,540 1470,2340 2400,2760 2760,3030
then,| {} the you were
|第二个计算，

730
00:24:04,650 --> 00:24:07,170
0,210 210,480 480,1230 1440,1890 2100,2520
the second computation,| like this
|比如这个计算，将从头开始重新计算 errors ，

731
00:24:07,170 --> 00:24:09,000
0,810 1080,1290 1290,1440 1440,1770 1770,1830
computation would {re-compute -} {}

732
00:24:09,000 --> 00:24:09,800
0,570
errors

733
00:24:11,090 --> 00:24:12,220
0,270 270,330 330,810
from the beginning,|
|

734
00:24:12,530 --> 00:24:13,640
0,180 180,270 270,390 390,600 600,1110
so if you run this
如果你运行这个工作负载，

735
00:24:13,970 --> 00:24:15,640
0,420 420,1050
{workload -},|
|

736
00:24:15,850 --> 00:24:17,590
0,570 570,960 960,1050 1050,1140 1140,1740
{the,Spark -} you know computation
Spark 会重新计算 errors ，

737
00:24:17,590 --> 00:24:19,690
0,210 210,360 360,1020 1050,1650 1650,2100
would {re-compute -} {} errors,|
|

738
00:24:19,690 --> 00:24:21,220
0,90 90,240 240,840 870,1260 1260,1530
you know from a the
从开始文件开始。

739
00:24:21,220 --> 00:24:22,260
0,330 330,750
starting file.|
|

740
00:24:23,030 --> 00:24:24,320
0,270 270,450 450,660 660,960
Got it, thank you.|
知道了，谢谢。|

741
00:24:25,360 --> 00:24:26,620
0,390 390,690 690,810 810,1080 1080,1260
{} So I actually have
关于这一点，我有一个问题，

742
00:24:26,620 --> 00:24:28,510
0,90 90,600 600,1050 1080,1410 1410,1890
a question about this point,|
|

743
00:24:28,570 --> 00:24:30,430
0,390 390,840 840,1170 1170,1650 1650,1860
so for the partitions that
对于不调用 persist 的分区，

744
00:24:30,430 --> 00:24:32,290
0,90 90,510 510,960 960,1440 1440,1860
we don't call persist on,|
|

745
00:24:32,590 --> 00:24:33,940
0,390 390,540 540,600 600,840 840,1350
{} in the {mapreduce -}
在 mapreduce 的情况中，

746
00:24:33,940 --> 00:24:35,890
0,510 510,690 690,1260 1260,1560 1590,1950
case,| we basically {} stored
|我们把它们存储在中间文件中，

747
00:24:35,890 --> 00:24:37,930
0,210 210,330 330,810 810,1320 1350,2040
them in intermediate files,| but
|但我们仍然将它们存储在本地文件系统中，

748
00:24:37,930 --> 00:24:40,690
0,120 120,960 960,1290 1290,2250 2280,2760
we nonetheless stored them in

749
00:24:40,690 --> 00:24:42,880
0,510 720,1170 1170,1440 1440,1920 1950,2190
a local file system,| let's
|比如，在 mapreduce 的情况下，

750
00:24:42,880 --> 00:24:43,600
0,180 180,360 360,420 420,630 630,720
say in the case of

751
00:24:43,600 --> 00:24:45,190
0,180 180,570 750,1050 1050,1200 1200,1590
{mapreduce -},| do we actually
|我们在这里存储中间文件吗，

752
00:24:45,190 --> 00:24:47,800
0,810 1440,2010 2010,2310 2310,2460 2460,2610
store intermediate files here,| that
|我们不持久化在某些持久存储中，

753
00:24:47,800 --> 00:24:49,060
0,60 60,270 270,780 780,990 990,1260
we don't persist in some

754
00:24:49,060 --> 00:24:50,770
0,600 600,990 990,1140 1140,1440 1440,1710
persistent storage,| or we just
|或者我们只是将整个流保存在内存中？

755
00:24:50,770 --> 00:24:52,300
0,240 240,330 330,630 630,1200 1320,1530
keep the whole flow {}

756
00:24:52,300 --> 00:24:55,300
0,360 390,1020 1200,1770 1920,2400 2400,3000
in memory? {}| By default,
|默认情况下，整个流都在内存中，

757
00:24:55,300 --> 00:24:56,770
0,60 60,330 330,660 660,870 870,1470
the whole flow is {in,memory},|
|

758
00:24:56,770 --> 00:24:59,170
0,660 720,1230 1230,1440 1440,1770 1770,2400
except {} you can provide
除非你可以提供，

759
00:24:59,380 --> 00:25:02,200
0,540 540,1200 2070,2280 2280,2460 2460,2820
to,| {} there's one exception,|
|有一个例外，|

760
00:25:02,200 --> 00:25:02,770
0,90 90,180 180,360 360,540 540,570
that we'll talk about a
我们稍后会更详细地讨论，

761
00:25:02,770 --> 00:25:03,880
0,150 150,270 270,420 420,480 480,1110
little bit more in detail

762
00:25:03,880 --> 00:25:04,960
0,210 210,240 240,510 510,990
in a second, hopefully,|
|

763
00:25:05,260 --> 00:25:07,860
0,420 420,750 750,1410 1620,2280
{} which is {}
你可以看到这里的 persist ，

764
00:25:08,300 --> 00:25:10,160
0,900 900,1170 1170,1350 1350,1500 1500,1860
{} you see this persist

765
00:25:10,160 --> 00:25:12,680
0,480 930,1350 1350,1830 1830,2040 2040,2520
here,| this {persist,here} take another
|这个 persist 使用另一个标志，我认为是 reliable ，

766
00:25:12,680 --> 00:25:13,790
0,570 570,630 630,780 780,870 870,1110
flag, I think it's called

767
00:25:13,790 --> 00:25:14,840
0,690
reliable,|
|

768
00:25:15,570 --> 00:25:17,640
0,390 390,900 960,1110 1110,1500 1530,2070
and then, {} that {}
然后，集合存储在 HDFS 中，这个称为检查点。

769
00:25:17,670 --> 00:25:18,900
0,360 360,450 450,720 720,1110 1110,1230
set is actually stored in

770
00:25:18,900 --> 00:25:20,640
0,360 360,840 870,1380 1380,1620 1620,1740
{HDFS -}, basically called this

771
00:25:20,640 --> 00:25:21,660
0,60 60,750
a checkpoint.|
|

772
00:25:22,760 --> 00:25:27,170
0,150 150,270 270,570 570,810 4170,4410
I see, thank you.| {I,have}
我明白了，谢谢。|关于分区，我有一个简短的问题，

773
00:25:27,170 --> 00:25:28,220
0,60 60,240 240,540 540,780 780,1050
a quick question about the

774
00:25:28,250 --> 00:25:32,660
0,690 840,1680 2790,3540 3540,3840 3840,4410
partitioning,| that with {} partitioning,
|对于分区， RDD 最初，

775
00:25:32,660 --> 00:25:35,510
0,330 360,1230 1260,2010 2010,2460 2670,2850
the RDDs initially,| {} is
|是否最初 HDFS 对它们分区，

776
00:25:35,510 --> 00:25:38,150
0,240 390,1170 1170,1500 1500,2070 2070,2640
it initially {HDFS -} who

777
00:25:38,180 --> 00:25:40,490
0,600 600,1170 1320,1650 1650,1890 1890,2310
partitions them| for each worker
|为每个 worker 操作是 Spark 处理。

778
00:25:40,490 --> 00:25:41,900
0,120 120,510 510,1200
to operate {on,is}

779
00:25:42,380 --> 00:25:46,370
0,570 570,1080 1080,1290 1290,3510 3510,3990
Spark handling.| { -} This
|这个 lines 在 HDFS 中，

780
00:25:46,400 --> 00:25:47,960
0,690 720,900 900,1380 1380,1470 1470,1560
lines are {in,HDFS},| you know
|分区是由 HDFS 中的文件直接定义的，

781
00:25:47,960 --> 00:25:49,580
0,300 300,660 660,780 780,1200 1200,1620
the partition is defined basically

782
00:25:49,580 --> 00:25:52,280
0,510 510,1440 1470,1920 1920,2490 2490,2700
by the files directly in

783
00:25:52,280 --> 00:25:54,590
0,420 420,870 1470,1830 1830,2070 2070,2310
{hdfs -},| {} you can
|你可以重复，

784
00:25:54,590 --> 00:25:56,390
0,750 810,1260 1260,1470 1470,1620 1620,1800
repetition,| {} and you'll see
|你很快就会看到，可能是阶段在这样做，

785
00:25:56,390 --> 00:25:57,320
0,90 90,120 120,390 390,540 540,930
in a second that actually

786
00:25:57,320 --> 00:25:58,640
0,240 240,450 450,540 540,780 780,1320
it might be the stages

787
00:25:58,640 --> 00:26:00,170
0,90 90,240 240,750 900,1200 1200,1530
to do so,| for example
|例如使用散列分区技巧，

788
00:26:00,170 --> 00:26:01,640
0,240 240,360 360,630 630,1020 1020,1470
using this hash partition trick,|
|

789
00:26:02,090 --> 00:26:05,270
0,690 690,1830 2250,2730 2730,2820 2820,3180
{} and you can define
你还可以定义自己的分区程序，

790
00:26:05,270 --> 00:26:06,530
0,270 270,510 510,690 690,1110 1110,1260
also your own {partitioner -},|
|

791
00:26:06,530 --> 00:26:08,450
0,240 240,900 960,1350 1350,1470 1470,1920
there's a {partitioner -} object
提供一个分区程序对象或抽象。

792
00:26:08,450 --> 00:26:09,770
0,60 60,690 690,870 870,1020 1020,1320
or abstraction that you can

793
00:26:09,800 --> 00:26:12,340
0,600
supply.|
|

794
00:26:12,880 --> 00:26:14,560
0,180 180,300 300,540 540,1050 1440,1680
So, it's already handled by
所以，它已经由 HDFS 处理，

795
00:26:14,560 --> 00:26:15,610
0,300 300,690 690,870 870,960 960,1050
{HDFS -},| but if you
|但如果你想为 Spark 再来一次，

796
00:26:15,610 --> 00:26:16,360
0,210 210,300 300,450 450,510 510,750
want to do it again

797
00:26:16,360 --> 00:26:17,740
0,210 210,600 600,750 750,870 870,1380
to Spark,| then you can.|
|那么你可以。|

798
00:26:19,180 --> 00:26:20,170
0,90 90,390 390,690 690,810 810,990
Of course, files are also
当然，文件也是创建于，

799
00:26:20,170 --> 00:26:22,720
0,390 390,690 840,1290 1380,1920 1920,2550
created by,| this files presumably
|这个文件可能有旁边的日志系统创建，

800
00:26:22,990 --> 00:26:25,300
0,480 480,930 930,1320 1320,1770 1860,2310
{} here created by logging

801
00:26:25,300 --> 00:26:26,140
0,390 390,510 510,690 690,750 750,840
system that sits on the

802
00:26:26,140 --> 00:26:27,490
0,360 360,480 480,630 630,1080 1080,1350
side,| and just produce different
|并且产生不同的分区，

803
00:26:27,490 --> 00:26:29,230
0,690 840,1440 1440,1500 1500,1590 1590,1740
partitions,| or you know you
|或者如果你愿意，你可以重新洗牌。

804
00:26:29,230 --> 00:26:30,190
0,150 150,600 600,690 690,750 750,960
can reshuffle if you want

805
00:26:30,190 --> 00:26:30,540
0,150
to.|
|

806
00:26:31,060 --> 00:26:32,320
0,180 180,450 450,690 690,900
Makes sense, thank you.|
理解了，谢谢。|

807
00:26:35,280 --> 00:26:37,440
0,1050 1080,1740
Okay, {}
好的，那么，

808
00:26:39,100 --> 00:26:40,660
0,450 450,1230
so, {}|
|

809
00:26:41,130 --> 00:26:42,120
0,240 240,330 330,480 480,840 840,990
and so let me,| so
所以让我，|所以这是执行模型，

810
00:26:42,120 --> 00:26:44,160
0,420 420,570 570,1050 1050,1530 1590,2040
that's the execution model, {}|
|

811
00:26:44,160 --> 00:26:44,850
0,300 300,360 360,510 510,570 570,690
and I want to talk
我想讨论一下容错。

812
00:26:44,850 --> 00:26:45,660
0,60 60,330 330,450 450,630 630,810
a little bit about fault

813
00:26:45,660 --> 00:26:47,680
0,570 900,1740
tolerance {}.|
|

814
00:26:47,980 --> 00:26:49,360
0,240 240,390 390,750 780,1050 1050,1380
And so let's go back
所以让我们回到这一点，这种容错

815
00:26:49,360 --> 00:26:50,710
0,330 330,600 630,840 840,1080 1080,1350
to {} this, this sort

816
00:26:50,710 --> 00:26:51,610
0,90 90,300 300,570 570,690 690,900
of fault tolerance| and the
|我们担心的是容错性，

817
00:26:51,610 --> 00:26:52,720
0,180 180,270 270,390 390,720 720,1110
thing that we worry about

818
00:26:52,720 --> 00:26:54,010
0,180 180,510 510,630 630,930 990,1290
fault tolerance is that,| maybe
|也许你认识的其中一个工人可能会撞车，对吧，

819
00:26:54,010 --> 00:26:56,230
0,180 180,270 270,420 420,1110 1470,2220
one of these workers {}

820
00:26:56,560 --> 00:26:58,160
0,390 420,600 600,1350
{you,know} might crash,

821
00:26:58,500 --> 00:27:00,660
0,240 240,1020 1020,1170 1170,1800 1800,2160
right,| then the worker had
|然后，工人已经计算了一些分区

822
00:27:00,660 --> 00:27:02,640
0,120 120,570 570,750 750,1410 1650,1980
is computing some partition| and
|所以我们需要重新执行

823
00:27:02,640 --> 00:27:03,570
0,150 150,270 270,450 450,750 750,930
so we need to {re-execute,that

824
00:27:03,570 --> 00:27:07,230
0,600 1110,1860 2040,2580 2580,3060 3090,3660
-}| {} and as basically
|而由于这个计划基本上跟地图还原是一样的，对吧，

825
00:27:07,230 --> 00:27:08,460
0,210 210,630 630,750 750,840 840,1230
this plans are the same

826
00:27:08,460 --> 00:27:10,200
0,120 120,360 360,840 870,1200 1200,1740
as {mapreduce -}, right, {}|
|

827
00:27:10,440 --> 00:27:12,600
0,510 510,1110 1110,1530 1530,1770 1770,2160
{} were if a worker
如果一名工人坠毁，

828
00:27:12,600 --> 00:27:14,880
0,870 1020,1170 1170,1440 1440,1680 1680,2280
crashes,| {} we need to,
|我们需要，在MapReduce中，地图任务需要重新执行

829
00:27:15,000 --> 00:27:16,470
0,540 540,750 750,960 960,1200 1200,1470
{in,mapreduce} and the map tasks

830
00:27:16,470 --> 00:27:17,730
0,150 150,240 240,450 450,600 600,1260
need {to -} be re-executed|
|

831
00:27:17,730 --> 00:27:18,870
0,120 120,450 450,720 720,810 810,1140
and perhaps maybe {} reduce
可能还需要重新执行Reduced任务，

832
00:27:18,870 --> 00:27:19,740
0,270 270,420 420,510 510,660 660,870
{task -} has to be

833
00:27:19,740 --> 00:27:21,600
0,630 1110,1410 1410,1650 1650,1770 1770,1860
re-executed,| now in here, the
|现在在这里，任务稍微复杂一些，

834
00:27:21,600 --> 00:27:23,100
0,270 270,360 360,630 630,780 780,1500
task is slightly more complicated,|
|

835
00:27:23,130 --> 00:27:24,510
0,540 540,660 660,1020 1020,1230 1230,1380
because they're basically like these
因为它们基本上就像是这些阶段

836
00:27:24,510 --> 00:27:26,550
0,660 930,1260 1260,1620 1620,1770 1770,2040
stages| and so it means
|这就意味着，如果一个工人失败了，

837
00:27:26,550 --> 00:27:28,590
0,210 210,360 360,960 990,1440 1440,2040
that if one {worker -}

838
00:27:28,620 --> 00:27:29,280
0,120 120,270 270,420 420,510 510,660
fails,| we may have to
|我们可能不得不重新计算舞台。

839
00:27:29,280 --> 00:27:30,300
0,330 330,420 420,960
re-compute the stage.|
|

840
00:27:31,230 --> 00:27:32,700
0,240 240,600 840,1140 1140,1320 1320,1470
{} So, {} let's talk
所以，让我们更多地谈谈这一点，

841
00:27:32,700 --> 00:27:33,540
0,30 30,240 240,390 390,630 630,840
a little bit more about

842
00:27:33,540 --> 00:27:35,370
0,420 660,930 930,1110 1110,1200 1200,1830
that,| that sort of perspective
|从容错的角度来看，对，

843
00:27:35,370 --> 00:27:36,810
0,330 330,750 750,990 990,1230 1230,1440
{from,fault,tolerance -}, right,| that's what
|这就是我们正在努力实现的目标。

844
00:27:36,810 --> 00:27:38,260
0,240 240,510 510,570 570,1170
we're trying to achieve.|
|

845
00:27:39,600 --> 00:27:40,740
0,270 270,330 330,570 570,900 900,1140
This is really different than
这与您在实验2或实验3或paxos中实现的容错功能真的不同

846
00:27:40,740 --> 00:27:42,300
0,210 210,390 390,960 960,1140 1140,1560
like the {fail,tolerance} that were

847
00:27:42,300 --> 00:27:44,130
0,330 330,840 840,900 900,1380 1380,1830
you implemented in lab {2,or}

848
00:27:44,130 --> 00:27:46,530
0,330 330,540 540,1230 1230,1590 1830,2400
3 or paxos| and stable
|以及稳定的储藏室之类的东西，

849
00:27:46,530 --> 00:27:47,520
0,540 540,630 630,720 720,840 840,990
storage and all that kind

850
00:27:47,520 --> 00:27:49,350
0,60 60,480 780,1260 1260,1500 1500,1830
of stuff,| {} and here
|我们真正担心的是一名工人的撞车事故，

851
00:27:49,350 --> 00:27:51,450
0,270 270,540 540,1050 1170,1740 1740,2100
really what we're we're worried

852
00:27:51,450 --> 00:27:52,500
0,450 450,540 540,600 600,930 930,1050
about is {} crash of

853
00:27:52,500 --> 00:27:53,740
0,30 30,690
a worker,|
|

854
00:27:56,270 --> 00:27:57,890
0,150 150,420 420,810 810,960 960,1620
the worker loses its memory,
工蚁失去了记忆，失去了记忆，

855
00:28:01,240 --> 00:28:02,680
0,390 390,1110
lost memory,|
|

856
00:28:04,040 --> 00:28:05,630
0,150 150,240 240,510 510,870 870,1590
and that means losses partition.
这意味着损失分割。你知道，竞争的后续部分可能依赖于这种分区

857
00:28:10,720 --> 00:28:12,910
0,690 720,1320 1320,1410 1410,1830 1860,2190
And {} you know later

858
00:28:12,910 --> 00:28:14,350
0,240 240,330 330,660 690,1260 1260,1440
part of the competition are

859
00:28:14,350 --> 00:28:16,270
0,270 270,810 810,960 960,1620 1800,1920
probably dependent on {that,partition}| and
|因此，我们需要重新读取或重新计算此分区。

860
00:28:16,270 --> 00:28:19,840
0,150 150,240 240,990 1020,1740 2100,3570
so we need to reread

861
00:28:19,840 --> 00:28:21,400
0,240 240,600 660,990 990,1140 1140,1560
or {re-compute -} this partition.|
|

862
00:28:21,400 --> 00:28:22,300
0,120 120,240 240,360 360,750 750,900
And so the solution is
因此，该解决方案与MapReduce中的解决方案完全相同，

863
00:28:22,300 --> 00:28:24,130
0,630 630,840 840,960 960,1230 1230,1830
exactly like in {mapreduce -},|
|

864
00:28:24,310 --> 00:28:25,780
0,150 150,240 240,690 690,810 810,1470
you know basically the scheduler
你知道，基本上，调度人员在某些时候会通知没有得到答案，

865
00:28:26,170 --> 00:28:27,400
0,630 630,720 720,900 900,1140 1140,1230
notice at some point that

866
00:28:27,400 --> 00:28:28,600
0,210 210,360 360,420 420,1020
doesn't get an answer,|
|

867
00:28:29,360 --> 00:28:30,920
0,210 210,420 420,1290
and then reruns
然后重新运行该分区的舞台。

868
00:28:31,420 --> 00:28:33,340
0,180 180,780 1050,1260 1260,1410 1410,1920
the stage for that partition.|
|

869
00:28:44,200 --> 00:28:45,460
0,450 450,600 600,900 900,1080 1080,1260
And you know and what
你知道，最酷的是，

870
00:28:45,460 --> 00:28:47,140
0,90 90,180 180,390 390,780 810,1680
is the cool part,| {like,exactly}
|就像在MapReduceAll中一样，如果我们查看API中的所有这些转换，

871
00:28:47,140 --> 00:28:48,820
0,150 150,270 270,420 420,1080 1320,1680
as it {in,mapreduce -} all

872
00:28:48,820 --> 00:28:49,360
0,90 90,150 150,300 300,420 420,540
if we look at all

873
00:28:49,360 --> 00:28:50,680
0,120 120,810 810,960 960,1080 1080,1320
these transformations that are sitting

874
00:28:50,680 --> 00:28:52,210
0,270 270,330 330,450 450,1200 1320,1530
here in the API,| all
|所有这些转换都是起作用的。

875
00:28:52,210 --> 00:28:54,660
0,150 150,990 1140,1350 1350,1890
these transformations are functional.|
|

876
00:28:57,400 --> 00:28:58,660
0,180 180,330 330,720 720,930 930,1260
So they basically take one
所以他们基本上只接受一个输入，

877
00:28:58,660 --> 00:28:59,920
0,630 720,870 870,1050 1050,1230 1230,1260
input,| {} they take an
|他们将RDD作为输入，

878
00:28:59,920 --> 00:29:01,180
0,390 390,480 480,570 570,990 990,1260
RDD as an input,| they
|它们会产生另一种RDD作为输出，

879
00:29:01,180 --> 00:29:02,770
0,300 300,630 630,1020 1020,1110 1110,1590
produce another {RDD,as -} output,|
|

880
00:29:03,040 --> 00:29:05,350
0,600 600,1050 1050,1230 1230,1530 1530,2310
{} and just completely deterministic.|
而且完全是确定性的。|

881
00:29:05,840 --> 00:29:07,610
0,210 210,690 720,1260 1260,1560 1560,1770
And so like {you,know} in
就像你在MapReduce中所知道的那样，你知道这些映射和函数运算的归约，

882
00:29:07,610 --> 00:29:10,040
0,210 210,840 840,1620 1950,2310 2310,2430
{mapreduce -} {you,know,these} maps and

883
00:29:10,040 --> 00:29:12,380
0,300 300,480 480,900 900,1680 1920,2340
reduce for functional operations, {}|
|

884
00:29:12,380 --> 00:29:14,450
0,210 210,690 720,1530 1530,1590 1590,2070
if you restart a stage
如果重新启动来自同一输入的一系列转换的阶段，

885
00:29:14,450 --> 00:29:16,370
0,300 300,480 480,870 870,960 960,1920
where a sequence of transformations

886
00:29:16,460 --> 00:29:18,740
0,390 390,480 480,1080 1080,1680 1770,2280
from the same input,| then
|然后，您将产生相同的输出

887
00:29:18,740 --> 00:29:20,000
0,210 210,600 600,660 660,870 870,1260
you'll produce the same output|
|

888
00:29:20,210 --> 00:29:22,430
0,390 390,510 510,720 720,1530 1560,2220
and so you recreate the
因此，您可以重新创建相同的分区，

889
00:29:22,580 --> 00:29:23,780
0,780
same

890
00:29:23,980 --> 00:29:25,480
0,570
partition,|
|

891
00:29:28,520 --> 00:29:30,020
0,360 360,660 660,1110 1110,1230 1230,1500
{recreate -} partitions {[] -
重新创建分区[]。

892
00:29:30,020 --> 00:29:31,520
0,300
-}.|
|

893
00:29:34,020 --> 00:29:34,860
0,570
Okay?|
好吧?|

894
00:29:37,600 --> 00:29:38,980
0,270 270,690 690,840 840,1110 1110,1380
{} Sorry, is this why
对不起，这就是为什么它们是不变的吗？

895
00:29:38,980 --> 00:29:40,870
0,120 120,210 210,990 1320,1710 1710,1890
they are immutable?| There's also
|还有一个原因，我认为它们是不变的，是的。

896
00:29:40,870 --> 00:29:41,530
0,90 90,330 330,390 390,540 540,660
the reason, I think they're

897
00:29:41,530 --> 00:29:42,920
0,330 330,750 750,1170
[] immutable, yes.|
|

898
00:29:48,240 --> 00:29:49,770
0,210 210,360 360,900 930,1260 1260,1530
Okay, there's one tricky case
好吧，不过有一个棘手的案子，我想谈谈，

899
00:29:49,770 --> 00:29:51,420
0,480 660,1200 1200,1440 1440,1530 1530,1650
though, {} which I want

900
00:29:51,420 --> 00:29:53,040
0,60 60,210 210,630 1080,1320 1320,1620
to talk about,| so this
|因此，这基本上是针对狭义情况的容错，

901
00:29:53,040 --> 00:29:55,740
0,1830 1830,2220 2220,2280 2280,2580 2580,2700
the {fault,tolerance} is basically for

902
00:29:55,740 --> 00:29:57,040
0,60 60,390 390,990
the narrow case,|
|

903
00:29:57,890 --> 00:29:59,000
0,240 240,330 330,840 840,960 960,1110
it's the same as sort
这与我们以前在MapReduce中看到的情况是一样的，

904
00:29:59,000 --> 00:30:00,200
0,90 90,300 300,420 420,720 720,1200
of as we saw before

905
00:30:00,200 --> 00:30:01,580
0,390 420,630 630,960 960,1290 1290,1380
in {mapreduce -},| but you
|但你知道，棘手的情况实际上是广泛的依赖。

906
00:30:01,580 --> 00:30:03,170
0,180 180,450 450,780 780,1200 1200,1590
know the tricky {case,is} actually

907
00:30:03,170 --> 00:30:06,100
0,480 810,1230 1230,2100
the wide dependencies.|
|

908
00:30:12,670 --> 00:30:14,470
0,630 690,900 900,1500 1530,1680 1680,1800
So let's say you know
所以假设你知道我们有你知道的一些变化，

909
00:30:14,470 --> 00:30:15,880
0,180 180,840 900,1020 1020,1140 1140,1410
we have you know some

910
00:30:15,880 --> 00:30:17,300
0,1140
transformations,|
|

911
00:30:19,850 --> 00:30:21,440
0,720 750,1080 1080,1380 1380,1470 1470,1590
and, {} one of these
并且，其中一个转换依赖于

912
00:30:21,440 --> 00:30:24,590
0,1110 1500,2160 2370,2610 2610,3030 3030,3150
transformations {} is dependent on|
|

913
00:30:24,590 --> 00:30:26,900
0,450 540,1080 1080,1470 1650,2070 2070,2310
a {you,know} {this,is,like,sort,of} {here,is} one
你知道，这就像是这里有一个工人，这里有另一个工人，

914
00:30:26,900 --> 00:30:28,130
0,480 480,540 540,630 630,870 870,1230
worker, here is another worker,|
|

915
00:30:28,130 --> 00:30:29,320
0,60 60,150 150,360 360,960
{and -} another worker.|
和另一名工人。|

916
00:30:31,240 --> 00:30:32,830
0,300 300,510 510,660 660,810 810,1590
And one of these stages
其中一个阶段实际上依赖于多个父分区，

917
00:30:33,130 --> 00:30:35,800
0,840 1140,1650 1650,2010 2010,2250 2250,2670
{ -} is actually dependent

918
00:30:35,800 --> 00:30:36,720
0,570
on

919
00:30:39,320 --> 00:30:42,380
0,150 150,690 690,900 900,1770 1800,3060
a number of parent partitions,|
|

920
00:30:42,890 --> 00:30:44,600
0,480 480,480 1050,1230 1230,1380 1380,1710
so {} let's say whatever
所以让我们说，不管怎样，这可能是一个连接

921
00:30:44,600 --> 00:30:45,530
0,210 210,390 390,450 450,540 540,930
maybe this is a join|
|

922
00:30:45,530 --> 00:30:46,730
0,270 270,390 390,570 570,870 870,1200
or we'll see later other
或者我们以后会看到其他的行动，

923
00:30:46,730 --> 00:30:49,460
0,750 1440,1920 1950,2490 2490,2580 2580,2730
operations,| {} where you know
|你知道我们实际上是在收集许多分区的信息，

924
00:30:49,460 --> 00:30:50,900
0,240 240,540 540,870 870,1320 1320,1440
we're actually collecting information for

925
00:30:50,900 --> 00:30:53,060
0,210 210,270 270,1020 1230,2160 2160,2160
lots of partitions,| and {}
|你知道，从那里创建一个RDD，

926
00:30:54,170 --> 00:30:55,490
0,480 480,810 840,1110 1110,1140 1140,1320
you know create a {RDD

927
00:30:55,490 --> 00:30:56,840
0,420 420,600 600,840 1050,1200 1200,1350
-} from that,| from that
|可能会被地图或其他什么继续使用的RDD

928
00:30:56,840 --> 00:30:57,800
0,150 150,480 480,630 630,840 840,960
{RDD -} that might be

929
00:30:57,800 --> 00:30:59,240
0,240 240,480 480,690 690,780 780,1440
used again by a map

930
00:30:59,240 --> 00:31:01,430
0,120 120,690 810,1080 1080,1380 2010,2190
or whatever keep going| and
|所以现在假设你知道我们是工人，我们在这里坠毁，

931
00:31:01,430 --> 00:31:03,080
0,360 390,600 600,810 810,1350 1530,1650
so now let's say you

932
00:31:03,080 --> 00:31:05,030
0,150 150,600 630,1080 1080,1680 1680,1950
know we're we're worker and

933
00:31:05,030 --> 00:31:06,300
0,330 330,690 690,1050
we crash here,|
|

934
00:31:07,590 --> 00:31:09,390
0,540 540,720 720,900 900,990 990,1800
then we need to reconstruct
那么我们需要重建这个RDD，

935
00:31:09,420 --> 00:31:12,000
0,390 390,540 540,1110
this {RDD -},|
|

936
00:31:15,640 --> 00:31:16,900
0,570 570,660 660,780 780,1110 1110,1260
and you know we sort
你知道我们有点跟上了，

937
00:31:16,900 --> 00:31:18,220
0,60 60,600 600,930 930,1110 1110,1320
of followed,| {} that means
|这意味着我们必须，我们也可以重新计算这个RDD，

938
00:31:18,220 --> 00:31:19,690
0,120 120,210 210,360 360,570 690,1470
that we have to, {we,could}

939
00:31:19,690 --> 00:31:20,710
0,120 120,270 270,690 690,870 870,1020
also {recompute -} this {RDD

940
00:31:20,710 --> 00:31:22,870
0,450 810,1020 1020,1620 1620,1800 1800,2160
-},| to recompute this RDD
|要在此工作进程上重新计算此RDD，

941
00:31:22,870 --> 00:31:24,310
0,150 150,330 330,960 1020,1200 1200,1440
on this worker,| that means
|这意味着我们还需要其他工作进程上的分区。

942
00:31:24,310 --> 00:31:26,080
0,120 120,480 480,840 840,1140 1140,1770
we also need the partitions

943
00:31:26,080 --> 00:31:27,360
0,180 180,240 240,450 450,1050
on the other workers.|
|

944
00:31:27,820 --> 00:31:30,970
0,690 690,990 990,1470 1620,2400 2430,3150
And, {} so, {} the
因此，在特定的工作者、特定的分区上执行和重建竞争

945
00:31:31,780 --> 00:31:34,300
0,540 540,960 960,1710 1710,1890 1890,2520
{} and reconstruction the execution

946
00:31:34,300 --> 00:31:37,390
0,570 1110,2280 2280,2910 2910,3030 3030,3090
of a competition on a

947
00:31:37,390 --> 00:31:39,400
0,690 870,1170 1170,1620 1620,1710 1710,2010
particular {} worker, a particular

948
00:31:39,400 --> 00:31:41,710
0,570 600,990 990,1380 1380,2010 2040,2310
partition| may actually result that
|可能会导致实际上这些也需要重新计算。

949
00:31:41,710 --> 00:31:44,680
0,300 300,990 1560,2220 2430,2850 2850,2970
actually these ones also need

950
00:31:44,680 --> 00:31:45,840
0,90 90,240 240,390 390,930
to be {recomputed -}.|
|

951
00:31:47,290 --> 00:31:47,980
0,240 240,450 450,510 510,600 600,690
Of course, you can do
当然，你可以部分并行地做这件事，

952
00:31:47,980 --> 00:31:49,900
0,180 180,690 690,1170 1170,1800 1800,1920
this partially in parallel,| you
|你可以直接问你知道，你知道，开始重复这个人，

953
00:31:49,900 --> 00:31:50,710
0,120 120,240 240,600 600,690 690,810
can just ask you know

954
00:31:50,710 --> 00:31:51,730
0,300 300,390 390,480 480,810 810,1020
please, you know start to

955
00:31:51,730 --> 00:31:52,810
0,390 390,570 570,870 870,960 960,1080
repeat this guy,| we can
|我们可以看到那个人，

956
00:31:52,810 --> 00:31:54,880
0,120 120,390 390,780 1080,1500 1500,2070
see that guy,| {} and
|你知道，然后再生产最终的RDD，

957
00:31:54,880 --> 00:31:56,020
0,120 120,270 270,780 780,990 990,1140
you know produce then the

958
00:31:56,020 --> 00:31:58,270
0,630 630,990 990,1260 1260,1680 1920,2250
final {RDD -} again, {}|
|

959
00:31:58,270 --> 00:31:59,320
0,240 240,360 360,480 480,960 960,1050
but you know certainly you
但你知道，你当然知道失败，一个工作者将导致许多许多分区的重新计算，

960
00:31:59,320 --> 00:32:02,230
0,240 240,1050 1620,2190 2190,2460 2460,2910
know {} failure, one worker

961
00:32:02,230 --> 00:32:03,790
0,240 240,390 390,990 990,1230 1230,1560
going to result in the

962
00:32:03,820 --> 00:32:06,100
0,240 240,990 1200,1410 1410,1800 1800,2280
{recomputation -} of many many

963
00:32:06,130 --> 00:32:07,480
0,1230
partitions,|
|

964
00:32:08,960 --> 00:32:11,060
0,150 150,420 420,930 930,1500 1530,2100
and {that,sort,of} slightly, { -}
而这一点，它可能会有一点代价，

965
00:32:11,060 --> 00:32:13,580
0,1230 1230,1410 1410,1530 1530,1860 1860,2520
it could be slightly costly,|
|

966
00:32:14,060 --> 00:32:16,040
0,330 330,780 870,1050 1050,1530 1530,1980
and so the solution is
因此，解决方案是，作为一名程序员，

967
00:32:16,100 --> 00:32:17,930
0,270 270,810 810,960 960,1020 1020,1830
{} that as a programmer,|
|

968
00:32:18,140 --> 00:32:19,370
0,300 300,570 570,990 990,1140 1140,1230
you can say you can
您可以说您实际上可以对稳定存储上的RDDS进行检查点或持久化。

969
00:32:19,370 --> 00:32:22,100
0,420 450,990 990,1470 1530,1890 1890,2730
actually {checkpoint -} or persist

970
00:32:23,210 --> 00:32:26,690
0,750 750,1530 1920,2520 2520,2820 2820,3480
{} RDDs on stable storage.|
|

971
00:32:27,520 --> 00:32:29,020
0,300 300,690 750,900 900,1080 1080,1500
And so you might decide,|
所以你可能会决定，|

972
00:32:29,020 --> 00:32:30,070
0,210 210,690 690,870 870,960 960,1050
for example, this is an
例如，这是一个RDD，

973
00:32:30,070 --> 00:32:33,020
0,570 570,900 1740,2640
RDD that, {}|
|

974
00:32:33,460 --> 00:32:34,120
0,180 180,270 270,450 450,600 600,660
then you don't want to
那么你就不想在失败的情况下重新计算了，

975
00:32:34,120 --> 00:32:35,410
0,120 120,750 780,960 960,1020 1020,1290
{recompute -} in the case

976
00:32:35,410 --> 00:32:36,820
0,120 120,420 420,990 990,1260 1260,1410
of a failure,| because it
|因为它需要重新计算所有不同的分区，

977
00:32:36,820 --> 00:32:38,320
0,480 480,660 660,780 780,1290 1290,1500
{requires -} {you,know} recomputing all

978
00:32:38,320 --> 00:32:40,030
0,120 120,390 390,990 1200,1530 1530,1710
the different partitions,| you may
|您可能希望对此RDD设置检查点。

979
00:32:40,030 --> 00:32:41,440
0,150 150,240 240,480 480,990 1110,1410
want to {checkpoint -} this

980
00:32:41,440 --> 00:32:42,340
0,150 150,630
{RDD -}.|
|

981
00:32:48,960 --> 00:32:50,130
0,150 150,420 420,540 540,720 720,1170
And then we know this
然后我们知道这个阶段，

982
00:32:50,160 --> 00:32:51,720
0,450 450,780 780,1020 1020,1200 1200,1560
stage,| when actually when this
|当你知道计算需要重新执行的时候，

983
00:32:51,720 --> 00:32:53,310
0,120 120,420 600,1320 1320,1530 1530,1590
you know computation needs to

984
00:32:53,310 --> 00:32:54,930
0,180 180,390 390,1080 1290,1500 1500,1620
be {reexecuted -},| {} gonna
|我将实际读取您知道的来自检查点的分区结果

985
00:32:54,930 --> 00:32:56,370
0,270 270,690 720,810 810,960 960,1440
actually read you know the

986
00:32:56,400 --> 00:32:58,170
0,690 690,900 900,1020 1020,1470 1470,1770
results of the partitions from

987
00:32:58,170 --> 00:33:00,660
0,360 840,1470 1590,2070 2070,2220 2220,2490
the checkpoint| instead of actually
|而不是真正从头开始重新计算它们。

988
00:33:00,660 --> 00:33:01,950
0,300 300,630 630,750 750,1080 1080,1290
{having -} to recompute them

989
00:33:01,950 --> 00:33:04,320
0,480 480,1140 1500,1710 1710,2130 2160,2370
from scratch.| And so this
|这就是Spark支持检查点的原因

990
00:33:04,320 --> 00:33:06,060
0,90 90,540 570,930 930,1320 1320,1740
is why {} spark supports

991
00:33:06,060 --> 00:33:07,680
0,750 750,1020 1020,1380 1380,1530 1530,1620
checkpoints| and that's sort of
|这就是他们对广泛依赖的容错故事。

992
00:33:07,680 --> 00:33:09,400
0,450 750,1560
their {}

993
00:33:10,090 --> 00:33:11,890
0,660 900,1170 1170,1290 1290,1350 1350,1800
{} fault {tolerance -} story

994
00:33:11,890 --> 00:33:13,940
0,450 450,960 960,1830
for wide dependencies.|
|

995
00:33:17,800 --> 00:33:19,120
0,210 210,510 510,660 660,1050
Any questions about this?|
对此有什么问题吗？|

996
00:33:21,000 --> 00:33:22,200
0,480 510,750 750,930 930,1080 1080,1200
{} I I had one
我我只有一个问题。

997
00:33:22,200 --> 00:33:27,570
0,540 3090,3660 3660,3870 3870,4530 4770,5370
question.| So there was {},
|确实是这样，所以你大体上坚持正确，

998
00:33:28,670 --> 00:33:30,500
0,150 150,330 330,1110 1140,1620 1620,1830
so you persist right just

999
00:33:30,500 --> 00:33:32,780
0,480 480,1020 1020,1410 1410,2100 2100,2280
in general,| but they, they
|但是他们，他们也提到了一面可靠的旗帜。

1000
00:33:32,780 --> 00:33:34,580
0,240 240,570 570,690 690,1200 1200,1800
also mentioned a reliable flag.|
|

1001
00:33:34,700 --> 00:33:36,200
0,480 810,1200 1200,1320 1320,1380 1380,1500
Hmm.| {} So I was
嗯。|所以我在想，

1002
00:33:36,200 --> 00:33:36,980
0,480
wondering,|
|

1003
00:33:37,320 --> 00:33:38,820
0,300 300,540 540,660 660,1140 1140,1500
like what's the difference between
比如，仅仅坚持和使用可靠的标志有什么区别。

1004
00:33:38,820 --> 00:33:40,140
0,180 180,750 750,930 930,1200 1200,1320
just persisting and using a

1005
00:33:40,140 --> 00:33:41,340
0,390 390,900
reliable flag.|
|

1006
00:33:41,770 --> 00:33:43,060
0,450 450,690 690,990 990,1140 1140,1290
Persist just means you're gonna
持久化只是意味着你要将RDD保存在内存中

1007
00:33:43,060 --> 00:33:44,500
0,240 240,420 420,900 900,960 960,1440
keep that RDD in memory|
|

1008
00:33:44,710 --> 00:33:45,370
0,270 270,360 360,480 480,600 600,660
and you're not going to
你不会把它扔掉的，

1009
00:33:45,370 --> 00:33:46,400
0,210 210,300 300,720
throw it away,|
|

1010
00:33:47,200 --> 00:33:48,430
0,360 360,570 570,720 720,870 870,1230
{} so you can reuse
所以你可以在以后的比赛中重复使用它，在内存中使用，

1011
00:33:48,430 --> 00:33:50,290
0,120 120,210 210,450 450,1260 1590,1860
it in later competitions in

1012
00:33:50,290 --> 00:33:52,810
0,300 300,600 600,1050 1440,1800 1800,2520
and {use,in} memory,| the checkpoint
|检查点或可靠性标志基本上意味着，

1013
00:33:52,810 --> 00:33:55,090
0,270 270,930 930,1350 1350,1680 1680,2280
or reliability flag basically means,|
|

1014
00:33:56,210 --> 00:33:58,010
0,270 270,540 540,990 990,1110 1110,1800
you actually write a copy
您实际上将整个RDD的副本写入HDFS。

1015
00:33:58,070 --> 00:33:59,930
0,150 150,240 240,570 570,1260 1380,1860
of the whole RDD to

1016
00:33:59,930 --> 00:34:01,180
0,420 420,990
{hdfs -}.|
|

1017
00:34:05,560 --> 00:34:06,880
0,180 180,690 690,780 780,840 840,1320
And hdfs is a persistent
而HDFS是持久或稳定的存储文件系统。

1018
00:34:06,880 --> 00:34:08,410
0,210 210,630 630,930 930,1170 1170,1530
or {a,stable} storage file system.|
|

1019
00:34:12,170 --> 00:34:13,130
0,210 210,510 510,630 630,810 810,960
Is there a way to
有没有一种方法可以告诉斯帕克不再坚持某事，

1020
00:34:13,130 --> 00:34:15,290
0,240 240,870 870,1230 1260,1620 1620,2160
tell spark to {unpersist -}

1021
00:34:15,290 --> 00:34:17,420
0,570 840,1050 1050,1800 1800,2040 2040,2130
something,| because otherwise like for
|因为否则，例如，如果您坚持使用RDD

1022
00:34:17,420 --> 00:34:18,770
0,420 420,630 630,810 810,1230 1230,1350
example if you persist in

1023
00:34:18,770 --> 00:34:20,420
0,150 150,720 990,1410 1410,1530 1530,1650
{RDD -}| and you do
|而且你做了大量的计算，

1024
00:34:20,420 --> 00:34:22,550
0,90 90,390 390,450 450,1500 1980,2130
a lot of computations,| but
|但就像后来的那些计算数字使用RDD一样，

1025
00:34:22,550 --> 00:34:24,050
0,150 150,390 390,630 630,1290 1290,1500
like those later computations number

1026
00:34:24,050 --> 00:34:25,220
0,210 210,300 300,480 480,960
use the {RDD -},|
|

1027
00:34:26,080 --> 00:34:26,890
0,270 270,480 480,600 600,750 750,810
you might just have it
你可能会把它永远留在记忆中。

1028
00:34:26,890 --> 00:34:29,050
0,360 360,660 660,930 930,1530 1560,2160
sticking around in memory forever.|
|

1029
00:34:29,780 --> 00:34:31,070
0,570 570,600 600,810 810,1080 1080,1290
Yeah, oh yeah, so we,|
是啊，哦是啊，所以我们，|

1030
00:34:31,070 --> 00:34:33,020
0,660 660,1080 1080,1410 1410,1530 1530,1950
I I presume you can
我想你可以，或者说Spark使用了一个通用的策略，

1031
00:34:33,140 --> 00:34:35,270
0,840 840,1200 1200,1710 1710,1800 1800,2130
{} or there's a general

1032
00:34:35,270 --> 00:34:37,370
0,540 540,1200 1200,1560 1560,1920 1920,2100
strategy that spark uses,| they
|他们稍微谈了一下这件事

1033
00:34:37,370 --> 00:34:38,210
0,210 210,240 240,450 450,570 570,840
talk a little bit about

1034
00:34:38,210 --> 00:34:40,220
0,420 690,1110 1110,1380 1380,1770 1770,2010
this| is that they have
|他们真的没有空间了，

1035
00:34:40,220 --> 00:34:41,810
0,180 180,390 390,540 540,930 930,1590
there's really no space anymore,|
|

1036
00:34:42,020 --> 00:34:44,840
0,180 180,450 450,990 1020,1800 2040,2820
{} they might {} spill
它们可能会将一些RDDS泄漏到HDFS或移除它们，

1037
00:34:44,840 --> 00:34:46,400
0,180 180,690 690,810 810,1170 1170,1560
some RDDs to {hdfs -}

1038
00:34:46,400 --> 00:34:48,200
0,270 270,570 570,900 1050,1140 1140,1800
or remove them, { -}|
|

1039
00:34:48,230 --> 00:34:49,130
0,240 240,330 330,660 660,780 780,900
the the {paper,slightly -} vague
这份文件对他们的具体计划略显含糊。

1040
00:34:49,130 --> 00:34:50,780
0,300 300,870 870,960 960,1110 1110,1650
on exactly you know what

1041
00:34:50,780 --> 00:34:51,860
0,150 150,390 390,480 480,870
their plan for {that,is}.|
|

1042
00:34:54,010 --> 00:34:55,570
0,210 210,510 990,1140 1140,1380 1380,1560
Thank you.| Of course, when
谢谢。|当然，当比赛结束，一个用户被你注销，或者你停止你的司机，

1043
00:34:55,570 --> 00:34:58,120
0,90 90,570 570,1140 1170,1830 1860,2550
the competition ends and a

1044
00:34:58,120 --> 00:35:01,420
0,1050 1050,1200 1200,1950 2220,3060 3060,3300
user you logout, {} or

1045
00:35:01,420 --> 00:35:02,860
0,120 120,390 390,510 510,930 930,1440
you stop your driver,| then
|那么我想你应该知道那些RDDS肯定已经从记忆中消失了。

1046
00:35:02,890 --> 00:35:04,420
0,720 750,1140 1140,1230 1230,1320 1320,1530
I think you know those

1047
00:35:04,420 --> 00:35:05,770
0,420 420,720 720,900 900,1020 1020,1350
RDDs definitely gone from memory.|
|

1048
00:35:11,060 --> 00:35:11,940
0,600
Okay?|
好吧?|

1049
00:35:13,940 --> 00:35:16,460
0,330 330,1020 1050,1500 1500,1650 1650,2520
Okay, so that is almost
好了，这就是你所知道的火花的故事，

1050
00:35:16,460 --> 00:35:17,360
0,90 90,240 240,360 360,750 750,900
you know the story of

1051
00:35:17,360 --> 00:35:21,260
0,630 660,1410 1830,2730 2880,3690 3780,3900
spark,| { -} the you
|你知道，我们已经看到了什么是RDD，

1052
00:35:21,260 --> 00:35:22,160
0,120 120,570 570,750 750,870 870,900
know we've seen what a

1053
00:35:22,160 --> 00:35:23,840
0,540 540,810 840,1200 1200,1410 1410,1680
RDD is,| {} we've seen
|我们已经看到了处决是如何进行的

1054
00:35:23,840 --> 00:35:26,870
0,930 1080,1170 1170,1800 1800,2280 2520,3030
how the execution works| and
|我们已经看到了容错计划是如何工作的，

1055
00:35:26,870 --> 00:35:27,890
0,180 180,390 390,600 600,840 840,1020
we've seen how the fault

1056
00:35:27,890 --> 00:35:30,080
0,300 300,600 600,1020 1320,1770 2010,2190
tolerance plan works,| {} the
|我想谈的是另一个例子

1057
00:35:30,080 --> 00:35:31,280
0,270 270,510 510,600 600,780 780,1200
thing that I want to

1058
00:35:31,280 --> 00:35:32,900
0,240 240,480 480,600 600,900 900,1620
talk about is another example|
|

1059
00:35:32,960 --> 00:35:34,820
0,210 210,420 420,750 750,1110 1110,1860
to really show off where
真正炫耀火花闪耀的地方

1060
00:35:34,820 --> 00:35:37,610
0,510 510,1140 1140,1860 2070,2520 2520,2790
{} spark shines| and that
|这是一个迭代的例子。

1061
00:35:37,610 --> 00:35:39,100
0,120 120,210 210,600 600,1170
is an iterative example.|
|

1062
00:35:40,240 --> 00:35:41,440
0,210 210,300 300,870 870,990 990,1200
So in competition that has
因此，在具有迭代结构的竞争中，

1063
00:35:41,440 --> 00:35:43,100
0,60 60,390 390,870
an iterative structure,|
|

1064
00:35:46,060 --> 00:35:47,230
0,330 330,390 390,690 690,1020 1020,1170
and the particular one I
而我想要谈的就是PageRank。

1065
00:35:47,230 --> 00:35:47,830
0,120 120,180 180,330 330,540 540,600
want to talk about the

1066
00:35:47,830 --> 00:35:48,900
0,570
{PageRank}.|
|

1067
00:35:52,900 --> 00:35:55,270
0,90 90,600 1020,1860 1860,2280 2280,2370
{} I assume most of
我想你们大多数人都熟悉某种形式的页面排名，

1068
00:35:55,270 --> 00:35:56,470
0,150 150,450 450,810 810,960 960,1200
you are familiar with page

1069
00:35:56,470 --> 00:35:59,080
0,240 240,630 660,840 840,1350 1590,2610
rank in some form,| basically
|基本上，这是一个对网页赋予权重或重要性的算法的计划，

1070
00:35:59,080 --> 00:36:01,270
0,300 300,360 360,690 690,1320 1530,2190
it's a plan to {}

1071
00:36:01,270 --> 00:36:03,400
0,540 540,1080 1080,1410 1410,1860 1890,2130
algorithm to give weight or

1072
00:36:03,400 --> 00:36:06,130
0,660 660,990 990,1200 1200,1830 2220,2730
important to web pages,| and
|并且这取决于指向特定网页的链接的数量，

1073
00:36:06,130 --> 00:36:07,630
0,300 300,780 780,1080 1080,1170 1170,1500
this dependent on the number

1074
00:36:07,630 --> 00:36:09,310
0,270 270,960 960,1290 1290,1590 1590,1680
of links that point to

1075
00:36:09,310 --> 00:36:10,420
0,60 60,480 480,660 660,900 900,1110
a particular web page,| so
|例如，如果你有一个网页U1，Main指向它自己，

1076
00:36:10,420 --> 00:36:11,140
0,90 90,420 420,510 510,600 600,720
for example if you have

1077
00:36:11,140 --> 00:36:12,850
0,720 720,900 900,1140 1140,1290 1290,1710
a web page {U1 -},

1078
00:36:14,040 --> 00:36:15,660
0,330 330,570 570,810 810,900 900,1620
{} main points to itself,|
|

1079
00:36:16,110 --> 00:36:17,820
0,570 570,870 870,1260 1260,1530 1530,1710
{} {you,have} maybe a web
你可能有一个网页U3，

1080
00:36:17,820 --> 00:36:19,290
0,270 270,420 420,960 1170,1350 1350,1470
page {U3 -},| so I'll
|所以我将使用一个例子和网页U2，

1081
00:36:19,290 --> 00:36:20,880
0,210 210,300 300,1020 1020,1200 1200,1590
use an example and {web,page}

1082
00:36:20,880 --> 00:36:23,490
0,810 1170,1890 1890,2040 2040,2100 2100,2610
U2,| U2 has a link
|U2具有到自身和到U3的链接

1083
00:36:23,850 --> 00:36:26,010
0,210 210,1380 1380,1830 1830,1980 1980,2160
to itself and to {U3

1084
00:36:26,010 --> 00:36:28,260
0,570 810,960 960,1620 1650,2010 2010,2250
-}| and maybe {you,know} U3
|也许你知道U3和U1有联系。

1085
00:36:28,260 --> 00:36:29,460
0,150 150,240 240,540 540,750 750,1200
has a link {to,U1 -}.|
|

1086
00:36:30,310 --> 00:36:32,260
0,540 810,1290 1290,1560 1560,1830 1830,1950
And basically page rank is
基本上，页面排名是基于这些连接性的算法，

1087
00:36:32,260 --> 00:36:34,120
0,60 60,720 750,1260 1260,1470 1470,1860
an algorithm based on these

1088
00:36:34,120 --> 00:36:36,100
0,690 690,930 1110,1320 1320,1890 1890,1980
{connectivities -},| {} computers you
|你知道网页的重要性吗？

1089
00:36:36,100 --> 00:36:37,480
0,180 180,690 720,1200 1200,1290 1290,1380
know the importance of a

1090
00:36:37,480 --> 00:36:39,610
0,180 180,690 900,1590 1590,1890 1890,2130
web page| {} and page
|以及早期算法的页面排名，

1091
00:36:39,610 --> 00:36:40,630
0,150 150,240 240,390 390,480 480,1020
rank for sort of the

1092
00:36:41,050 --> 00:36:43,510
0,960 960,1140 1140,1230 1230,1740 1770,2460
early one of the algorithms,|
|

1093
00:36:43,510 --> 00:36:45,460
0,270 270,810 810,1410 1410,1650 1650,1950
that really drove the Google
它真正推动了谷歌搜索机器的发展，

1094
00:36:45,460 --> 00:36:47,830
0,300 300,810 870,1590 1590,2070 2070,2370
search machine,| {} {in,the,sense} that
|从这个意义上说，如果你有一个搜索结果，

1095
00:36:48,040 --> 00:36:49,480
0,210 210,330 330,600 600,1050 1080,1440
if you had a search

1096
00:36:49,480 --> 00:36:50,500
0,390 390,450 450,660 660,810 810,1020
result,| the way you rank
|你对搜索结果进行排名的方式是，

1097
00:36:50,500 --> 00:36:51,910
0,210 210,600 600,720 720,1020 1020,1410
search result is that,| if
|如果搜索结果出现在更重要网页上，

1098
00:36:51,910 --> 00:36:54,250
0,540 540,1410 1410,1650 1650,1890 1920,2340
{search,result} appears on a more

1099
00:36:54,250 --> 00:36:55,570
0,420 420,600 600,900 900,1080 1080,1320
important web page,| {you,know} that
|你知道，结果会在列表中提升到更高的位置，

1100
00:36:55,570 --> 00:36:57,580
0,480 630,990 990,1500 1500,1590 1590,2010
results gets promoted to {higher,in}

1101
00:36:57,580 --> 00:36:59,710
0,90 90,570 990,1410 1410,1890 1890,2130
the list,| {} and {}
|这是早期的原因之一，

1102
00:36:59,710 --> 00:37:00,280
0,150 150,240 240,390 390,510 510,570
that was one of the

1103
00:37:00,280 --> 00:37:03,040
0,870 870,1170 1170,1530 1530,2490 2490,2760
reasons early days,| Google search
|谷歌搜索引擎实际上会产生更好的搜索结果，

1104
00:37:03,040 --> 00:37:05,170
0,360 360,600 600,1200 1440,1860 1860,2130
machine actually produce better search

1105
00:37:05,170 --> 00:37:06,700
0,390 390,840 840,930 930,1140 1140,1530
results,| were the more important
|如果更重要的信息实际上排序，更重要的网页是在顶部。

1106
00:37:06,700 --> 00:37:08,140
0,480 480,810 810,960 960,1140 1140,1440
information actually order more important

1107
00:37:08,140 --> 00:37:09,200
0,450 450,660 660,990
webpages were {on,top}.|
|

1108
00:37:11,150 --> 00:37:13,910
0,660 900,1290 1290,1530 1530,2010 2160,2760
{} And so the paper
因此，本文介绍了Spark中页面排名的实现。

1109
00:37:13,910 --> 00:37:16,460
0,240 240,570 570,1260 1350,2250 2250,2550
{} talks about {} shows

1110
00:37:16,460 --> 00:37:20,780
0,450 480,660 660,1410 2430,3270 3420,4320
off {} the {} implementation

1111
00:37:20,780 --> 00:37:22,730
0,60 60,330 330,660 660,1260 1320,1950
of page rank in spark.|
|

1112
00:37:26,780 --> 00:37:28,910
0,180 180,450 450,840 840,1620 1620,2130
So here's the implementation of
下面是页面排名的Spark实现的实现

1113
00:37:28,940 --> 00:37:33,380
0,630 1170,2670 2670,3180 3210,4320 4320,4440
{} the spark implementation of

1114
00:37:33,380 --> 00:37:35,420
0,300 330,600 600,960 1050,1650 1650,2040
the page rank| {} and
|就像你之前知道的那样，这只是一个描述，

1115
00:37:35,420 --> 00:37:36,470
0,150 150,660 660,750 750,870 870,1050
as before you know this

1116
00:37:36,470 --> 00:37:38,540
0,150 150,390 390,1350 1380,1920 1920,2070
is just a description,| so
|所以我们来看一下单独的线条，

1117
00:37:38,540 --> 00:37:39,500
0,150 150,300 300,420 420,510 510,960
we look at the individual

1118
00:37:39,500 --> 00:37:41,360
0,630 900,1620
lines, {}|
|

1119
00:37:42,200 --> 00:37:42,980
0,90 90,180 180,420 420,540 540,780
you know, these are just
你知道，这些只是实际如何计算页面排名的诀窍

1120
00:37:42,980 --> 00:37:44,990
0,510 510,1320 1320,1470 1470,1770 1770,2010
the recipe to actually how

1121
00:37:44,990 --> 00:37:47,600
0,600 870,1470 1530,1890 1890,2160 2160,2610
do {} compute page rank|
|

1122
00:37:47,810 --> 00:37:49,310
0,390 390,750 750,1080 1080,1410 1410,1500
and only when like you
而且只有当你知道在这个特殊的情况下，

1123
00:37:49,310 --> 00:37:50,270
0,120 120,180 180,330 330,600 600,960
know in this particular case,|
|

1124
00:37:50,270 --> 00:37:51,230
0,90 90,180 180,330 330,600 600,960
if you do say ranks
如果你真的说队伍在最后聚集，

1125
00:37:51,230 --> 00:37:52,040
0,570
collect

1126
00:37:52,260 --> 00:37:54,000
0,180 180,240 240,570 570,990 1470,1740
at the very end,| and
|然后，实际上竞争会在你知道的机器集群上进行

1127
00:37:54,000 --> 00:37:55,980
0,270 270,600 600,1290 1290,1440 1440,1980
then actually competition would run

1128
00:37:56,100 --> 00:37:57,780
0,510 510,1200 1200,1260 1260,1440 1440,1680
{} on you know the

1129
00:37:57,810 --> 00:38:00,450
0,390 390,510 510,1230 1500,2100 2100,2640
cluster of machines| and using
|并使用我们到目前为止看到的某种执行模式。

1130
00:38:00,450 --> 00:38:02,520
0,180 180,270 270,900 900,1680 1740,2070
sort of execution {} pattern

1131
00:38:02,520 --> 00:38:03,480
0,120 120,300 300,480 480,630 630,960
that we've seen so far.|
|

1132
00:38:04,320 --> 00:38:05,460
0,240 240,600 690,720 750,1080 1080,1140
And so I want to
所以我想更详细地介绍这个例子，

1133
00:38:05,460 --> 00:38:07,290
0,330 330,930 930,960 960,1470 1470,1830
walk through {} this {}

1134
00:38:07,290 --> 00:38:08,220
0,510 510,570 570,720 720,810 810,930
example a little bit more

1135
00:38:08,220 --> 00:38:09,660
0,660 870,1080 1080,1230 1230,1380 1380,1440
detail,| {} to get a
|为了得到一种感觉你知道吗，为了得到更好的感觉，

1136
00:38:09,660 --> 00:38:11,340
0,600 600,720 720,810 810,1080 1080,1680
sense you know what, to

1137
00:38:11,370 --> 00:38:12,660
0,330 330,360 360,570 570,870 870,1290
get a better sense,| why
|为什么火花在迭代的情况下是闪耀的。

1138
00:38:12,660 --> 00:38:13,860
0,420 420,540 540,990 990,1080 1080,1200
spark are shines in the

1139
00:38:13,860 --> 00:38:14,860
0,300 300,840
iterative case.|
|

1140
00:38:15,530 --> 00:38:18,500
0,510 750,1260 1590,2220 2640,2880 2880,2970
{} So, {} there are
所以，这里有两个RDDS，

1141
00:38:18,500 --> 00:38:20,150
0,420 420,540 540,930 930,1380 1440,1650
two {RDDs -} here, {}|
|

1142
00:38:20,150 --> 00:38:20,870
0,180 180,360 360,480 480,540 540,720
I'm also going to talk
我还将谈论一些在Spark中很酷的优化，

1143
00:38:20,870 --> 00:38:21,980
0,150 150,270 270,900 900,1050 1050,1110
about some optimizations that are

1144
00:38:21,980 --> 00:38:23,780
0,390 390,750 780,1380 1410,1650 1650,1800
cool in spark,| one of
|这些链接之一是RDDS

1145
00:38:23,780 --> 00:38:25,730
0,150 150,690 690,810 810,1350 1680,1950
these links {RDDs -} {}|
|

1146
00:38:25,730 --> 00:38:27,830
0,210 210,510 510,600 600,1350 1350,2100
and links is basically represents
而链接基本上代表了图的连接

1147
00:38:27,830 --> 00:38:30,500
0,1290 1560,2100 2100,2160 2160,2220 2220,2670
the connection of the graphs|
|

1148
00:38:30,500 --> 00:38:32,060
0,150 150,390 390,960 960,1230 1230,1560
and so precisely it probably
因此，准确地说，它可能有一条线，

1149
00:38:32,060 --> 00:38:34,730
0,480 750,1020 1020,1770 1800,2310 2370,2670
has a line,| I'm going
|我将这样写它，作为每个URL的一行，

1150
00:38:34,730 --> 00:38:35,480
0,60 60,270 270,390 390,540 540,750
to write it like that,

1151
00:38:35,480 --> 00:38:38,300
0,120 120,210 210,690 930,2280 2280,2820
as a line per url,|
|

1152
00:38:38,300 --> 00:38:40,070
0,300 300,630 630,960 960,1380 1560,1770
so here {U1 -}, it
所以在这里U1，它有两个传出链路，

1153
00:38:40,070 --> 00:38:42,080
0,180 180,390 390,870 870,1500 1710,2010
has two outgoing links, {}|
|

1154
00:38:42,080 --> 00:38:44,540
0,240 240,870 870,1320 1350,2070 2070,2460
{U1 -} {} {U3 -},|
U1 U3，|

1155
00:38:48,550 --> 00:38:49,700
0,810

1156
00:38:51,620 --> 00:38:52,880
0,390 390,480 480,750 750,1050 1050,1260
actually, I missed one link
实际上，我在这里漏掉了一个环节。

1157
00:38:52,880 --> 00:38:53,860
0,330
here.|
|

1158
00:38:54,240 --> 00:38:56,080
0,210 210,720 750,1530
And then, {}
然后，你知道U2，U2的条目，现在已经到了U2和U3，

1159
00:38:56,380 --> 00:38:59,140
0,570 720,1710 1770,2190 2190,2310 2310,2760
{you,know,the} U2, entry for U2

1160
00:38:59,140 --> 00:39:00,700
0,240 240,450 450,660 660,1110 1110,1560
which has now going to

1161
00:39:00,700 --> 00:39:02,200
0,420 420,540 540,690 690,1230
U2 and {U3 -},|
|

1162
00:39:04,660 --> 00:39:06,250
0,300 300,420 420,540 540,990 1050,1590
and there is an entry,
有一个条目，你知道U3是去U1的。

1163
00:39:06,250 --> 00:39:07,960
0,90 90,420 450,720 720,1320
you know {U3 -}

1164
00:39:08,180 --> 00:39:10,040
0,540 540,900 900,1350 1350,1500 1500,1860
{} going to {U1 -}.|
|

1165
00:39:13,030 --> 00:39:13,810
0,150 150,300 300,390 390,750 750,780
So this is basically a
这基本上是对万维网的描述，

1166
00:39:13,810 --> 00:39:15,550
0,570 570,750 750,870 870,1200 1200,1740
description of, you will the

1167
00:39:15,580 --> 00:39:17,560
0,300 300,510 510,1050 1500,1860 1860,1980
world wide web,| and of
|当然你知道我的小例子，我有三个网页，

1168
00:39:17,560 --> 00:39:18,970
0,330 330,420 420,900 900,1110 1110,1410
course you know my tiny

1169
00:39:18,970 --> 00:39:20,050
0,180 180,660 660,780 780,930 930,1080
little example, I have three

1170
00:39:20,050 --> 00:39:22,210
0,210 210,870 1080,1620 1620,1980 1980,2160
web pages,| but if {you,know}
|但如果你知道我们是在谷歌的规模上运行这项工作，

1171
00:39:22,210 --> 00:39:23,230
0,450 450,690 690,870 870,960 960,1020
were running this at the

1172
00:39:23,230 --> 00:39:24,550
0,480 480,690 690,1140 1140,1200 1200,1320
scale of Google,| you would
|你会有十亿个网页，对吧，

1173
00:39:24,550 --> 00:39:25,690
0,90 90,150 150,480 480,690 690,1140
have a billion web pages,

1174
00:39:25,690 --> 00:39:27,280
0,300 720,1170 1170,1260 1260,1410 1410,1590
right,| and so this file
|所以这个文件是巨大的，它被分区。

1175
00:39:27,280 --> 00:39:29,620
0,90 90,1020 1020,1410 1530,1680 1680,2340
is gigantic and it's partitioned

1176
00:39:29,920 --> 00:39:32,000
0,600 600,1320 1350,1980
{} in partitions.|
|

1177
00:39:33,340 --> 00:39:34,960
0,420 420,570 570,750 750,1380
{} So that's links,|
这就是链接，|

1178
00:39:35,240 --> 00:39:37,610
0,510 510,690 690,1050 1050,1830 1890,2370
{} and then ranks {}
然后排名是一个类似的文件

1179
00:39:37,610 --> 00:39:39,950
0,240 240,540 540,930 930,1500 1710,2340
is a similar file {}|
|

1180
00:39:39,950 --> 00:39:41,540
0,270 270,690 690,810 810,1260 1260,1590
that contains the current ranks
包含这些网页的当前排名的

1181
00:39:41,540 --> 00:39:43,250
0,150 150,300 300,480 480,1080 1380,1710
for these web pages| and
|所以你可以认为这些是U1，你知道逗号，你知道它是等级，

1182
00:39:43,250 --> 00:39:44,000
0,90 90,180 180,270 270,450 450,750
so you can think about

1183
00:39:44,000 --> 00:39:45,530
0,210 210,540 540,720 720,900 900,1530
these as a {U1 -},

1184
00:39:45,990 --> 00:39:47,910
0,330 330,1020 1020,1110 1110,1260 1260,1920
{you,know} comma you know {it's,rank},|
|

1185
00:39:48,150 --> 00:39:49,770
0,600 600,810 810,990 990,1350 1350,1620
{} and let's assume the
让我们假设排名初始化为1.0

1186
00:39:49,770 --> 00:39:51,990
0,480 480,1110 1110,1380 1380,1590 1590,2220
ranks initialized {1.0 - -}|
|

1187
00:39:52,320 --> 00:39:54,000
0,510 510,870 870,960 960,1290 1320,1680
and then {you - -}
然后你知道这是1.0，

1188
00:39:54,000 --> 00:39:55,100
0,180 180,420 420,840
know here's 1.0,|
|

1189
00:39:55,510 --> 00:39:58,140
0,570 600,1440 1470,2130
then {U2,you,know -}
然后U2，你知道1.0，

1190
00:39:58,360 --> 00:40:00,080
0,330 330,480 480,1440
{1.0 - -},|
|

1191
00:40:00,420 --> 00:40:02,440
0,780 990,1260 1260,1680
{} {U3 -}
U3 1.0。

1192
00:40:02,700 --> 00:40:04,060
0,210 210,390 390,810
{1.0 - -}.|
|

1193
00:40:04,970 --> 00:40:06,170
0,480 480,660 660,720 720,930 930,1200
{} And we see actually
我们看到实际上这些链接，

1194
00:40:06,170 --> 00:40:09,080
0,210 210,870 900,1560 1890,2160 2190,2910
that the links,| the links
|这些链接实际上保存在内存中，

1195
00:40:09,080 --> 00:40:10,670
0,180 180,690 690,900 900,1110 1110,1590
are these is actually persisted

1196
00:40:10,670 --> 00:40:12,470
0,60 60,570 630,1140 1140,1560 1560,1800
in memory,| that presumably in
|这可能与我们之前看到的错误文件错误RDD的方式相同。

1197
00:40:12,470 --> 00:40:13,220
0,60 60,330 330,450 450,630 630,750
the same way as the

1198
00:40:13,220 --> 00:40:14,330
0,300 300,720 720,840 840,930 930,1110
error file that we saw

1199
00:40:14,330 --> 00:40:16,100
0,480 480,600 600,1140 1140,1290 1290,1770
before, the error {RDD -}.|
|

1200
00:40:16,700 --> 00:40:17,440
0,480

1201
00:40:17,840 --> 00:40:20,720
0,120 120,630 840,1530 1560,2160 2160,2880
And then {} ranks, it's
然后排名，它被初始化为某个

1202
00:40:21,080 --> 00:40:22,880
0,930 930,1050 1050,1470 1470,1560 1560,1800
initialized to something| and then
|然后基本上有一种迭代次数的描述，以产生新的排名RDD。

1203
00:40:22,880 --> 00:40:25,760
0,420 420,720 720,1020 1410,1980 2490,2880
basically there's sort of {}

1204
00:40:25,760 --> 00:40:28,970
0,780 810,1260 1260,1620 1620,2460 2760,3210
description of {number,of} iterations {}

1205
00:40:28,970 --> 00:40:31,520
0,270 270,960 960,1590 1620,1920 1920,2550
to produce {} new ranks

1206
00:40:31,610 --> 00:40:32,820
0,360 360,540 540,990
{} {RDD -}.|
|

1207
00:40:33,490 --> 00:40:34,600
0,240 240,600 600,840 840,900 900,1110
You can see a little
你可以看到这实际上是如何进行的，

1208
00:40:34,600 --> 00:40:35,830
0,300 300,600 600,780 780,1020 1020,1230
bit how this {actually -}

1209
00:40:35,830 --> 00:40:37,960
0,150 150,450 450,870 1410,1890 1890,2130
{} plays out,| {} and
|我们注意到的一件事是

1210
00:40:37,960 --> 00:40:38,650
0,240 240,330 330,390 390,600 600,690
one of the things we

1211
00:40:38,650 --> 00:40:40,540
0,390 390,540 540,870 1020,1680 1680,1890
notice is| that links gets
|这种链接在每次迭代中都会被重复使用，

1212
00:40:40,540 --> 00:40:42,400
0,600 600,750 750,1020 1020,1530
reused in every iteration,|
|

1213
00:40:43,190 --> 00:40:45,170
0,420 420,720 720,930 930,1200 1200,1980
and length actually gets joined
而长度实际上与排名联系在一起，

1214
00:40:45,530 --> 00:40:48,230
0,660 690,1410 1500,2070 2070,2430 2430,2700
with ranks,| what means what
|什么意思这意味着什么，

1215
00:40:48,230 --> 00:40:49,070
0,150 150,240 240,510 510,600 600,840
does it mean,| to actually
|要真正做到这一点，把这一点连接起来，

1216
00:40:49,070 --> 00:40:50,210
0,180 180,390 390,690 690,870 870,1140
do this join up this

1217
00:40:50,210 --> 00:40:52,970
0,420 600,990 990,1800 1800,2340 2340,2760
this,| this operation, this operation
|这个操作，这个操作基本上创建了一个RDD

1218
00:40:52,970 --> 00:40:54,590
0,330 330,810 810,930 930,1050 1050,1620
basically creates an {RDD -}|
|

1219
00:40:55,010 --> 00:40:55,940
0,300 300,390 390,660 660,780 780,930
and we wonder how does
我们想知道RDD是什么样子的，

1220
00:40:55,940 --> 00:40:57,110
0,90 90,510 510,720 720,1020 1020,1170
the RDD look like,| well
|RDD看起来会像U1，

1221
00:40:57,110 --> 00:40:57,770
0,120 120,420 420,480 480,600 600,660
that RDD is going to

1222
00:40:57,770 --> 00:40:59,750
0,180 180,540 630,990 990,1590 1890,1980
look like {U1 -},| you
|你知道，然后加入队伍，和链接文件，

1223
00:40:59,750 --> 00:41:01,310
0,450 690,900 900,1080 1080,1170 1170,1560
know, and then the joining

1224
00:41:01,310 --> 00:41:03,620
0,330 360,570 570,900 900,1110 1110,2310
of the ranks in the,

1225
00:41:04,480 --> 00:41:05,650
0,180 180,240 240,450 450,780 780,1170
and the link file,| so
|所以会是U1，U1，U2

1226
00:41:05,710 --> 00:41:06,880
0,150 150,300 300,450 450,540 540,1170
it's gonna be {U1 -}

1227
00:41:07,270 --> 00:41:09,130
0,300 300,810 810,1470 1470,1650 1650,1860
{U1 -} U2,| because those
|因为那些是U3传出链路加上U1的等级，

1228
00:41:09,130 --> 00:41:10,390
0,90 90,240 240,510 540,750 750,1260
are { -} {U3 -}

1229
00:41:10,390 --> 00:41:12,130
0,480 480,840 840,1170 1170,1260 1260,1740
outgoing links plus the rank

1230
00:41:12,530 --> 00:41:14,090
0,450 450,630 630,1170 1200,1440 1440,1560
for {U1 -},| which I'm
|我要把它写成r1。

1231
00:41:14,090 --> 00:41:15,470
0,210 210,270 270,420 420,840 840,1380
going to go write as

1232
00:41:15,530 --> 00:41:17,480
0,720 960,1620
{R1 -}.|
|

1233
00:41:17,880 --> 00:41:18,630
0,120 120,300 300,480 480,570 570,750
And that's sort of the
这就是这里正在产生的RDD

1234
00:41:18,630 --> 00:41:20,010
0,360 360,540 540,720 720,1110 1110,1380
RDD that's being produced here|
|

1235
00:41:20,070 --> 00:41:21,300
0,150 150,420 420,690 690,900 900,1230
and so same thing for
所以不管你知道什么U2，都是一样的，

1236
00:41:21,300 --> 00:41:22,410
0,150 150,240 240,540 540,660 660,1110
you know whatever {U2 -},|
|

1237
00:41:22,410 --> 00:41:23,940
0,540 810,990 990,1200 1200,1350 1350,1530
and the one for {U3
U3的排名是U1，R3的排名是3，

1238
00:41:23,940 --> 00:41:26,130
0,600 660,1110 1110,1500 1500,1710 1710,2190
-} is whatever {U1 -}

1239
00:41:27,340 --> 00:41:29,000
0,1350
and

1240
00:41:29,220 --> 00:41:32,180
0,660 960,1230 1230,1560 1590,2310
{you,know} {R3 -} {rank,for,3},|
|

1241
00:41:32,540 --> 00:41:35,030
0,360 360,1260 1260,1650 1650,1950 1950,2490
basically {merges,these} two, as literally
基本上合并这两个文件，就像字面上基于key连接两个文件一样。

1242
00:41:35,030 --> 00:41:36,620
0,360 360,450 450,660 660,1200 1200,1590
joins the two files based

1243
00:41:36,620 --> 00:41:37,460
0,150 150,510
on key.|
|

1244
00:41:38,120 --> 00:41:39,060
0,630
Okay?|
好吧?|

1245
00:41:39,860 --> 00:41:41,210
0,150 150,600 600,660 660,990 990,1350
And then you know it
然后你知道它在上面运行一个Flat Map的计算

1246
00:41:41,210 --> 00:41:42,650
0,420 420,510 510,1050 1050,1140 1140,1440
runs a computation of {flatMap

1247
00:41:42,650 --> 00:41:43,700
0,300 300,480 480,810 810,930 930,1050
-} on this| and that
|而平板地图本身内部有一个链接上的地图，

1248
00:41:43,700 --> 00:41:45,860
0,240 240,450 450,870 870,1380 1380,2160
{flatMap -} itself internally has

1249
00:41:45,890 --> 00:41:47,900
0,360 360,780 780,1020 1020,1650 1860,2010
a map over links,| so
|所以基本上它会被冲掉，

1250
00:41:47,900 --> 00:41:48,980
0,300 300,390 390,510 510,570 570,1080
basically it's going to run

1251
00:41:49,130 --> 00:41:51,080
0,900 930,1590 1590,1680 1680,1890 1890,1950
over,| like the screen is
|就像屏幕要浏览这些列表一样

1252
00:41:51,080 --> 00:41:51,890
0,120 120,180 180,390 390,600 600,810
going to run over these

1253
00:41:51,890 --> 00:41:55,040
0,600 930,1320 1320,2010 2070,2340 2340,3150
lists| and basically {} partition
|基本上将你知道的排名划分或划分到传出的URL。

1254
00:41:55,040 --> 00:41:57,110
0,300 300,840 840,1140 1140,1530 1530,2070
or divide up the rank

1255
00:41:57,200 --> 00:41:58,370
0,150 150,240 240,510 510,750 750,1170
you know to the outgoing

1256
00:41:58,370 --> 00:41:59,260
0,810
urls.|
|

1257
00:41:59,960 --> 00:42:01,130
0,390 390,540 540,630 630,1110 1110,1170
And so it will you
所以你会知道它创造了形式的三元组，

1258
00:42:01,130 --> 00:42:03,800
0,120 120,750 780,1110 1110,1860 2190,2670
know create {} triples {}

1259
00:42:03,800 --> 00:42:06,470
0,120 120,240 240,1020 1290,2160 2340,2670
of the form,| {} let
|那就让我用绿色写吧，

1260
00:42:06,470 --> 00:42:08,030
0,120 120,300 300,420 420,1080 1110,1560
me write this {in,green,then},| {U1
|U1 r1除以2，

1261
00:42:08,030 --> 00:42:12,260
0,720 1110,1980 2190,2490 2490,3180 3540,4230
-} {} {R1 -} divided

1262
00:42:12,260 --> 00:42:13,300
0,150 150,720
by 2,|
|

1263
00:42:15,120 --> 00:42:17,220
0,480 540,1020 1020,1770
and {U1 -}
以及传出链路上的U1或U3，

1264
00:42:17,770 --> 00:42:19,360
0,270 270,660 660,1170 1200,1470 1470,1590
or {U3 -} over the

1265
00:42:19,360 --> 00:42:20,710
0,390 390,720 720,870 870,1140 1140,1350
outgoing links,| so give 1
|所以1给U1，1给U3，

1266
00:42:20,710 --> 00:42:22,360
0,210 210,720 840,1080 1080,1290 1290,1650
to U1, 1 to U3,|
|

1267
00:42:22,360 --> 00:42:25,600
0,540 540,990 1410,1680 1680,2250 2700,3240
here's U3, {R1 -}, divided
这是U3，R1除以2，依此类推，

1268
00:42:25,600 --> 00:42:27,880
0,540 630,990 1140,1710 1710,1950 1950,2280
over 2, etc,| it creates
|它创造了这种形式的三元组，

1269
00:42:27,880 --> 00:42:28,690
0,360 360,450 450,600 600,750 750,810
{triples,of -} this kind of

1270
00:42:28,690 --> 00:42:30,100
0,300 300,420 420,810 810,1020 1020,1410
form,| so basically it computers
|所以基本上，它计算出了在传出边上划分排名的方式

1271
00:42:30,100 --> 00:42:32,320
0,120 120,510 510,1290 1290,1590 1740,2220
the way divides that rank

1272
00:42:32,320 --> 00:42:34,210
0,390 390,510 510,960 960,1560 1710,1890
across the outgoing edges| and
|并让你知道这些排名的值，你知道的向外的边缘，

1273
00:42:34,210 --> 00:42:35,800
0,300 300,420 420,750 750,1140 1140,1590
gives you know the values

1274
00:42:35,800 --> 00:42:38,350
0,120 120,630 930,1860 1890,2490 2490,2550
of these {} ranks you

1275
00:42:38,350 --> 00:42:39,850
0,210 210,660 660,780 780,1110 1110,1500
know to the outgoing edges,|
|

1276
00:42:39,850 --> 00:42:41,230
0,300 300,450 450,750 750,1050 1050,1380
so the outgoing edges, so
所以向外的边缘，所以我们有一个很大的RDD，你知道这个表格，

1277
00:42:41,230 --> 00:42:42,490
0,60 60,210 210,510 510,930 960,1260
we got a big {}

1278
00:42:42,490 --> 00:42:44,380
0,630 750,1050 1050,1440 1440,1590 1590,1890
RDD that has {you,know} this

1279
00:42:44,380 --> 00:42:44,860
0,390
form,|
|

1280
00:42:46,600 --> 00:42:48,700
0,330 330,840 840,1620 1650,1980 1980,2100
that's produced basically, that is
这基本上是产生的，这就是贡献RDD。

1281
00:42:48,700 --> 00:42:51,200
0,90 90,1080 1590,2190
the contributions RDD.|
|

1282
00:42:53,130 --> 00:42:54,360
0,210 210,360 360,420 420,690 690,1230
Then there's a final step
然后是最后一步，

1283
00:42:54,690 --> 00:42:56,520
0,300 300,1200 1230,1410 1410,1530 1530,1830
in the,| {I,think} it first
|我认为它首先要减少关键字，

1284
00:42:56,520 --> 00:42:57,360
0,240 240,300 300,390 390,690 690,840
has to be reduced by

1285
00:42:57,360 --> 00:42:59,310
0,600 840,1020 1020,1380 1380,1770 1770,1950
key,| so basically grabs all
|所以基本上就是把你知道的所有U1加在一起，然后把它们相加，

1286
00:42:59,310 --> 00:43:00,390
0,90 90,270 270,780 780,990 990,1080
the {U1's -} you know

1287
00:43:00,390 --> 00:43:02,370
0,660 840,1020 1020,1500 1500,1800 1800,1980
together and {then,sums} them,| so
|所以基本上这将导致的结果是，

1288
00:43:02,370 --> 00:43:03,750
0,360 360,510 510,750 750,1230 1230,1380
basically this will result is

1289
00:43:03,750 --> 00:43:04,860
0,240 240,360 360,510 510,750 750,1110
that,| you know all the
|你知道所有的权重或分数权重，

1290
00:43:05,160 --> 00:43:08,820
0,1470 1500,2370 2370,2370 2820,3270 3270,3660
{weights -} {or,the} fractional weights,|
|

1291
00:43:08,820 --> 00:43:09,750
0,120 120,240 240,570 570,780 780,930
you know that {} {U1
你知道U1要收到的是加起来的。

1292
00:43:09,750 --> 00:43:10,710
0,240 240,360 360,480 480,540 540,960
-} is going to receive

1293
00:43:10,710 --> 00:43:11,760
0,150 150,330 330,630 630,900
are being added up.|
|

1294
00:43:12,030 --> 00:43:13,200
0,480 480,690 690,870 870,1080 1080,1170
So, {} {U1 -} of
所以，U1当然会受到自身的重量，

1295
00:43:13,200 --> 00:43:14,370
0,240 240,300 300,420 420,480 480,1170
course is going to receive

1296
00:43:14,610 --> 00:43:17,220
0,510 510,840 840,1410 1440,2190 2310,2610
{} weight from itself,| this
|这一个将与U3联系在一起，

1297
00:43:17,220 --> 00:43:18,630
0,510 660,840 840,960 960,1020 1020,1410
one is going to relate

1298
00:43:18,630 --> 00:43:19,920
0,390 390,600 600,1020
from {U3 -},|
|

1299
00:43:20,380 --> 00:43:21,730
0,210 210,630 630,720 720,990 990,1350
and so you will sum
所以你会总结说，

1300
00:43:21,730 --> 00:43:22,600
0,270 270,450 450,570 570,630 630,870
up,| there's going to be
|将会有r1除以2

1301
00:43:22,600 --> 00:43:23,700
0,210 210,780
{R1 -}

1302
00:43:23,990 --> 00:43:26,360
0,450 450,810 810,960 960,1620 1800,2370
{} divided by 2| and
|和R3除以1，

1303
00:43:26,360 --> 00:43:28,160
0,240 240,750 750,1140 1140,1260 1260,1800
{R3 -} divided by 1,|
|

1304
00:43:29,480 --> 00:43:30,620
0,360 360,450 450,600 600,1020 1020,1140
and that was basically the
这基本上就是已经创造出来的总和。

1305
00:43:30,620 --> 00:43:33,040
0,570 1050,1320 1320,1530 1530,2100
sum, that's been created.|
|

1306
00:43:33,510 --> 00:43:34,440
0,180 180,270 270,390 390,570 570,930
And so {that -} {gives,us}
这就给了我们一份金额清单

1307
00:43:34,440 --> 00:43:35,790
0,90 90,330 330,660 660,1230 1230,1350
a list of sums| and
|然后再把它们加起来

1308
00:43:35,790 --> 00:43:36,450
0,180 180,390 390,480 480,540 540,660
then that's when they are

1309
00:43:36,450 --> 00:43:38,490
0,270 270,600 1110,1440 1440,1800 1800,2040
added up| and computed into
|并计算成最终的值。

1310
00:43:38,490 --> 00:43:39,520
0,60 60,330 330,750
a final value.|
|

1311
00:43:43,000 --> 00:43:44,860
0,240 240,660 660,1020 1080,1530 1530,1860
It produces the new ranks
它产生了新的等级RDD，

1312
00:43:44,860 --> 00:43:45,940
0,120 120,480 480,660 660,960 960,1080
{RDD -},| which has the
|它和我们之前看到的形状是一样的，也就是这个形状，

1313
00:43:45,940 --> 00:43:47,860
0,450 450,1020 1050,1410 1410,1590 1590,1920
same shape as the one

1314
00:43:47,860 --> 00:43:49,510
0,90 90,180 180,390 390,990 1020,1650
that we saw before, namely

1315
00:43:49,540 --> 00:43:52,780
0,270 270,960 1590,1800 1800,2430 2760,3240
this shape,| for every web
|对于每个网页，都有一个数字。

1316
00:43:52,780 --> 00:43:54,070
0,390 390,660 660,750 750,840 840,1290
page, there is a number.|
|

1317
00:43:57,670 --> 00:43:58,680
0,120 120,360 360,720
{Does,this} makes sense?|
这有意义吗？|

1318
00:44:00,840 --> 00:44:03,060
0,300 300,780 1140,1650 1650,1800 1800,2220
And so, {} it's interesting
所以，知道这样的描述是很有趣的，

1319
00:44:03,060 --> 00:44:04,590
0,510 540,690 690,1200 1200,1350 1350,1530
to know that sort of

1320
00:44:04,590 --> 00:44:05,940
0,480 480,750 750,1200 1200,1260 1260,1350
description,| so first of all,
|所以首先，你可以看到，

1321
00:44:05,940 --> 00:44:07,530
0,90 90,180 180,360 360,1230 1230,1590
you can see that,| actually
|实际上，对页面排名的描述相当精确

1322
00:44:07,530 --> 00:44:09,390
0,120 120,510 510,630 630,1080 1170,1860
the description of {page,rank} quite

1323
00:44:09,390 --> 00:44:11,940
0,630 1050,1320 1320,1590 1590,1740 1740,2550
precise| and there's one examples,|
|这里有一个例子，|

1324
00:44:11,940 --> 00:44:13,020
0,150 150,270 270,480 480,630 630,1080
this is like if you
这就好比，如果您必须以MapReduce样式运行此应用程序，

1325
00:44:13,200 --> 00:44:14,460
0,240 240,300 300,630 630,990 990,1260
had to run this in

1326
00:44:14,460 --> 00:44:15,810
0,90 90,270 270,600 600,990 990,1350
a {mapreduce -} style,| then
|那就意味着这个循环的每一次迭代，

1327
00:44:15,900 --> 00:44:16,800
0,150 150,300 300,510 510,630 630,900
that would mean that every

1328
00:44:16,800 --> 00:44:19,320
0,690 930,1050 1050,1260 1260,1740 1920,2520
iteration of this loop, {}|
|

1329
00:44:19,320 --> 00:44:19,800
0,120 120,210 210,330 330,390 390,480
at the end of the
在迭代结束时，

1330
00:44:19,800 --> 00:44:21,360
0,510 510,690 690,930 1080,1440 1440,1560
iteration,| you would store the
|您可以将结果存储在文件系统中，

1331
00:44:21,360 --> 00:44:22,680
0,360 360,450 450,540 540,780 780,1320
results in the file system,|
|

1332
00:44:23,010 --> 00:44:24,990
0,240 240,930 930,930 930,1290 1290,1980
and then {} you reread
然后你重读你知道的下一次迭代的结果

1333
00:44:24,990 --> 00:44:27,240
0,90 90,270 270,900 1140,1890 1890,2250
you know the iteration from

1334
00:44:27,240 --> 00:44:28,260
0,210 210,660 660,750 750,810 810,1020
the result for the next

1335
00:44:28,260 --> 00:44:31,320
0,510 570,1050 1290,1890 1890,2490 2490,3060
iteration| and in {} in
|在这个Spark系统中，使用每一次迭代都会直接耗尽内存，将结果留在内存中，

1336
00:44:31,350 --> 00:44:32,360
0,390 390,930
this {}

1337
00:44:32,730 --> 00:44:35,100
0,360 360,840 930,1380 1380,1830 1830,2370
spark system, uses every iteration

1338
00:44:35,100 --> 00:44:36,270
0,360 360,630 630,750 750,810 810,1170
runs straight out of memory,

1339
00:44:36,270 --> 00:44:37,500
0,330 330,720 720,810 810,1140 1140,1230
leaves results in memory,| so
|这样下一次迭代就可以在那里找到它，

1340
00:44:37,500 --> 00:44:38,460
0,150 150,210 210,480 480,840 840,960
that the next iteration could

1341
00:44:38,460 --> 00:44:39,390
0,150 150,240 240,390 390,630 630,930
pick it up right there,|
|

1342
00:44:40,050 --> 00:44:41,430
0,150 150,930 960,1080 1080,1200 1200,1380
and furthermore you know these
此外，您知道这些链接文件在所有迭代之间是共享的。

1343
00:44:41,430 --> 00:44:43,770
0,360 360,960 1200,1500 1500,1950 1950,2340
links file {} is shared

1344
00:44:43,770 --> 00:44:45,160
0,240 240,390 390,480 480,1290
among all the iterations.|
|

1345
00:44:46,380 --> 00:44:47,430
0,270 270,660 720,840 840,990 990,1050
Okay, so to get a
好的，为了更有意义一点，

1346
00:44:47,430 --> 00:44:48,420
0,150 150,240 240,420 420,810 810,990
little bit more sense,| like
|就像你知道为什么，还有一个很酷的，

1347
00:44:48,420 --> 00:44:49,650
0,90 90,210 210,690 690,870 870,1230
you know why, there's also

1348
00:44:49,650 --> 00:44:51,840
0,120 120,810 930,1830
a cool, {}|
|

1349
00:44:52,120 --> 00:44:53,290
0,240 240,450 450,750 750,960 960,1170
the way to look at
看待这场比赛的方法是实际查看这场比赛的谱系图。

1350
00:44:53,290 --> 00:44:54,190
0,180 180,330 330,540 540,750 750,900
is to actually look at

1351
00:44:54,190 --> 00:44:55,780
0,420 450,840 840,1320
the lineage graph

1352
00:44:56,160 --> 00:44:58,080
0,360 360,510 510,900 900,1590
for this particular competition.|
|

1353
00:44:59,770 --> 00:45:00,610
0,210 210,390 390,540 540,630 630,840
So let's look at the
那么让我们来看一下谱系图，

1354
00:45:00,610 --> 00:45:02,960
0,300 300,660 660,1200 1230,2010
lineage graph for {},|
|

1355
00:45:06,440 --> 00:45:08,270
0,240 240,540 540,840 840,1140 1140,1830
so here's the lineage graph
这是For页面排名的谱系图。

1356
00:45:08,300 --> 00:45:12,260
0,930 1260,2070 2340,3630
for {} the

1357
00:45:12,950 --> 00:45:13,920
0,660
{}

1358
00:45:14,180 --> 00:45:15,200
0,180 180,660
for {page,rank}.|
|

1359
00:45:16,380 --> 00:45:17,220
0,300 300,420 420,480 480,660 660,840
And so a couple things
所以我想指出几件事，

1360
00:45:17,220 --> 00:45:19,080
0,60 60,210 210,1290 1320,1560 1560,1860
I want to point out,|
|

1361
00:45:19,380 --> 00:45:20,220
0,330 330,420 420,570 570,690 690,840
first of all, so the
首先，这些谱系图像是动态的，

1362
00:45:20,220 --> 00:45:21,840
0,240 240,630 630,780 780,1350 1350,1620
lineage graphs like dynamic,| almost
|几乎看起来，

1363
00:45:21,840 --> 00:45:23,240
0,120 570,1170
it looks,|
|

1364
00:45:24,130 --> 00:45:25,160
0,720

1365
00:45:27,010 --> 00:45:28,520
0,240 240,450 450,600 600,1050
{you,know} just keep growing
你知道，你知道，随着迭代的次数不断增长，

1366
00:45:28,970 --> 00:45:29,780
0,180 180,390 390,450 450,720 720,810
{you,know} with the number of

1367
00:45:29,780 --> 00:45:32,510
0,720 1170,1740 1740,2160 2160,2460 2460,2730
iterations,| {} and so as
|因此，当你知道的时间表基本上计算出新的阶段时，

1368
00:45:32,510 --> 00:45:33,860
0,60 60,690 690,750 750,930 930,1350
the schedule you know basically

1369
00:45:33,860 --> 00:45:36,800
0,450 450,660 660,1230 1410,2280 2280,2940
computes does new stages,| then,
|然后，它继续前进，

1370
00:45:36,800 --> 00:45:38,240
0,0 0,630 630,780 780,1170 1170,1440
{} it { -} keeps

1371
00:45:38,240 --> 00:45:39,500
0,270 270,600 810,1020 1020,1140 1140,1260
going,| and {you,know} we can
|你知道我们可以看到阶段会是什么，对吗，

1372
00:45:39,500 --> 00:45:40,310
0,150 150,300 300,390 390,720 720,810
see what the stages are

1373
00:45:40,310 --> 00:45:42,350
0,180 180,390 390,720 720,1230 1440,2040
gonna be, correct,| because, {}
|因为，你知道，循环的每一次迭代都是一个阶段

1374
00:45:42,350 --> 00:45:43,360
0,120 120,180 330,540 540,750
you know sort of,

1375
00:45:44,100 --> 00:45:46,320
0,120 120,360 360,690 690,1380 1890,2220
you know every iteration of

1376
00:45:46,320 --> 00:45:48,210
0,390 390,990 1080,1140 1140,1620 1650,1890
a loop {} is {}

1377
00:45:48,210 --> 00:45:49,770
0,330 330,720 720,900 900,1170 1170,1560
one stage| and will basically
|并且基本上会将你知道的变换的一部分附加到谱系图中。

1378
00:45:49,770 --> 00:45:52,710
0,420 420,1080 1080,1080 2100,2610 2610,2940
append {you,know} {} parts of

1379
00:45:53,070 --> 00:45:55,470
0,690 690,900 900,1500 1890,2130 2130,2400
transformations {} to the lineage

1380
00:45:55,470 --> 00:45:56,100
0,420
graph.|
|

1381
00:45:56,500 --> 00:45:57,190
0,180 180,270 270,390 390,630 630,690
So we see here's the
所以我们看到这是输入文件，这是链接

1382
00:45:57,190 --> 00:45:59,890
0,300 300,930 1260,1560 1560,1980 1980,2700
input file, {} here's links|
|

1383
00:46:00,220 --> 00:46:01,360
0,450 450,570 570,660 660,870 870,1140
and as we saw the
正如我们所看到的，这些链接实际上创造了一些链接，

1384
00:46:01,390 --> 00:46:03,220
0,360 360,570 570,930 930,1470 1530,1830
links actually created ones,| then
|然后保存在内存中，

1385
00:46:03,220 --> 00:46:05,050
0,540 540,690 690,1230 1260,1410 1410,1830
persisted in memory,| we're not
|我们不在这上面，坚持在记忆中

1386
00:46:05,050 --> 00:46:06,430
0,90 90,360 360,690 690,840 840,1380
on this, persist in memory|
|

1387
00:46:06,610 --> 00:46:07,870
0,150 150,240 240,510 510,1080 1080,1260
and is being reused many
并被多次重复使用，

1388
00:46:07,870 --> 00:46:09,730
0,240 240,630 630,960 990,1620 1620,1860
many times,| like every loop
|就像每一次循环迭代一样，基本上被重用的等级

1389
00:46:09,730 --> 00:46:12,250
0,570 780,1260 1260,1650 1650,1890 1890,2520
iteration basically {the,ranks} being reused|
|

1390
00:46:12,550 --> 00:46:13,750
0,270 270,360 360,660 660,900 900,1200
and so again, we're compared
因此，再一次，我们被比作地图还原，

1391
00:46:13,750 --> 00:46:14,950
0,150 150,510 510,900 900,1110 1110,1200
to {mapreduce -},| if you
|如果您必须将此代码写入MapReduceStyle，

1392
00:46:14,950 --> 00:46:15,910
0,120 120,210 210,600 600,750 750,960
have to {write,this} to {mapreduce

1393
00:46:15,910 --> 00:46:17,230
0,270 270,810 840,1020 1020,1170 1170,1320
-} style,| you don't get
|你不明白我们用的是什么

1394
00:46:17,230 --> 00:46:18,160
0,150 150,330 330,690 720,840 840,930
that we use| and so
|因此，这当然是非常出色的表现，

1395
00:46:18,160 --> 00:46:19,210
0,210 210,330 330,570 570,690 690,1050
that's of course going to

1396
00:46:19,360 --> 00:46:22,240
0,780 780,1590 1590,1980 2130,2790 2790,2880
tremendously performance,| because links you
|因为正如我们之前所说的，链接，

1397
00:46:22,240 --> 00:46:23,470
0,120 120,270 270,480 480,660 660,1230
know as we said before,|
|

1398
00:46:23,560 --> 00:46:25,510
0,150 150,300 300,630 630,1410 1410,1950
it's like just gigantic file,|
它就像一个巨大的文件，|

1399
00:46:25,510 --> 00:46:27,250
0,180 180,510 510,1170 1170,1350 1350,1740
that basically corresponds to one
这基本上相当于宇宙中每个网页的一行。

1400
00:46:27,250 --> 00:46:29,020
0,420 420,690 690,1290 1290,1470 1470,1770
line for every web page

1401
00:46:29,020 --> 00:46:30,250
0,300 300,540 540,660 660,720 720,1230
in the in the universe.|
|

1402
00:46:32,100 --> 00:46:33,960
0,840 840,1230 1230,1380 1380,1530 1530,1860
Another interesting thing to observe
在这里观察到的另一件有趣的事情是

1403
00:46:33,960 --> 00:46:36,300
0,330 330,720 1080,1740 1890,2160 2160,2340
here is that| we see
|我们在这里看到了广泛的依赖关系，对吧，

1404
00:46:36,300 --> 00:46:37,590
0,30 30,270 270,840 840,1080 1110,1290
a wide dependencies here, right,|
|

1405
00:46:37,590 --> 00:46:38,910
0,150 150,240 240,360 360,570 570,1320
this is a wide dependency,|
这是一种广泛的依赖，|

1406
00:46:41,470 --> 00:46:43,180
0,450 450,690 690,780 780,1020 1020,1710
could be the wide dependency,|
可能是广泛的依赖，|

1407
00:46:43,270 --> 00:46:43,990
0,330 330,420 420,450 450,600 600,720
will be a little bit
稍后我会对此做得更复杂一些，

1408
00:46:43,990 --> 00:46:45,100
0,150 150,660 660,900 900,1020 1020,1110
more sophisticated about this in

1409
00:46:45,100 --> 00:46:46,060
0,60 60,510
a second,|
|

1410
00:46:46,260 --> 00:46:48,750
0,630 840,1140 1140,1500 1500,1680 1680,2490
{} because basically these contributions
因为基本上这些贡献，你知道，当我们贡献中间结果时，

1411
00:46:48,750 --> 00:46:49,770
0,120 120,210 210,420 420,540 540,1020
you know when we contribute

1412
00:46:49,770 --> 00:46:52,560
0,540 570,1170 1230,1770 1770,2310 2520,2790
to the intermediate result, {}|
|

1413
00:46:52,560 --> 00:46:54,120
0,180 180,420 420,510 510,960 960,1560
it is a join across
它是跨级别和链接连接，

1414
00:46:54,120 --> 00:46:55,420
0,390 390,540 540,1140
ranks and links,|
|

1415
00:46:55,800 --> 00:46:57,570
0,390 390,930 1020,1230 1230,1500 1500,1770
and so {} it needs
因此它需要来自链接的分区，

1416
00:46:57,570 --> 00:47:01,050
0,300 300,1140 1260,2430 2430,2820 2820,3480
the partitions {} from links,|
|

1417
00:47:01,110 --> 00:47:03,300
0,210 210,540 540,990 990,1590 1620,2190
and {it,needs} partitions from ranks
而且它需要从行列到基本上的分区来计算贡献的分区，对不起。

1418
00:47:03,300 --> 00:47:06,390
0,300 300,510 510,1140 1380,1710 1710,3090
{to,basically} to compute {} partition

1419
00:47:06,390 --> 00:47:10,530
0,1980 2040,2640 2820,3060 3060,3570 3600,4140
for contribute, {contrib -} RDD,

1420
00:47:10,530 --> 00:47:11,140
0,390
sorry.|
|

1421
00:47:11,760 --> 00:47:13,530
0,510 720,930 930,1110 1110,1290 1290,1770
{} So that might require
因此，这可能需要您从网络通信中了解。

1422
00:47:13,530 --> 00:47:14,460
0,120 120,270 270,660 660,840 840,930
you know from from a

1423
00:47:14,460 --> 00:47:17,280
0,270 270,930 1530,2250 2340,2550 2550,2820
network communication.| But it turns
|但事实证明，它们有一种巧妙的优化，

1424
00:47:17,280 --> 00:47:20,040
0,450 720,990 990,1410 1410,2280 2280,2760
out they have {sort,of,a} clever

1425
00:47:20,040 --> 00:47:21,180
0,900
optimization,|
|

1426
00:47:23,840 --> 00:47:25,370
0,360 360,810 810,1020 1020,1110 1110,1530
and this is in response
这是对早些时候关于分区的问题的回应

1427
00:47:25,370 --> 00:47:26,810
0,120 120,210 210,510 510,840 840,1440
to an earlier question about

1428
00:47:26,900 --> 00:47:29,930
0,420 420,1110 1320,1740 1740,2820 2880,3030
{} partitioning| {} the you
|您可以使用散列分区指定要分区和RDD。

1429
00:47:29,930 --> 00:47:31,280
0,120 120,780 780,990 990,1170 1170,1350
can specify you want to

1430
00:47:31,520 --> 00:47:34,040
0,810 1200,1800 1890,2280 2280,2400 2400,2520
partition {} and {RDD -

1431
00:47:34,040 --> 00:47:35,750
0,540 810,1050 1050,1350 1350,1440 1440,1710
-}, {} using a hash

1432
00:47:35,750 --> 00:47:36,540
0,540
partition.|
|

1433
00:47:38,960 --> 00:47:40,850
0,390 390,930 930,1110 1110,1320 1320,1890
And what does that mean
这意味着，

1434
00:47:40,880 --> 00:47:43,820
0,390 390,900 900,1620 1650,2610 2640,2940
is that,| the links and
|链接和排名文件，这两个RDDS将以相同的方式进行分区

1435
00:47:43,820 --> 00:47:45,500
0,270 270,900 1230,1380 1380,1500 1500,1680
ranks file, { -} these

1436
00:47:45,500 --> 00:47:47,090
0,150 150,930 1110,1410 1410,1530 1530,1590
two RDDs are going to

1437
00:47:47,090 --> 00:47:48,050
0,120 120,510 510,600 600,660 660,960
be partitioned in the same

1438
00:47:48,050 --> 00:47:49,310
0,240 240,330 330,510 510,780 780,1260
way| and they're actually partition
|它们实际上是按键或散列键分区的。

1439
00:47:49,310 --> 00:47:50,630
0,240 240,810 870,1110 1110,1230 1230,1320
by key or by the

1440
00:47:50,630 --> 00:47:51,950
0,300 300,450 450,810 840,1050 1050,1320
hash {} key.| So we
|所以我们回过头来看之前的照片，

1441
00:47:51,950 --> 00:47:54,080
0,150 150,630 660,1230 1230,1800 1800,2130
look back at our previous

1442
00:47:54,080 --> 00:47:54,860
0,600
picture,|
|

1443
00:47:55,210 --> 00:47:58,330
0,360 360,450 450,1080 1380,2250 2400,3120
{} the keys for {}
你知道，排名的关键是U1 U2 U3，

1444
00:47:58,360 --> 00:47:59,980
0,690 720,840 840,1140 1140,1440 1440,1620
ranks, you know, are {U1

1445
00:47:59,980 --> 00:48:02,350
0,270 270,900 900,1320 1590,1920 1920,2370
-} {U2,U3 -},| the keys
|链接的密钥。

1446
00:48:02,350 --> 00:48:04,500
0,720 960,1860
for {}

1447
00:48:04,620 --> 00:48:07,200
0,330 330,1290 1470,2130 2130,2280 2280,2580
{} {} links.| Okay, so
|好的，U1，U2，U3排名的关键，

1448
00:48:07,230 --> 00:48:08,370
0,120 120,360 360,540 540,900 900,1140
the key for ranks {U1

1449
00:48:08,370 --> 00:48:10,620
0,180 180,480 480,930 1080,1530 1530,2250
-} U2 U3,| keys for
|链接的密钥也是U1 U2 U3。

1450
00:48:10,710 --> 00:48:12,570
0,720 720,870 870,1350 1350,1470 1470,1860
links are also {U1 -}

1451
00:48:12,570 --> 00:48:13,800
0,570 570,960
U2 U3.|
|

1452
00:48:14,140 --> 00:48:16,390
0,240 240,990 1080,1530 1530,1890 1890,2250
And basically, {} the {client,for}
基本上，优化的客户端，

1453
00:48:16,390 --> 00:48:17,650
0,570 570,720 720,810 810,870 870,1260
optimization,| this is a standard
|这是数据库文献中的标准优化，

1454
00:48:17,650 --> 00:48:20,140
0,780 960,1290 1290,1500 1500,1890 1890,2490
optimization from the database literature,|
|

1455
00:48:20,320 --> 00:48:21,580
0,240 240,480 480,630 630,780 780,1260
is that if you partition
如果你按关键字划分链接和排名，

1456
00:48:21,580 --> 00:48:23,560
0,720 720,960 960,1260 1260,1440 1440,1980
links and ranks by key,|
|

1457
00:48:23,650 --> 00:48:25,060
0,540 540,600 600,750 750,990 990,1410
then you know this one
那么你就知道这台机器上会有U1，

1458
00:48:25,060 --> 00:48:25,630
0,120 120,240 240,300 300,480 480,570
is going to have {U1

1459
00:48:25,630 --> 00:48:27,280
0,330 330,450 450,630 630,1230
-} on one machine,|
|

1460
00:48:28,310 --> 00:48:29,450
0,180 180,390 390,540 540,690 690,1140
now, maybe this is U2
现在，也许这是一台机器上的U2，

1461
00:48:29,450 --> 00:48:30,660
0,90 90,270 270,810
on one machine,|
|

1462
00:48:32,680 --> 00:48:34,060
0,540 570,1080 1080,1200 1200,1320 1320,1380
and ranks just going to
和排名将会有同样的事情，

1463
00:48:34,060 --> 00:48:35,020
0,120 120,180 180,420 420,810 810,960
have the same thing,| just
|只需在一台机器上安装U1

1464
00:48:35,020 --> 00:48:36,100
0,120 120,360 360,450 450,900 930,1080
gonna have {U1 -} on

1465
00:48:36,100 --> 00:48:37,240
0,180 180,630 630,720 720,780 780,1140
one machine| and in fact
|事实上，你知道它会在同一台机器上有U1，

1466
00:48:37,240 --> 00:48:37,750
0,90 90,210 210,330 330,450 450,510
you know it's going to

1467
00:48:37,750 --> 00:48:38,740
0,210 210,420 420,690 690,750 750,990
have U1 on the same

1468
00:48:38,740 --> 00:48:42,130
0,600 960,1620 1650,2340 2370,3030 3030,3390
machine,| as links {} one
|这句话把U2和U3联系在了一起。

1469
00:48:42,130 --> 00:48:43,420
0,360 360,540 540,1020 1020,1140 1140,1290
saying for U2 and {U3

1470
00:48:43,420 --> 00:48:43,980
0,330
-}.|
|

1471
00:48:45,710 --> 00:48:48,020
0,330 330,750 750,1320 1320,1560 1560,2310
So even though this join
因此，即使该连接在[感知上]是广泛的依赖，

1472
00:48:48,170 --> 00:48:51,050
0,540 540,1170 1170,1770 1770,2010 2010,2880
{} is [perceptually] wide dependency,|
|

1473
00:48:51,110 --> 00:48:52,490
0,360 360,540 540,720 720,840 840,1380
{} it can be executed
它可以像狭义依赖一样执行，

1474
00:48:52,490 --> 00:48:53,990
0,210 210,300 300,600 600,1260 1260,1500
like a narrow dependency,| because
|因为基本上要计算这两个的连接，

1475
00:48:53,990 --> 00:48:55,820
0,660 870,1020 1020,1620 1650,1740 1740,1830
basically to compute you know

1476
00:48:55,820 --> 00:48:57,140
0,150 150,480 480,570 570,780 780,1320
the join of these two,|
|

1477
00:48:57,290 --> 00:48:58,790
0,390 390,690 690,810 810,930 930,1500
{} for the {U1 -}
对于第一分区的U1，对于P1，

1478
00:48:59,030 --> 00:49:00,920
0,210 210,540 570,840 840,1380
for the first partition,

1479
00:49:01,310 --> 00:49:02,930
0,510 510,690 690,1140 1290,1440 1440,1620
for {P1 },| you only
|您只需查看链接的分区P1

1480
00:49:02,930 --> 00:49:03,470
0,180 180,240 240,420 420,480 480,540
have to look at the

1481
00:49:03,470 --> 00:49:05,060
0,540 540,750 750,1020 1020,1140 1140,1590
partition {P1 -} of links|
|

1482
00:49:05,060 --> 00:49:06,470
0,210 210,420 420,1020 1020,1170 1170,1410
and {P1 -} {P1 -}
和职级的P1和P1，

1483
00:49:06,470 --> 00:49:08,540
0,210 210,810 1020,1500 1500,1980 1980,2070
of ranks,| {} because you
|因为你知道密钥是以相同的方式散列到同一台机器上的。

1484
00:49:08,540 --> 00:49:09,770
0,120 120,360 360,720 720,870 870,1230
know the keys are hashed

1485
00:49:09,770 --> 00:49:10,800
0,90 90,180 180,420 420,750
in the same way

1486
00:49:11,010 --> 00:49:12,200
0,150 150,210 210,420 420,990
to the same machine.|
|

1487
00:49:12,640 --> 00:49:15,400
0,390 390,600 600,990 1020,1470 1470,2760
{} And so the scheduler
因此调度器或程序员实际上可以指定这些散列分区，

1488
00:49:15,400 --> 00:49:16,630
0,330 330,510 510,930 930,1020 1020,1230
or the programmer can actually

1489
00:49:16,630 --> 00:49:18,910
0,420 420,570 570,810 810,1440 1740,2280
specify these hash partitions,| scheduler
|调度程序看到，哈，您知道联接实际上使用散列分区，

1490
00:49:18,910 --> 00:49:20,800
0,450 480,840 840,960 960,1140 1140,1890
sees, ha, you know the

1491
00:49:20,830 --> 00:49:22,960
0,420 420,1050 1050,1440 1440,1650 1650,2130
join actually uses hash partitions,|
|

1492
00:49:22,960 --> 00:49:24,550
0,90 90,270 270,960 960,1470 1470,1590
the hash partitions that are
相同的散列分区，

1493
00:49:24,550 --> 00:49:26,650
0,90 90,600 750,900 900,1590 1620,2100
the same,| and therefore actually
|因此实际上并不需要如此广泛的依赖，

1494
00:49:26,650 --> 00:49:27,520
0,240 240,480 480,570 570,690 690,870
don't have to do this

1495
00:49:27,520 --> 00:49:29,230
0,450 480,1200 1200,1290 1290,1530 1530,1710
wide dependency,| I don't have
|我不需要像MapReduce那样做一个完整的屏障，

1496
00:49:29,230 --> 00:49:30,610
0,90 90,300 300,480 480,840 840,1380
to do a complete barrier

1497
00:49:30,610 --> 00:49:32,350
0,180 180,480 480,1110 1230,1650 1650,1740
as {mapreduce -},| but I
|但我只能把这当做狭隘的依赖。

1498
00:49:32,350 --> 00:49:33,280
0,120 120,450 450,690 690,840 840,930
can just treat this as

1499
00:49:33,280 --> 00:49:34,300
0,120 120,300 300,870
an narrow dependency.|
|

1500
00:49:35,120 --> 00:49:37,250
0,480 480,780 1020,1260 1260,1770 1800,2130
{} So, {} that's pretty
所以，这很酷，

1501
00:49:37,250 --> 00:49:40,490
0,510 1290,1920 2130,2850 2850,3000 3000,3240
cool,| {} then you know
|然后你再一次知道，

1502
00:49:40,490 --> 00:49:42,230
0,510 510,510 510,1380 1380,1440 1440,1740
again,| {} if a machine
|如果一台机器出现故障，对吧，

1503
00:49:42,230 --> 00:49:43,340
0,390 390,810 810,870 870,1080 1080,1110
fails, right,| we talked a
|我们早些时候谈过这个问题，

1504
00:49:43,340 --> 00:49:45,080
0,210 210,330 330,540 540,660 660,1740
little bit about it earlier,|
|

1505
00:49:45,110 --> 00:49:47,540
0,180 180,330 330,750 780,1350 1560,2430
that might be a painful,|
这可能是一个痛苦的，|

1506
00:49:47,540 --> 00:49:48,740
0,540 570,720 720,840 840,1020 1020,1200
because you may have to
因为您可能需要重新执行许多循环或一次迭代

1507
00:49:48,740 --> 00:49:50,480
0,180 180,630 630,870 870,1470 1500,1740
{reexecute -} many loops or

1508
00:49:50,480 --> 00:49:53,450
0,330 330,1110 1440,1800 1800,2250 2370,2970
one iterations| and so, {}
|所以，你知道，如果你可能会认真地写这篇文章，

1509
00:49:53,450 --> 00:49:54,020
0,120 120,180 180,300 300,420 420,570
you know if you would

1510
00:49:54,020 --> 00:49:55,100
0,270 270,450 450,600 600,750 750,1080
probably write this for real,|
|

1511
00:49:55,100 --> 00:49:57,050
0,480 660,1140 1140,1290 1290,1860 1860,1950
then, {} the programmer would
然后，程序员可能会说，

1512
00:49:57,050 --> 00:49:58,520
0,330 330,510 510,690 690,960 960,1470
probably say,| like maybe every
|就像你知道的每10次迭代，基本上就是检查点，

1513
00:49:58,520 --> 00:50:01,580
0,90 90,210 210,480 480,1320
you know 10 iterations

1514
00:50:02,250 --> 00:50:03,940
0,150 150,270 270,660 660,1380
you know basically checkpoint,|
|

1515
00:50:11,260 --> 00:50:12,040
0,180 180,360 360,450 450,660 660,780
so that you don't have
这样你就不必从头开始重新计算了。

1516
00:50:12,040 --> 00:50:13,690
0,90 90,300 300,960 960,990 990,1650
to {recompute - -} {}

1517
00:50:13,720 --> 00:50:15,220
0,510 510,660 660,750 750,930 930,1500
computation all the way from

1518
00:50:15,250 --> 00:50:16,240
0,210 210,270 270,630
from the beginning.|
|

1519
00:50:16,540 --> 00:50:17,470
0,180 180,330 330,450 450,630 630,930
Oh, so we don't actually
哦，所以我们并不是每次都重新计算链接或其他东西，对吧，

1520
00:50:17,470 --> 00:50:19,030
0,180 180,600 600,930 930,1050 1050,1560
{recompute -} links or anything

1521
00:50:19,030 --> 00:50:20,770
0,240 240,720 840,1260 1470,1650 1650,1740
each time, right,| like we
|好像我们不坚持一样，抱歉。

1522
00:50:20,770 --> 00:50:22,280
0,270 270,840 840,1170
don't persist, sorry.|
|

1523
00:50:22,870 --> 00:50:23,710
0,150 150,270 270,540 540,690 690,840
We don't {persist -}, no,
我们不坚持，不，一点也不，

1524
00:50:23,710 --> 00:50:25,480
0,210 210,300 300,630 1320,1560 1560,1770
not at all,| the only
|唯一坚持下来的只有一个是链接，对吧，

1525
00:50:25,480 --> 00:50:26,470
0,120 120,210 210,330 330,870 870,990
thing that was persist with

1526
00:50:26,470 --> 00:50:27,700
0,180 180,420 420,570 570,930 930,1230
only one was links, right,|
|

1527
00:50:27,700 --> 00:50:28,330
0,180 180,240 240,330 330,510 510,630
this is the only thing
这是唯一一件可以说是持久化的事情。

1528
00:50:28,330 --> 00:50:29,920
0,150 150,450 600,1170 1170,1230 1230,1590
that was kind of persist

1529
00:50:29,920 --> 00:50:30,660
0,390
call.|
|

1530
00:50:31,100 --> 00:50:33,020
0,150 150,300 300,480 480,1110 1500,1920
Oh, we do persistent.| Links,
哦，我们做坚持不懈。|链接，我们做到了。

1531
00:50:33,020 --> 00:50:34,920
0,90 90,450 780,1260
we do.| Okay.|
|好吧。|

1532
00:50:35,760 --> 00:50:37,470
0,300 300,480 480,570 570,1080 1080,1710
But not the intermediate RDDs,|
但不是中间的RDDS，|

1533
00:50:38,470 --> 00:50:39,490
0,210 210,360 360,690 690,930 930,1020
because they're basically new {RDD
因为它们基本上每次都是新的RDD，

1534
00:50:39,490 --> 00:50:41,170
0,300 300,510 510,780 780,1320 1350,1680
-} every time,| like ranks
|就像第一级是一个新的RDD，

1535
00:50:41,170 --> 00:50:42,790
0,450 450,690 690,840 840,930 930,1620
one {is,a} new RDD,| ranks
|等级2是一个新的RDD。

1536
00:50:42,790 --> 00:50:44,050
0,390 390,570 570,780 780,870 870,1260
{2,is} a new {RDD -}.|
|

1537
00:50:45,990 --> 00:50:47,640
0,690 780,1140 1140,1230 1230,1440 1440,1650
{} But you may want
但您可能想要保存它们，您知道偶尔会将它们存储在HDFS中，

1538
00:50:47,640 --> 00:50:48,720
0,180 180,540 540,870 870,930 930,1080
to persist them, you know

1539
00:50:48,720 --> 00:50:51,210
0,630 630,1260 1260,1560 1560,1890 1890,2490
occasionally and stored in hdfs,|
|

1540
00:50:51,210 --> 00:50:52,410
0,150 150,450 690,930 930,1080 1080,1200
so that {} if you
因此，如果你不得不失败，你不必回到迭代循环，迭代零来计算所有的东西。

1541
00:50:52,410 --> 00:50:53,730
0,120 120,540 570,720 720,1230 1230,1320
have to a failure, you

1542
00:50:53,730 --> 00:50:54,480
0,150 150,240 240,330 330,450 450,750
don't have to go back

1543
00:50:54,480 --> 00:50:56,370
0,180 180,660 660,1140 1140,1500 1500,1890
to iteration loop, iteration zero

1544
00:50:56,370 --> 00:50:57,800
0,180 480,780 780,1140
to compute everything.|
|

1545
00:51:01,370 --> 00:51:02,420
0,210 210,330 330,450 450,630 630,1050
Okay, does this make sense?|
好的，这说得通吗？|

1546
00:51:03,350 --> 00:51:05,750
0,210 210,660 660,780 780,1440 1530,2400
Oh, sorry, the different contribs,
哦，对不起，不同的工具，它们可以并行计算吗？

1547
00:51:05,750 --> 00:51:07,010
0,300 300,510 510,630 630,1080 1080,1260
can they be computed in

1548
00:51:07,010 --> 00:51:08,020
0,780
parallel?|
|

1549
00:51:08,490 --> 00:51:10,460
0,420 420,690 690,1230 1230,1680
On different partitions, yes.|
在不同的分区上，是的。|

1550
00:51:11,500 --> 00:51:13,720
0,570 690,1110 1110,1740 1740,1950 1950,2220
{} Because there's like this
因为有一条线是垂直向下的。

1551
00:51:13,720 --> 00:51:15,610
0,300 300,450 450,840 840,1350 1350,1890
line that goes vertically down.|
|

1552
00:51:15,700 --> 00:51:17,740
0,150 150,630 630,1170 1170,1560 1560,2040
That vertically down, {} it's
垂直向下，是管道，对，

1553
00:51:17,740 --> 00:51:18,800
0,660
pipelines,

1554
00:51:19,440 --> 00:51:21,510
0,690 690,1470 1470,1650 1650,1770 1770,2070
right,| there's just two types
|只有两种类型的并行，

1555
00:51:21,510 --> 00:51:23,490
0,60 60,660 660,840 840,1200 1200,1980
of parallelism,| there stage parallelism,|
|在那里有阶段并行，|

1556
00:51:23,550 --> 00:51:24,270
0,180 180,360 360,480 480,630 630,720
and there is sort of
不同分区之间存在某种并行性，

1557
00:51:24,270 --> 00:51:26,580
0,600 600,840 840,1110 1110,1800 2070,2310
parallelism between different partitions,| and
|我们可以考虑这件事，你知道整个事情，

1558
00:51:26,580 --> 00:51:27,360
0,90 90,210 210,360 360,600 600,780
we could think about this

1559
00:51:27,360 --> 00:51:28,860
0,540 690,810 810,990 990,1260 1260,1500
thing, you know this whole

1560
00:51:28,860 --> 00:51:30,960
0,540 780,1110 1110,1560 1560,1830 1830,2100
thing,| like running many many
|就像在不同的分区上运行多次一样。

1561
00:51:30,960 --> 00:51:33,000
0,570 570,960 960,1200 1200,1890
times on different partitions.|
|

1562
00:51:45,300 --> 00:51:46,740
0,270 270,570 600,870 870,1320 1320,1440
So in this case, the
因此，在这种情况下，在最后的收集将是唯一的地方，我们有一个宽。

1563
00:51:46,740 --> 00:51:48,240
0,600 600,780 780,960 960,1260 1260,1500
collect at the very end

1564
00:51:48,240 --> 00:51:49,290
0,180 180,300 300,420 420,840 840,1050
will be the only place

1565
00:51:49,290 --> 00:51:50,310
0,120 120,240 240,390 390,510 510,1020
where we have a wide.|
|

1566
00:51:50,520 --> 00:51:52,980
0,870 870,1320 1320,1860 1980,2130 2130,2460
Yeah, exactly exactly,| the collect
是的，就是这样，|收藏品是唯一的收藏品

1567
00:51:52,980 --> 00:51:53,820
0,60 60,180 180,390 390,660 660,840
is the only one that's

1568
00:51:53,820 --> 00:51:54,860
0,360
gonna,|
|

1569
00:51:55,080 --> 00:51:56,220
0,150 150,480 480,900 900,990 990,1140
yeah whatever we're we have
是的，不管我们是什么，我们有更多的正确的分区，

1570
00:51:56,220 --> 00:51:57,740
0,270 270,750 750,1230
more partitions correct,|
|

1571
00:51:58,420 --> 00:51:59,320
0,300 300,540 540,570 570,840 840,900
I making a mess of
我把这张照片搞砸了，

1572
00:51:59,320 --> 00:52:00,370
0,210 210,600 600,720 720,930 930,1050
this picture,| but that is
|但这必须从每个人那里得到。

1573
00:52:00,370 --> 00:52:02,410
0,420 600,840 840,1290 1740,1950 1950,2040
gonna have to get it

1574
00:52:02,410 --> 00:52:03,380
0,120 120,600
from everyone.|
|

1575
00:52:09,120 --> 00:52:10,920
0,510 960,1080 1080,1290 1290,1410 1410,1800
Okay, I hope that everyone
好的，我希望大家都能看到这真的很酷，对吧。

1576
00:52:10,920 --> 00:52:11,910
0,300 300,450 450,570 570,810 810,990
sees this is actually pretty

1577
00:52:11,910 --> 00:52:12,960
0,360 360,690
cool, right.|
|

1578
00:52:13,300 --> 00:52:14,590
0,600 600,690 690,810 810,1140 1140,1290
{} You know just by
你知道，仅仅通过表达这些计算

1579
00:52:14,590 --> 00:52:16,600
0,600 600,720 720,1440 1440,1830 1830,2010
expressing these computations| and sort
|以及某种谱系图或数据流计算，

1580
00:52:16,600 --> 00:52:17,710
0,90 90,360 360,690 690,990 990,1110
of {} lineage graph or

1581
00:52:17,710 --> 00:52:19,600
0,270 270,480 480,1230 1410,1740 1740,1890
data flow computation,| {} the
|对于这样的组织，计划程序还有一些空间，

1582
00:52:19,600 --> 00:52:20,800
0,390 390,660 660,780 780,870 870,1200
scheduler {has,a} bit of room

1583
00:52:20,800 --> 00:52:23,260
0,240 240,1050 1080,1530 1530,1860 1860,2460
for organizations like this, {}|
|

1584
00:52:23,260 --> 00:52:26,200
0,360 360,810 810,990 990,1710 2070,2940
it's exploding hash partitions, {}|
它正在爆炸散列分区，|

1585
00:52:26,500 --> 00:52:27,670
0,720 750,810 810,960 960,1140 1140,1170
the you know {we,get} a
你知道，我们有很多的并行性，

1586
00:52:27,670 --> 00:52:29,290
0,150 150,210 210,990 1020,1500 1500,1620
lot of parallelism,| {} we
|我们也可以重复使用，你知道我们可以将一个RDD的结果保存在内存中，

1587
00:52:29,290 --> 00:52:30,850
0,120 120,660 660,1350 1350,1440 1440,1560
can also reuse, you know

1588
00:52:30,850 --> 00:52:32,410
0,210 210,360 360,540 540,690 870,1560
we can keep the results

1589
00:52:32,410 --> 00:52:33,610
0,60 60,420 420,780 780,870 870,1200
of one RDD in memory,|
|

1590
00:52:33,610 --> 00:52:34,420
0,90 90,240 240,330 330,450 450,810
so that we can reuse
这样我们就可以在下一次迭代中重复使用它

1591
00:52:34,420 --> 00:52:35,530
0,90 90,240 240,330 330,510 510,1110
it for the next iteration|
|

1592
00:52:35,920 --> 00:52:37,480
0,210 210,330 330,570 570,1140 1260,1560
and you can {sort,of,see}, {}|
你可以在某种程度上看到|

1593
00:52:37,480 --> 00:52:38,410
0,270 270,330 330,420 420,570 570,930
that you know these techniques
你知道这些技术结合在一起

1594
00:52:38,410 --> 00:52:39,490
0,600 600,690 690,840 840,900 900,1080
combined| {you,know} going to give
|你知道，这将给你带来显著的性能优化，

1595
00:52:39,490 --> 00:52:42,040
0,270 270,840 870,1440 1440,1830 1830,2550
you {} significant performance optimization,|
|

1596
00:52:44,640 --> 00:52:46,470
0,270 270,570 570,720 720,1410 1410,1830
and allows you to express
并允许您表达更强大或更有趣的计算。

1597
00:52:46,470 --> 00:52:48,990
0,630 660,1560 1560,1800 1800,2220 2220,2520
more powerful or more interesting

1598
00:52:48,990 --> 00:52:50,140
0,810
computations.|
|

1599
00:52:52,420 --> 00:52:53,200
0,150 150,420 420,540 540,720 720,780
So maybe with that I
因此，也许我想总结一下这堂课。

1600
00:52:53,200 --> 00:52:54,790
0,270 270,420 420,900 900,1050 1050,1590
was like summarize this lecture.|
|

1601
00:53:02,100 --> 00:53:05,820
0,630 2100,2280 2280,2490 2490,3000 3030,3720
{} {So,a} couple things, {}|
所以有几件事，|

1602
00:53:06,760 --> 00:53:08,320
0,210 210,390 390,510 510,1290
{you,know} so {RDDs -}
你知道，RDDS是由函数变换制成的，

1603
00:53:08,740 --> 00:53:11,720
0,450 450,870 870,1320 1320,2160
are made by functional

1604
00:53:12,360 --> 00:53:13,680
0,870
transformations,|
|

1605
00:53:19,110 --> 00:53:21,450
0,630 810,1320 1320,1920 1950,2100 2100,2340
{} {they're,group} together in sort
它们以某种谱系图的形式聚集在一起，

1606
00:53:21,450 --> 00:53:22,900
0,60 60,540 540,1200
of lineage graph,|
|

1607
00:53:23,510 --> 00:53:24,320
0,210 210,300 300,480 480,690 690,810
you can think about as
你可以把它想象成一个数据流图，

1608
00:53:24,320 --> 00:53:25,880
0,60 60,300 300,510 510,1260
a data flow graph,|
|

1609
00:53:26,140 --> 00:53:29,320
0,600 600,810 810,1050 1050,1500 1500,3180
{} and this gives the,
这给了，这允许重复使用，

1610
00:53:29,350 --> 00:53:33,910
0,180 180,630 630,1560 3540,4260 4260,4560
this allows reuse,| {it,also} allows
|它还允许通过调度器进行一些巧妙的组织。

1611
00:53:33,910 --> 00:53:35,590
0,180 180,540 540,1410 1410,1590 1590,1680
some clever organizations by the

1612
00:53:35,590 --> 00:53:37,220
0,660
scheduler.|
|

1613
00:53:41,600 --> 00:53:43,880
0,960 990,1620 1620,1710 1710,1950 1950,2280
And basically it was also
而且基本上它也是额外的，

1614
00:53:43,880 --> 00:53:45,710
0,330 330,960 960,1200 1200,1410 1410,1830
more extra,| it's more {expressiveness
|它的表现力比你所知道的MapReduce本身更强，

1615
00:53:45,710 --> 00:53:48,540
0,510
-}

1616
00:53:53,120 --> 00:53:55,130
0,630 630,900 900,1350 1350,1470 1470,2010
than {you,know} mapreduce by itself,|
|

1617
00:53:58,290 --> 00:54:00,330
0,330 330,600 600,930 930,1800 1800,2040
and which results basically in
这基本上带来了良好的表现，

1618
00:54:00,360 --> 00:54:02,430
0,840 870,1110 1110,1650 1650,1950 1950,2070
{} good performance,| because a
|因为很多数据都留在内存中。

1619
00:54:02,430 --> 00:54:03,480
0,150 150,240 240,330 330,720 720,1050
lot of the data stays

1620
00:54:03,480 --> 00:54:04,320
0,120 120,510
in memory.|
|

1621
00:54:14,790 --> 00:54:15,990
0,210 210,300 300,480 480,870 870,1200
So if you actually if
所以，如果你真的对此感到兴奋，

1622
00:54:15,990 --> 00:54:17,250
0,90 90,390 390,600 600,930 1020,1260
you're excited about this, {}|
|

1623
00:54:17,250 --> 00:54:18,030
0,120 120,210 210,360 360,480 480,780
you can try it out,|
你可以试一下，|

1624
00:54:18,120 --> 00:54:20,310
0,630 630,780 780,1470 1470,1650 1650,2190
{} {you,can} download {you,know} spark
你可以下载你知道的Spark Play，然后写一些程序，

1625
00:54:20,340 --> 00:54:21,780
0,450 450,660 660,990 990,1140 1140,1440
{} play around and {write,some}

1626
00:54:21,780 --> 00:54:23,370
0,600 600,990 990,1110 1110,1350 1440,1590
programs,| or you know go
|或者你知道，去数据库网站

1627
00:54:23,370 --> 00:54:24,990
0,300 330,810 810,1020 1020,1380 1380,1620
to {databricks.com - -}| and
|而你正在创建账户

1628
00:54:24,990 --> 00:54:26,160
0,120 120,420 420,900 900,1050 1050,1170
you're creating accounts| and then
|然后你可以在他们的集群上对他们进行火花计算。

1629
00:54:26,160 --> 00:54:28,560
0,90 90,180 180,600 720,1680 1680,2400
you can run spark computations

1630
00:54:28,560 --> 00:54:30,000
0,120 120,480 480,570 570,750 750,1440
on their on their clusters.|
|

1631
00:54:31,030 --> 00:54:32,740
0,240 240,750 900,1320 1320,1500 1500,1710
So we're excited about this
所以我们对此很兴奋，并想试一试，

1632
00:54:32,740 --> 00:54:33,280
0,90 90,210 210,270 270,420 420,540
and want to try it

1633
00:54:33,280 --> 00:54:34,390
0,210 210,300 300,750 750,900 900,1110
out,| you know it's pretty
|你知道要做到这一点很容易，

1634
00:54:34,390 --> 00:54:36,070
0,210 210,270 270,420 420,660 1080,1680
easy to do so,| unlike
|不像农场，你可以像不玩一样，

1635
00:54:36,070 --> 00:54:37,120
0,450 450,540 540,660 660,900 900,1050
FaRM, you can just like

1636
00:54:37,120 --> 00:54:39,370
0,180 180,390 390,750 1080,1980 2010,2250
not play with,| but this
|但这实际上你可以走出去试一试。

1637
00:54:39,370 --> 00:54:40,360
0,330 330,450 450,600 600,810 810,990
actually you can actually go

1638
00:54:40,360 --> 00:54:41,420
0,150 150,270 270,510 510,810
out and try out.|
|

1639
00:54:41,650 --> 00:54:42,760
0,390 390,510 510,690 690,930 930,1110
Okay, with that, I want
好了，说到这里，我想今天就到此为止

1640
00:54:42,760 --> 00:54:45,340
0,60 60,780 900,1290 1290,1770 1770,2580
to stop for today| and
|以及那些想留下来问更多问题的人，

1641
00:54:45,700 --> 00:54:47,770
0,660 660,1260 1260,1380 1380,1620 1620,2070
{} and the people that

1642
00:54:47,770 --> 00:54:48,580
0,120 120,180 180,300 300,690 690,810
want to hang around and

1643
00:54:48,580 --> 00:54:49,990
0,210 210,330 330,840 840,1200 1200,1410
ask more questions,| please feel
|请随时这样做，

1644
00:54:49,990 --> 00:54:51,370
0,180 180,270 270,420 420,900 1200,1380
free to do so,| the
|我唯一想提醒人们的是

1645
00:54:51,370 --> 00:54:52,120
0,150 150,300 300,390 390,570 570,750
only thing I want to

1646
00:54:52,150 --> 00:54:53,830
0,390 390,720 720,960 990,1290 1290,1680
remind people of is that|
|

1647
00:54:53,860 --> 00:54:55,720
0,360 360,480 480,780 1170,1650 1650,1860
you know the deadline of
你知道4b的最后期限有点远了，

1648
00:54:55,720 --> 00:54:58,540
0,300 300,930 930,1680 1680,2400 2430,2820
for 4b is a little

1649
00:54:58,540 --> 00:55:00,070
0,120 120,510 510,810 1140,1380 1380,1530
bit away,| but I just
|但我只想提醒大家，4b是相当棘手的，

1650
00:55:00,070 --> 00:55:00,850
0,120 120,180 180,420 420,630 630,780
want to remind people the

1651
00:55:00,850 --> 00:55:02,860
0,180 180,420 420,780 780,1290 1320,2010
{4b,is -} pretty tricky,| requires
|需要一点设计，

1652
00:55:02,860 --> 00:55:04,240
0,30 30,150 150,240 240,840 1110,1380
a bit of design, {}|
|

1653
00:55:04,240 --> 00:55:05,590
0,270 270,570 600,900 900,1110 1110,1350
so, {} don't don't start
所以，不要开始得太晚。

1654
00:55:05,590 --> 00:55:06,220
0,120 120,450
too late.|
|

1655
00:55:06,660 --> 00:55:08,400
0,570 570,690 690,990 1050,1620 1620,1740
And with that I'll see
到时我会在周二见你。

1656
00:55:08,400 --> 00:55:09,260
0,90 90,150 150,540
you on Tuesday.|
|

1657
00:55:14,450 --> 00:55:16,550
0,180 180,870 870,1530 1560,1830 1830,2100
And again questions, I'm happy
再问一次问题，我很乐意回答。

1658
00:55:16,550 --> 00:55:17,480
0,180 180,420 420,600
to answer them.|
|

1659
00:55:18,560 --> 00:55:20,400
0,240 240,600
Thank you.|
谢谢。|

1660
00:55:21,010 --> 00:55:22,210
0,330 330,480 480,660 660,750 750,1200
{} I had a question
我有一个关于检查站的问题，

1661
00:55:22,210 --> 00:55:25,120
0,540 570,810 810,1860 2010,2550 2550,2910
about the checkpoints,| {I,think} if
|我想如果他们提到自动检查站，

1662
00:55:25,120 --> 00:55:29,350
0,270 270,960 1230,1890 1890,2820 3180,4230
they mention automatic checkpoints,| using
|使用有关每次计算所需时间的数据。

1663
00:55:29,470 --> 00:55:31,090
0,420 420,930 960,1230 1230,1470 1470,1620
data about how long each

1664
00:55:31,090 --> 00:55:32,480
0,630 630,1140
computation took.|
|

1665
00:55:32,570 --> 00:55:34,100
0,570 750,1230

1666
00:55:34,320 --> 00:55:35,640
0,120 120,360 360,690 690,960 960,1320
I wasn't really sure what
我不太确定他们这么说是什么意思，

1667
00:55:35,670 --> 00:55:37,020
0,240 240,660 660,780 780,1080 1080,1350
they mean by this,| but
|但是，他们将针对什么进行优化。

1668
00:55:37,860 --> 00:55:38,940
0,300 300,510 510,750 750,930 930,1080
what, what are they going

1669
00:55:38,940 --> 00:55:40,940
0,60 60,270 270,1140 1140,1680
to be optimizing for.|
|

1670
00:55:41,300 --> 00:55:42,440
0,450 450,660 660,900 900,930 930,1140
I'm gonna build a whole
我要建一个完整的检查站是正确的，

1671
00:55:42,440 --> 00:55:43,550
0,480 480,570 570,840 840,990 990,1110
checkpoints is correct,| there's an
|这是一种最优化，

1672
00:55:43,550 --> 00:55:46,850
0,660 660,1290 1470,2430 2460,2940 2940,3300
optimization between,| {you,know} taking checkpoint
|你知道占领检查站是很昂贵的，

1673
00:55:46,850 --> 00:55:47,880
0,90 90,750
is expensive,|
|

1674
00:55:48,220 --> 00:55:49,930
0,690 690,960 960,1170 1170,1470 1470,1710
{} and so you know
所以你知道，这需要时间，

1675
00:55:49,960 --> 00:55:52,240
0,210 210,720 1140,1740 1740,1950 1950,2280
takes time,| {} in but
|但在重新执行时，如果机器出现故障，

1676
00:55:52,240 --> 00:55:53,500
0,210 210,360 360,930 930,1050 1050,1260
in {reexecution -}, if there's

1677
00:55:53,500 --> 00:55:55,180
0,120 120,510 510,1170 1200,1500 1500,1680
a machine failure,| also takes
|也要花很多时间。

1678
00:55:55,180 --> 00:55:56,060
0,60 60,180 180,240 240,600
a lot of time.|
|

1679
00:55:56,520 --> 00:55:57,990
0,750 750,990 990,1110 1110,1170 1170,1470
{} And so for example
举个例子，如果你选择从不检查点，

1680
00:55:57,990 --> 00:55:59,160
0,60 60,150 150,300 300,660 660,1170
if you take never checkpoint,|
|

1681
00:55:59,160 --> 00:56:00,000
0,210 210,330 330,630 630,750 750,840
then you basically have to
那么基本上你要从头再来一次比赛，对吧，

1682
00:56:00,000 --> 00:56:01,140
0,150 150,540 540,600 600,1020 1020,1140
{reexecute -} the competition from

1683
00:56:01,140 --> 00:56:02,220
0,60 60,420 450,780
the beginning, right,|
|

1684
00:56:02,540 --> 00:56:03,380
0,300 300,480 480,540 540,660 660,840
{} but if you take
但如果你定期设置检查站，

1685
00:56:03,380 --> 00:56:04,880
0,600 600,1140 1140,1230 1230,1320 1320,1500
periodically checkpoints,| you know you
|你知道你不需要重复你知道你在检查站之前所做的计算，

1686
00:56:04,880 --> 00:56:06,470
0,300 300,450 450,750 750,1470 1470,1590
don't have to repeat you

1687
00:56:06,470 --> 00:56:07,790
0,210 210,360 360,840 840,1050 1050,1320
know the computation that you

1688
00:56:07,790 --> 00:56:09,050
0,180 180,510 510,570 570,1050 1050,1260
did before the checkpoint,| but
|但检查检查站需要时间。

1689
00:56:09,050 --> 00:56:10,550
0,510 510,600 600,990 990,1200 1200,1500
checking the checkpoint takes time.|
|

1690
00:56:11,640 --> 00:56:12,510
0,240 240,390 390,510 510,660 660,870
{} So if you take
因此，如果你频繁地设置检查站，

1691
00:56:12,510 --> 00:56:14,010
0,210 210,510 510,1170 1170,1350 1350,1500
very frequent checkpoints,| you don't
|你不需要重新计算很多东西，

1692
00:56:14,010 --> 00:56:14,670
0,90 90,180 180,300 300,600 600,660
have to {recompute -} a

1693
00:56:14,670 --> 00:56:15,600
0,360 360,510 510,630 630,810 810,930
lot,| but you spend all
|但你把所有的时间都花在了设置检查站上。

1694
00:56:15,600 --> 00:56:17,080
0,90 90,330 330,570 570,1140
your time taking checkpoints.|
|

1695
00:56:18,060 --> 00:56:18,990
0,300 300,510 510,720 720,840 840,930
And so there's sort of
所以这里有一个优化问题，

1696
00:56:18,990 --> 00:56:20,140
0,510 540,870
{} {you,know}

1697
00:56:20,830 --> 00:56:22,750
0,180 180,690 690,990 990,1470 1770,1920
an optimization problem here,| you
|你知道你想拿下检查站

1698
00:56:22,750 --> 00:56:23,350
0,90 90,210 210,360 360,420 420,600
know you want to take

1699
00:56:23,350 --> 00:56:25,570
0,300 300,810 810,1020 1290,1530 1530,2220
the checkpoints| and some regular
|和一些你愿意重新计算的有规律的间隔。

1700
00:56:25,570 --> 00:56:28,150
0,690 720,1560 1650,1950 1950,2340 2340,2580
interval {} you're willing to

1701
00:56:28,150 --> 00:56:29,960
0,390 390,960 960,1080 1080,1560
take to {recompute -}.|
|

1702
00:56:32,060 --> 00:56:33,260
0,270 270,420 420,600 600,840 840,1200
Okay, so maybe like compute
好的，所以可能会像计算检查点一样，只针对非常大的计算。

1703
00:56:33,260 --> 00:56:35,480
0,510 510,750 750,1200 1260,1800 1800,2220
checkpoints only for very large

1704
00:56:35,480 --> 00:56:37,430
0,1290 1320,1470 1470,1680 1680,1830 1830,1950
computations.| Yeah, or like for
|是的，或者像在页面排名的情况下，

1705
00:56:37,430 --> 00:56:38,330
0,330 330,390 390,510 510,720 720,900
example in the case of

1706
00:56:38,330 --> 00:56:39,410
0,90 90,510 510,570 570,690 690,1080
{page,rank -},| you know maybe
|你知道，也许你知道，每10次重复一次。

1707
00:56:39,410 --> 00:56:40,640
0,120 120,810 840,900 900,1050 1050,1230
you know do it ever

1708
00:56:40,640 --> 00:56:41,760
0,210 210,930
10 iterations.|
|

1709
00:56:44,800 --> 00:56:46,750
0,780 1230,1380 1380,1710 1710,1770 1770,1950
{Thank,you}.| It depends, of course,
谢谢。|当然，这取决于是否决定设立检查站，

1710
00:56:46,750 --> 00:56:48,100
0,90 90,480 480,570 570,1080 1080,1350
if decides to checkpoint,| but
|但决定看看哪一家可以更频繁地结账。

1711
00:56:48,100 --> 00:56:49,330
0,390 390,480 480,720 720,870 870,1230
decides to check which follow

1712
00:56:49,330 --> 00:56:50,830
0,90 90,300 390,750 1170,1230 1230,1500
you can check out more

1713
00:56:50,830 --> 00:56:51,660
0,510
frequently.|
|

1714
00:56:52,260 --> 00:56:53,130
0,330 330,450 450,510 510,750 750,870
But in the case of
但在这个页面排名的情况下，

1715
00:56:53,130 --> 00:56:54,270
0,270 300,660 660,960 960,1050 1050,1140
this page rank,| you know
|你知道那个检查站会很大，

1716
00:56:54,270 --> 00:56:55,020
0,180 180,360 360,540 540,690 690,750
that checkpoint is going to

1717
00:56:55,020 --> 00:56:56,000
0,90 90,300 300,690
be pretty big,|
|

1718
00:56:56,600 --> 00:56:57,350
0,240 240,300 300,420 420,480 480,750
there is going to be
每个网页都会有一行或一条你知道的记录。

1719
00:56:57,350 --> 00:56:59,480
0,360 540,1290 1290,1500 1500,1890 1890,2130
a line or record {you,know}

1720
00:56:59,480 --> 00:57:01,520
0,690 750,1080 1080,1260 1260,1770
per a web page.|
|

1721
00:57:03,310 --> 00:57:04,900
0,180 180,390 390,750 750,1080 1080,1590
That makes sense, thank you.|
这很有道理，谢谢你。|

1722
00:57:05,110 --> 00:57:05,920
0,480
{You're,welcome}.|
不用谢。|

1723
00:57:07,300 --> 00:57:08,710
0,180 180,480 480,600 600,1050 1050,1410
I have a question about
我有一个关于司机的问题，

1724
00:57:08,710 --> 00:57:11,470
0,270 300,960 1440,1710 1710,1800 1800,2760
the driver,| does the application,
|做应用，就像做驱动，是客户端的驱动，

1725
00:57:11,470 --> 00:57:13,360
0,270 270,720 810,1050 1050,1140 1140,1890
is like does the driver,

1726
00:57:13,810 --> 00:57:14,650
0,240 240,360 360,450 450,720 720,840
{} is the driver on

1727
00:57:14,650 --> 00:57:15,910
0,90 90,450 450,900 930,1140 1140,1260
the client side,| or is
|或者就是这样。

1728
00:57:15,910 --> 00:57:19,540
0,330 810,1530 1620,3000 3240,3480 3480,3630
it.| Okay.| Yeah.| If it
|好吧。|嗯。|如果它崩溃了，我们会输掉整个图表，这没什么，

1729
00:57:19,540 --> 00:57:20,710
0,300 300,450 450,630 630,870 870,1170
crashes, we lose like the

1730
00:57:20,710 --> 00:57:22,120
0,90 90,600 600,1050 1050,1170 1170,1410
the whole graph and that's

1731
00:57:22,120 --> 00:57:24,400
0,300 300,780 780,990 990,1230 1350,2280
fine,| because that's the application.|
|因为这就是应用程序。|

1732
00:57:25,140 --> 00:57:26,190
0,480 480,630 630,840 840,930 930,1050
Yeah, I don't actually know
是啊，我也不知道会发生什么，

1733
00:57:26,190 --> 00:57:29,430
0,150 150,480 480,2040 2130,2820 2820,3240
what happens,| because {} {the,scheduler}
|因为调度器有一个[]，

1734
00:57:29,430 --> 00:57:30,300
0,150 150,210 210,600
has a [],|
|

1735
00:57:31,140 --> 00:57:34,830
0,960 990,1770 2160,2970 2970,3150 3150,3690
and {} {the,scheduler} fault tolerance,|
和调度器容错，|

1736
00:57:35,160 --> 00:57:35,850
0,210 210,390 390,450 450,600 600,690
{} so I don't know
所以我不知道你什么时候知道会发生什么，

1737
00:57:35,850 --> 00:57:36,750
0,330 330,480 480,570 570,750 750,900
exactly when you know what

1738
00:57:36,750 --> 00:57:38,160
0,330 330,540 540,630 630,750 750,1410
happens,| maybe you could reconnect
|也许你可以重新连接我我不知道。

1739
00:57:38,160 --> 00:57:40,660
0,270 270,360 360,540 540,1200
I I don't know.|
|

1740
00:57:43,940 --> 00:57:45,230
0,150 150,330 330,390 390,810 810,1290
I had a question about
我有一个关于为什么依赖优化的问题，

1741
00:57:45,230 --> 00:57:48,110
0,240 240,870 870,1650 1650,2550 2550,2880
the why dependency optimization,| you
|您提到他们会进行散列分区，

1742
00:57:48,110 --> 00:57:49,400
0,330 330,510 570,810 810,960 960,1290
mentioned that they do the

1743
00:57:49,400 --> 00:57:51,200
0,360 360,1170 1170,1470 1500,1650 1650,1800
hash partitioning,| {} how does
|这是怎么回事。

1744
00:57:51,200 --> 00:57:51,960
0,180 180,480
that work.|
|

1745
00:57:52,490 --> 00:57:53,450
0,390 390,480 480,720 720,810 810,960
Okay, I say a little
好的，我再多说一点，

1746
00:57:53,450 --> 00:57:54,290
0,120 120,390 390,510 510,720 720,840
bit more,| so this is
|所以这不是，

1747
00:57:54,290 --> 00:57:55,760
0,240 240,660 660,1200 1200,1320 1320,1470
not,| {} hasing is not
|在今天，拥有已经不是什么东西了，

1748
00:57:55,760 --> 00:57:57,080
0,240 240,540 540,870 960,1200 1200,1320
something today,| then there is
|然后实际上有一些东西是标准的数据库、分区方案、

1749
00:57:57,080 --> 00:57:59,600
0,240 240,540 540,840 840,1470 1830,2520
actually something that's { -}

1750
00:57:59,600 --> 00:58:02,390
0,330 330,480 510,1260 1260,1920 1920,2790
is a standard database, {}

1751
00:58:02,420 --> 00:58:03,600
0,480 480,960
partitioning scheme,|
|

1752
00:58:04,120 --> 00:58:05,590
0,390 390,570 570,720 720,1200 1200,1470
and it is cool,| because
这很酷，|因为如果你需要加入电脑，

1753
00:58:05,590 --> 00:58:06,910
0,60 60,150 150,360 360,720 720,1320
if you need computer join,|
|

1754
00:58:07,440 --> 00:58:09,030
0,870 900,1110 1110,1320 1320,1410 1410,1590
you don't have to do
你不需要做很多沟通，

1755
00:58:09,030 --> 00:58:10,080
0,60 60,210 210,270 270,870 870,1050
a lot of communication,| so
|所以让我开始一张新的幻灯片，

1756
00:58:10,080 --> 00:58:11,580
0,150 150,1140 1140,1260 1260,1470 1470,1500
let me just start a

1757
00:58:11,580 --> 00:58:12,810
0,150 150,450 450,600 600,1140 1140,1230
new slide,| it's because it's
|这是因为它有点难读。

1758
00:58:12,810 --> 00:58:14,850
0,30 30,210 210,480 480,750 1170,2040
a little hard to read.|
|

1759
00:58:14,850 --> 00:58:19,280
0,360 390,1110
So {hash,partition},|
所以散列分区，|

1760
00:58:20,210 --> 00:58:20,810
0,150 150,270 270,330 330,450 450,600
so if you have two
因此，如果您有两个数据集，

1761
00:58:20,810 --> 00:58:23,210
0,270 270,780 1650,1860 1860,1980 1980,2400
{datasets -},| {here's -} dataset
|这是数据集1，这是数据集2，

1762
00:58:23,210 --> 00:58:25,700
0,450 780,1290 1290,1770 2010,2250 2250,2490
one, {here's,dataset} two,| {} {they,have}
|他们有钥匙，对，钥匙一，钥匙二，

1763
00:58:25,700 --> 00:58:27,740
0,390 390,990 990,1290 1290,1800 1800,2040
keys, right, key one, key

1764
00:58:27,740 --> 00:58:28,660
0,540
two,|
|

1765
00:58:29,620 --> 00:58:30,640
0,120 120,240 240,360 360,450 450,1020
so they have the same
所以他们有一套相同的钥匙，

1766
00:58:30,640 --> 00:58:31,760
0,150 150,240 240,900
set of keys,|
|

1767
00:58:32,250 --> 00:58:34,140
0,540 540,930 930,1050 1050,1560 1590,1890
then what you do by
然后通过对您的分区进行哈希分区数据集和分区数量，

1768
00:58:34,140 --> 00:58:35,790
0,180 180,960 1050,1230 1230,1590 1590,1650
hash partitioning your partition the

1769
00:58:35,790 --> 00:58:37,950
0,480 480,630 630,930 930,1680 1710,2160
dataset and {number,of} partitions,| so
|所以砰的一声，你就得保持，

1770
00:58:37,980 --> 00:58:41,520
0,420 450,600 600,1260 1950,2700 2940,3540
boom boom boom and you

1771
00:58:41,520 --> 00:58:42,940
0,360 360,480 480,1050
have to keep,|
|

1772
00:58:44,830 --> 00:58:45,790
0,180 180,300 300,630 630,780 780,960
so you have {} {K1
所以你有K1，你有K2，这实际上决定了分区的结果。

1773
00:58:45,790 --> 00:58:47,080
0,480 480,570 570,870 870,1020 1020,1290
-}, you has {K2 -}

1774
00:58:47,080 --> 00:58:48,070
0,120 120,270 270,480 480,900 900,990
and that actually determines the

1775
00:58:48,070 --> 00:58:49,680
0,540 540,930 930,1200
partition ends up.|
|

1776
00:58:50,000 --> 00:58:52,400
0,330 330,660 660,930 930,1560 2010,2400
And so all the keys
因此，实际上具有相同散列的所有密钥都出现在同一位置，

1777
00:58:52,400 --> 00:58:53,600
0,150 150,570 570,870 870,960 960,1200
that actually have the same

1778
00:58:53,600 --> 00:58:54,500
0,360 360,630 630,750 750,840 840,900
hash went up in the

1779
00:58:54,500 --> 00:58:55,730
0,270 270,570 570,840 840,1020 1020,1230
same place,| so like this
|所以就像这台机器1，机器2，机器3，

1780
00:58:55,730 --> 00:58:58,970
0,360 360,840 1200,1770 1770,2370 2850,3240
machine 1, machine 2, machine

1781
00:58:58,970 --> 00:59:01,280
0,630 840,1080 1080,1230 1230,1620 1620,2310
3,| so you take whatever
|所以你把你散列的K1的任何东西放在这里，

1782
00:59:01,520 --> 00:59:02,750
0,150 150,510 510,690 690,1050 1050,1230
you hash {K1 -}, that

1783
00:59:02,750 --> 00:59:04,220
0,210 210,360 360,810 1170,1290 1290,1470
goes in here,| you know
|你知道你散列了任何K2，可能在文件中的其他地方，谁知道它在哪里

1784
00:59:04,220 --> 00:59:06,080
0,180 180,600 600,1140 1140,1560 1560,1860
you hash whatever {K2 -},

1785
00:59:06,080 --> 00:59:07,040
0,210 210,300 300,630 630,870 870,960
may be somewhere else in

1786
00:59:07,040 --> 00:59:08,000
0,90 90,480 480,570 570,780 780,960
the file, who knows where

1787
00:59:08,000 --> 00:59:09,140
0,90 90,450 660,870 870,990 990,1140
it is| and you hash
|然后你散列到分区。

1788
00:59:09,140 --> 00:59:10,490
0,300 300,750 990,1200 1200,1260 1260,1350
to partition.| You do the
|您可以在这里对其他数据集执行相同的操作，

1789
00:59:10,490 --> 00:59:11,480
0,240 240,390 390,870
same thing here,

1790
00:59:11,740 --> 00:59:13,780
0,660 690,900 900,1050 1050,1500 1530,2040
{} for the other datasets,|
|

1791
00:59:13,780 --> 00:59:15,010
0,90 90,360 360,570 570,780 780,1230
so here's {dataset -} one,|
这是数据集一，|

1792
00:59:17,620 --> 00:59:20,440
0,210 210,660 660,1110
{here's} dataset two,|
这是数据集2，|

1793
00:59:21,060 --> 00:59:23,130
0,240 240,480 480,600 600,1200 1530,2070
like links and ranks| and
喜欢链接和排名|接下来会发生的是，

1794
00:59:23,130 --> 00:59:24,780
0,360 360,540 540,930 930,1350 1350,1650
what will happen is that,|
|

1795
00:59:24,930 --> 00:59:26,340
0,300 300,420 420,960 990,1200 1200,1410
all the records in this
此数据集中的所有记录，

1796
00:59:26,340 --> 00:59:28,650
0,630 630,840 840,1320 1380,1890 1950,2310
dataset,| that have the same
|它们与其他数据集中的记录具有相同的键，

1797
00:59:28,650 --> 00:59:30,990
0,600 870,1290 1290,1740 1740,2190 2220,2340
keys as records in the

1798
00:59:30,990 --> 00:59:32,640
0,150 150,390 390,750 870,1290 1290,1650
other {dataset -},| those keys
|这些钥匙或记录会被放在同一台机器里，对吧，

1799
00:59:32,640 --> 00:59:33,600
0,90 90,330 330,690 690,810 810,960
or those records will end

1800
00:59:33,600 --> 00:59:34,740
0,150 150,270 270,360 360,690 690,1140
up in the same machine,

1801
00:59:35,130 --> 00:59:36,690
0,210 210,360 360,720 720,900 900,1560
right,| so you're gonna partition,|
|所以你要分割，|

1802
00:59:37,060 --> 00:59:38,590
0,300 300,510 510,930 930,1170 1170,1530
{} this guy and basically
这个人和基本上K1也会在同一台机器上结束，

1803
00:59:38,590 --> 00:59:39,460
0,210 210,420 420,570 570,720 720,870
{K1 -} will end up

1804
00:59:39,460 --> 00:59:40,900
0,210 210,480 930,1110 1110,1170 1170,1440
here too, on the same

1805
00:59:40,900 --> 00:59:41,600
0,390
machine,|
|

1806
00:59:44,130 --> 00:59:45,750
0,420 420,540 540,930 930,1350 1350,1620
correct and same for the
其他密钥正确且相同，

1807
00:59:45,750 --> 00:59:47,070
0,360 360,630 630,870 870,960 960,1320
other keys,| because you basically
|因为你基本上使用相同的散列函数，

1808
00:59:47,070 --> 00:59:48,450
0,180 180,240 240,510 510,780 780,1380
use the same hash function,|
|

1809
00:59:48,450 --> 00:59:49,050
0,120 120,180 180,270 270,330 330,600
and you have the same
你有一套相同的钥匙

1810
00:59:49,050 --> 00:59:50,310
0,150 150,240 240,720 990,1170 1170,1260
set of keys| and so
|因此，这允许您以相同的方式对数据集进行分区

1811
00:59:50,310 --> 00:59:51,270
0,150 150,510 510,660 660,750 750,960
this allows you to take

1812
00:59:51,270 --> 00:59:52,650
0,60 60,720 720,870 870,1260 1260,1380
a dataset {you,know} partition that

1813
00:59:52,650 --> 00:59:53,730
0,300 300,360 360,450 450,690 690,1080
both in the same way|
|

1814
00:59:53,760 --> 00:59:55,440
0,300 300,570 570,750 750,1230 1230,1680
{} using this hashing trick.|
使用这种散列技巧。|

1815
00:59:56,100 --> 00:59:57,180
0,120 120,270 270,360 360,840 840,1080
And this is cool,| because
这很酷，|因为现在如果您需要对这两个数据集进行连接，

1816
00:59:57,180 --> 00:59:57,780
0,210 210,330 330,390 390,510 510,600
now if you need to

1817
00:59:57,780 --> 00:59:59,910
0,150 150,240 240,840 1560,1950 1950,2130
do a join over these

1818
00:59:59,910 --> 01:00:01,020
0,150 150,690 690,930 930,1020 1020,1110
two datasets,| like if you
|例如，如果您需要连接这两个数据集，

1819
01:00:01,020 --> 01:00:02,070
0,120 120,360 360,750 750,930 930,1050
need to join these two

1820
01:00:02,070 --> 01:00:03,600
0,240 240,720 870,1110 1110,1440 1440,1530
{datasets -},| that basically you
|基本上，你可以只连接分区，

1821
01:00:03,600 --> 01:00:04,800
0,120 120,300 300,600 600,690 690,1200
can just join the partitions,|
|

1822
01:00:06,420 --> 01:00:07,230
0,210 210,390 390,570 570,720 720,810
and you don't have to
而且你不需要交流，

1823
01:00:07,230 --> 01:00:08,460
0,870
communicate,|
|

1824
01:00:08,800 --> 01:00:09,430
0,90 90,180 180,360 360,450 450,630
you know each of these
你知道，这些机器中的每一台都不需要与任何其他机器通信，

1825
01:00:09,430 --> 01:00:10,750
0,390 390,630 630,780 780,840 840,1320
machines doesn't have to communicate

1826
01:00:10,750 --> 01:00:12,940
0,150 150,360 360,870 1080,1920 1950,2190
with any other machine,| because
|因为它知道它拥有您知道的另一个数据集拥有的所有密钥

1827
01:00:12,940 --> 01:00:14,020
0,120 120,570 570,690 690,930 930,1080
it knows it has all

1828
01:00:14,020 --> 01:00:15,940
0,60 60,480 480,600 600,1680 1680,1920
the keys you know the

1829
01:00:15,940 --> 01:00:17,590
0,450 480,1020 1020,1380 1380,1500 1500,1650
other dataset has| and they're
|它们都在同一台机器上。

1830
01:00:17,590 --> 01:00:18,580
0,210 210,330 330,390 390,600 600,990
all on the same machine.|
|

1831
01:00:20,260 --> 01:00:21,490
0,270 270,540 540,690 690,1080 1080,1230
{Gotcha -}, so basically it's
明白了，基本上它只是尝试排序，而不是排序，

1832
01:00:21,490 --> 01:00:24,040
0,210 210,870 1020,1500 1530,2250 2280,2550
just trying {} sort, not

1833
01:00:24,040 --> 01:00:25,360
0,330 330,480 480,720 720,1140 1170,1320
sort,| but like bucket the
|但就像把不同的东西装进同一台机器一样，

1834
01:00:25,360 --> 01:00:26,950
0,420 420,1080 1080,1230 1230,1320 1320,1590
different objects in the same

1835
01:00:26,950 --> 01:00:28,660
0,480 480,600 600,780 780,1350 1350,1710
machine,| so that it doesn't
|这样它就不会交流了。

1836
01:00:28,660 --> 01:00:31,620
0,510
communicate.|
|

1837
01:00:32,070 --> 01:00:33,180
0,390 420,720 720,900 900,990 990,1110
Okay great, thank you so
好的，非常感谢。

1838
01:00:33,180 --> 01:00:35,910
0,330 1830,2070 2070,2400 2400,2610 2610,2730
much.| So this means the
|这意味着散列函数必须确保，

1839
01:00:35,910 --> 01:00:37,350
0,270 270,870 900,1170 1170,1290 1290,1440
hash function has to make

1840
01:00:37,350 --> 01:00:39,180
0,240 240,540 960,1230 1230,1440 1440,1830
sure that,| there are no
|没有必须像在另一台机器上使用计算一样的链接。

1841
01:00:39,180 --> 01:00:41,280
0,750 1050,1440 1680,1830 1830,2010 2010,2100
links that would have to

1842
01:00:41,280 --> 01:00:42,060
0,90 90,390
be like

1843
01:00:42,330 --> 01:00:44,010
0,360 360,900 900,990 990,1230 1230,1680
{using,the} computation on another machine.|
|

1844
01:00:44,910 --> 01:00:46,140
0,330 330,510 510,750 750,1050 1050,1230
Yeah, well, they're good since
是的，它们很好，因为它们使用相同的散列函数

1845
01:00:46,140 --> 01:00:46,980
0,90 90,270 270,360 360,570 570,840
they use the same hash

1846
01:00:46,980 --> 01:00:48,180
0,510 660,900 900,1020 1020,1140 1140,1200
function| and they have the
|而且他们有相同的钥匙，你知道这是会发生的。

1847
01:00:48,180 --> 01:00:49,050
0,210 210,540 540,660 660,750 750,870
same keys, you know that

1848
01:00:49,050 --> 01:00:50,280
0,120 120,450
will happen.|
|

1849
01:00:54,100 --> 01:00:55,320
0,390 420,810
{} yeah.|
嗯。|

1850
01:00:56,340 --> 01:00:58,050
0,720 720,1200 1200,1320 1320,1380 1380,1710
{} I had a question,|
我有个问题，|

1851
01:00:58,050 --> 01:00:59,190
0,150 180,630 630,870 870,930 930,1140
I actually wanted to come
我其实想回到我之前问的那个问题上来。

1852
01:00:59,190 --> 01:01:00,060
0,180 180,270 270,360 360,750 750,870
back to the question I

1853
01:01:00,060 --> 01:01:06,570
0,240 240,840 960,2730 5010,5490 5940,6510
asked before.| Yeah, good.| So
|是啊，很好。|所以让我敞开心扉。是啊，我想也让我打开报纸吧。

1854
01:01:06,600 --> 01:01:08,040
0,180 180,330 330,600 600,900 930,1440
let me open up. Yeah,

1855
01:01:08,040 --> 01:01:08,850
0,150 150,240 240,480 480,720 720,810
let me also open the

1856
01:01:08,850 --> 01:01:11,190
0,270 270,330 330,720 930,2190 2190,2340
paper, I guess.| {} Any
|任何其他有问题的人，

1857
01:01:11,190 --> 01:01:12,570
0,300 300,570 570,660 660,780 780,1380
other people that have questions,|
|

1858
01:01:12,600 --> 01:01:13,530
0,300 300,510 510,660 660,780 780,930
because maybe this will take
因为这可能需要一点时间。

1859
01:01:13,530 --> 01:01:14,520
0,30 30,210 210,390 390,600 600,990
a little bit of time.|
|

1860
01:01:15,530 --> 01:01:16,220
0,210 210,510 510,540 540,630 630,690
Yeah, actually, I had a
是的，实际上，我有一个简短的问题关于农场的容错能力，

1861
01:01:16,220 --> 01:01:17,690
0,180 180,570 570,780 780,1200 1230,1470
quick question on the fault

1862
01:01:17,690 --> 01:01:20,300
0,510 600,1260 1260,1740 1740,1830 1830,2610
tolerance, fault tolerance of FaRM,|
|

1863
01:01:20,480 --> 01:01:23,450
0,480 750,1500 2100,2580 2580,2850 2850,2970
{} so so just to
所以为了弄清楚到底发生了什么，

1864
01:01:23,450 --> 01:01:26,180
0,540 540,810 810,1290 1290,1710 2460,2730
clarify what happens,| so if
|因此，如果在决策点之前发生故障，

1865
01:01:26,180 --> 01:01:28,370
0,120 120,630 630,1320 1320,2040 2040,2190
a failure occurs before the

1866
01:01:28,370 --> 01:01:29,600
0,510 510,1050
decision point,|
|

1867
01:01:29,840 --> 01:01:31,940
0,630 990,1560 1560,1680 1680,1950 1950,2100
{} then the entire thing
然后整个事情就中止了，

1868
01:01:31,940 --> 01:01:32,960
0,120 120,180 180,720 750,900 900,1020
is {aborted -},| but it
|但它发生在决定点之后，

1869
01:01:32,960 --> 01:01:34,580
0,420 420,840 840,930 930,1380 1380,1620
occurs after the decision point,|
|

1870
01:01:34,580 --> 01:01:37,100
0,150 150,690 690,1050 1500,2010 2010,2520
then after the failed computers
然后在出现故障的计算机重新启动后，

1871
01:01:37,100 --> 01:01:38,210
0,150 150,420 420,720 720,870 870,1110
come back up,| they have
|他们必须重新向协调员确认他们是否应该承诺。

1872
01:01:38,210 --> 01:01:40,400
0,420 840,1110 1110,1440 1440,1530 1530,2190
to {reask -} the coordinator

1873
01:01:40,400 --> 01:01:41,000
0,120 120,300 300,330 330,540 540,600
for whether or not they

1874
01:01:41,000 --> 01:01:41,840
0,150 150,570
should commit.|
|

1875
01:01:42,340 --> 01:01:43,600
0,210 210,540 540,780 780,1050 1050,1260
{} They don't really {reask
他们说话不太对劲，

1876
01:01:43,600 --> 01:01:45,820
0,570 600,930 930,1200 1200,1890 1890,2220
-} right,| like what happens
|就像发生故障后会发生什么一样，恢复过程会运行，

1877
01:01:45,820 --> 01:01:47,680
0,180 180,990 990,1620 1620,1800 1800,1860
is {there,after} failure there's a

1878
01:01:47,680 --> 01:01:49,180
0,420 420,750 750,1320
recovery process runs,|
|

1879
01:01:49,500 --> 01:01:51,090
0,150 150,210 210,660 660,1140 1140,1590
and the recovery process looks
恢复过程看起来基本上所有的日志都被排空了

1880
01:01:51,120 --> 01:01:53,130
0,1200 1200,1440 1440,1530 1530,1920 1920,2010
basically all the logs are

1881
01:01:53,130 --> 01:01:55,530
0,660 660,1320 1590,1980 1980,2070 2070,2400
drained| and then the recovery
|然后恢复过程查看系统的状态，

1882
01:01:55,530 --> 01:01:56,580
0,330 330,600 600,690 690,780 780,1050
process looks at the state

1883
01:01:56,580 --> 01:01:58,620
0,90 90,180 180,780 1110,1740 1740,2040
of the system,| and based
|并基于系统的状态

1884
01:01:58,620 --> 01:01:59,400
0,90 90,150 150,360 360,450 450,780
on the state of system|
|

1885
01:01:59,400 --> 01:02:00,210
0,90 90,420 420,570 570,630 630,810
and decides what to do
并决定如何处理交易，

1886
01:02:00,210 --> 01:02:02,220
0,180 180,780 1050,1410 1410,1860 1860,2010
with transaction,| either aborted or
|要么中止，要么提交，

1887
01:02:02,220 --> 01:02:03,000
0,300 300,540
commits it,|
|

1888
01:02:03,600 --> 01:02:06,720
0,510 780,1230 1230,1830 1860,2940 2940,3120
and the key aspect here
该协议的关键方面是

1889
01:02:06,720 --> 01:02:07,740
0,60 60,180 180,660 660,870 870,1020
in this protocol is| to
|以确保在事务协调器实际已向应用程序报告时

1890
01:02:07,740 --> 01:02:09,660
0,720 960,1260 1260,1350 1350,1440 1440,1920
ensure that at the point

1891
01:02:09,720 --> 01:02:11,920
0,600 990,1890
when the

1892
01:02:12,110 --> 01:02:13,910
0,420 420,870 870,1440 1440,1680 1680,1800
{} transaction coordinator actually have

1893
01:02:13,910 --> 01:02:15,140
0,480 480,540 540,630 630,1110 1110,1230
reported to the application| that
|该交易已成功提交，

1894
01:02:15,140 --> 01:02:17,510
0,90 90,540 540,1170 1560,1800 1800,2370
the transaction succeeded {} committed,|
|

1895
01:02:17,810 --> 01:02:18,620
0,270 270,420 420,630 630,690 690,810
{} it has to be
必须是这样的，

1896
01:02:18,620 --> 01:02:19,340
0,60 60,330 330,450 450,690 690,720
the case,| that there are
|系统中留下了足够多的证据，

1897
01:02:19,370 --> 01:02:20,960
0,540 540,840 840,900 900,1350 1350,1590
enough pieces of evidence left

1898
01:02:20,960 --> 01:02:22,670
0,630 990,1140 1140,1230 1230,1590 1590,1710
around in the system,| so
|所以在恢复过程中，

1899
01:02:22,670 --> 01:02:24,050
0,210 210,480 480,540 540,990 990,1380
that during the recovery process,|
|

1900
01:02:24,050 --> 01:02:25,640
0,120 120,660 660,840 840,1230 1230,1590
that transaction is definitely committed,|
这笔交易肯定是被提交的，|

1901
01:02:26,780 --> 01:02:28,660
0,660 660,900 900,1620
and, {} that's,
而且，这就是我们的计划。

1902
01:02:29,100 --> 01:02:30,000
0,210 210,330 330,420 420,480 480,900
that's sort of the plan.|
|

1903
01:02:30,700 --> 01:02:31,870
0,510 510,630 630,900 900,990 990,1170
And the reason that there's
有足够证据的原因是，

1904
01:02:31,870 --> 01:02:33,370
0,180 180,630 630,810 810,1050 1050,1500
enough evidence is,| because there's
|因为到处都有大量的记录，

1905
01:02:33,370 --> 01:02:35,170
0,210 210,720 720,1080 1080,1320 1320,1800
these large records lying around,|
|

1906
01:02:35,560 --> 01:02:37,330
0,270 270,660 660,1050 1050,1440 1440,1770
{} there's commands background records
到处都是司令部的背景记录

1907
01:02:37,330 --> 01:02:39,370
0,420 420,690 690,1230 1350,1500 1500,2040
right lying around| and there's
|还有这一条承诺记录。

1908
01:02:39,400 --> 01:02:40,960
0,300 300,600 600,900 900,1290
this one commit record.|
|

1909
01:02:43,140 --> 01:02:44,880
0,180 180,450 450,690 690,1080 1110,1740
I see, so if something,|
我明白了，所以如果有什么事，|

1910
01:02:44,880 --> 01:02:46,590
0,150 150,540 540,810 900,1140 1140,1710
for example if a failure
例如，如果在主服务器上发生故障，则在提交主服务器之前。

1911
01:02:46,590 --> 01:02:49,350
0,840 930,1170 1170,1260 1260,2160 2190,2760
occurs on a primary, before

1912
01:02:49,380 --> 01:02:51,840
0,420 420,720 720,1410 1620,2160
against commit primary.| Yep.|
|是啊。|

1913
01:02:52,070 --> 01:02:53,750
0,240 240,600 600,1080 1230,1530 1530,1680
What happens there?| {} So
那里发生了什么？|所以这很有趣，

1914
01:02:53,750 --> 01:02:54,860
0,150 150,450 450,600 600,810 810,1110
that's interesting,| so there's enough
|所以有足够的备份记录，对吧，

1915
01:02:54,860 --> 01:02:56,400
0,420 420,720 720,1230
backup record, correct,|
|

1916
01:02:56,620 --> 01:02:57,910
0,150 150,510 510,1080 1080,1140 1140,1290
to basically decide you know
基本上决定每个碎片实际提交的每个备份，

1917
01:02:57,910 --> 01:02:59,140
0,180 180,420 420,840 840,990 990,1230
that every backup that every

1918
01:02:59,140 --> 01:03:00,820
0,480 480,720 720,900 900,1380
shard actually has committed,|
|

1919
01:03:01,360 --> 01:03:03,250
0,840 840,1290 1290,1560 1560,1680 1680,1890
and, {} and so that's
所以，这就是足够的信息，让恢复过程说

1920
01:03:03,250 --> 01:03:04,600
0,240 240,780 780,870 870,960 960,1350
enough information for the recovery

1921
01:03:04,600 --> 01:03:05,950
0,300 300,390 390,600 600,1050 1080,1350
process to say| I am
|我要竞选那笔交易，

1922
01:03:05,950 --> 01:03:06,910
0,120 120,180 180,390 390,810 810,960
going to run for that

1923
01:03:06,910 --> 01:03:08,290
0,480 720,1020 1020,1140 1140,1290 1290,1380
transaction,| because it could have
|因为它可能已经犯下了。

1924
01:03:08,290 --> 01:03:09,080
0,510
committed.|
|

1925
01:03:10,630 --> 01:03:11,560
0,270 270,360 360,540 540,630 630,930
Got it, so it doesn't
明白了，所以在这种情况下不需要初选，

1926
01:03:11,560 --> 01:03:12,550
0,210 210,300 300,750 750,810 810,990
need the primary in that

1927
01:03:12,550 --> 01:03:13,750
0,360 360,390 390,720 720,1080 1080,1200
case,| {} can use the
|可以使用备份，因为备份具有。

1928
01:03:13,750 --> 01:03:15,580
0,600 600,810 810,900 900,1380 1380,1830
backups because the backups have.|
|

1929
01:03:17,140 --> 01:03:18,160
0,720
{Yeah,exactly}.|
是啊，就是这样。|

1930
01:03:20,030 --> 01:03:21,560
0,390 390,510 510,690 690,960 1320,1530
Got it, thank you,| and
明白了，谢谢，|如果备份失败，会发生什么情况。

1931
01:03:21,560 --> 01:03:23,030
0,210 210,510 510,690 690,990 1020,1470
what happens if the backup

1932
01:03:23,030 --> 01:03:25,910
0,810 1590,2010 2010,2310 2310,2640 2640,2880
fails.| {} Well then one
|好吧，那么其中一个备份失败

1933
01:03:25,910 --> 01:03:26,780
0,90 90,150 150,450 450,750 750,870
of the backup fails| and
|这大概意味着提交记录仍在那里，

1934
01:03:26,780 --> 01:03:27,800
0,390 390,540 540,780 780,930 930,1020
presumably that means that the

1935
01:03:27,800 --> 01:03:29,510
0,540 570,1020 1020,1080 1080,1320 1320,1710
commit record to still there,|
|

1936
01:03:30,100 --> 01:03:31,240
0,180 180,300 300,690 690,930 930,1140
and then again there's enough
再说一次，有足够的信息来决定

1937
01:03:31,240 --> 01:03:32,740
0,510 510,600 600,1050 1050,1200 1200,1500
information to decide| that actual
|该实际事务需要提交，

1938
01:03:32,740 --> 01:03:34,200
0,450 450,630 630,720 720,1170
transaction needs to commit,|
|

1939
01:03:34,400 --> 01:03:36,200
0,360 360,510 510,840 840,1380 1380,1800
and there's enough backups around
而且周围有足够的备份来真正了解新的价值

1940
01:03:36,200 --> 01:03:37,070
0,90 90,390 390,600 600,810 810,870
to actually know what the

1941
01:03:37,070 --> 01:03:38,360
0,150 150,570 570,810 840,1050 1050,1290
new values| or there's also
|或者还有日志条目，它实际上包含，

1942
01:03:38,360 --> 01:03:40,490
0,150 150,630 660,1320 1680,1890 1890,2130
the log entries which actually

1943
01:03:40,490 --> 01:03:41,870
0,390 390,570 570,840 840,990 990,1380
contains,| so if a primary
|所以如果初选开始了，

1944
01:03:41,870 --> 01:03:43,010
0,90 90,420 750,870 870,990 990,1140
is up,| it will have
|它将有一个日志条目，

1945
01:03:43,010 --> 01:03:44,240
0,60 60,390 390,870 930,1080 1080,1230
a log entry,| there will
|将有一个已提交的条目，并且没有备份实际完成事务。

1946
01:03:44,240 --> 01:03:45,890
0,90 90,180 180,480 480,1050 1170,1650
be a committed entry {plus,there}

1947
01:03:45,890 --> 01:03:47,360
0,60 60,210 210,690 690,1200 1200,1470
are not backups actually {}

1948
01:03:47,360 --> 01:03:48,460
0,240 240,360 360,870
finish the transaction.|
|

1949
01:03:50,650 --> 01:03:51,520
0,300 300,570
Thank you.|
谢谢。|

1950
01:03:52,380 --> 01:03:53,580
0,180 180,480 480,720 720,990 990,1200
Oh, sorry to follow up
哦，很抱歉要跟进这件事，

1951
01:03:53,580 --> 01:03:54,450
0,90 90,390 390,540 540,660 660,870
on that,| if you said
|如果你说如果第一次失败了，

1952
01:03:54,450 --> 01:03:57,630
0,360 720,990 990,1140 1140,1890 2160,3180
that if the primary failed,|
|

1953
01:03:57,630 --> 01:03:58,740
0,420 450,630 630,780 780,990 990,1110
then you could use the
然后，您可以使用备份来完成操作，

1954
01:03:58,740 --> 01:04:01,200
0,600 600,1020 1290,1800 1980,2370 2370,2460
backups to {complete,the} action,| if
|如果它们的数量足够多，

1955
01:04:01,200 --> 01:04:02,760
0,300 300,540 540,630 630,960 1350,1560
there's enough of them,| so
|所以我们需要选举新的初选？

1956
01:04:02,760 --> 01:04:04,620
0,210 270,1170 1170,1320 1320,1800 1800,1860
we need to elect a

1957
01:04:04,620 --> 01:04:05,620
0,180 180,780
new primary?|
|

1958
01:04:06,540 --> 01:04:07,530
0,240 240,570 570,780 780,900 900,990
I I think this is
我我想这一切都发生在，

1959
01:04:07,530 --> 01:04:09,870
0,150 150,450 450,870 870,1650 1680,2340
all happened during the {},|
|

1960
01:04:09,930 --> 01:04:10,950
0,510 510,630 630,720 720,930 930,1020
basically you can think of
基本上，您可以将恢复过程视为主要

1961
01:04:10,950 --> 01:04:12,510
0,330 330,750 750,1230 1230,1470 1470,1560
the recovery process as a

1962
01:04:12,510 --> 01:04:14,400
0,450 840,1140 1140,1320 1320,1500 1500,1890
primary| and that just finishes
|这就结束了所有的事情。

1963
01:04:14,400 --> 01:04:15,320
0,330 330,690
everything off.|
|

1964
01:04:16,520 --> 01:04:18,080
0,480 480,720 720,1050 1050,1290 1290,1560
Oh, so whoever does the
哦，所以不管是谁做的恢复工作都是主要的。

1965
01:04:18,200 --> 01:04:19,800
0,480 480,570 570,660 660,1290
recovery is the primary.|
|

1966
01:04:19,900 --> 01:04:21,860
0,1650
Yeah.|
嗯。|

1967
01:04:22,280 --> 01:04:24,470
0,390 570,780 780,1230 1560,1830 1830,2190
Okay, make sense, thank you.|
好的，有道理，谢谢。|

1968
01:04:24,560 --> 01:04:26,240
0,360 360,900 900,1230 1230,1350 1350,1680
{I,think} explicitly they you know
我认为他们明确地宣传初选，

1969
01:04:26,270 --> 01:04:27,830
0,480 480,510 510,960 960,1350 1350,1560
promote {} primary,| just like
|就像勇往直前去做一样。

1970
01:04:27,830 --> 01:04:28,640
0,150 150,330 330,420 420,540 540,810
go ahead and do it.|
|

1971
01:04:30,060 --> 01:04:31,230
0,150 150,300 300,390 390,630 630,1170
And what is like enough
以及什么是足够多的备份。

1972
01:04:31,230 --> 01:04:33,810
0,900 1260,2010 2010,2130 2130,2250 2250,2580
backups.| Well, we have {f+1
|嗯，我们有f+1，对吧，

1973
01:04:33,810 --> 01:04:34,740
0,390
-},

1974
01:04:35,800 --> 01:04:37,570
0,510 630,1170 1170,1560 1560,1650 1650,1770
right,| {} and so it
|所以这意味着，你知道，只要还剩一个，

1975
01:04:37,570 --> 01:04:38,950
0,300 300,660 690,810 810,1170 1230,1380
means that, you know so

1976
01:04:38,950 --> 01:04:40,120
0,120 120,210 210,360 360,480 480,1170
long as one is left,|
|

1977
01:04:40,920 --> 01:04:42,540
0,300 300,630 630,1020 1020,1410 1440,1620
{you,know} we were good,| so
你知道我们很棒，|所以我们可以有不止一次的失败，

1978
01:04:42,540 --> 01:04:43,560
0,90 90,270 270,510 510,750 750,1020
we can have more than

1979
01:04:43,560 --> 01:04:45,360
0,300 300,510 510,1110 1500,1680 1680,1800
f one failures,| we can
|在这个特定的图中，我们只能有f个故障，f是1。

1980
01:04:45,360 --> 01:04:46,710
0,180 180,480 480,1020 1020,1170 1170,1350
only have {f,failures} in this

1981
01:04:46,710 --> 01:04:49,500
0,360 360,930 1050,1440 1440,1860
particular drawing {f,is} 1.|
|

1982
01:04:51,100 --> 01:04:51,910
0,210 210,330 330,510 510,570 570,810
So there has to be
所以每个碎片都要有，你知道只剩下一台机器了。

1983
01:04:51,910 --> 01:04:53,200
0,90 90,720 870,990 990,1080 1080,1290
per shard, you know one

1984
01:04:53,200 --> 01:04:54,280
0,330 330,780
machine left.|
|

1985
01:04:56,090 --> 01:04:57,530
0,270 270,390 390,570 570,1080 1170,1440
Okay, that makes sense, thank
好的，有道理，谢谢。

1986
01:04:57,530 --> 01:04:58,400
0,570
you.|
|

1987
01:04:58,640 --> 01:04:59,560
0,210 210,600
You're welcome.|
不用谢。|

1988
01:05:02,440 --> 01:05:03,850
0,390 390,720 720,900 900,1140 1140,1410
Okay, Felipe, it just {me,and}
好了，菲利普，就我和你。

1989
01:05:03,850 --> 01:05:04,560
0,390
you.|
|

1990
01:05:06,750 --> 01:05:08,460
0,600 630,1050 1050,1350 1350,1530 1530,1710
Well, unless anyone else ask
我想，除非其他人问我问题。

1991
01:05:08,460 --> 01:05:12,200
0,510 510,630 630,1740
questions I think.|
|

1992
01:05:14,710 --> 01:05:18,080
0,1080 1650,1710 1710,2280 2280,3090
Yeah, {I,and,you}.| {So,it's} page,
是的，我和你。|所以他们在第六页上解释了一页又一页。

1993
01:05:18,280 --> 01:05:20,500
0,660 660,1110 1110,1260 1260,1500 1500,2220
{page,they} explain on page 6.|
|

1994
01:05:20,920 --> 01:05:24,820
0,420 420,1500 2670,3060 3060,3600 3600,3900
Yeah yeah.| That below table
对，对。|这在表3下面。

1995
01:05:24,820 --> 01:05:26,600
0,630 810,1380
3.| Yep.|
|是啊。|

1996
01:05:27,660 --> 01:05:29,820
0,630 870,1260 1260,1530 1530,1800 1800,2160
{} Some [bare] ground starts
一些[裸露的]地面开始了最有趣的问题，

1997
01:05:29,820 --> 01:05:31,770
0,120 120,540 540,1110 1110,1590 1590,1950
the most interesting question right,|
|

1998
01:05:31,770 --> 01:05:34,140
0,420 420,870 870,1110 1110,1350 1530,2370
it goes on to define.|
它接着定义了。|

1999
01:05:34,890 --> 01:05:36,390
0,420 420,810 810,1050 1050,1140 1140,1500
Both sufficient usual to classify
两者通常足以将依赖关系分类为两种类型，

2000
01:05:36,390 --> 01:05:38,790
0,630 630,900 900,1260 1260,1980 1980,2400
dependencies {in,two} types,| narrow where
|其中父分区较窄，父RDD由子RDD权限的最多一个分区使用，

2001
01:05:38,820 --> 01:05:40,380
0,300 300,690 690,750 750,1380 1380,1560
parent partition, the {parent,RDD} is

2002
01:05:40,380 --> 01:05:42,060
0,420 420,600 600,1050 1050,1320 1320,1680
used by most one partition

2003
01:05:42,060 --> 01:05:42,900
0,90 90,210 210,540 540,630 630,840
of the child {RDD -}

2004
01:05:42,930 --> 01:05:44,580
0,240 240,390 390,600 600,930 1140,1650
right,| so this is.| Right.|
|所以这就是。|正确的。|

2005
01:05:44,820 --> 01:05:45,960
0,210 210,360 360,600 600,750 750,1140
So let me, so let's
所以让我，让我们画出正确的，

2006
01:05:45,960 --> 01:05:47,220
0,210 210,450 450,720 720,870 870,1260
draw this correct,| so here
|因此，这里我们有一个父分区。

2007
01:05:47,220 --> 01:05:49,940
0,150 150,1020 1140,1290 1290,1770
we have a parent

2008
01:05:51,060 --> 01:05:53,640
0,780 1920,2340
partition.| Right.|
|正确的。|

2009
01:05:54,960 --> 01:05:55,770
0,240 240,420 420,540 540,720 720,810
And let's say there's a
假设有一张地图，

2010
01:05:55,770 --> 01:05:57,480
0,810
map,|
|

2011
01:05:57,820 --> 01:05:58,840
0,390 390,690 690,810 810,930 930,1020
and here we have the
这里我们有一个子分区。

2012
01:05:58,840 --> 01:05:59,940
0,330 330,780
child partition.|
|

2013
01:06:04,640 --> 01:06:05,540
0,450
Okay?|
好吧?|

2014
01:06:05,840 --> 01:06:06,560
0,570
Right.|
正确的。|

2015
01:06:07,550 --> 01:06:08,690
0,240 240,360 360,630 630,720 720,1140
Good, so that's the narrow,
很好，这是狭义的，这是狭义的。

2016
01:06:08,690 --> 01:06:09,890
0,180 180,240 240,330 330,630 630,1200
this is the narrow case.|
|

2017
01:06:12,600 --> 01:06:15,260
0,600 600,1260 1560,2100
Right, but {}
是的，但我认为就像我想的例子一样，你知道每个父母至多被孩子的一个分区使用，

2018
01:06:16,530 --> 01:06:18,740
0,180 180,780 810,1050 1050,1860
I think like the

2019
01:06:19,460 --> 01:06:21,380
0,120 120,690 690,870 870,1290 1290,1920
the example of {I,was,thinking} {of,is}

2020
01:06:21,380 --> 01:06:22,240
0,120 120,450
you know

2021
01:06:22,890 --> 01:06:26,400
0,780 810,1230 1260,2220 2490,2970 2970,3510
each {} parent is used

2022
01:06:26,400 --> 01:06:28,540
0,270 270,930 1290,1860
by {at,most} {}

2023
01:06:29,590 --> 01:06:31,420
0,300 300,810 810,900 900,1020 1020,1830
one partition of the child,|
|

2024
01:06:31,950 --> 01:06:34,170
0,240 240,390 390,1170 1200,1920 1950,2220
but the child right,| that
但孩子是对的，|但这并没有说明什么，

2025
01:06:34,170 --> 01:06:35,550
0,270 270,450 450,810 810,1050 1050,1380
doesn't say anything about,| like
|就像它说的那样，就像它不一定意味着它是一对一的关系，对吧。

2026
01:06:35,940 --> 01:06:38,250
0,330 330,990 1230,1590 1590,1950 2130,2310
it says right like it

2027
01:06:38,250 --> 01:06:39,450
0,300 300,780 780,960 960,1080 1080,1200
doesn't necessarily mean it's a

2028
01:06:39,450 --> 01:06:40,960
0,420 420,1290
one-to-one relationship,

2029
01:06:41,250 --> 01:06:43,320
0,360 390,900 900,1320 1680,2040 2040,2070
right.| Well, because more or
|嗯，因为或多或少都要改正，

2030
01:06:43,320 --> 01:06:44,640
0,150 150,360 360,540 540,900 900,1320
less have to correct,| {let's,say},
|比方说，假设我们有一个很宽的，对吗，

2031
01:06:44,640 --> 01:06:46,230
0,690 900,1170 1170,1320 1320,1470 1470,1590
{} let's say we have

2032
01:06:46,230 --> 01:06:47,670
0,300 330,720 720,1020 1020,1320 1320,1440
a wide one, correct,| so
|然后在这里我们有父分区1。

2033
01:06:47,670 --> 01:06:48,440
0,390
then

2034
01:06:49,040 --> 01:06:51,380
0,420 420,570 570,990 1050,2040
here we have parent

2035
01:06:52,230 --> 01:06:54,240
0,540 540,1020
partition one.|
|

2036
01:06:54,520 --> 01:06:55,760
0,780

2037
01:06:56,350 --> 01:06:57,850
0,420 420,570 570,960 990,1410 1410,1500
Here we have maybe it
在这里，也许它们中的任何一个都是正确的，

2038
01:06:57,850 --> 01:06:59,140
0,300 300,480 480,570 570,780 780,1290
has any of them correct,|
|

2039
01:06:59,140 --> 01:07:02,890
0,1410 1410,1740 1740,2100 2730,3450 3510,3750
here, here's n in the
这里，这里是宽的那个中的n，孩子是。

2040
01:07:02,890 --> 01:07:03,960
0,300 300,780
wide one,

2041
01:07:06,660 --> 01:07:08,760
0,210 210,630 630,1050
the child is.|
|

2042
01:07:09,920 --> 01:07:12,110
0,660 690,1170 1410,1680 1680,1980 1980,2190
Right, {} what what what
好的，我想说的是

2043
01:07:12,110 --> 01:07:12,950
0,90 90,360 360,420 420,570 570,840
I what I was saying

2044
01:07:12,950 --> 01:07:14,840
0,420 570,870 870,870 870,1590 1710,1890
is| I I think you
|我想你知道根据论文中给出的定义，

2045
01:07:14,840 --> 01:07:15,950
0,150 150,450 450,510 510,570 570,1110
know based on the definition

2046
01:07:15,950 --> 01:07:17,480
0,240 240,300 300,420 420,1080
given in the paper,|
|

2047
01:07:17,720 --> 01:07:19,760
0,480 480,780 780,1260 1500,1680 1680,2040
this could be a narrow
这可能是一个狭窄的隔断，

2048
01:07:19,760 --> 01:07:21,080
0,720
partition,|
|

2049
01:07:24,010 --> 01:07:25,450
0,330 330,450 450,960 960,990 990,1440
and in fact, I mean
事实上，我的意思是，如果你看一下，

2050
01:07:25,480 --> 01:07:26,800
0,270 270,390 390,540 540,870 870,1320
like if you look at,|
|

2051
01:07:27,260 --> 01:07:28,160
0,600

2052
01:07:28,580 --> 01:07:30,770
0,240 240,360 360,990 1020,1440 1440,2190
like a join with input
就像使用输入共同分区的联接一样，就像您拥有的那样。

2053
01:07:30,800 --> 01:07:33,230
0,960 1020,1290 1290,1440 1440,1890 2130,2430
co-partition, like you have.| The
|哈希分区，实际上是宽的变成了窄的。

2054
01:07:33,230 --> 01:07:34,400
0,150 150,630 630,780 780,1110 1110,1170
hash partition that actually the

2055
01:07:34,400 --> 01:07:35,360
0,270 270,450 450,690 690,900 900,960
wide one turns into a

2056
01:07:35,360 --> 01:07:36,220
0,330 330,570
narrow one.|
|

2057
01:07:36,530 --> 01:07:39,020
0,900 900,1500 1500,1650 1650,1890 1890,2490
Right, but you still have
对，但你仍然有一个分区，一个子分区

2058
01:07:39,140 --> 01:07:41,570
0,570 630,810 810,1710 1980,2130 2130,2430
like a partition, a child

2059
01:07:41,570 --> 01:07:44,420
0,660 660,1170 1170,1680 1710,2520 2580,2850
partition| getting like like being
|感觉就像是从几个父分区计算出来的，对吧。

2060
01:07:44,420 --> 01:07:46,200
0,510 510,720 720,1410
computed from several

2061
01:07:46,510 --> 01:07:51,760
0,1530 1530,2250 2280,2850 2850,3420 4050,5250
parent partitions, right.| {} Explicitly
|明确提到这一权利，

2062
01:07:51,760 --> 01:07:52,990
0,300 300,480 510,810 870,1080 1080,1230
mention that right,| I think
|我认为这是唯一的例子。

2063
01:07:52,990 --> 01:07:54,480
0,120 120,240 240,570 570,1170
that's the only example.|
|

2064
01:07:54,910 --> 01:07:57,700
0,600 600,1230 1620,2220 2520,2640 2640,2790
Yeah, but like I think
是啊，但我觉得那句话打错了，对吧。

2065
01:07:57,700 --> 01:07:58,360
0,150 150,180 180,480 480,540 540,660
there's a typo in that

2066
01:07:58,360 --> 01:07:59,380
0,390 390,720
sentence, right.|
|

2067
01:08:02,250 --> 01:08:03,540
0,240 240,540 540,690 690,1080 1080,1290
I I mean I'm not
我的意思是我不确定这是不是，

2068
01:08:03,540 --> 01:08:04,950
0,300 300,540 540,900 900,1260 1260,1410
sure it's,| yeah I I'm
|是的，我，我不确定是不是，

2069
01:08:04,950 --> 01:08:06,840
0,210 210,570 570,780 780,1200 1500,1890
not sure if it's,| what
|他们的意思是喜欢作家。

2070
01:08:06,840 --> 01:08:08,610
0,150 150,540 540,660 660,960 960,1770
they meant to like writer.|
|

2071
01:08:09,240 --> 01:08:11,850
0,750 840,2100 2100,2220 2220,2490 2490,2610
Alright, well, we know we
好的，我们知道我们的结论就是这两个案子，就像我拿到的一样。

2072
01:08:11,850 --> 01:08:12,840
0,480 480,660 660,750 750,840 840,990
conclude this is the two

2073
01:08:12,840 --> 01:08:13,720
0,660
cases,

2074
01:08:13,930 --> 01:08:15,610
0,240 240,360 360,540 540,1020 1050,1680
like I got.| Yeah.| {I,guess}
|嗯。|我想是的，而且没有其他案件，

2075
01:08:15,610 --> 01:08:16,180
0,90 90,180 180,210 210,390 390,570
and there are no other

2076
01:08:16,180 --> 01:08:17,180
0,540
cases,|
|

2077
01:08:17,350 --> 01:08:19,090
0,900 900,1200 1200,1440 1440,1620 1620,1740
oh, and so then we
哦，这样我们就可以正确地进行每一次手术了

2078
01:08:19,090 --> 01:08:20,950
0,90 90,300 300,450 450,1020 1050,1860
can go for every operation

2079
01:08:20,950 --> 01:08:21,850
0,360 360,450 450,720 720,810 810,900
correct| and then we can
|然后我们可以看到它是窄的宽的。

2080
01:08:21,850 --> 01:08:23,290
0,210 210,420 420,600 600,1080 1080,1440
see when it's narrow wide

2081
01:08:23,290 --> 01:08:23,740
0,90
one.|
|

2082
01:08:23,910 --> 01:08:27,960
0,780 1290,1620 1860,2310 2310,2640 3630,4050
{Right,right}.| So once the job
好的好的。|因此，一旦定义这些操作的程序员的工作

2083
01:08:27,960 --> 01:08:29,520
0,60 60,150 150,870 870,1110 1110,1560
of the programmer that defines

2084
01:08:29,520 --> 01:08:31,200
0,150 150,750 750,900 900,1200 1200,1680
these operations| to actually indicate
|要实际指示它是宽分区还是窄、宽依赖或窄依赖，

2085
01:08:31,200 --> 01:08:32,640
0,240 240,450 450,540 540,990 990,1440
whether it's a wide partition

2086
01:08:32,640 --> 01:08:34,590
0,210 210,240 240,660 960,1500 1500,1950
or a narrow, wide dependency

2087
01:08:34,590 --> 01:08:36,630
0,120 120,180 180,480 480,1020 1770,2040
or a narrow dependency,| that's
|这就是图3所示的内容。

2088
01:08:36,630 --> 01:08:38,790
0,720 1110,1320 1320,1770 1770,2070 2070,2160
what, for figure table {3

2089
01:08:38,790 --> 01:08:42,600
0,120 120,510 960,2880 2910,3360 3360,3810
-} about.| Yeah, like what
|是啊，就像我说的那样，

2090
01:08:42,600 --> 01:08:43,740
0,90 90,300 300,450 450,630 630,1140
I'm saying is like,| usually
|通常就像我在纸上看到的那样，

2091
01:08:43,740 --> 01:08:45,060
0,360 390,660 660,780 780,1080 1080,1320
like like the way I

2092
01:08:45,060 --> 01:08:46,650
0,210 210,300 300,510 510,1140 1170,1590
saw it through paper,| like
|就像，你的例子会是，

2093
01:08:46,650 --> 01:08:47,660
0,300 330,900
{} like,

2094
01:08:47,880 --> 01:08:49,260
0,510 510,870 870,960 960,1080 1080,1380
your example on the wide

2095
01:08:49,260 --> 01:08:51,330
0,150 150,330 330,720 1290,1830 1830,2070
would be,| {} could would
|可能是一种狭隘的依赖，

2096
01:08:51,330 --> 01:08:53,160
0,120 120,180 180,570 570,1170 1170,1830
be a narrow dependency,| unless
|除非你有几个孩子

2097
01:08:53,280 --> 01:08:54,570
0,390 390,510 510,630 630,840 840,1290
right like you have several

2098
01:08:54,570 --> 01:08:56,760
0,630 840,990 990,1080 1080,1500 1500,2190
child| and the parent partitions
|而父分区是这样的。

2099
01:08:56,760 --> 01:08:58,980
0,210 210,630 900,1710 1740,1950 1950,2220
are like.| Okay, so in
|好的，所以总的来说，

2100
01:08:58,980 --> 01:09:00,030
0,450 450,720 720,840 840,990 990,1050
general,| okay, it is the
|好的，当然是这样的，

2101
01:09:00,030 --> 01:09:01,230
0,270 270,360 360,750 900,1050 1050,1200
case of course,| if there's
|如果这里还有另一个子分区，

2102
01:09:01,230 --> 01:09:02,700
0,270 270,600 600,960 960,1290 1320,1470
another child partition here,| okay
|好的，也许这就是为什么我们想要，

2103
01:09:02,700 --> 01:09:03,750
0,270 300,540 540,690 690,870 870,1050
so maybe that's why we're

2104
01:09:03,750 --> 01:09:05,040
0,150 150,210 210,480 900,1050 1050,1290
trying to get,| so let's
|所以让我们分开，真实的画面实际上画出了这个，

2105
01:09:05,400 --> 01:09:07,080
0,600 660,900 900,1140 1140,1470 1470,1680
separate, the real picture actually

2106
01:09:07,080 --> 01:09:08,140
0,360 360,780
draws this,|
|

2107
01:09:08,330 --> 01:09:09,350
0,150 150,300 300,450 450,690 690,1020
so it has another child
因此它有另一个子分区

2108
01:09:09,350 --> 01:09:13,070
0,570 720,930 930,1620 1710,2820 3120,3720
partition| and basically operations, {}
|从根本上说，这些转变就是。

2109
01:09:13,070 --> 01:09:15,000
0,510 510,1200 1200,1680
the transformations are.|
|

2110
01:09:17,210 --> 01:09:19,970
0,690 720,1380 1770,2040 2040,2400 2400,2760
Exactly, yeah and that's narrow
完全正确，是的，而且这肯定是狭隘的，就像。

2111
01:09:19,970 --> 01:09:23,090
0,180 180,660 690,1590 1950,2640 2940,3120
for sure, like.| This on
|这个在右边，这个是宽的。

2112
01:09:23,090 --> 01:09:23,720
0,60 60,240 240,420 420,540 540,630
the right side, this is

2113
01:09:23,720 --> 01:09:24,800
0,240 240,330 330,540 540,780 780,1080
wide.| {} Sorry, that's wide,
|抱歉，太宽了，是的。

2114
01:09:24,830 --> 01:09:25,880
0,450 450,660 660,750 750,780 780,1050
yeah.| That's what I meant,
|这就是我的意思，这肯定是广泛的。

2115
01:09:25,880 --> 01:09:29,930
0,1380 1860,3390 3390,3600 3600,3720 3720,4050
{that,for,sure} is wide.| {Another,I} drew
|我画的另一幅也是宽的，我相信。

2116
01:09:29,930 --> 01:09:31,040
0,60 60,270 270,540 570,750 750,1110
is also wide I believe.|
|

2117
01:09:31,850 --> 01:09:33,380
0,330 330,690 690,780 780,1050 1050,1530
Look if you do join,|
听着，如果你真的加入，|

2118
01:09:33,380 --> 01:09:34,700
0,90 90,240 240,480 480,930 930,1320
if you do an action
如果你做一个动作，比如收集最末端，你就知道广泛的依赖。

2119
01:09:34,700 --> 01:09:37,220
0,390 630,1590 1590,2160 2160,2250 2250,2520
like {} collect the very

2120
01:09:37,220 --> 01:09:38,570
0,360 510,630 630,750 750,1080 1080,1350
end, you know wide dependency.|
|

2121
01:09:38,570 --> 01:09:39,340
0,480
Yeah,
好的，好的。

2122
01:09:39,700 --> 01:09:41,350
0,420 420,570 570,840 840,1170 1170,1650
okay.| It doesn't say, it
|它没有说，它没有说，它必须来自不同的RDDS，

2123
01:09:41,350 --> 01:09:41,980
0,210 210,330 330,420 420,540 540,630
doesn't say, it has to

2124
01:09:41,980 --> 01:09:43,090
0,120 120,210 210,450 450,990 990,1110
come from different RDDs,| it
|它只是说它必须来自不同的分区。

2125
01:09:43,090 --> 01:09:43,900
0,180 180,420 420,600 600,690 690,810
just says like it has

2126
01:09:43,900 --> 01:09:45,280
0,60 60,180 180,480 480,780 780,1380
to come from different partitions.|
|

2127
01:09:45,580 --> 01:09:46,600
0,120 120,240 240,420 420,510 510,1020
And so this is narrow,
所以这是狭窄的，所以我认为狭窄只是一对一的情况。

2128
01:09:47,230 --> 01:09:48,190
0,180 180,270 270,480 480,840 840,960
so I think narrow is

2129
01:09:48,190 --> 01:09:49,330
0,300 300,360 360,690 690,1080 1080,1140
only the case where is

2130
01:09:49,330 --> 01:09:50,240
0,210 210,300 300,570
{one-to-one - -}.|
|

2131
01:09:50,610 --> 01:09:53,220
0,810 840,1470 1470,1770 1800,2040 2040,2610
Okay.| {Narrow,is} like, narrow means
好吧。|窄就像，窄就是没有交流。

2132
01:09:53,250 --> 01:09:55,080
0,270 270,960
no communication.|
|

2133
01:09:55,870 --> 01:09:56,740
0,690
Right,
好的，好的，是的。

2134
01:09:56,810 --> 01:09:57,740
0,720
okay,

2135
01:10:02,840 --> 01:10:03,860
0,840
yep.|
|

2136
01:10:07,660 --> 01:10:08,770
0,240 240,570 570,810 810,930 930,1110
Yeah, I think I think
是的，我想我想我困惑的那个案例

2137
01:10:08,770 --> 01:10:10,510
0,600 630,1080 1080,1260 1260,1410 1410,1740
the case where I was

2138
01:10:10,510 --> 01:10:12,490
0,600 600,780 780,960 960,1260 1440,1980
confused| was like {} like
|就像是多对一，

2139
01:10:13,030 --> 01:10:16,060
0,840 1110,1680 1680,1770 1770,2250 2280,3030
{} {many-to-one - -},| like
|就像我认为，根据这个定义，

2140
01:10:16,330 --> 01:10:17,350
0,450 450,660 660,870 870,960 960,1020
I think based on the

2141
01:10:17,350 --> 01:10:18,610
0,540 540,630 630,780 780,1080 1080,1260
definition of the,| like of
|就像报纸上的，

2142
01:10:18,610 --> 01:10:19,900
0,150 150,330 330,720 750,1140 1140,1290
the of the paper,| like
|像多对一的关系还是，还是狭隘的。

2143
01:10:19,900 --> 01:10:21,070
0,90 90,360 360,420 420,660 660,1170
the {many-to-one - -} relation

2144
01:10:21,070 --> 01:10:21,980
0,120 120,690
is still,

2145
01:10:22,180 --> 01:10:25,390
0,690 810,1200 1200,1800 2160,2520 2520,3210
{} still narrow.| No, I
|不，我想他们是故意的。

2146
01:10:25,390 --> 01:10:26,740
0,180 180,690 720,1170 1170,1260 1260,1350
think they mean it to

2147
01:10:26,740 --> 01:10:29,530
0,180 180,1890 1920,2460 2460,2580 2580,2790
be.| Yeah yeah, but like
|是的，是的，但严格来说，如果你真的，

2148
01:10:29,530 --> 01:10:30,760
0,540 540,720 720,810 810,990 990,1230
strictly like if you really,|
|

2149
01:10:30,760 --> 01:10:32,560
0,330 330,1080 1230,1410 1410,1560 1560,1800
like yeah I I think
就像，是的，我想也许就像你会看到的那样，

2150
01:10:32,560 --> 01:10:34,090
0,330 330,510 510,570 570,1380 1380,1530
maybe like an implementation you'll

2151
01:10:34,090 --> 01:10:36,010
0,240 240,570 930,1530 1530,1890 1890,1920
see like,| yeah what are
|是啊，你在说什么好像它很宽。

2152
01:10:36,010 --> 01:10:36,880
0,90 90,360 390,600 600,720 720,870
you saying right like it's

2153
01:10:36,880 --> 01:10:37,520
0,450
wide.|
|

2154
01:10:37,710 --> 01:10:38,430
0,150 150,240 240,420 420,570 570,720
I was just like,| I
我就像是，|我想如果你读起来像。

2155
01:10:38,430 --> 01:10:39,300
0,150 150,270 270,450 450,690 690,870
think if you read like.|
|

2156
01:10:39,300 --> 01:10:42,810
0,480 540,1740 1740,2100 2130,2670 2670,3510
[] confusing.| Paper actually yeah
[]令人困惑。|纸面上实际上是的，你可能会感到困惑，就像多对一的关系，

2157
01:10:42,810 --> 01:10:44,310
0,270 420,630 630,780 780,1290 1290,1500
you can get confused like

2158
01:10:44,310 --> 01:10:45,330
0,240 240,330 330,480 480,510 510,1020
{many-to-one - -} {} relationship,|
|

2159
01:10:45,420 --> 01:10:46,770
0,330 330,600 600,900 900,990 990,1350
now the {one-to-many - -}
现在一对多显然是广泛的，是的，

2160
01:10:46,770 --> 01:10:48,660
0,120 120,660 660,1140 1170,1530
is clearly wide, yeah,|
|

2161
01:10:49,000 --> 01:10:50,890
0,210 210,540 540,1020 1200,1500 1500,1890
but, yeah okay, sounds good.|
但是，好的，听起来不错。|

2162
01:10:51,430 --> 01:10:54,060
0,540 570,2160
Okay.| Yeah,
好吧。|是的，我认为这篇论文总体上更容易理解。

2163
01:10:54,330 --> 01:10:56,190
0,180 180,690 690,1050 1080,1560 1560,1860
I think the paper easier

2164
01:10:56,190 --> 01:10:58,470
0,90 90,570 570,660 660,1380 1620,2280
to understand in general.| Okay.|
|好吧。|

2165
01:10:59,390 --> 01:11:01,430
0,420 420,870 1110,1290 1290,1560 1560,2040
Good okay.| There's that easier
好的，好的。|对于农场来说，这比纸更容易。

2166
01:11:01,460 --> 01:11:03,590
0,390 390,810 810,870 870,1710 1800,2130
{than,the} paper for FaRM. {}|
|

2167
01:11:03,590 --> 01:11:08,120
0,30 30,2820 3330,3900 3960,4440 4440,4530
Oh yeah, sure.| Yeah, I
哦，好的，当然。|是的，我想是的我想那可能是最耐用的两张纸，

2168
01:11:08,120 --> 01:11:09,920
0,180 180,900 930,1050 1050,1470 1470,1800
think so I think those

2169
01:11:09,920 --> 01:11:11,060
0,150 150,420 420,630 630,990 990,1140
were probably the most two

2170
01:11:11,060 --> 01:11:12,500
0,510 510,780 780,960 960,960 960,1440
heavy-duty paper,| so a lot
|因此，这一学期将会有很多事情发生。

2171
01:11:12,500 --> 01:11:13,700
0,210 210,480 480,660 660,990
will see {in,this} term.|
|

2172
01:11:14,940 --> 01:11:16,830
0,480 510,840 840,1440 1440,1590 1590,1890
Okay, nice.| {The,part} it's hard
好的，很好。|这部分很难留在那里，

2173
01:11:16,830 --> 01:11:17,850
0,60 60,300 300,570 600,720 720,1020
to stay there,| I think
|我认为剩下的要多一点，你知道的更多，

2174
01:11:17,850 --> 01:11:19,260
0,210 210,540 540,780 780,1140 1170,1410
the remaining was a little

2175
01:11:19,260 --> 01:11:21,900
0,120 120,690 840,930 930,1320 1500,2640
bit more you know more,|
|

2176
01:11:21,900 --> 01:11:22,830
0,300 300,540 540,690 690,750 750,930
{} I'm going to say
我要直截了当地说，

2177
01:11:22,830 --> 01:11:26,310
0,810 1230,1710 2010,2610 2610,3180 3180,3480
straightforward,| {} perhaps fewer moving
|也许移动的碎片更少了。

2178
01:11:26,310 --> 01:11:27,060
0,570
pieces.|
|

2179
01:11:27,710 --> 01:11:28,580
0,600
Nice.|
好的。|

2180
01:11:29,980 --> 01:11:32,650
0,540 570,960 1500,1770 1770,2400 2400,2670
Okay, awesome, thanks {professor -}.|
好的，太棒了，谢谢教授。|

2181
01:11:32,770 --> 01:11:34,000
0,180 180,240 240,510 510,900 930,1230
Can I ask one last
我能问最后一个问题吗，

2182
01:11:34,000 --> 01:11:35,590
0,570 600,900 900,1110 1110,1500 1500,1590
question,| I just realized that
|我刚刚意识到我有，

2183
01:11:35,590 --> 01:11:38,410
0,120 120,1380 1860,2010 2010,2310 2310,2820
I have,| it was about
|是关于谈话的，你可以让它瘫痪，

2184
01:11:38,410 --> 01:11:40,390
0,240 240,960 960,1140 1140,1410 1410,1980
the conversation, you can paralyze

2185
01:11:40,390 --> 01:11:41,220
0,150 150,630
it,| if
|如果是不同的分区，

2186
01:11:41,490 --> 01:11:42,690
0,210 210,360 360,420 420,690 690,1200
if it's a different partitions,|
|

2187
01:11:42,690 --> 01:11:44,220
0,210 210,420 420,600 600,1230
but if it's also
但如果它也是你说的如果它在里面。

2188
01:11:44,780 --> 01:11:46,070
0,360 360,480 480,780 780,900 900,1290
{} you said if it's

2189
01:11:46,340 --> 01:11:48,680
0,180 180,720 720,1230 1230,1950 1950,2340
in.| The stage stages right,|
|舞台的舞台是对的，|

2190
01:11:48,680 --> 01:11:49,730
0,90 90,270 270,780 780,930 930,1050
you know there's sort of
你知道流并行是什么样子的，如果你愿意的话，或者流水线并行。

2191
01:11:49,730 --> 01:11:51,020
0,750 780,960 960,1050 1050,1140 1140,1290
{} what is it like

2192
01:11:51,020 --> 01:11:52,550
0,390 390,1020 1020,1110 1110,1230 1230,1530
streaming parallelism, if you will

2193
01:11:52,550 --> 01:11:55,400
0,270 270,690 690,1290 1980,2760 2760,2850
or pipeline parallelism.| Let me
|让我看看能不能找到一张照片，有一张。

2194
01:11:55,400 --> 01:11:56,060
0,180 180,270 270,300 300,450 450,660
see if I can find

2195
01:11:56,060 --> 01:11:57,440
0,30 30,720
a picture,

2196
01:11:58,110 --> 01:11:59,640
0,210 210,360 360,450 450,840
there's one of them.|
|

2197
01:12:01,280 --> 01:12:03,980
0,1170 1230,2400

2198
01:12:04,840 --> 01:12:06,550
0,120 120,330 330,570 570,960 960,1710
I gotta find lineage graph,
我得找到谱系图，不，不，

2199
01:12:06,580 --> 01:12:08,720
0,1200 1230,1830
{} no,

2200
01:12:09,820 --> 01:12:10,800
0,690
no,|
|

2201
01:12:11,260 --> 01:12:12,730
0,150 150,450 450,810 810,960 960,1470
right here whenever this graph,|
就在这里，每当这张图，|

2202
01:12:12,760 --> 01:12:14,410
0,270 270,390 390,630 630,840 840,1650
great now maybe here's one
很好，现在也许有一张图片我们可以修改。

2203
01:12:14,440 --> 01:12:15,910
0,450 450,540 540,630 630,750 750,1470
picture that we can modify.|
|

2204
01:12:16,800 --> 01:12:17,960
0,270 270,390 390,480 480,840
{} Do you see?|
你看到了吗？|

2205
01:12:18,900 --> 01:12:22,530
0,690 870,1530 1650,2250 2550,3450 3450,3630
Yes.| Okay, so basically this
是。|好的，基本上这是要收集的谱系图

2206
01:12:22,530 --> 01:12:23,550
0,60 60,180 180,510 510,810 810,1020
is the {lineage,graph -} here

2207
01:12:23,550 --> 01:12:26,340
0,120 120,660 960,1650 1800,2460 2520,2790
to collect| and so this
|所以这就像是一个正确的阶段，

2208
01:12:26,340 --> 01:12:27,900
0,150 150,300 300,510 510,1080 1080,1560
is like one stage right,|
|

2209
01:12:30,820 --> 01:12:32,080
0,330 330,780 780,990 990,1200 1200,1260
the scheduler runs one of
调度器为每个分区运行每个工作器的一个阶段，对吧，

2210
01:12:32,080 --> 01:12:33,400
0,120 120,540 540,660 660,810 810,1320
the stages of each worker,

2211
01:12:33,970 --> 01:12:36,520
0,210 210,330 330,930 1020,1470 1920,2550
for each partition, right,| so
|因此每个工作器在分区上运行一个阶段，

2212
01:12:36,700 --> 01:12:37,880
0,660
each

2213
01:12:38,610 --> 01:12:41,900
0,900
worker

2214
01:12:42,110 --> 01:12:43,670
0,240 240,840 840,930 930,1020 1020,1560
runs {a,stage} on the partition,|
|

2215
01:12:48,770 --> 01:12:50,570
0,180 180,750 750,960 960,1200 1200,1800
so basically all these partitions,
所以基本上所有这些分区，都是在不同的工作进程上并行运行的，

2216
01:12:50,570 --> 01:12:52,580
0,300 300,450 450,870 1260,1710 1710,2010
are all these stages running

2217
01:12:52,580 --> 01:12:54,360
0,540 540,690 690,960 960,1560
parallel on different workers,|
|

2218
01:12:55,200 --> 01:12:57,450
0,420 420,1230 1470,1620 1620,2070 2070,2250
then within a stage, there's
然后在一个阶段内，也有并行，

2219
01:12:57,450 --> 01:12:58,560
0,240 240,840
also parallelism,|
|

2220
01:12:59,100 --> 01:13:01,050
0,420 420,1290 1320,1470 1470,1680 1680,1950
{} because you know every
因为你知道每个过滤器都是流水线的，

2221
01:13:01,050 --> 01:13:03,800
0,720 780,1470 1470,1680 1680,2430
filter {} is pipelined,|
|

2222
01:13:04,010 --> 01:13:05,450
0,300 300,960 960,1110 1110,1260 1260,1440
{} without you know they
如果你不知道他们的意思就像你读到的那样，

2223
01:13:05,450 --> 01:13:07,040
0,480 480,810 810,930 930,1230 1260,1590
mean like you read,| maybe
|也许就像第一张和唱片一样，

2224
01:13:07,040 --> 01:13:08,660
0,180 180,270 270,720 720,960 960,1620
like the first and records,|
|

2225
01:13:09,450 --> 01:13:10,470
0,240 240,510 510,690 690,930 930,1020
and then you apply the
然后你应用过滤操作，

2226
01:13:10,470 --> 01:13:11,740
0,330 330,960
filter operation,|
|

2227
01:13:12,780 --> 01:13:15,390
0,210 210,870 870,1650 1650,2010 2010,2610
and then a it produces
然后a，你知道，不管记录少了多少，

2228
01:13:15,390 --> 01:13:18,720
0,120 120,180 180,690 840,1950 3000,3330
you know whatever fewer n

2229
01:13:18,720 --> 01:13:19,600
0,600
records,|
|

2230
01:13:20,030 --> 01:13:21,440
0,720 720,870 870,990 990,1320 1320,1410
and you know then the
你知道，然后下一个你知道的过滤器，你知道的，处理这n个记录，

2231
01:13:21,440 --> 01:13:22,880
0,510 510,600 600,720 720,1320 1350,1440
next you know filter you

2232
01:13:22,880 --> 01:13:24,860
0,150 150,540 540,1110 1140,1410 1410,1980
know process those n records,|
|

2233
01:13:24,890 --> 01:13:26,330
0,240 240,690 690,1050 1050,1260 1260,1440
the [] crossing those {}
打破这些记录的[]，

2234
01:13:26,330 --> 01:13:28,400
0,630 870,1020 1020,1260 1260,1770 1770,2070
records,| the first filter reads
|第一个过滤器读取下一个N，

2235
01:13:28,400 --> 01:13:29,380
0,90 90,300 300,660
the next n,|
|

2236
01:13:30,560 --> 01:13:32,030
0,360 360,450 450,540 540,1020 1020,1470
and you know produces them
你知道，生产它们，然后把它们传递下去

2237
01:13:32,090 --> 01:13:33,560
0,180 180,450 450,810 810,960 960,1470
and then pass them on|
|

2238
01:13:33,560 --> 01:13:34,490
0,180 180,420 420,510 510,660 660,930
and then you know making
然后你知道在一些数字记录中取得结果，

2239
01:13:34,490 --> 01:13:35,960
0,480 480,600 600,810 810,1140 1140,1470
results in some number records,|
|

2240
01:13:35,960 --> 01:13:37,310
0,180 180,750 750,900 900,1140 1140,1350
{} again, and it goes
再一次，而且还在继续，

2241
01:13:37,310 --> 01:13:38,780
0,180 180,300 300,510 960,1140 1140,1470
on and on,| so basically
|所以基本上所有这些，哎呀，像这些所有这些转换都是流水线的，

2242
01:13:38,780 --> 01:13:41,090
0,330 330,930 1350,1650 1650,1890 1890,2310
all these all these, oops,

2243
01:13:41,150 --> 01:13:44,150
0,150 150,570 630,990 990,1470 1710,3000
like these all these transformations

2244
01:13:44,540 --> 01:13:45,760
0,240 240,840
are pipelined,|
|

2245
01:13:48,200 --> 01:13:49,490
0,210 210,360 360,570 570,1020 1020,1290
and so they're always running
所以它们总是同时运行

2246
01:13:49,490 --> 01:13:51,470
0,540 540,810 810,1200 1200,1620 1650,1980
concurrently| or running not truly
|或者不是真正同时运行，它们是以流水线方式运行的。

2247
01:13:51,470 --> 01:13:52,400
0,450 450,630 630,870 870,930 930,930
concurrently, they're running in a

2248
01:13:52,400 --> 01:13:53,600
0,480 480,840
pipeline fashion.|
|

2249
01:13:54,440 --> 01:13:55,910
0,600 690,900 900,1080 1080,1350 1350,1470
Oh, I just said this
哦，我刚说了这是批次的事情，他们在谈论。

2250
01:13:55,910 --> 01:13:57,350
0,180 180,300 300,930 960,1260 1260,1440
is a batch thing, they

2251
01:13:57,350 --> 01:13:59,780
0,120 120,450 450,870 900,1680 2130,2430
were talking about.| Yeah, so
|是的，所以事情都过去了，分批进行，

2252
01:13:59,780 --> 01:14:01,130
0,180 180,510 510,810 810,900 900,1350
things are past and batches,|
|

2253
01:14:01,130 --> 01:14:02,690
0,180 180,480 480,1020 1020,1110 1110,1560
and basically {every,stage} the pipeline
基本上，管道的每个阶段都是成批处理的。

2254
01:14:02,720 --> 01:14:04,460
0,1080 1080,1560
processes batch.|
|

2255
01:14:05,500 --> 01:14:07,180
0,420 420,630 630,1140 1140,1530 1530,1680
Okay, okay, yeah makes for
好的，好的，我说得很清楚，

2256
01:14:07,180 --> 01:14:08,200
0,270 270,450 450,720 720,840 840,1020
clear,| yeah, thank you so
|是啊，非常感谢你，

2257
01:14:08,200 --> 01:14:09,460
0,300 300,450 450,870 990,1110 1110,1260
much,| that was it was
|这是一堂有趣的课，谢谢你。

2258
01:14:09,460 --> 01:14:11,320
0,210 240,690 690,1170 1170,1470 1470,1860
an interesting lecture, thank you.|
|

2259
01:14:11,350 --> 01:14:12,680
0,270 270,390 390,810
Okay, you're welcome,
好的，不客气，很高兴你喜欢，

2260
01:14:13,040 --> 01:14:14,280
0,270 270,330 330,570 570,900
glad you enjoy it,|
|

2261
01:14:14,650 --> 01:14:16,000
0,330 330,810
{it's,a,cool} system.|
这是一个很酷的系统。|

2262
01:14:16,420 --> 01:14:18,500
0,480 750,1380

2263
01:14:23,780 --> 01:14:25,040
0,660 660,930 930,1080 1080,1140 1140,1260
Sorry, sorry, can you hear
抱歉，抱歉，你现在能听到我说话吗。

2264
01:14:25,040 --> 01:14:28,520
0,120 120,390 630,2580 2580,3180 3180,3480
me now.| Yeah yeah, wondering
|是啊，是啊，不知道是怎么回事。

2265
01:14:28,520 --> 01:14:31,880
0,150 150,450 450,2190 2370,2730 2730,3360
what did yeah.| {No,problem}, I'm
|没问题，我很抱歉，

2266
01:14:31,880 --> 01:14:33,320
0,210 210,420 420,660 660,1140 1170,1440
sorry about that,| I yeah
|我很抱歉我在听，

2267
01:14:33,320 --> 01:14:34,220
0,240 240,300 300,450 450,750 750,900
sorry I was listening,| I
|我意识到我们会走得很晚，

2268
01:14:34,220 --> 01:14:37,220
0,450 570,1470 1710,1950 1950,2670 2670,3000
{ -} I I realized

2269
01:14:37,220 --> 01:14:38,030
0,120 120,210 210,450 450,720 720,810
we'd be going late,| I'm
|我会试着让这个问题变得非常简短，

2270
01:14:38,030 --> 01:14:38,600
0,120 120,180 180,330 330,420 420,570
going to try to make

2271
01:14:38,600 --> 01:14:40,550
0,150 150,480 480,690 690,1140 1230,1950
this question very quick,| I've
|我以前也用过Spark。

2272
01:14:40,550 --> 01:14:42,290
0,300 300,420 420,660 660,990 990,1740
gotten to use spark before.|
|

2273
01:14:43,310 --> 01:14:46,130
0,990 990,1500 1530,2520 2520,2640 2640,2820
Thank you, thank you so
谢谢，非常感谢。

2274
01:14:46,130 --> 01:14:48,590
0,450 1230,1410 1410,2070 2070,2100 2280,2460
much.| So yeah {} yeah
|所以，是的，是的，我真的，真的很感谢这堂课，

2275
01:14:48,590 --> 01:14:50,120
0,270 270,630 630,900 900,1350 1350,1530
I really, really appreciate this

2276
01:14:50,120 --> 01:14:51,830
0,810 810,900 900,1290 1290,1410 1410,1710
lecture,| {} spark is actually
|火花实际上是我在未来的工作中会用到的东西，

2277
01:14:51,830 --> 01:14:53,000
0,330 330,480 480,600 600,810 810,1170
something that I'm gonna use

2278
01:14:53,000 --> 01:14:54,230
0,120 120,300 300,690 690,1080 1080,1230
in my future job,| so
|所以我很感谢你教我这个，

2279
01:14:54,230 --> 01:14:55,520
0,60 60,540 540,690 690,1050 1050,1290
I appreciate you teaching this

2280
01:14:55,520 --> 01:14:57,920
0,210 270,1050 1170,1470 1470,1950 1950,2400
me,| {} just one.| Probably,
|只有一个。|也许，也许我不确定这是否真的会对你编写Spark程序有所帮助。

2281
01:14:57,920 --> 01:14:59,120
0,570 570,780 780,960 960,1080 1080,1200
probably I'm not sure this

2282
01:14:59,360 --> 01:15:00,650
0,360 360,690 690,930 930,1050 1050,1290
will really help your writing

2283
01:15:00,650 --> 01:15:03,920
0,330 330,900 1050,2760 2760,3120 3120,3270
spark programs.| No, I mean
|不，我是说我当实习生的时候真的不知道我在做什么，

2284
01:15:03,920 --> 01:15:04,580
0,90 90,300 300,420 420,540 540,660
I did it as an

2285
01:15:04,580 --> 01:15:06,080
0,570 570,780 780,1080 1080,1320 1320,1500
intern really not knowing what

2286
01:15:06,080 --> 01:15:07,580
0,90 90,300 300,750 750,1110 1110,1500
I was doing,| but like
|但像这样帮助我给出了更多的背景信息。

2287
01:15:07,610 --> 01:15:09,140
0,270 270,420 420,750 750,1140 1140,1530
this has helped me give

2288
01:15:09,230 --> 01:15:10,670
0,360 360,480 480,1050 1050,1200 1200,1440
give more context with it.|
|

2289
01:15:12,100 --> 01:15:13,450
0,390 390,720 720,930 930,1230 1230,1350
So I guess the the
所以我想我要问的问题是火花计划，

2290
01:15:13,450 --> 01:15:14,770
0,180 180,600 600,810 810,990 990,1320
quick question with a spark

2291
01:15:14,770 --> 01:15:17,440
0,510 510,780 780,1140 1440,2040 2100,2670
programs that,| { -} {the,way}
|我对火花工作的理解是

2292
01:15:17,440 --> 01:15:18,940
0,150 150,300 300,720 720,1020 1020,1500
that I've understood spark jobs

2293
01:15:18,940 --> 01:15:21,370
0,450 480,930 930,1500 1500,2220 2220,2430
is| how spark constructs a
|Spark如何构造所有任务的有向无环图，以及。

2294
01:15:21,370 --> 01:15:24,370
0,570 570,1680 1680,2130 2130,2580 2580,3000
directed a directed acyclic graph

2295
01:15:24,370 --> 01:15:27,160
0,150 150,300 300,390 390,1020 1140,2790
of all the tasks, and.|
|

2296
01:15:27,760 --> 01:15:28,870
0,510 540,720 720,900 900,990 990,1110
Yep, and this is what
是的，这就是你所说的宽分区和窄分区。

2297
01:15:28,870 --> 01:15:29,740
0,120 120,330 330,540 540,660 660,870
you talked about with the

2298
01:15:29,740 --> 01:15:31,810
0,360 360,990 990,1140 1140,1470 1470,2070
wide partitions and narrow partitions.|
|

2299
01:15:31,810 --> 01:15:35,800
0,90 90,450 690,1230 1230,1830 3540,3990
I {think,they're,called,dependencies}, {not -} partitions.|
我认为它们被称为依赖项，而不是分区。|

2300
01:15:35,800 --> 01:15:38,980
0,210 690,1080 1110,2100 2130,2730 2730,3180
{} Oh yep, okay, okay.
哦是的，好的，好的。好的，对不起，

2301
01:15:39,600 --> 01:15:42,540
0,630 870,1320 1320,1590 1590,2070 2430,2940
{} okay, sorry,| {} that
|有了我们的RDDS，我想，

2302
01:15:42,540 --> 01:15:43,860
0,510 510,660 660,1050 1050,1200 1200,1320
with our RDDs and I

2303
01:15:43,860 --> 01:15:44,700
0,240 240,600
guess like,|
|

2304
01:15:45,010 --> 01:15:47,050
0,300 300,780 780,930 930,1290 1290,2040
okay, this is different terminology
好的，这是不同的术语，

2305
01:15:47,050 --> 01:15:47,940
0,600
between,|
|

2306
01:15:48,660 --> 01:15:50,550
0,390 390,1290 1290,1440 1440,1650 1650,1890
the dependencies are like these
依赖关系类似于所有任务的有向无环图中的这些任务，

2307
01:15:50,550 --> 01:15:52,230
0,510 510,660 660,780 780,1230 1230,1680
tasks in the directed acyclic

2308
01:15:52,230 --> 01:15:53,580
0,540 570,690 690,810 810,870 870,1350
graph of all the tasks,|
|

2309
01:15:53,580 --> 01:15:55,060
0,180 180,390 420,1260
but the RDDs
但是RDDS，就像这个图中的每个任务一样，并不是由这个RDD表示的。

2310
01:15:55,400 --> 01:15:58,370
0,690 690,1260 1290,1770 1800,2310 2820,2970
that's like each task in

2311
01:15:58,370 --> 01:15:59,750
0,150 150,420 420,540 540,750 750,1380
this graph is not represented

2312
01:15:59,750 --> 01:16:00,940
0,150 150,390 390,540 540,900
by this {RDD -}.|
|

2313
01:16:01,370 --> 01:16:02,570
0,180 180,270 270,510 510,660 660,1200
Let me actually go back,|
让我回到过去，|

2314
01:16:02,990 --> 01:16:04,520
0,330 330,510 510,990 990,1050 1050,1530
maybe these pictures are right.|
也许这些照片是对的。|

2315
01:16:04,550 --> 01:16:06,860
0,630 1440,1770 1770,1950 1950,2250 2250,2310
{} And oh gosh I
哦，天哪，我很感谢你留在这里，

2316
01:16:06,860 --> 01:16:08,150
0,480 480,540 540,780 780,960 960,1290
appreciate you staying here,| please
|如果你一定要去，请告诉我。

2317
01:16:08,150 --> 01:16:08,750
0,150 150,240 240,360 360,510 510,600
let me know if you

2318
01:16:08,750 --> 01:16:14,600
0,150 150,2970 3000,3270 3570,4410 4620,5850
have to go to.| {No,no,no,no,no,that's,right,I,have,more,time}.|
|不，不，没错，我有更多的时间。|

2319
01:16:14,750 --> 01:16:15,420
0,420
So,
所以，好的，这是一种RDD正确的方法，

2320
01:16:16,070 --> 01:16:17,540
0,420 450,870 900,1200 1200,1320 1320,1470
okay, so this is sort

2321
01:16:17,540 --> 01:16:19,430
0,90 90,120 120,720 720,1080 1470,1890
of a RDD correct,| let
|让我画另一种颜色，这样我们就可以[同意]，

2322
01:16:19,430 --> 01:16:21,740
0,120 180,660 660,1320 1410,1920 1920,2310
me draw another color, so

2323
01:16:21,830 --> 01:16:23,630
0,270 270,450 450,900 1080,1650 1650,1800
we can [agree],| this {is,an}
|这是一个RDD，RDD有一堆分区，

2324
01:16:23,630 --> 01:16:24,520
0,180 180,630
{RDD -},

2325
01:16:25,410 --> 01:16:26,670
0,690 690,930 930,990 990,1170 1170,1260
RDD has a bunch of

2326
01:16:26,670 --> 01:16:27,680
0,720
partitions,|
|

2327
01:16:28,420 --> 01:16:30,220
0,360 360,630 630,1110 1140,1410 1410,1800
and here's another {RDD -}.|
这是另一个RDD。|

2328
01:16:33,230 --> 01:16:36,530
0,510 720,1200 1590,2250 2790,3150 3150,3300
Okay, yep and {} the
好吧，是的，这些箭基本上都是一样的故事，

2329
01:16:36,530 --> 01:16:38,120
0,450 450,570 570,1290 1290,1440 1440,1590
arrows are basically as sort

2330
01:16:38,120 --> 01:16:39,860
0,60 60,690 810,1050 1050,1290 1290,1740
of like the same story,|
|

2331
01:16:39,950 --> 01:16:41,630
0,240 240,420 420,840 1200,1500 1500,1680
when we actually finish this
当我们真的拍完这张照片时，

2332
01:16:41,630 --> 01:16:43,070
0,300 300,540 540,690 690,960 990,1440
picture too,| on the side
|在这一边有更多的隔板，

2333
01:16:43,070 --> 01:16:44,780
0,270 270,510 510,1290
here more partitions,|
|

2334
01:16:45,050 --> 01:16:49,160
0,480 480,1050 1080,2160 2460,3360 3390,4110
here's the RDDs, boom RDD,
这是RDDS，BOM RDD，BOM RDD，

2335
01:16:49,460 --> 01:16:51,530
0,660 660,870 870,1170 1530,1770 1770,2070
boom {RDD - -},| those
|这些转换基本上是在RDDS之间，对，

2336
01:16:51,530 --> 01:16:53,750
0,690 690,1050 1050,1560 1560,1830 1830,2220
transformations basically between {RDDs -},

2337
01:16:53,750 --> 01:16:56,280
0,330 1110,1320 1320,1650 1650,2310
right,| so the arrows,|
|所以这些箭，|

2338
01:16:56,880 --> 01:16:58,950
0,390 390,630 990,1200 1200,1500 1500,2070
let me pick another color,|
让我选另一种颜色，|

2339
01:16:58,980 --> 01:17:00,420
0,90 90,180 180,420 420,1110
you know these errors,
你知道这些错误，这些都是转换。

2340
01:17:01,050 --> 01:17:02,680
0,300 300,480 480,1320
those are transformations.|
|

2341
01:17:04,010 --> 01:17:05,960
0,540 540,840 840,1200 1200,1680 1680,1950
Got you, and this is
明白了，这就像是智能作业的有向循环图的一部分，

2342
01:17:05,960 --> 01:17:07,310
0,240 240,360 360,570 570,1140 1170,1350
this is like part of

2343
01:17:07,310 --> 01:17:08,840
0,210 210,660 660,750 750,1170 1170,1530
the directed {} cyclical graph

2344
01:17:08,840 --> 01:17:10,430
0,120 120,210 210,570 570,1140 1230,1590
of the smart job,| every
|每一次转换都会导致创建另一个RDD，

2345
01:17:10,430 --> 01:17:12,860
0,270 270,1170 1170,1500 1500,1860 1890,2430
single transformation leads to creating

2346
01:17:12,860 --> 01:17:14,720
0,330 330,450 450,870 1230,1680 1680,1860
another {RDD -},| that makes
|这是有道理的，这是有道理的。

2347
01:17:14,720 --> 01:17:16,580
0,390 390,840 840,1020 1020,1440 1500,1860
sense, that makes sense.| Okay
|好的，唯一的问题是有些箭头很宽，有些很窄，

2348
01:17:16,580 --> 01:17:17,360
0,120 120,270 270,330 330,600 600,780
and then the only thing

2349
01:17:17,360 --> 01:17:18,110
0,180 180,360 360,510 510,600 600,750
is like some of these

2350
01:17:18,110 --> 01:17:18,980
0,720
arrows

2351
01:17:19,270 --> 01:17:20,740
0,390 390,1050 1050,1170 1170,1350 1350,1470
are wide and some of

2352
01:17:20,740 --> 01:17:21,760
0,180 180,270 270,780
them are narrow,|
|

2353
01:17:22,040 --> 01:17:23,390
0,390 390,480 480,1110 1110,1290 1290,1350
and the graph, from the
从图表上看，你不能真正区分哪些是窄的，哪些是窄的，

2354
01:17:23,390 --> 01:17:24,950
0,450 450,630 630,900 900,1080 1080,1560
graph, you can't really tell

2355
01:17:25,370 --> 01:17:26,780
0,300 300,480 480,690 690,810 810,1410
whether which ones are narrow

2356
01:17:26,780 --> 01:17:28,760
0,300 300,510 510,780 780,1260 1680,1980
or which ones are {},|
|

2357
01:17:28,760 --> 01:17:31,220
0,270 270,930 930,1050 1050,1560 1560,2460
which transformations are narrow transformations
哪些变换是窄变换或宽变换。

2358
01:17:31,280 --> 01:17:34,460
0,1380 1380,2250 2460,2760 2760,3000 3000,3180
{or,wide} transformations.| You're talking about
|你说的是Spark程序展示给你的图表。

2359
01:17:34,460 --> 01:17:35,690
0,90 90,360 360,720 720,870 870,1230
the graph that's the spark

2360
01:17:35,690 --> 01:17:37,610
0,360 360,810 810,1200 1200,1530 1770,1920
program actually shows you in

2361
01:17:37,610 --> 01:17:38,160
0,360
there.|
|

2362
01:17:38,520 --> 01:17:40,020
0,360 360,570 570,780 780,1080 1080,1500
{} Yeah, this linear graph,
是的，这个线性图，你不能。

2363
01:17:40,020 --> 01:17:41,910
0,90 90,480 480,1080 1110,1530 1590,1890
you can't.| Gotcha, okay, okay.|
|明白了，好的，好的。|

2364
01:17:42,150 --> 01:17:43,860
0,450 450,750 750,1290 1320,1560 1560,1710
Yeah, that's {} here, so
是的，在这里，所以这里看一下这张谱系图，

2365
01:17:43,860 --> 01:17:44,910
0,330 330,540 540,630 630,780 780,1050
here look at this lineage

2366
01:17:44,910 --> 01:17:47,610
0,540 870,1590 1770,1950 1950,2520 2520,2700
graph a bit,| like this
|就像这个变换变换，所有的变换都变窄了，想变窄了，

2367
01:17:47,610 --> 01:17:50,220
0,630 690,1290 1320,1920 1920,2190 2190,2610
transformation transformation transformation, {all,that} transformation

2368
01:17:50,220 --> 01:17:51,330
0,270 270,420 420,600 600,870 870,1110
narrow, would like narrow,| because
|因为这是一支单箭，

2369
01:17:51,330 --> 01:17:52,800
0,90 90,150 150,390 390,900 1110,1470
it's a single arrow,| but
|但这不是真的，对吧，

2370
01:17:52,800 --> 01:17:53,790
0,120 120,300 300,480 480,750 750,990
it's not really true right,|
|

2371
01:17:53,790 --> 01:17:54,480
0,120 120,210 210,450 450,600 600,690
like the last one, for
例如，像最后一个，必须是一个宽的，

2372
01:17:54,480 --> 01:17:56,340
0,510 720,1080 1080,1320 1320,1620 1620,1860
example, must be a wide

2373
01:17:56,340 --> 01:17:56,900
0,300
one,|
|

2374
01:17:58,450 --> 01:17:59,740
0,360 360,480 480,600 600,870 870,1290
because it will collect information
因为它将从所有人那里收集信息。

2375
01:17:59,740 --> 01:18:01,020
0,150 150,300 300,450 450,750
from all.| {Gotcha -}.|
|抓到你了。|

2376
01:18:03,110 --> 01:18:04,820
0,420 450,900 930,1230 1230,1560 1560,1710
Okay, {} then I I
好吧，那么我我想我在想

2377
01:18:04,820 --> 01:18:05,990
0,240 240,360 360,540 540,900 900,1170
guess I was wondering| like
|比如，你有没有关于资源的建议，

2378
01:18:05,990 --> 01:18:08,690
0,150 150,300 300,810 840,2400 2400,2700
do you have recommendations on

2379
01:18:08,690 --> 01:18:11,450
0,840 840,1290 1620,2340 2340,2610 2610,2760
resources for things,| that can
|这可以向我展示Spark如何计算出如何构建有向无环图来完成所有这些任务。

2380
01:18:11,450 --> 01:18:14,210
0,210 210,360 360,870 870,1740 2160,2760
show me how spark figures

2381
01:18:14,210 --> 01:18:16,070
0,240 240,360 360,480 480,1500 1530,1860
out how to construct the

2382
01:18:16,070 --> 01:18:18,290
0,570 570,1020 1020,1470 1470,1860 1890,2220
directed acyclic graph to do

2383
01:18:18,290 --> 01:18:21,080
0,180 180,390 390,930 930,1740 1920,2790
all these tasks.| Yeah, look
|是的，看看调度程序，仅此而已。

2384
01:18:21,080 --> 01:18:25,160
0,180 180,2370 2490,2880 2880,3660 3840,4080
at scheduler {that's,all}.| Right and
|是的，是的，我在报纸上看到了，

2385
01:18:25,160 --> 01:18:26,450
0,300 300,900 900,1140 1140,1200 1200,1290
yeah I read in the

2386
01:18:26,450 --> 01:18:28,310
0,480 480,750 750,1020 1020,1710 1740,1860
paper,| like I I you
|就像我，你知道，我在尽我所能理解这份文件，

2387
01:18:28,310 --> 01:18:29,030
0,150 150,360 360,480 480,660 660,720
know I was trying to

2388
01:18:29,030 --> 01:18:30,440
0,510 510,600 600,990 990,1170 1170,1410
comprehend the paper as best

2389
01:18:30,440 --> 01:18:31,520
0,120 120,210 210,510 510,720 720,1080
as I could,| but it's
|但你知道这很难，但是。

2390
01:18:31,520 --> 01:18:33,290
0,120 120,210 210,900 900,1470 1470,1770
you know it's difficult, but.|
|

2391
01:18:33,680 --> 01:18:34,880
0,180 180,270 270,540 540,840 840,1200
It will always be {difficult,to,read},|
它总是很难读懂，|

2392
01:18:35,180 --> 01:18:36,830
0,180 180,270 270,870 870,1320 1350,1650
so the scheduler I think
所以，我想我会先回到论文[]论文，

2393
01:18:36,830 --> 01:18:37,850
0,90 90,240 240,360 360,720 720,1020
I would go back first

2394
01:18:37,850 --> 01:18:40,610
0,360 360,840 870,1680 2040,2430 2430,2760
to {} thesis [] thesis,|
|

2395
01:18:40,610 --> 01:18:41,270
0,210 210,390 390,480 480,630 630,660
I'm sure it has a
我肯定它在调度程序上有一个[]。

2396
01:18:41,270 --> 01:18:42,660
0,270 270,510 510,900 900,1140
[] on the scheduler.|
|

2397
01:18:43,440 --> 01:18:45,300
0,390 420,780 840,1350 1350,1680 1680,1860
Gotcha gotcha, oh okay| and
明白了，明白了，哦，好的|这将向我展示Spark是如何计算出如何制作这个图表的。

2398
01:18:45,300 --> 01:18:46,380
0,450 450,600 600,750 750,960 960,1080
that'll show me just how

2399
01:18:46,380 --> 01:18:47,460
0,420 420,750 750,900 900,990 990,1080
spark figures out how to

2400
01:18:47,460 --> 01:18:48,302
0,240 240,420 420,780
make this graph.
