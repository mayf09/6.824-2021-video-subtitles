1
00:00:01,280 --> 00:00:06,830
好的，早上好，下午好，晚上好，不管你在哪里，

2
00:00:07,370 --> 00:00:11,060
今天的计划是讨论 Frangipani ，

3
00:00:11,120 --> 00:00:14,360
这是一篇 1997 年的论文，

4
00:00:14,360 --> 00:00:16,610
所以这是一篇有点老的论文，

5
00:00:17,240 --> 00:00:21,230
本文的研究背景是网络文件系统，

6
00:00:29,510 --> 00:00:33,710
你应该考虑像 Athena AFS 这样的系统，

7
00:00:34,010 --> 00:00:35,480
像 Athena 的文件系统，

8
00:00:35,780 --> 00:00:39,650
Dropbox 一个更现代的版本，

9
00:00:40,040 --> 00:00:41,960
但这里的总体目标是，

10
00:00:41,960 --> 00:00:44,750
在一组用户之间共享文件。

11
00:00:45,520 --> 00:00:50,140
Frangipani 本身没有被广泛使用，

12
00:00:50,230 --> 00:00:53,410
或者没有在[]之外被广泛使用。

13
00:00:53,410 --> 00:00:54,760
所以今天关注的观点，

14
00:00:54,880 --> 00:01:00,430
你应该从这篇论文中得到的三个想法，

15
00:01:00,430 --> 00:01:05,080
这些想法将在未来几周内反复出现。

16
00:01:05,320 --> 00:01:10,690
第一，缓存一致性协议，

17
00:01:13,310 --> 00:01:15,170
第二，分布式锁，

18
00:01:23,430 --> 00:01:26,580
第三，分布式崩溃恢复。

19
00:01:32,830 --> 00:01:35,200
这三个想法将会，

20
00:01:35,200 --> 00:01:37,930
如我所说，会在接下来的几周里出现，

21
00:01:38,200 --> 00:01:39,910
特别是，我们将阅读，

22
00:01:39,940 --> 00:01:41,620
从下周要开始，

23
00:01:41,620 --> 00:01:43,870
两个[重型]事务系统，

24
00:01:44,140 --> 00:01:48,250
它们构建于，

25
00:01:48,280 --> 00:01:51,280
获取或使用一些技术，

26
00:01:51,280 --> 00:01:53,260
实际上 Frangipani 也在使用的。

27
00:01:53,730 --> 00:01:59,010
所以， Frangipani 是对这三个主题更平和的介绍，

28
00:01:59,010 --> 00:02:01,740
在我们谈到重型事务系统之前。

29
00:02:02,560 --> 00:02:06,130
Frangipani 本身的想法也是一个有趣的设计，

30
00:02:06,400 --> 00:02:09,850
从分布式系统角度来看，

31
00:02:09,850 --> 00:02:11,500
这是一个很酷的系统。

32
00:02:12,070 --> 00:02:14,440
让我来说明这个，

33
00:02:14,440 --> 00:02:19,750
通过[]网络文件系统的传统设计，

34
00:02:20,110 --> 00:02:25,590
所以传统的或最常见的网络文件系统设计，

35
00:02:25,590 --> 00:02:29,790
如果考虑 Athena 上的 AFS ，

36
00:02:29,790 --> 00:02:32,370
如果你有一组客户端，

37
00:02:33,710 --> 00:02:35,540
这是一个很简单的图，

38
00:02:36,170 --> 00:02:38,870
一组客户端连接到某个网络，

39
00:02:39,380 --> 00:02:41,570
表示网络的是一条线，

40
00:02:41,720 --> 00:02:44,120
共享多个文件服务器，

41
00:02:45,140 --> 00:02:48,020
然后文件服务器有数据在磁盘上。

42
00:02:52,740 --> 00:02:58,000
基本上所有的复杂性，

43
00:02:58,000 --> 00:03:01,450
好的，稍后我将详细介绍缓存一致性，

44
00:03:01,930 --> 00:03:07,420
设计中的所有复杂性基本上都在这里，

45
00:03:07,420 --> 00:03:08,290
在文件服务器上，

46
00:03:09,070 --> 00:03:11,860
文件服务器实现文件系统操作，

47
00:03:11,860 --> 00:03:14,590
open close read write stat 等东西，

48
00:03:15,010 --> 00:03:20,920
它们以抗崩溃方式将数据写入磁盘，

49
00:03:21,220 --> 00:03:23,770
而客户端很简单，

50
00:03:23,830 --> 00:03:25,030
它们并没有做太多事情，

51
00:03:25,030 --> 00:03:28,150
也许像在 AFS 中那样进行一些缓存，

52
00:03:28,150 --> 00:03:30,070
但是大多数都是，

53
00:03:30,100 --> 00:03:34,300
它们转发正在运行的程序的文件系统操作，

54
00:03:34,570 --> 00:03:37,060
比如 Vi 在客户端 1 上，

55
00:03:37,060 --> 00:03:38,290
它执行 open close ，

56
00:03:38,500 --> 00:03:39,700
而客户端所做的大部分工作都是，

57
00:03:39,700 --> 00:03:41,800
将这些操作转发到文件服务器。

58
00:03:42,510 --> 00:03:45,150
这设计受欢迎的一个原因是，

59
00:03:45,150 --> 00:03:48,060
因为，从安全的角度来说，

60
00:03:48,150 --> 00:03:49,560
这是一个很好的设计，

61
00:03:49,560 --> 00:03:53,280
因为大多数文件服务器都是可信的，

62
00:03:53,400 --> 00:03:55,050
但客户端不一定是可信的。

63
00:03:56,760 --> 00:03:58,410
当然，在 MIT 的环境中，

64
00:03:58,410 --> 00:04:00,270
机器是公开的，

65
00:04:00,270 --> 00:04:02,550
谁知道是谁在上面安装了什么样的软件，

66
00:04:02,550 --> 00:04:05,550
那是一个不错的性质。

67
00:04:05,940 --> 00:04:08,700
Frangipani 有一个非常不同的设计，

68
00:04:08,910 --> 00:04:10,860
一个更分散的设计。

69
00:04:14,300 --> 00:04:17,780
在 Frangipani 中有很多文件服务器，

70
00:04:18,020 --> 00:04:21,230
它没有真正的文件服务器，

71
00:04:21,230 --> 00:04:23,180
在字面意思上，

72
00:04:23,180 --> 00:04:28,190
而是客户端本身运行文件服务器代码。

73
00:04:28,790 --> 00:04:31,250
假设有两个客户端，

74
00:04:31,490 --> 00:04:34,250
大多数文件系统代码本身，

75
00:04:34,250 --> 00:04:36,560
比如有索引节点管理器，

76
00:04:36,560 --> 00:04:40,130
inode 更新文件，创建目录，

77
00:04:40,250 --> 00:04:42,920
所有代码不是在文件服务器上，

78
00:04:42,950 --> 00:04:44,900
而是在客户端上，

79
00:04:45,630 --> 00:04:53,040
文件服务器共享的唯一东西是一个大的虚拟磁盘。

80
00:04:58,730 --> 00:04:59,750
如果你愿意，

81
00:04:59,750 --> 00:05:02,000
在你的脑海里中有一个图像，

82
00:05:02,000 --> 00:05:03,860
或者脑海中有一个概念性图像是，

83
00:05:03,860 --> 00:05:07,910
虚拟磁盘就像一个大型固态硬盘驱动器，

84
00:05:07,910 --> 00:05:09,500
所以文件服务器，

85
00:05:09,500 --> 00:05:11,720
共享一个固态硬盘，

86
00:05:11,720 --> 00:05:15,140
彼此共享一个磁盘，

87
00:05:15,320 --> 00:05:16,820
当然在内部，

88
00:05:16,820 --> 00:05:20,390
这个虚拟磁盘是使用一个名为 Petal 的系统实现的，

89
00:05:20,750 --> 00:05:23,810
是由许多机器组成的，

90
00:05:24,110 --> 00:05:29,090
但是机器复制磁盘块，

91
00:05:29,090 --> 00:05:31,520
内部有 Paxos ，用来确保，

92
00:05:31,520 --> 00:05:34,610
操作可以按正确的顺序应用，

93
00:05:34,760 --> 00:05:35,780
诸如此类的事情，

94
00:05:35,780 --> 00:05:37,640
但从外部来看，

95
00:05:37,790 --> 00:05:41,900
接口是 read 块，或 write 块，

96
00:05:42,420 --> 00:05:44,310
所以它看起来就像一个普通的磁盘。

97
00:05:45,150 --> 00:05:48,420
这个设计有趣的是，

98
00:05:48,420 --> 00:05:49,830
设计协议，

99
00:05:49,890 --> 00:05:53,700
这个设计中的许多复杂性都在客户端。

100
00:05:56,100 --> 00:05:58,170
你喜欢这个的一个原因，

101
00:05:58,170 --> 00:05:59,730
或者为什么这样，

102
00:05:59,730 --> 00:06:04,110
你可以通过增加工作站数量来扩展文件系统，

103
00:06:04,110 --> 00:06:06,210
所以，如果你增加客户端数量，

104
00:06:06,360 --> 00:06:08,250
你可以获得更多的 CPU 能力，

105
00:06:08,250 --> 00:06:09,360
因为你得到了更多的客户端，

106
00:06:09,360 --> 00:06:12,060
每个客户端可以在自己的文件系统上运行。

107
00:06:12,590 --> 00:06:15,470
所以，很多非常繁重的计算

108
00:06:15,470 --> 00:06:17,120
都可以在客户端机器上完成，

109
00:06:17,270 --> 00:06:19,610
根本不涉及任何文件服务器，

110
00:06:19,760 --> 00:06:20,540
这是真的，

111
00:06:20,540 --> 00:06:21,890
在左边，

112
00:06:21,890 --> 00:06:25,220
传统的网络文件系统设计通常是这种情况，

113
00:06:25,220 --> 00:06:31,490
性能瓶颈出现在文件服务器中，

114
00:06:31,490 --> 00:06:34,760
当客户端数量变得太大时，

115
00:06:34,790 --> 00:06:36,440
通常在这种情况下，

116
00:06:36,470 --> 00:06:39,410
我们将文件系统拆分到不同的文件服务器中。

117
00:06:40,900 --> 00:06:42,280
好吧，这是一种，

118
00:06:42,610 --> 00:06:44,170
所以，从我们的角度来看，

119
00:06:44,170 --> 00:06:47,020
至少从分布式系统设计来看，

120
00:06:47,230 --> 00:06:48,520
Frangipani 很有趣，

121
00:06:48,520 --> 00:06:50,410
因为它更加分散，

122
00:06:50,410 --> 00:06:53,170
比起传统的网络文件系统设计。

123
00:06:56,190 --> 00:07:01,260
他们想要探索这种设计的原因

124
00:07:01,350 --> 00:07:02,940
与用例有很大关系，

125
00:07:02,940 --> 00:07:05,400
他们想象的或他们的目标，

126
00:07:05,400 --> 00:07:07,260
我想说一点关于用例的事情，

127
00:07:07,260 --> 00:07:10,830
因为，在电子邮件中有很多与此相关的问题。

128
00:07:10,830 --> 00:07:14,570
那么，它的用例是什么，

129
00:07:14,990 --> 00:07:18,020
用例是，

130
00:07:18,020 --> 00:07:20,210
一些研究人员和工程师

131
00:07:24,370 --> 00:07:33,660
编译、编辑他们的程序或编写文档。

132
00:07:39,710 --> 00:07:45,980
它的设计来自著名研究实验室[]的论文，

133
00:07:46,430 --> 00:07:50,930
[]研究人员有 50 到 100 个，

134
00:07:51,260 --> 00:07:53,060
他们所做的是，

135
00:07:53,060 --> 00:07:55,670
为他们的用例设计一个文件系统，

136
00:07:56,510 --> 00:07:59,150
所以每个人都是可信的，

137
00:07:59,360 --> 00:08:01,190
所有机器都是可信的，

138
00:08:01,190 --> 00:08:02,840
所有运行的软件都是可信的，

139
00:08:03,170 --> 00:08:07,310
所以，安全方面的事情不是一个问题，

140
00:08:07,310 --> 00:08:11,240
所有这些研究人员都是重负荷计算机用户，

141
00:08:11,570 --> 00:08:13,550
所以他们想要，

142
00:08:13,580 --> 00:08:16,100
但大多数情况下，他们在自己的私人文件上工作，

143
00:08:16,100 --> 00:08:17,570
他们编写自己的程序，

144
00:08:17,570 --> 00:08:20,390
他们编写自己的文档，

145
00:08:20,390 --> 00:08:24,170
所以，[]希望与高性能文件系统的文件进行交互。

146
00:08:24,780 --> 00:08:27,330
当然，他们可能会分享，

147
00:08:27,420 --> 00:08:30,150
否则，分享就不会很有趣，

148
00:08:32,550 --> 00:08:35,100
它们可能分享文件和目录，

149
00:08:36,030 --> 00:08:38,340
它以两种方式表现出来，

150
00:08:38,640 --> 00:08:39,960
他们可能会一起工作，

151
00:08:39,960 --> 00:08:41,670
一起合作写一篇论文，

152
00:08:41,670 --> 00:08:43,590
像我们今天读到的论文，

153
00:08:43,890 --> 00:08:48,120
所以他们希望能够访问共享文件，

154
00:08:48,240 --> 00:08:50,520
对于保存特定论文的目录，

155
00:08:50,820 --> 00:08:53,790
所以用户到用户的共享。

156
00:08:57,770 --> 00:08:59,240
然后还有第二种形式的共享，

157
00:08:59,240 --> 00:09:02,090
比如同一用户可能登录到多个工作站，

158
00:09:10,740 --> 00:09:12,000
一个以上的工作站，

159
00:09:12,840 --> 00:09:13,650
所以再说一次，

160
00:09:13,650 --> 00:09:18,030
其中一个研究人员去了公共图书馆或他们的图书馆，

161
00:09:18,030 --> 00:09:20,640
[]的公共工作站，

162
00:09:21,000 --> 00:09:24,420
也希望能够从那个计算机读取或写入他们的文件。

163
00:09:25,000 --> 00:09:26,260
这就是用例，

164
00:09:26,710 --> 00:09:32,680
在这个用例中，有许多设计含义，

165
00:09:33,480 --> 00:09:37,620
或者由用例驱动的设计选择。

166
00:09:40,180 --> 00:09:43,990
所以，主要的一个，

167
00:09:43,990 --> 00:09:46,810
由这个用例驱动的就是缓存。

168
00:09:51,560 --> 00:09:54,860
所以，不是将数据全部保留在 Petal 中，

169
00:09:54,860 --> 00:09:56,990
并且每个读或写操作都要经过 Petal ，

170
00:09:57,110 --> 00:09:58,400
他们想要安排，

171
00:09:58,400 --> 00:10:01,160
所以大多数发生在工作站上，

172
00:10:01,430 --> 00:10:03,200
所以研究人员，

173
00:10:03,440 --> 00:10:05,720
因为他们主要工作在自己的私人文件上，

174
00:10:05,720 --> 00:10:07,100
这似乎很有道理，

175
00:10:07,100 --> 00:10:09,590
它们在本地工作站上缓存数据，

176
00:10:09,950 --> 00:10:11,780
然后，当读取或写入文件时，

177
00:10:11,780 --> 00:10:14,390
基本上不需要网络传输，

178
00:10:14,690 --> 00:10:18,380
你可以以高性能进行写入。

179
00:10:18,680 --> 00:10:23,570
他们避免传输到 Petal 的一种方法，

180
00:10:23,690 --> 00:10:28,670
是使用回写式缓存而不是直写式，

181
00:10:28,730 --> 00:10:31,490
所以如果操作发生留在缓存中，

182
00:10:31,490 --> 00:10:34,340
在后来的某个时候，他们逐渐传输到 Petal ，

183
00:10:34,340 --> 00:10:37,070
我们稍后将会看到。

184
00:10:38,180 --> 00:10:39,680
所以，将它们结合起来，

185
00:10:39,680 --> 00:10:41,450
即使它们主要是，

186
00:10:41,450 --> 00:10:43,340
工作负载是私有的，

187
00:10:43,460 --> 00:10:45,650
他们没有共享的地方，

188
00:10:45,770 --> 00:10:47,450
或者他们确实共享了，

189
00:10:47,600 --> 00:10:49,760
他们想要有很强的一致性，

190
00:10:50,480 --> 00:10:52,760
或者有时被称为连贯性。

191
00:11:00,870 --> 00:11:02,940
所以它的意思是，

192
00:11:02,940 --> 00:11:07,350
例如，如果一个用户写入文件，

193
00:11:07,350 --> 00:11:11,370
然后另一个用户，许多工作站读取这个文件，

194
00:11:11,370 --> 00:11:14,370
那个用户会看到改动，

195
00:11:14,370 --> 00:11:17,040
其他工作站，其他用户所做的，

196
00:11:17,670 --> 00:11:20,970
所以，他们想要强一致性。

197
00:11:22,360 --> 00:11:28,840
所以，这是推动这一设计的两个设计选择，

198
00:11:29,260 --> 00:11:35,550
以及性能。

199
00:11:42,120 --> 00:11:46,200
所以，稍微考虑一下可能会有所帮助，

200
00:11:46,200 --> 00:11:49,290
例如，对于文件系统，还有哪些其他用例，

201
00:11:49,290 --> 00:11:52,710
我们经常谈到的一个很好的是，

202
00:11:52,710 --> 00:11:53,970
考虑一下 GFS ，

203
00:11:54,360 --> 00:11:58,380
GFS 会不会成为 Frangipani 的替代品

204
00:11:58,380 --> 00:12:00,420
或者反过来，他们的对比起来如何？

205
00:12:00,870 --> 00:12:02,400
思考这一问题的一种方式是，

206
00:12:02,400 --> 00:12:06,930
GFS 是为 mapreduce 应用程序设计的文件系统，

207
00:12:07,260 --> 00:12:12,840
它是一个文件系统，其中的文件不会被缓存，

208
00:12:12,840 --> 00:12:14,730
事实上，这些文件往往非常大，

209
00:12:14,730 --> 00:12:18,120
它们甚至不适合在我们所说的这种类型的缓存中，

210
00:12:18,420 --> 00:12:21,450
它也是从头到尾按顺序读取的，

211
00:12:21,480 --> 00:12:22,080
仅此而已，

212
00:12:22,440 --> 00:12:26,040
也许其他计算机会读取该文件，

213
00:12:26,040 --> 00:12:28,140
因为一些其他的 mapreduce 应用程序运行。

214
00:12:28,830 --> 00:12:30,750
所以，你想想 GFS ，

215
00:12:30,810 --> 00:12:33,180
根本就没有数据缓存，

216
00:12:33,210 --> 00:12:35,910
需要使用一些缓存来跟踪，

217
00:12:36,270 --> 00:12:38,820
块服务器所在的位置，

218
00:12:38,940 --> 00:12:42,090
但在 GFS 中根本没有进行数据缓存，

219
00:12:42,240 --> 00:12:44,970
所以，在 GFS 中也没有缓存一致性，

220
00:12:45,180 --> 00:12:47,760
所以，他们的目标是某种类型的应用程序，

221
00:12:47,850 --> 00:12:49,470
这完全说不通。

222
00:12:50,080 --> 00:12:51,310
同样地，在 GFS 中，

223
00:12:51,400 --> 00:12:54,100
GFS 并不是一个真正的文件系统，

224
00:12:54,100 --> 00:12:55,570
从这个意义上来说，

225
00:12:55,570 --> 00:12:58,990
并不打算运行 VI GCC ，

226
00:12:59,140 --> 00:13:02,890
所以，没有提供直接的 POSIX 或 Unix 兼容性，

227
00:13:02,920 --> 00:13:07,180
在 Frangipani 中，你可以运行标准 Unix 应用程序，

228
00:13:07,480 --> 00:13:08,800
应该能正常运行，

229
00:13:08,950 --> 00:13:14,110
应用程序的行为方式与没有分布式文件系统一样，

230
00:13:14,110 --> 00:13:15,370
而是单一文件系统。

231
00:13:16,990 --> 00:13:18,910
同样，在 GFS 中，

232
00:13:18,940 --> 00:13:24,340
有一些库，

233
00:13:24,340 --> 00:13:28,510
应用程序用来在 GFS 中读取或写入文件，

234
00:13:28,510 --> 00:13:31,480
但它不是 100% Unix 兼容的。

235
00:13:32,640 --> 00:13:34,020
所以这给你一个感觉，

236
00:13:34,020 --> 00:13:39,150
这些工作负载推动了这些不同系统的设计，

237
00:13:39,150 --> 00:13:40,530
在 GFS 的情况中，

238
00:13:40,740 --> 00:13:43,770
mapreduce 驱动了设计，

239
00:13:43,770 --> 00:13:46,890
在 Frangipani 或共享文件系统的情况中，

240
00:13:46,890 --> 00:13:50,220
是在共享文件系统上工作的用户的问题，

241
00:13:50,220 --> 00:13:52,560
但是他们执行的大多数操作，

242
00:13:52,650 --> 00:13:56,760
可能只是文件本身，并在本地执行。

243
00:13:57,900 --> 00:14:00,720
这在设置的对比上是有意义的，

244
00:14:00,780 --> 00:14:03,720
所以，你可以看到，有很多不同的文件系统，

245
00:14:03,960 --> 00:14:06,990
比如 zookeeper 也是一种提供文件系统接口，

246
00:14:06,990 --> 00:14:08,310
但它并不是真正的文件系统，

247
00:14:08,310 --> 00:14:10,920
它更像是一种协调服务，

248
00:14:10,920 --> 00:14:13,770
你不会在 zookeeper 保存大文件。

249
00:14:16,130 --> 00:14:19,550
对这个设置，有什么问题吗？

250
00:14:21,780 --> 00:14:23,700
你能简单重复一下，

251
00:14:23,700 --> 00:14:29,640
为什么在客户机上运行文件服务器代码可以增强可伸缩性，

252
00:14:30,110 --> 00:14:32,030
而不是让客户端和文件服务器

253
00:14:32,300 --> 00:14:34,490
在不同的机器上。

254
00:14:35,840 --> 00:14:37,280
是的，比如，

255
00:14:37,280 --> 00:14:39,650
如果回到上一张幻灯片，

256
00:14:39,650 --> 00:14:41,540
在左边的网络文件系统，

257
00:14:41,540 --> 00:14:43,220
有很多客户端，

258
00:14:43,370 --> 00:14:44,990
我们假设只有一个，

259
00:14:45,020 --> 00:14:47,030
让我把这张图简化一下，

260
00:14:47,420 --> 00:14:50,240
忽略第二文件服务器，只有一个文件服务器，

261
00:14:50,240 --> 00:14:52,520
这样每个人都可以共享这个文件服务器上的文件，

262
00:14:52,670 --> 00:14:55,640
然后这些客户端都将在该单一文件服务器上处理，

263
00:14:56,300 --> 00:14:59,480
所有的读或写操作都将被发送到文件服务器，

264
00:14:59,480 --> 00:15:01,610
文件服务器直接查找，

265
00:15:01,640 --> 00:15:05,540
它打开文件并做安全检查，

266
00:15:05,600 --> 00:15:06,410
诸如此类的事情，

267
00:15:06,410 --> 00:15:09,590
所有的计算都是针对文件系统本身，

268
00:15:09,590 --> 00:15:12,020
这一切都发生在文件服务器身上，

269
00:15:12,050 --> 00:15:14,510
在传统的网络文件系统设计中，

270
00:15:14,840 --> 00:15:16,700
在 Frangipani 中，情况并非如此，

271
00:15:17,030 --> 00:15:20,750
在 Frangipani 中，所有文件系统操作都在工作站上执行。

272
00:15:21,260 --> 00:15:23,570
我们有多个工作站，

273
00:15:23,570 --> 00:15:26,810
文件系统可以扩展的工作负载，

274
00:15:26,810 --> 00:15:29,300
或者它可以支持随着工作站数量的增加而扩展。

275
00:15:31,330 --> 00:15:31,750
我明白了，

276
00:15:31,750 --> 00:15:34,030
在传统的架构中，

277
00:15:34,030 --> 00:15:37,240
每个文件服务器都包含或存储，

278
00:15:37,240 --> 00:15:40,600
我们假设整个文件系统的一部分，

279
00:15:40,600 --> 00:15:42,220
所以，不是这种情况，

280
00:15:42,220 --> 00:15:46,560
每个文件服务器都有整个系统的副本，

281
00:15:46,950 --> 00:15:49,470
它可能是拆分跨文件服务器的。

282
00:15:49,650 --> 00:15:51,900
是的，它可能是，

283
00:15:51,900 --> 00:15:54,300
例如， AFS 有不同的卷，

284
00:15:54,480 --> 00:15:57,720
文件服务器管理不同的卷，

285
00:15:57,720 --> 00:16:01,140
MIT 所有用户的数据分布在不同的卷上，

286
00:16:01,710 --> 00:16:05,010
但是一个卷的所有数据都将是一个文件服务器，

287
00:16:05,010 --> 00:16:07,200
所以，那个文件卷命中太多，

288
00:16:07,290 --> 00:16:09,480
你会遇到性能瓶颈。

289
00:16:10,000 --> 00:16:11,050
好的，太棒了，谢谢。

290
00:16:13,700 --> 00:16:16,070
关于这个设置，有什么问题吗，

291
00:16:16,100 --> 00:16:20,220
在我们深入了解更多 Frangipani 之前？

292
00:16:25,660 --> 00:16:26,320
好的，很好。

293
00:16:26,920 --> 00:16:29,980
所以他们所做的设计选择，

294
00:16:30,010 --> 00:16:32,470
带来了一些挑战，

295
00:16:33,720 --> 00:16:35,850
所以我想谈谈这些挑战。

296
00:16:40,980 --> 00:16:48,330
驱动几乎大量设计的主要因素是，

297
00:16:48,330 --> 00:16:51,960
假设你有一个工作站，工作站 1 ，

298
00:16:52,170 --> 00:16:54,540
那时候，人们有工作站，

299
00:16:54,540 --> 00:16:57,810
笔记本电脑还不存在，

300
00:16:58,140 --> 00:17:00,240
今天可能是各种各样的笔记本电脑，

301
00:17:00,240 --> 00:17:02,100
但是有一个工作站，

302
00:17:02,220 --> 00:17:06,420
一些人读取文件，读取文件 f ，

303
00:17:06,930 --> 00:17:09,600
也许是成绩数据库，成绩文件，

304
00:17:10,020 --> 00:17:11,700
所以，

305
00:17:11,700 --> 00:17:15,570
这意味着那个文件缓存在工作站中。

306
00:17:16,340 --> 00:17:20,030
所以，运行 VI 的程序的客户端，

307
00:17:20,030 --> 00:17:23,030
可以更新和操作文件，

308
00:17:23,270 --> 00:17:24,680
然后晚些时候，

309
00:17:24,680 --> 00:17:27,860
结果将写回 Petal ，

310
00:17:27,860 --> 00:17:29,210
或者如果你愿意，（写入）磁盘。

311
00:17:29,810 --> 00:17:33,500
所以，这个模型面临的挑战是三个[]，

312
00:17:33,980 --> 00:17:37,730
第一，其他人，工作站 2 ，

313
00:17:38,750 --> 00:17:39,620
可能在某一时刻，

314
00:17:39,620 --> 00:17:40,730
执行 cat f ，

315
00:17:41,870 --> 00:17:43,250
获取文件 f ，

316
00:17:43,550 --> 00:17:45,560
当然，情况应该是这样的，

317
00:17:45,560 --> 00:17:50,090
至少在正常情况下，我们有一个传统的 Unix 文件系统，

318
00:17:50,360 --> 00:17:53,780
你会看到那个 f 的最后一次写入，

319
00:17:53,810 --> 00:17:56,630
所以，即使写入可能发生在不同的工作站上，

320
00:17:56,870 --> 00:17:59,930
当第二工作站读取该文件时，

321
00:17:59,930 --> 00:18:03,110
我们会看到数据显示出来，

322
00:18:03,440 --> 00:18:05,930
这就是他们将会是什么样子，

323
00:18:06,290 --> 00:18:08,210
大致归结为缓存一致性，

324
00:18:10,800 --> 00:18:14,850
其他说法，连贯性的同义词是缓存一致性，

325
00:18:15,000 --> 00:18:19,380
就像我们在之前的论文中看到的更多的术语，

326
00:18:19,620 --> 00:18:22,740
但是在计算机体系结构的领域，

327
00:18:22,740 --> 00:18:27,810
连贯性这个术语来自于那个领域，

328
00:18:28,410 --> 00:18:30,720
所以你可以把它们当成同义词。

329
00:18:32,660 --> 00:18:37,970
第二，第二个会发生的问题，

330
00:18:37,970 --> 00:18:39,620
我们需要处理的是，

331
00:18:39,710 --> 00:18:44,180
假设工作站 1 和工作站 2

332
00:18:44,360 --> 00:18:47,300
都想要在共享目录中创建文件，

333
00:18:47,300 --> 00:18:52,220
所以工作站 1 在目录 d 中创建了一个文件 f ，

334
00:18:52,310 --> 00:18:57,230
工作站 2 也在目录 d 中创建文件 g 。

335
00:18:57,910 --> 00:19:00,130
现在我们希望至少安排，

336
00:19:00,130 --> 00:19:02,350
工作站 1 进行变更，

337
00:19:02,350 --> 00:19:03,940
然后工作站 2 进行变更，

338
00:19:04,330 --> 00:19:05,710
这里的两个文件，

339
00:19:05,770 --> 00:19:11,860
一个文件不会覆盖其他的文件夹，

340
00:19:11,860 --> 00:19:15,550
或者覆盖文件夹导致其他文件消失。

341
00:19:16,350 --> 00:19:19,200
所以这就是第二个主题，原子性，

342
00:19:22,980 --> 00:19:24,930
这些操作创建文件，

343
00:19:24,930 --> 00:19:27,810
必须是某种原子操作，

344
00:19:27,810 --> 00:19:29,130
这样它们不会交错，

345
00:19:29,130 --> 00:19:30,750
使我们得到错误的结果。

346
00:19:32,300 --> 00:19:33,500
然后是最后一个问题，

347
00:19:33,890 --> 00:19:37,040
我们需要处理的是，

348
00:19:37,040 --> 00:19:41,230
工作站 1 可能会崩溃，

349
00:19:41,260 --> 00:19:45,010
当执行一个复杂的文件系统操作时，

350
00:19:50,160 --> 00:19:51,780
所以它必须有故事，

351
00:19:51,780 --> 00:19:54,390
文件系统是如何恢复的，

352
00:19:55,140 --> 00:19:57,660
所以，这是一个关于崩溃恢复的故事。

353
00:20:01,990 --> 00:20:03,610
比如，在第一个例子中，

354
00:20:03,610 --> 00:20:07,240
工作站在目录 d 中生成一个文件，

355
00:20:07,420 --> 00:20:09,040
这是一个复杂的操作，

356
00:20:09,040 --> 00:20:10,930
目录需要修改，

357
00:20:10,930 --> 00:20:12,400
inode 需要分配，

358
00:20:12,400 --> 00:20:14,650
inode 需要初始化，

359
00:20:14,650 --> 00:20:17,110
然后 inode 编号需要写入目录，

360
00:20:17,200 --> 00:20:19,750
所以它涉及多种类型的文件系统操作，

361
00:20:19,750 --> 00:20:21,040
我们希望是这样的情况，

362
00:20:21,040 --> 00:20:25,000
如果文件系统在任何步骤之间崩溃，

363
00:20:25,090 --> 00:20:27,040
在这种复杂的文件系统操作中，

364
00:20:27,130 --> 00:20:28,150
最好是这样的情况，

365
00:20:28,150 --> 00:20:29,650
文件系统恢复正常。

366
00:20:30,170 --> 00:20:30,890
我的意思是，

367
00:20:30,890 --> 00:20:32,090
文件系统正确恢复，

368
00:20:32,090 --> 00:20:34,430
至少它的内部数据结构是正确的，

369
00:20:34,730 --> 00:20:36,620
比如， inode 不会丢失，

370
00:20:36,620 --> 00:20:39,770
因为它不会显示在目录中，等等，

371
00:20:39,800 --> 00:20:42,680
或者，甚至整个内部结构都是一致的，

372
00:20:43,640 --> 00:20:45,380
所以这是崩溃恢复的主题。

373
00:20:46,220 --> 00:20:50,900
所以 Petal 在 Frangipani 需要解决所有这些问题，

374
00:20:50,900 --> 00:20:56,480
我的计划是一个接一个地查看，

375
00:20:56,480 --> 00:20:58,940
讨论 Frangipani 如何解决这些问题。

376
00:21:00,520 --> 00:21:02,710
对于顶级挑战，有什么问题吗？

377
00:21:09,820 --> 00:21:11,590
好的，让我们继续。

378
00:21:12,030 --> 00:21:15,510
所以，第一件事是缓存连贯性或缓存一致性。

379
00:21:27,740 --> 00:21:36,120
所以， Frangipani 使用的解决方案中的关键方面是，

380
00:21:36,120 --> 00:21:37,680
实际上是一个锁服务器，

381
00:21:38,580 --> 00:21:45,410
锁服务器有一个表，

382
00:21:46,010 --> 00:21:50,960
对于每个文件的 inode 编号，

383
00:21:51,760 --> 00:21:54,850
谁必须在这个时间点加锁，

384
00:21:54,850 --> 00:21:55,780
谁是拥有者。

385
00:21:58,070 --> 00:21:59,480
所以我们可能有文件 f ，

386
00:21:59,510 --> 00:22:01,940
它表示工作站，

387
00:22:02,480 --> 00:22:03,740
锁服务器有一个记录，

388
00:22:03,740 --> 00:22:06,290
工作站 1 拥有那把锁，

389
00:22:07,040 --> 00:22:13,580
锁服务本身是一个分布式服务，

390
00:22:13,580 --> 00:22:16,280
你可以把它大致想象成 zookeeper ，

391
00:22:16,310 --> 00:22:21,410
它提供获取释放锁，

392
00:22:21,410 --> 00:22:22,670
它是容错的，

393
00:22:22,670 --> 00:22:25,010
在 Frangipani 的情况，

394
00:22:25,010 --> 00:22:27,920
使用的是基于 Paxos 的实现，

395
00:22:28,250 --> 00:22:34,820
分布在多台机器上，高容错性等。

396
00:22:36,390 --> 00:22:40,620
所以，这是锁服务器，

397
00:22:40,860 --> 00:22:41,640
事实证明，

398
00:22:41,640 --> 00:22:46,970
工作站也应该为它们的锁维护一张表，

399
00:22:47,420 --> 00:22:48,950
这是工作站 1 ，

400
00:22:49,190 --> 00:22:50,780
这可能是，

401
00:22:50,810 --> 00:22:54,440
假设工作站 1 缓存文件 f 和 g ，

402
00:22:55,920 --> 00:22:59,610
可能 h 缓存在工作站 1 ，

403
00:22:59,610 --> 00:23:01,860
h 可能缓存在工作站 2 ，

404
00:23:02,700 --> 00:23:06,270
然后工作站 1 有一张类似的表，

405
00:23:06,450 --> 00:23:10,710
列举了它所持有的每个锁，

406
00:23:10,740 --> 00:23:12,930
它是忙的还是闲的，

407
00:23:14,370 --> 00:23:18,510
可能 f 的锁状态是忙的，

408
00:23:18,690 --> 00:23:22,380
这意味着文件服务器在操作那个文件，

409
00:23:22,410 --> 00:23:26,280
所以，它正在使用那个文件，

410
00:23:26,280 --> 00:23:27,870
第二种状态是，

411
00:23:27,870 --> 00:23:30,060
假设文件 g 也缓存在这里，

412
00:23:30,270 --> 00:23:33,570
g 可能在闲的状态，

413
00:23:33,930 --> 00:23:37,530
这意味着， g 在这一时刻没有被修改，

414
00:23:37,530 --> 00:23:43,200
在那个瞬时时间，没有被文件处理，

415
00:23:43,470 --> 00:23:46,050
但这就是他们所说的粘锁。

416
00:23:47,480 --> 00:23:51,020
所以，如果文件服务器在某个时刻[]，

417
00:23:51,020 --> 00:23:52,640
它将再次使用文件 g ，

418
00:23:52,790 --> 00:23:53,810
它可以这样做，

419
00:23:53,810 --> 00:23:55,760
不必与 Petal 通信，

420
00:23:55,880 --> 00:23:58,670
或者重新加载缓存或任何类似的东西，

421
00:23:58,730 --> 00:24:00,110
因为它有一个粘锁，

422
00:24:00,110 --> 00:24:02,330
它知道没有其他（工作站）获取，

423
00:24:02,330 --> 00:24:04,970
在这期间，没有其他工作站获取锁。

424
00:24:06,060 --> 00:24:08,340
所以，这是粘锁，

425
00:24:08,760 --> 00:24:09,930
事实证明，

426
00:24:10,050 --> 00:24:15,060
这是两种[]的锁，

427
00:24:15,060 --> 00:24:17,250
用于他们所说的，

428
00:24:17,250 --> 00:24:21,090
所说的缓存一致性协议。

429
00:24:21,090 --> 00:24:24,180
一套信息或一套规则被遵守，

430
00:24:24,360 --> 00:24:26,400
来获得缓存一致性，

431
00:24:26,820 --> 00:24:28,800
基本规则是，

432
00:24:29,100 --> 00:24:31,800
指导原则是，

433
00:24:31,800 --> 00:24:33,660
为了缓存一个文件，

434
00:24:38,890 --> 00:24:40,840
你首先必须获取一把锁，

435
00:24:43,670 --> 00:24:47,030
你会看到这些规则是垫脚石，

436
00:24:47,030 --> 00:24:51,050
来获得缓存一致性或缓存连贯性。

437
00:24:52,260 --> 00:24:54,570
我要做一个小的简化，

438
00:24:54,660 --> 00:24:56,460
在论文中，

439
00:24:56,460 --> 00:25:00,660
他们描述的锁是排它的或读写锁。

440
00:25:00,780 --> 00:25:01,740
我会假设，

441
00:25:01,740 --> 00:25:03,120
在接下来的课程中，

442
00:25:03,120 --> 00:25:04,500
[排它的]并不重要，

443
00:25:04,530 --> 00:25:05,820
但这是一种优化，

444
00:25:05,820 --> 00:25:10,470
多个工作站可以在只读模式下拥有文件缓存。

445
00:25:12,530 --> 00:25:13,970
好的，所以有了这个，

446
00:25:13,970 --> 00:25:14,930
让我简单地谈一下，

447
00:25:14,930 --> 00:25:21,240
我们来了解一下 Frangipani 使用的协议。

448
00:25:22,010 --> 00:25:28,130
同样的，缓存连贯性或缓存一致性，

449
00:25:28,130 --> 00:25:31,340
即使分布式文件系统的目标，

450
00:25:31,580 --> 00:25:34,220
它应该像单个文件系统一样，

451
00:25:34,220 --> 00:25:36,050
你只有一台文件服务器，

452
00:25:36,050 --> 00:25:38,720
你希望有相同的结果

453
00:25:38,720 --> 00:25:40,610
由分布式文件系统返回的（结果），

454
00:25:41,000 --> 00:25:43,190
你不能区分它是不是分布式的，

455
00:25:43,760 --> 00:25:47,210
所以这提醒我线性一致性，

456
00:25:47,210 --> 00:25:52,970
事实上，我相信 Frangipani 的目标，

457
00:25:52,970 --> 00:25:55,280
它是可线性化的文件系统操作。

458
00:25:56,200 --> 00:25:58,540
好的，我们有锁服务器，

459
00:26:00,790 --> 00:26:02,380
我们工作站 1 ，

460
00:26:04,200 --> 00:26:05,460
以及工作站 2 。

461
00:26:07,600 --> 00:26:11,050
这里有四个重要的信息，

462
00:26:11,050 --> 00:26:14,770
也就是请求锁，授予锁，

463
00:26:15,100 --> 00:26:18,130
撤销锁，释放锁，

464
00:26:18,130 --> 00:26:21,220
这就是往返传递的四条信息，

465
00:26:21,220 --> 00:26:23,440
在工作站和锁服务器，

466
00:26:23,440 --> 00:26:25,270
以及锁服务器和其他工作站之间。

467
00:26:25,810 --> 00:26:27,280
让我们来看看这个，

468
00:26:27,280 --> 00:26:29,050
假设锁服务器有，

469
00:26:29,830 --> 00:26:31,660
任何时候都没有人有锁，

470
00:26:31,660 --> 00:26:33,220
所以让我们画一些时间线，

471
00:26:33,910 --> 00:26:37,330
工作站 1 想要请求，

472
00:26:38,080 --> 00:26:40,930
希望读写文件 f ，

473
00:26:41,230 --> 00:26:43,570
发送一个锁请求，

474
00:26:43,600 --> 00:26:45,520
到锁服务器，为了文件 f ，

475
00:26:46,580 --> 00:26:49,850
所以是工作站现在还不能做任何事情，

476
00:26:50,120 --> 00:26:52,910
锁服务器检查它的表，

477
00:26:53,180 --> 00:26:56,330
发现 f 没有人使用，

478
00:26:56,330 --> 00:26:59,360
将工作站 1 列为锁持有者，

479
00:26:59,420 --> 00:27:04,890
发回消息，授予 f 锁，

480
00:27:06,160 --> 00:27:10,240
所以，在这个时刻，工作站 1 获得 f 锁，

481
00:27:10,270 --> 00:27:11,770
现在它可以读或写，

482
00:27:11,770 --> 00:27:14,260
现在它可以从 Petal 读取文件，

483
00:27:18,660 --> 00:27:21,660
其实也可以对它进行修改，

484
00:27:21,750 --> 00:27:25,140
现在这些修改保留在本地，什么都没有发生，

485
00:27:25,140 --> 00:27:28,170
是一个写会缓存，而不是直写缓存，

486
00:27:28,600 --> 00:27:31,990
所以，它只是留在客户端。

487
00:27:32,640 --> 00:27:35,850
事实上，工作站甚至可以释放锁，

488
00:27:35,880 --> 00:27:38,820
在这里从忙变为闲，

489
00:27:42,370 --> 00:27:45,190
所以，它需要再次加锁，

490
00:27:45,190 --> 00:27:47,440
例如，写入之后再次写入，

491
00:27:47,440 --> 00:27:49,150
我们可以完全在本地操作，

492
00:27:49,150 --> 00:27:51,910
而不用与锁服务器交互。

493
00:27:52,710 --> 00:27:54,420
这是一个轻微的简化，

494
00:27:54,420 --> 00:27:55,650
稍后我们会看到，

495
00:27:55,680 --> 00:27:58,110
锁绑定一个租期，

496
00:27:58,110 --> 00:28:00,660
所以客户端至少要定期更新租期，

497
00:28:00,750 --> 00:28:05,490
但它不必从 Petal 重新读取文件 f ，

498
00:28:06,120 --> 00:28:07,500
如果租期已到。

499
00:28:08,880 --> 00:28:10,950
好的，所以会发生的情况，

500
00:28:10,950 --> 00:28:15,780
例如，如果工作站 2 想要读取文件 f ，

501
00:28:15,930 --> 00:28:17,280
会发生什么情况，

502
00:28:17,280 --> 00:28:18,780
工作站 2 想要读取，

503
00:28:18,780 --> 00:28:20,010
基本上它也会做同样的事情，

504
00:28:20,010 --> 00:28:23,520
它会发送获取或请求消息，

505
00:28:23,790 --> 00:28:26,040
向锁服务器的请求消息，

506
00:28:26,040 --> 00:28:27,000
表示我想要 f ，

507
00:28:27,790 --> 00:28:29,140
它的工作原理是，

508
00:28:29,260 --> 00:28:31,900
锁服务器查看这个表，

509
00:28:31,900 --> 00:28:35,380
看到 f 归工作站 1 所有，

510
00:28:35,530 --> 00:28:39,540
然后发送撤销消息到工作站 1 ，

511
00:28:39,810 --> 00:28:42,330
想要拿回锁，

512
00:28:42,510 --> 00:28:43,860
所以这将是 revoke f ，

513
00:28:44,520 --> 00:28:45,870
在这一点上，

514
00:28:46,490 --> 00:28:48,260
Petal 实际上做得更多一点，

515
00:28:48,260 --> 00:28:50,450
Frangipani 做得更多一点，

516
00:28:50,630 --> 00:28:54,530
因为我们必须确保工作站 2 观察到写入，

517
00:28:54,620 --> 00:28:56,030
工作站 1 已完成的，

518
00:28:56,240 --> 00:28:57,380
所以这样做的方式是，

519
00:28:57,380 --> 00:28:59,300
在这一时刻，

520
00:29:02,180 --> 00:29:05,120
工作站 1 将 f 写入 Petal ，

521
00:29:06,020 --> 00:29:07,040
我们很快会看到，

522
00:29:07,040 --> 00:29:10,310
将 f 写到 Petal 是一个稍微复杂的操作，

523
00:29:10,310 --> 00:29:12,350
比我所说的更复杂，

524
00:29:12,470 --> 00:29:13,340
但是考虑一下，

525
00:29:13,340 --> 00:29:14,210
在这个点上，

526
00:29:14,450 --> 00:29:18,740
工作站 1 刷新它的状态到 Petal ，

527
00:29:19,580 --> 00:29:21,080
一旦这项工作完成，

528
00:29:21,080 --> 00:29:22,910
一旦 Petal 确认，

529
00:29:22,910 --> 00:29:25,070
它已经收到了所有的数据，

530
00:29:25,250 --> 00:29:27,890
并发回一条消息， release f ，

531
00:29:32,100 --> 00:29:34,830
一旦锁服务器得到 release f ，

532
00:29:34,860 --> 00:29:36,810
它可以更新它的表，

533
00:29:36,810 --> 00:29:39,510
并将锁分配给工作站 2 ，

534
00:29:39,690 --> 00:29:44,250
发送 grant f 给 2 。

535
00:29:45,070 --> 00:29:45,460
糟糕。

536
00:29:52,420 --> 00:29:54,130
在这一点上，

537
00:29:54,160 --> 00:29:56,020
工作站 2 获得锁，

538
00:29:56,020 --> 00:30:00,520
现在它可以读取 Petal 中 f 文件中的所有信息，

539
00:30:00,700 --> 00:30:07,060
在这一点上，可以保证我们将看到文件 f 的最新变化，

540
00:30:07,060 --> 00:30:14,020
因为之前的拥有者肯定已经把状态刷新到 Petal ，

541
00:30:14,110 --> 00:30:17,530
在它释放锁，并将其返回给锁服务器之前，

542
00:30:17,710 --> 00:30:20,920
工作站 2 保证能观察到这些变化，

543
00:30:20,920 --> 00:30:23,110
所以这就是强一致性的来源，

544
00:30:23,620 --> 00:30:27,430
这些强一致性与锁管理密切相关。

545
00:30:29,860 --> 00:30:30,850
对于这个，有什么问题吗？

546
00:30:34,410 --> 00:30:36,030
在聊天中有一个问题。

547
00:30:36,720 --> 00:30:37,530
好的,

548
00:30:39,860 --> 00:30:40,940
我们需要写，

549
00:30:40,940 --> 00:30:42,320
聊天中有一个问题，

550
00:30:42,320 --> 00:30:43,670
让我来谈谈第一个问题，

551
00:30:43,910 --> 00:30:45,500
我们需要写入 Petal ，

552
00:30:45,500 --> 00:30:47,480
当释放读和写锁时，

553
00:30:47,600 --> 00:30:50,540
为什么我们需要在释放读锁时写入 Petal ？

554
00:30:50,930 --> 00:30:54,080
让我们忽略读写，

555
00:30:54,080 --> 00:30:55,940
读和写之间的区别，

556
00:30:56,240 --> 00:30:58,400
排它锁和读写锁，

557
00:30:58,640 --> 00:31:03,520
只关注排它锁，

558
00:31:03,550 --> 00:31:06,640
读取（锁）只是一个小的[应用]，

559
00:31:06,640 --> 00:31:08,410
它发生一个重要的优化，

560
00:31:08,590 --> 00:31:12,580
但它并没有明显地改变设计体系。

561
00:31:17,180 --> 00:31:18,050
还有其他问题吗？

562
00:31:19,150 --> 00:31:22,300
所以这种设计效率会很低，

563
00:31:22,300 --> 00:31:24,160
如果我们有两个不同的工作站，

564
00:31:24,160 --> 00:31:26,140
它们都在修改同一个文件。

565
00:31:26,350 --> 00:31:26,770
是的。

566
00:31:26,830 --> 00:31:29,530
你是让缓存来回跳动。

567
00:31:29,560 --> 00:31:33,340
是的，如果你们是两个工作站或两个不同的工程师，

568
00:31:33,340 --> 00:31:35,560
那个服务器会[敲打]同一个文件，

569
00:31:35,560 --> 00:31:37,240
这个文件会来回跳动。

570
00:31:38,290 --> 00:31:41,350
所以并不是很合适，

571
00:31:41,350 --> 00:31:42,400
所以你可以看到，

572
00:31:42,400 --> 00:31:46,180
比如他们设计的工作量的影响，

573
00:31:46,270 --> 00:31:48,160
他们真正的假设是，

574
00:31:48,160 --> 00:31:51,460
大多数工程师都在处理他们的私人文件，

575
00:31:51,700 --> 00:31:54,040
有时候，他们会共享文件，

576
00:31:54,040 --> 00:31:56,350
但他们可能并不是在处理同一个共享文件。

577
00:32:02,980 --> 00:32:04,000
我们在用 Git ，

578
00:32:04,000 --> 00:32:06,970
你可以想象，如果你共享你的代码库，

579
00:32:06,970 --> 00:32:09,670
或者检出你自己的代码库副本，

580
00:32:09,670 --> 00:32:10,600
做了你自己的修改，

581
00:32:10,600 --> 00:32:11,830
到某个时候，你把它写回去。

582
00:32:14,850 --> 00:32:16,410
抱歉，只是为了确认你说的，

583
00:32:16,560 --> 00:32:21,420
你可以在缓存中仍有文件的情况下释放锁？

584
00:32:23,040 --> 00:32:27,650
你可以，好的，所以我小心一点，

585
00:32:27,650 --> 00:32:29,600
当我提到释放锁的时候，

586
00:32:29,660 --> 00:32:31,520
不是释放锁服务器的，

587
00:32:31,670 --> 00:32:34,970
而是在本地将状态从忙改为闲，

588
00:32:37,020 --> 00:32:39,060
因为是粘锁，

589
00:32:39,060 --> 00:32:40,740
它还在工作站 1 ，

590
00:32:40,740 --> 00:32:43,950
锁服务器仍然认为工作站 1 拥有这个锁。

591
00:32:48,850 --> 00:32:49,960
这回答了你的问题吗？

592
00:32:51,330 --> 00:32:52,740
好的，好的，谢谢。

593
00:32:54,600 --> 00:32:55,890
那么，会发生什么，

594
00:32:56,510 --> 00:33:01,190
如果在它忙时， 2 的请求到来？

595
00:33:01,930 --> 00:33:03,820
是的，好问题，你认为会发生什么？

596
00:33:10,100 --> 00:33:11,180
它只是拒绝它们吗？

597
00:33:11,880 --> 00:33:14,640
不，我认为它不会拒绝它，只是等待，

598
00:33:14,880 --> 00:33:18,210
等待直到工作站 1 完成，

599
00:33:18,270 --> 00:33:21,840
修改文件 f 或执行文件系统操作，

600
00:33:22,230 --> 00:33:27,480
然后 Frangipani 代码将在本地释放锁，

601
00:33:27,750 --> 00:33:29,820
会看到有人在等它，

602
00:33:30,210 --> 00:33:32,790
因此将其更改为忙，

603
00:33:32,850 --> 00:33:35,520
开始将所有操作都刷新到 Petal ，

604
00:33:35,520 --> 00:33:36,750
然后释放锁。

605
00:33:38,530 --> 00:33:41,260
所以这很好地谈到了第二点，

606
00:33:41,260 --> 00:33:42,610
就是原子点，

607
00:33:42,640 --> 00:33:44,320
这或许会让事情变得更清楚。

608
00:33:45,330 --> 00:33:46,860
让我来谈谈原子性，

609
00:33:46,860 --> 00:33:49,620
因为它也使用相同的锁

610
00:33:49,740 --> 00:33:53,550
来实现原子文件系统操作，

611
00:33:56,260 --> 00:34:03,100
原子性，使用锁。

612
00:34:03,130 --> 00:34:06,780
所以，当你执行创建操作时，

613
00:34:06,780 --> 00:34:11,460
你执行创建文件系统操作或 create f ，

614
00:34:12,850 --> 00:34:14,500
不管是什么参数，

615
00:34:15,150 --> 00:34:16,800
当然，在内部，

616
00:34:16,800 --> 00:34:19,440
尽管应用程序调用创建文件系统调用，

617
00:34:19,440 --> 00:34:23,610
在内部实际上具有多个文件系统修改，

618
00:34:23,910 --> 00:34:27,000
例如，目录需要被修改，

619
00:34:27,060 --> 00:34:29,430
让我以稍微不同的顺序来做，

620
00:34:29,520 --> 00:34:33,120
我们需要为 f 分配一个 inode ，

621
00:34:34,260 --> 00:34:38,550
我们需要初始化 inode ，写入 inode ，

622
00:34:39,790 --> 00:34:41,710
然后更新目录，

623
00:34:44,150 --> 00:34:49,670
更新目录以添加条目 f ，

624
00:34:49,790 --> 00:34:52,880
为 f 分配的 inode ，

625
00:34:53,980 --> 00:34:57,190
这是 Unix 文件系统实现文件的典型方式，

626
00:34:57,730 --> 00:35:01,150
我们需要安排这些操作以原子方式进行，

627
00:35:01,570 --> 00:35:06,220
因为我们不想让其他工作站看到中间结果，

628
00:35:06,220 --> 00:35:09,520
发生的方式是通过获取这些锁，

629
00:35:09,940 --> 00:35:15,360
获取这个特定 inode 的锁，

630
00:35:15,360 --> 00:35:17,220
比如 inode 10 ，

631
00:35:17,220 --> 00:35:18,660
所以，你为 f 获取一把锁，

632
00:35:18,690 --> 00:35:22,170
我使用 "f" 作为锁，

633
00:35:22,170 --> 00:35:24,180
但是，它将是 inode 编号，

634
00:35:24,180 --> 00:35:24,990
然后在某个时刻，

635
00:35:24,990 --> 00:35:27,900
它释放[]的文件系统，

636
00:35:27,900 --> 00:35:29,190
它本身释放锁，

637
00:35:30,360 --> 00:35:33,150
同样地，这是一个本地释放操作，

638
00:35:33,150 --> 00:35:37,920
这并不意味着立即将其释放回锁服务器，

639
00:35:37,920 --> 00:35:41,070
只是将状态从忙更改为闲。

640
00:35:42,220 --> 00:35:45,640
所以，如果在任何特定的时间点，

641
00:35:45,700 --> 00:35:46,870
就像我们刚才问的那样，

642
00:35:46,870 --> 00:35:52,630
有一个撤销锁的请求，

643
00:35:55,860 --> 00:35:56,820
revoke f，

644
00:35:56,940 --> 00:35:59,730
请求不会被[服务]，

645
00:35:59,850 --> 00:36:04,320
直到位于工作站 1 的本地 Frangipani 文件系统，

646
00:36:04,970 --> 00:36:07,790
调用了本地释放操作，

647
00:36:08,300 --> 00:36:11,090
然后当本地释放操作时，

648
00:36:11,090 --> 00:36:14,360
它看到有一个 revoke 在等待，

649
00:36:14,600 --> 00:36:15,560
所以，在这一点上，

650
00:36:15,680 --> 00:36:24,250
它将刷新缓存状态到 Petal ，

651
00:36:26,180 --> 00:36:28,970
一旦它刷新缓存状态到 Petal ，

652
00:36:29,090 --> 00:36:33,800
它将授予撤销或接受撤销，

653
00:36:33,920 --> 00:36:36,260
并向锁服务器发回 release ，

654
00:36:36,260 --> 00:36:44,190
然后锁就可以分配给工作站 2 了。这能理解吗？

655
00:36:48,620 --> 00:36:50,450
所以只是确认，

656
00:36:50,450 --> 00:36:51,980
在这里的创建操作中，

657
00:36:51,980 --> 00:36:54,380
我们必须修改 inode ，

658
00:36:54,410 --> 00:36:57,230
我们必须修改 f 的 inode ，

659
00:36:57,230 --> 00:36:59,240
以及包含 f 的目录的 inode ，

660
00:36:59,240 --> 00:37:01,130
因为我们必须更新引用，

661
00:37:01,340 --> 00:37:02,690
这就意味着，

662
00:37:02,690 --> 00:37:08,280
从技术上讲，我们持有两把锁，

663
00:37:08,280 --> 00:37:10,020
我们必须释放这两把锁，

664
00:37:10,020 --> 00:37:12,170
在回复撤销请求之前。

665
00:37:12,180 --> 00:37:14,850
是的，当然，

666
00:37:14,850 --> 00:37:15,690
所以稍等一下查看论文，

667
00:37:15,690 --> 00:37:17,100
然后讨论他们怎么做，

668
00:37:17,100 --> 00:37:18,540
但从根本上说，他们有一些，

669
00:37:19,210 --> 00:37:21,100
不是非常粗粒度的锁，

670
00:37:21,100 --> 00:37:23,620
而且还有非常细粒度的锁，[]锁，

671
00:37:23,620 --> 00:37:26,140
他们每个 inode 都有一个锁，

672
00:37:26,440 --> 00:37:29,050
目录的 inode ，文件的 inode ，

673
00:37:29,320 --> 00:37:31,660
事实上，目录与文件没有什么不同，

674
00:37:31,660 --> 00:37:35,210
只不过是具有特定格式，

675
00:37:35,390 --> 00:37:37,280
所以创建 f ，

676
00:37:37,280 --> 00:37:38,840
我们必须分配，

677
00:37:38,930 --> 00:37:42,920
首先分配或获取目录 d 的锁，

678
00:37:43,160 --> 00:37:49,730
然后分配或获取 inode f 的锁，

679
00:37:49,950 --> 00:37:51,480
所以持有两把锁。

680
00:37:52,060 --> 00:37:54,280
你可能已经注意到的，

681
00:37:54,280 --> 00:37:57,100
当然，当你获取多个锁时，

682
00:37:57,100 --> 00:37:59,650
存在陷入死锁的风险，

683
00:37:59,650 --> 00:38:03,580
如果一个工作站以不同的顺序分配锁，

684
00:38:03,580 --> 00:38:04,720
你可能会陷入死锁，

685
00:38:04,990 --> 00:38:06,940
所以， Frangipani 遵循规则，

686
00:38:06,940 --> 00:38:09,670
所有的锁都以特定的方式排序，

687
00:38:09,760 --> 00:38:12,280
以固定的顺序获取锁。

688
00:38:14,370 --> 00:38:15,000
我明白了，谢谢。

689
00:38:15,270 --> 00:38:17,940
我想锁是按 inode 编号排序的。

690
00:38:21,480 --> 00:38:22,350
这个能理解吗？

691
00:38:23,840 --> 00:38:25,580
是的，所以那里有很多更复杂的东西。

692
00:38:29,180 --> 00:38:30,680
好的，所以，

693
00:38:31,660 --> 00:38:35,920
所以讨论了原子性文件系统操作，

694
00:38:35,920 --> 00:38:37,270
至少在崩溃时，

695
00:38:37,660 --> 00:38:39,190
如果没有崩溃，

696
00:38:39,340 --> 00:38:43,300
至少可以保证这些操作是原子发生的，

697
00:38:43,300 --> 00:38:45,310
因为锁确保了原子性，

698
00:38:45,760 --> 00:38:47,560
当然有可能是这样的，

699
00:38:47,560 --> 00:38:49,210
比如我们运气不好，

700
00:38:49,210 --> 00:38:52,180
工作站 1 崩溃，

701
00:38:52,180 --> 00:38:54,100
正好在这些操作的中间，

702
00:38:54,100 --> 00:38:56,740
例如在分配 inode 时，

703
00:38:56,860 --> 00:38:58,720
它还没有更新目录。

704
00:38:59,540 --> 00:39:02,480
我们假设崩溃发生在这里，

705
00:39:04,270 --> 00:39:07,360
如果我们不做些特别的事，

706
00:39:07,360 --> 00:39:09,580
我们可能会有什么顾虑。

707
00:39:17,100 --> 00:39:19,530
好的，我们可能有的顾虑，

708
00:39:19,560 --> 00:39:23,520
某些文件系统操作只是部分应用于 Petal ，

709
00:39:24,220 --> 00:39:26,710
这个变得更清楚了，

710
00:39:26,770 --> 00:39:29,110
如果我们考虑这个场景，

711
00:39:29,110 --> 00:39:31,180
在这个特殊的状态下发生了什么，

712
00:39:31,180 --> 00:39:36,160
当缓存状态已经刷新到 Petal 时。

713
00:39:36,650 --> 00:39:38,660
所以，这就是崩溃恢复的主题。

714
00:39:50,240 --> 00:39:56,120
事实证明，更新 Petal 中的状态，

715
00:39:56,150 --> 00:39:58,280
也遵循非常仔细的协议，

716
00:39:58,730 --> 00:40:01,970
这个协议通常被称为预写式日志，

717
00:40:21,570 --> 00:40:24,030
这可能是我们已经看到的术语，

718
00:40:24,030 --> 00:40:27,120
你们可能已经在 6.033 中看到过，

719
00:40:27,120 --> 00:40:29,130
Petal 也使用它，

720
00:40:29,130 --> 00:40:30,570
它是一种非常常见的技术，

721
00:40:30,600 --> 00:40:32,640
它也会发挥重要作用，

722
00:40:32,640 --> 00:40:34,710
在之后我们看到的论文里，

723
00:40:34,920 --> 00:40:37,890
所以 Petal 很好的引入

724
00:40:37,890 --> 00:40:40,740
这种预写式日志的想法，

725
00:40:41,310 --> 00:40:42,540
一种思考的方式，

726
00:40:42,540 --> 00:40:46,590
Petal 是为预写式日志设计的，

727
00:40:46,740 --> 00:40:50,790
使用预写式日志与任何其他预写式日志方案非常相似。

728
00:40:51,120 --> 00:40:53,430
所以思考它的方式如下，

729
00:40:53,430 --> 00:40:55,620
我们有虚拟磁盘，

730
00:40:56,390 --> 00:41:01,310
我们可以把磁盘想象成一个很长的块阵列，

731
00:41:01,900 --> 00:41:06,850
他们所做的是，将磁盘的一部分保留为日志，

732
00:41:08,140 --> 00:41:09,880
事实上，在 Petal 的情况中，

733
00:41:09,910 --> 00:41:11,110
每台服务器都有一个日志，

734
00:41:11,140 --> 00:41:14,440
但现在，我们假设有一个单一的日志，

735
00:41:14,770 --> 00:41:16,030
然后是文件系统，

736
00:41:17,060 --> 00:41:19,970
所以有一部分磁盘是为日志保留的，

737
00:41:19,970 --> 00:41:21,710
一部分磁盘是文件系统，

738
00:41:21,710 --> 00:41:23,690
文件系统包含 inode ，

739
00:41:24,560 --> 00:41:27,290
还有一些数据块，等等。

740
00:41:28,120 --> 00:41:29,920
规则是，

741
00:41:30,130 --> 00:41:32,680
当你更新 Petal 中的状态时，

742
00:41:33,160 --> 00:41:37,300
你要做的第一件事是第一次日志更新，

743
00:41:43,840 --> 00:41:46,900
所以，如果我们回到上一张图片，

744
00:41:47,020 --> 00:41:53,320
在那个点之后，在工作站 1 上的 Frangipani ，

745
00:41:53,530 --> 00:41:55,930
想把锁还给锁服务器，

746
00:41:55,930 --> 00:41:59,020
它首先要把它的状态写入 Petal ，

747
00:41:59,020 --> 00:42:00,370
这分为两步，

748
00:42:00,580 --> 00:42:03,820
第一步记录更新，

749
00:42:03,820 --> 00:42:07,930
发送更新到日志，

750
00:42:07,930 --> 00:42:10,180
例如，在这里，我们获得一个记录，

751
00:42:10,910 --> 00:42:15,200
这表示创建操作，

752
00:42:15,200 --> 00:42:20,500
所以有分配 inode 编号，

753
00:42:20,500 --> 00:42:22,870
不管结果是什么，

754
00:42:22,870 --> 00:42:26,260
如果你分配 inode 编号并且目录发生变化，

755
00:42:30,900 --> 00:42:32,640
稍后我们会更具体一点，

756
00:42:32,640 --> 00:42:36,150
但是更新包括修改，

757
00:42:36,150 --> 00:42:39,450
需要发生在文件系统块上的（修改），

758
00:42:39,510 --> 00:42:42,060
为了反映这一变化。

759
00:42:42,540 --> 00:42:46,200
所以首先记录更新，

760
00:42:46,440 --> 00:42:49,110
然后，一旦你更新了日志，

761
00:42:49,610 --> 00:42:53,420
然后，客户端的第二个执行的操作，

762
00:42:53,480 --> 00:42:56,390
工作站执行的是安装更新，

763
00:43:03,370 --> 00:43:09,070
做这两个步骤的原因是，

764
00:43:09,160 --> 00:43:12,040
一旦你记录了所有的变化，

765
00:43:12,400 --> 00:43:15,580
那么更新数据块就完全安全了，

766
00:43:15,580 --> 00:43:18,880
因为它们总是会更新文件系统，

767
00:43:18,880 --> 00:43:22,570
它总是以一致的状态结束，

768
00:43:22,870 --> 00:43:25,030
而理解这一点的方法是，

769
00:43:25,060 --> 00:43:28,090
让我们假设客户端工作站，

770
00:43:28,090 --> 00:43:30,400
正在刷新它的数据到 Petal ，

771
00:43:31,330 --> 00:43:32,890
在这里崩溃。

772
00:43:36,870 --> 00:43:37,650
这可以吗？

773
00:43:43,900 --> 00:43:46,270
是的，因为所有东西都已经存入日志，

774
00:43:46,270 --> 00:43:51,580
他们所说的 demon 恢复服务。

775
00:43:51,790 --> 00:43:55,540
是的， demon 会回到，

776
00:43:55,660 --> 00:43:56,590
这里会有一个 demon ，

777
00:43:56,590 --> 00:43:57,370
当发生崩溃时，

778
00:43:57,370 --> 00:43:59,770
这里有一个 demon 查看日志中是否有什么东西，

779
00:43:59,770 --> 00:44:00,730
如果日志里有任何东西，

780
00:44:00,730 --> 00:44:02,170
就应用到文件系统。

781
00:44:03,830 --> 00:44:06,950
为什么要这样做，

782
00:44:06,950 --> 00:44:09,380
为什么不立即写入或更新文件系统？

783
00:44:14,950 --> 00:44:17,200
因为我们可能会在更新过程中崩溃，

784
00:44:17,200 --> 00:44:19,570
我们不知道我们完成了[]。

785
00:44:19,600 --> 00:44:20,800
是的，完全正确，

786
00:44:20,800 --> 00:44:23,200
在我们之前的例子中，

787
00:44:23,200 --> 00:44:27,640
分配 inode 是在某个地方进行一些更改，

788
00:44:27,850 --> 00:44:29,320
比如在 inode 块上，

789
00:44:29,710 --> 00:44:32,230
添加目录到，

790
00:44:32,440 --> 00:44:35,440
或将文件 f 添加到特定目录，

791
00:44:35,590 --> 00:44:37,960
更新某处的目录块，数据块，

792
00:44:38,320 --> 00:44:40,930
所以这是两个独立的磁盘写入，

793
00:44:40,930 --> 00:44:41,770
它们不是原子的，

794
00:44:41,770 --> 00:44:43,780
所以我们会在两者中的一个崩溃，

795
00:44:43,960 --> 00:44:45,580
我们可能已经分配了 inode ，

796
00:44:45,580 --> 00:44:46,840
但是不在目录中，

797
00:44:47,540 --> 00:44:50,930
那么，如果我们崩溃并恢复，会发生什么，

798
00:44:50,960 --> 00:44:52,340
基本上会失去 inode ，

799
00:44:52,970 --> 00:44:54,620
除非我们能扫描整个磁盘，

800
00:44:54,620 --> 00:44:55,760
但那是非常昂贵的。

801
00:44:57,380 --> 00:44:59,000
所以他们说我们做的是，

802
00:44:59,000 --> 00:45:01,340
我们首先记录这两个更改，

803
00:45:01,340 --> 00:45:05,060
我们首先记录描述这两个更改的记录，

804
00:45:05,420 --> 00:45:07,340
然后应用更改。

805
00:45:08,800 --> 00:45:10,960
那么我们如何确保操作是原子的，

806
00:45:11,080 --> 00:45:12,460
所以第一个要更新的日志。

807
00:45:13,140 --> 00:45:14,100
第一次日志更新，

808
00:45:14,250 --> 00:45:15,120
是的，这很有趣，

809
00:45:15,180 --> 00:45:18,300
论文[] 100% 对应这个，

810
00:45:18,300 --> 00:45:21,030
但有几种方法可以做到这一点，

811
00:45:21,030 --> 00:45:25,560
他们提到每个日志记录都有一个校验和，

812
00:45:26,380 --> 00:45:30,370
所以，他们使用校验和来查看是否，

813
00:45:30,550 --> 00:45:33,490
在读日志记录之前，

814
00:45:33,490 --> 00:45:34,480
我们计算一个校验和，

815
00:45:34,570 --> 00:45:36,580
为了确保整个记录是完整的。

816
00:45:38,620 --> 00:45:39,460
我明白了，谢谢。

817
00:45:39,520 --> 00:45:40,570
另一种方法是，

818
00:45:40,570 --> 00:45:41,710
一种其他方式是，

819
00:45:41,710 --> 00:45:44,590
在你写入多个块时，比如 1 2 ，你知道几个街区就像一二

820
00:45:44,590 --> 00:45:45,820
然后你写入一个提交记录，

821
00:45:46,620 --> 00:45:48,300
我们的假设是，

822
00:45:48,300 --> 00:45:52,620
写入单个块，单个 512 扇区是原子操作，

823
00:45:52,620 --> 00:45:54,120
所以要么发生，要么不发生，

824
00:45:54,510 --> 00:45:55,950
所以你需要提交记录，

825
00:45:55,980 --> 00:45:57,960
完成写入或未完成写入，

826
00:45:58,350 --> 00:46:00,150
所以，你只需查看提交记录，

827
00:46:00,150 --> 00:46:03,000
如果提交记录不在那里，

828
00:46:03,030 --> 00:46:06,690
那么你就知道操作还没有完全记录下来，

829
00:46:06,840 --> 00:46:08,220
你不应该执行其中任何一项。

830
00:46:10,000 --> 00:46:10,420
我明白了，

831
00:46:10,510 --> 00:46:13,630
再仔细检查一下上一张幻灯片，

832
00:46:13,630 --> 00:46:17,680
如果崩溃发生在我们把东西刷新到 Petal 之前，

833
00:46:17,980 --> 00:46:19,450
那么这不是问题，对吧，

834
00:46:19,450 --> 00:46:21,790
因为如果工作站崩溃，

835
00:46:21,790 --> 00:46:23,410
崩溃跟工作站一起，

836
00:46:23,410 --> 00:46:25,870
但其他任何工作站都没有不一致的状态。

837
00:46:26,110 --> 00:46:28,060
这是正确的，只是数据会丢失，

838
00:46:28,750 --> 00:46:31,390
如果没有写到 Petal 中，

839
00:46:31,390 --> 00:46:33,250
就不会有任何可见性问题。

840
00:46:33,670 --> 00:46:36,580
所以崩溃发生在这里，

841
00:46:37,480 --> 00:46:39,550
在某些方面，这个并不重要，

842
00:46:39,700 --> 00:46:42,790
真正重要的是这个刷新操作中的崩溃。

843
00:46:43,790 --> 00:46:44,960
嗯，谢谢。

844
00:46:51,140 --> 00:46:55,640
好的，所以，在 Frangipani 有一个技巧，

845
00:46:55,640 --> 00:46:58,610
我们稍后会更详细地讨论这一点，

846
00:46:58,610 --> 00:47:06,080
也就是，在 Frangipani 中，每个服务器都有一个锁，

847
00:47:07,300 --> 00:47:08,530
这有点不寻常，

848
00:47:09,410 --> 00:47:11,240
我们稍后会看到，

849
00:47:11,270 --> 00:47:14,180
这回造成什么问题，

850
00:47:14,210 --> 00:47:16,610
所以我们将会看到，

851
00:47:16,610 --> 00:47:19,040
协议有一个小的扩展，

852
00:47:19,040 --> 00:47:20,690
让这个正常工作。

853
00:47:22,600 --> 00:47:25,150
好的，让我简单地说一下，

854
00:47:25,150 --> 00:47:26,890
日志记录中有什么，

855
00:47:32,570 --> 00:47:36,950
事实证明，这对崩溃恢复非常重要，

856
00:47:37,220 --> 00:47:41,900
特别是我们每台服务器都有多个 Frangipani 日志。

857
00:47:43,000 --> 00:47:44,260
所以每个日志都有，

858
00:47:44,810 --> 00:47:48,170
所以有记录在日志中，

859
00:47:48,500 --> 00:47:50,120
它们有一个序列号，

860
00:47:51,060 --> 00:47:54,540
不论编号 2 ， 1 2 ，

861
00:47:54,900 --> 00:47:56,730
日志的结尾是，

862
00:47:56,730 --> 00:48:00,420
下一个序列号比你的高一。

863
00:48:01,220 --> 00:48:03,140
所以他们有另一种标记的方法，

864
00:48:03,380 --> 00:48:08,510
在这些记录中是更新数组，

865
00:48:12,930 --> 00:48:15,150
描述文件系统操作，

866
00:48:15,540 --> 00:48:19,350
所以它包含需要更新的块号，

867
00:48:19,380 --> 00:48:24,060
例如，在我们的示例中，这是 inode 编号，

868
00:48:24,060 --> 00:48:25,590
包含信息节点的块，

869
00:48:25,590 --> 00:48:28,200
它会分配一个版本号，

870
00:48:29,010 --> 00:48:30,030
因为在这一记录中，

871
00:48:30,030 --> 00:48:32,340
我们随后会看到，为什么这很重要，

872
00:48:32,490 --> 00:48:35,910
基本上是该块编号的新字节。

873
00:48:37,840 --> 00:48:41,560
例如，在创建文件的情况下， create f ，

874
00:48:42,190 --> 00:48:45,990
这个数组中会有两个条目，

875
00:48:46,260 --> 00:48:47,340
两个条目，

876
00:48:49,140 --> 00:48:52,530
一个描述对 inode 块的更新，

877
00:48:52,530 --> 00:48:57,720
一个描述对目录数据块的更新。

878
00:49:05,140 --> 00:49:07,150
所以，复制过程中会发生什么，

879
00:49:07,150 --> 00:49:09,880
只是想把这一点说得非常清楚，

880
00:49:09,880 --> 00:49:12,430
当 revoke 的请求传入时，

881
00:49:12,730 --> 00:49:19,770
发生的第一件事是将日志放入 Petal ，

882
00:49:20,750 --> 00:49:21,800
一旦完成，

883
00:49:21,980 --> 00:49:25,910
发送更新块到 Petal ，

884
00:49:34,660 --> 00:49:36,190
然后释放锁。

885
00:49:41,790 --> 00:49:43,170
这可以确保，

886
00:49:43,230 --> 00:49:45,870
我们需要考虑几件事情，

887
00:49:46,140 --> 00:49:48,810
如果中间没有崩溃，

888
00:49:48,810 --> 00:49:52,440
那么这如前所述，

889
00:49:52,560 --> 00:49:54,300
是有趣的例子，

890
00:49:54,300 --> 00:49:56,490
当崩溃发生在，

891
00:49:56,580 --> 00:50:01,110
正好在发送日志到 P ，但是在更新 Petal 之前。

892
00:50:02,550 --> 00:50:03,990
所以，让我们稍微谈谈这一点。

893
00:50:06,670 --> 00:50:08,890
抱歉，你说的新字节是什么意思？

894
00:50:09,730 --> 00:50:13,730
好的，让我回去，

895
00:50:13,970 --> 00:50:17,120
使用另一种方式，更改信息节点块，

896
00:50:17,120 --> 00:50:18,830
以 inode 块为例，

897
00:50:19,160 --> 00:50:23,270
也许更新 inode 的某些部分，，

898
00:50:23,270 --> 00:50:27,050
然后你可以写下字节发生了变化，

899
00:50:27,050 --> 00:50:30,410
比如字节 0 到 5 和 12 有下列值，

900
00:50:30,740 --> 00:50:33,860
或字节 10 到 20 具有以下新值。

901
00:50:36,200 --> 00:50:38,090
但这些变化会不会像，

902
00:50:38,150 --> 00:50:41,510
因为这些块中的每一个最多为 512 字节，

903
00:50:42,080 --> 00:50:47,750
但你所做的修改可能比 512 字节大得多，

904
00:50:47,840 --> 00:50:50,780
每一个块都会有记录。

905
00:50:51,980 --> 00:50:54,320
所以，事实上，好的，所以有几点，

906
00:50:55,110 --> 00:50:56,490
首先，

907
00:50:57,000 --> 00:51:00,420
数据写入不会通过日志，

908
00:51:00,450 --> 00:51:01,470
所以有一点很重要，

909
00:51:01,470 --> 00:51:03,150
所以谢谢你问这个问题，

910
00:51:03,480 --> 00:51:04,920
所以当你写一个文件时，

911
00:51:05,190 --> 00:51:09,450
应用调用 write f 和一些数据，

912
00:51:09,720 --> 00:51:12,270
所有这些数据都不会通过日志，

913
00:51:12,670 --> 00:51:14,560
它们会直接传递给 Petal ，

914
00:51:14,590 --> 00:51:17,110
比如一旦你刷新状态，

915
00:51:17,680 --> 00:51:22,510
通过日志的唯一更改是元更新更改，

916
00:51:22,540 --> 00:51:24,310
所以元数据更改，

917
00:51:26,100 --> 00:51:29,880
元数据的含义是关于文件的信息，

918
00:51:30,640 --> 00:51:33,700
所以 inode 目录，这类东西，

919
00:51:33,700 --> 00:51:35,020
它们会通过日志。

920
00:51:35,660 --> 00:51:39,620
所以你在这里看到的描述是，

921
00:51:39,620 --> 00:51:43,280
文件系统元数据块的更新，

922
00:51:43,610 --> 00:51:46,280
inode 和目录数据。

923
00:51:48,300 --> 00:51:50,460
应用级别数据，

924
00:51:50,490 --> 00:51:53,400
实际构成文件的文件块，

925
00:51:53,760 --> 00:51:56,910
这些数据块直接写入到 Petal ，

926
00:51:56,910 --> 00:51:58,080
不通过日志。

927
00:51:59,620 --> 00:52:02,680
所以，思考这一点的含义是很有趣的，

928
00:52:02,890 --> 00:52:04,270
那个设计选择，

929
00:52:07,130 --> 00:52:09,920
不把每件事都通过日志有什么坏处？

930
00:52:12,330 --> 00:52:12,960
Assel 。

931
00:52:17,130 --> 00:52:19,680
对数据的更新可能会丢失。

932
00:52:20,840 --> 00:52:22,040
它们可能会丢失，是的，

933
00:52:23,010 --> 00:52:24,870
还有哪些其他场景是可能的，

934
00:52:24,870 --> 00:52:27,930
假设文件由 10 个数据块组成，

935
00:52:28,290 --> 00:52:30,690
我们开始写 10 个块，

936
00:52:30,690 --> 00:52:33,690
文件的最终状态是什么样的？

937
00:52:36,910 --> 00:52:38,290
变得不一致。

938
00:52:38,650 --> 00:52:39,970
是的，不一致，

939
00:52:39,970 --> 00:52:42,550
一些写入，没有写入，全部写入，

940
00:52:42,550 --> 00:52:43,840
谁知道是什么，

941
00:52:44,680 --> 00:52:47,410
但它不能保证所有 10 个都会同时应用。

942
00:52:48,470 --> 00:52:50,750
所以这是很重要的，

943
00:52:50,750 --> 00:52:55,560
当你需要原子写入时。

944
00:52:58,350 --> 00:53:02,100
好的，如果你不需要原子性，

945
00:53:02,280 --> 00:53:06,360
我们能不能去掉那些日志？

946
00:53:07,500 --> 00:53:09,810
我想是的，

947
00:53:09,810 --> 00:53:11,040
先保留这个问题，

948
00:53:11,040 --> 00:53:12,360
让我们首先来谈谈应用程序，

949
00:53:12,360 --> 00:53:15,030
然后我们再回到那个问题上。

950
00:53:15,180 --> 00:53:20,100
所以，好的，那个。

951
00:53:23,460 --> 00:53:27,690
所以，应用程序不能真正将它们的数据原子地写入日志，

952
00:53:27,690 --> 00:53:30,060
因为数据没有写入日志，

953
00:53:30,060 --> 00:53:32,250
所以没有写入日志，然后应用，

954
00:53:32,280 --> 00:53:34,080
所以，这意味着，

955
00:53:34,080 --> 00:53:39,800
例如，如果应用程序希望原子性地写入某个文件，

956
00:53:39,800 --> 00:53:41,690
那你就得自己安排，

957
00:53:42,110 --> 00:53:45,110
事实证明，大多数 Unix 文件都是这种情况，

958
00:53:45,500 --> 00:53:47,060
所以从 Frangipani 的角度来看，

959
00:53:47,060 --> 00:53:48,650
这并不能真正改变游戏规则，

960
00:53:48,980 --> 00:53:52,160
你在 Unix 文件系统中写了一个文件，

961
00:53:52,340 --> 00:53:54,470
你写入一个 VM 镜像，

962
00:53:54,470 --> 00:53:58,070
这不能保证整个镜像一致性地写入，

963
00:53:58,070 --> 00:54:01,400
在一次访问文件系统中，

964
00:54:01,610 --> 00:54:03,050
甚至在崩溃时。

965
00:54:03,470 --> 00:54:08,510
所以人们在应用程序中解决这个问题的典型方式是，

966
00:54:08,750 --> 00:54:10,220
它首先写入一个临时文件，

967
00:54:10,250 --> 00:54:11,750
将所有内容写入临时文件，

968
00:54:11,810 --> 00:54:14,900
然后做一个原子重命名，变成最终文件名称。

969
00:54:15,720 --> 00:54:21,180
所以， Frangipani 完全依赖于相同的设置，

970
00:54:21,210 --> 00:54:23,070
一种通常的 Unix 所做的，

971
00:54:23,280 --> 00:54:24,930
Frangipani 不会修改规则，

972
00:54:24,930 --> 00:54:31,290
这就是为什么文件写入不会通过日志记录。

973
00:54:31,960 --> 00:54:33,550
不通过日志有什么好处，

974
00:54:33,550 --> 00:54:35,110
所以很明显这是不利的一面，

975
00:54:35,110 --> 00:54:38,440
因为你不能使用日志原子地写入，

976
00:54:38,440 --> 00:54:40,840
你必须有自己的原子性方案，

977
00:54:40,840 --> 00:54:42,700
但它的优势是什么？

978
00:54:45,780 --> 00:54:47,220
好的，性能，

979
00:54:47,220 --> 00:54:50,400
因为元数据比实际数据要小得多。

980
00:54:50,610 --> 00:54:51,000
是的。

981
00:54:51,000 --> 00:54:53,070
同样还有内存。

982
00:54:53,280 --> 00:54:54,060
是的，就是这样，

983
00:54:54,060 --> 00:54:58,230
所以，如果你写一个巨大的文件，

984
00:54:58,440 --> 00:54:59,400
比如千兆字节文件，

985
00:54:59,400 --> 00:55:00,990
这意味着你必须写入 2 千兆字节，

986
00:55:01,350 --> 00:55:03,300
首先，将千兆字节写入日志，

987
00:55:03,300 --> 00:55:05,190
然后将千兆字节写入磁盘，

988
00:55:05,550 --> 00:55:08,910
这会极大地降低性能，

989
00:55:09,390 --> 00:55:13,980
这就是为什么通常不会将用户数据写入日志。

990
00:55:15,500 --> 00:55:18,770
是的，这是回到前面这个问题的非常重要的部分，

991
00:55:18,770 --> 00:55:23,000
内部文件系统结构保持一致是非常重要的，

992
00:55:23,000 --> 00:55:26,900
不是不一致的，

993
00:55:27,140 --> 00:55:31,670
所以，元数据更新都会通过日志，

994
00:55:32,060 --> 00:55:33,980
所以，当你创建文件时，

995
00:55:33,980 --> 00:55:35,180
你需要更新 inode 块，

996
00:55:35,180 --> 00:55:36,680
并且你需要更新目录块，

997
00:55:36,710 --> 00:55:38,750
保证会一起发生。

998
00:55:42,490 --> 00:55:47,170
所以，数据块是否会介于步骤 2 和步骤 3 之间？

999
00:55:48,300 --> 00:55:52,020
是的，我想他们只是发送出去，

1000
00:55:52,020 --> 00:55:54,600
可能在 1 之后，

1001
00:55:54,600 --> 00:55:56,940
它们可能并行发送数据块，

1002
00:55:56,940 --> 00:56:00,120
作为第 2 步的一部分，

1003
00:56:00,120 --> 00:56:01,590
并直接发送到 Petal ，

1004
00:56:02,500 --> 00:56:03,610
到文件系统[区域]。

1005
00:56:13,770 --> 00:56:14,340
好的?

1006
00:56:15,620 --> 00:56:17,990
所以我有个问题，

1007
00:56:18,020 --> 00:56:22,490
我不记得日志有多大了，

1008
00:56:22,490 --> 00:56:25,790
但我相信它可以跨越两个块。

1009
00:56:26,810 --> 00:56:32,090
日志可以是多条记录，是的。

1010
00:56:32,480 --> 00:56:35,390
是的，没错，最高可达 TB ，

1011
00:56:35,390 --> 00:56:38,960
那么，如果我们发送，

1012
00:56:39,940 --> 00:56:42,760
比如发送部分日志，

1013
00:56:42,760 --> 00:56:43,750
然后它崩溃，

1014
00:56:43,750 --> 00:56:45,130
当你发送日志时，

1015
00:56:45,130 --> 00:56:47,710
我们得到问题。

1016
00:56:48,460 --> 00:56:52,390
这正是我想说的，谢谢。

1017
00:56:52,660 --> 00:56:55,840
所以可能会发生多种崩溃，

1018
00:56:55,840 --> 00:56:59,150
如果我们崩溃了，

1019
00:56:59,150 --> 00:57:00,470
考虑多种情况，

1020
00:57:00,470 --> 00:57:02,900
比如崩溃发生在写入日志之前。

1021
00:57:11,530 --> 00:57:14,110
那么，在这种情况下，结果会是什么？

1022
00:57:18,910 --> 00:57:21,220
嗯，丢失了。

1023
00:57:21,250 --> 00:57:22,150
是的，丢失了。

1024
00:57:25,060 --> 00:57:28,330
然后我们来看这个场景，

1025
00:57:28,330 --> 00:57:30,760
比如崩溃发生在写入日志之后，

1026
00:57:39,550 --> 00:57:40,390
然后会发生什么？

1027
00:57:42,180 --> 00:57:43,950
这是一个稍微复杂的场景。

1028
00:57:44,620 --> 00:57:48,280
这是在写入日志到 Petal 之后吗？

1029
00:57:50,500 --> 00:57:52,450
然后 demon 会出来。

1030
00:57:52,540 --> 00:57:53,650
是的，然后是 demon 步骤，

1031
00:57:53,650 --> 00:57:55,720
这是一个有点复杂的故事，

1032
00:57:55,720 --> 00:57:59,350
因为这些是如何恢复的，

1033
00:57:59,350 --> 00:58:00,370
发生了什么。

1034
00:58:01,480 --> 00:58:05,590
所以，假设其他人希望获得这个文件上的锁，

1035
00:58:05,620 --> 00:58:08,560
崩溃的工作站所持有的，

1036
00:58:10,050 --> 00:58:12,270
在这里租期很重要，

1037
00:58:12,270 --> 00:58:14,940
所以每把锁都有租期，

1038
00:58:15,400 --> 00:58:17,200
锁服务器将执行的操作，

1039
00:58:17,350 --> 00:58:19,120
它不会授权，

1040
00:58:19,150 --> 00:58:22,030
锁服务器访问工作站 1 ，

1041
00:58:22,030 --> 00:58:24,670
请把锁 f 还给我，

1042
00:58:25,000 --> 00:58:27,760
工作站 1 没有反应，因为它崩溃了，

1043
00:58:28,090 --> 00:58:31,660
锁服务器所做的，

1044
00:58:31,690 --> 00:58:33,850
它会等到锁的租期过期。

1045
00:58:36,800 --> 00:58:39,830
为什么要等到锁租约到期？

1046
00:58:44,180 --> 00:58:45,950
我想在这种情况下，

1047
00:58:45,950 --> 00:58:52,040
服务器，

1048
00:58:52,570 --> 00:58:55,180
是的，崩溃的服务器也知道，

1049
00:58:55,740 --> 00:58:58,110
它不能续签租约，

1050
00:58:58,110 --> 00:59:00,090
这样它就可以自己清理。

1051
00:59:00,570 --> 00:59:02,880
是的，清理自己的东西，

1052
00:59:02,880 --> 00:59:03,870
这里的根本问题是什么，

1053
00:59:03,870 --> 00:59:04,980
我们试着挑战的，

1054
00:59:04,980 --> 00:59:06,450
就像之前的场景，

1055
00:59:06,450 --> 00:59:08,790
我们在之前的课程中反复看到的，

1056
00:59:08,790 --> 00:59:10,290
这里挑战总是存在的。

1057
00:59:11,070 --> 00:59:12,240
分区。

1058
00:59:12,390 --> 00:59:13,590
分区，没错，

1059
00:59:15,060 --> 00:59:16,320
可能是这种情况，

1060
00:59:16,740 --> 00:59:19,920
实际上工作站 1 并没有崩溃，

1061
00:59:20,280 --> 00:59:23,970
但锁服务器无法与工作站通信，

1062
00:59:23,970 --> 00:59:25,050
由于网络分区，

1063
00:59:25,260 --> 00:59:27,240
但是工作站可以与 Petal 通信，

1064
00:59:28,100 --> 00:59:31,280
所以它可能仍然在做出改变，

1065
00:59:31,460 --> 00:59:33,950
但正如你刚才所说，无论我们保证什么，

1066
00:59:33,950 --> 00:59:35,060
一旦租约到期，

1067
00:59:35,060 --> 00:59:37,670
工作站 1 肯定不会做任何更改。

1068
00:59:38,830 --> 00:59:40,000
好的，这是不允许的，

1069
00:59:40,240 --> 00:59:41,200
根据协议，

1070
00:59:41,200 --> 00:59:42,790
不允许再做任何更改。

1071
00:59:44,340 --> 00:59:48,420
所以，这就是为什么锁服务器要等到租约到期，

1072
00:59:48,420 --> 00:59:51,870
然后在这一点上，知道没有人再持有锁，

1073
00:59:52,200 --> 00:59:54,960
或者不持有锁，如果没有人写入 Petal ，

1074
00:59:55,140 --> 00:59:59,400
所以，在这一点上，它将要求剩余的工作站，

1075
00:59:59,610 --> 01:00:09,830
他们所说的恢复 demon ，

1076
01:00:10,720 --> 01:00:13,450
恢复 demon 将应用，

1077
01:00:13,480 --> 01:00:17,920
将读取工作站 1 的日志，

1078
01:00:17,950 --> 01:00:20,470
并应用那个日志中的操作。

1079
01:00:22,200 --> 01:00:22,800
好的?

1080
01:00:25,110 --> 01:00:28,080
考虑 demon 的方式，

1081
01:00:28,230 --> 01:00:31,290
这是术语，

1082
01:00:31,290 --> 01:00:35,820
它通常只是一项服务或服务器或服务器进程，

1083
01:00:35,910 --> 01:00:40,290
做的是打扫房子或打扫房子的任务，

1084
01:00:40,290 --> 01:00:44,400
不是真正持续使用的服务，

1085
01:00:44,610 --> 01:00:46,050
它们通常被称为 demon ，

1086
01:00:48,950 --> 01:00:50,240
所以一旦 demon 完成了，

1087
01:00:50,270 --> 01:00:52,400
然后锁可以，

1088
01:00:52,580 --> 01:00:54,650
锁服务器可以重新分配锁，

1089
01:00:54,650 --> 01:00:56,780
或将锁授权给另一个工作站。

1090
01:00:58,820 --> 01:00:59,750
为了再确认一下，

1091
01:00:59,750 --> 01:01:02,990
如果你在写入日志后崩溃，

1092
01:01:02,990 --> 01:01:04,940
你会得到一个一致的状态，

1093
01:01:04,940 --> 01:01:06,230
当涉及元数据时，

1094
01:01:06,230 --> 01:01:09,230
但不能保证用户已经完成了用户数据的写入。

1095
01:01:09,860 --> 01:01:12,200
是的，不能保证用户数据。

1096
01:01:13,060 --> 01:01:15,370
所以唯一保证的是，

1097
01:01:15,370 --> 01:01:19,000
真正的日志系统帮助实现的是，

1098
01:01:19,000 --> 01:01:22,300
内部文件系统数据结构一致。

1099
01:01:23,830 --> 01:01:24,910
好的，听起来不错。

1100
01:01:27,120 --> 01:01:28,140
这是重要的，

1101
01:01:28,140 --> 01:01:29,430
因为这将是相当糟糕的，

1102
01:01:29,460 --> 01:01:31,650
如果内部文件系统数据结构混乱，

1103
01:01:32,110 --> 01:01:33,730
每个人都可能会丢失他们的数据。

1104
01:01:37,420 --> 01:01:40,360
好的，还有另一个[]案例，

1105
01:01:40,900 --> 01:01:43,090
会发生什么，

1106
01:01:43,090 --> 01:01:44,860
好的，把日志写到 P ，

1107
01:01:44,890 --> 01:01:52,070
如果我们在写入日志的过程中崩溃，会发生什么？

1108
01:02:05,250 --> 01:02:08,760
这是不是你之前提到的它们的校验和，

1109
01:02:08,760 --> 01:02:11,190
我们可以检查它是不是完整的。

1110
01:02:11,250 --> 01:02:14,100
是的，说得好，

1111
01:02:14,130 --> 01:02:16,620
所以在这种情况下会发生什么，

1112
01:02:16,620 --> 01:02:19,170
前缀可能会，

1113
01:02:20,850 --> 01:02:22,710
前缀可能会在日志中，

1114
01:02:24,500 --> 01:02:30,500
但是每个前缀可能包含多个日志记录，

1115
01:02:30,500 --> 01:02:31,970
包含多个操作，

1116
01:02:31,970 --> 01:02:35,900
无论是序号 1 ，序号 2 ，多个记录，

1117
01:02:36,440 --> 01:02:40,070
如果我们在其中一个记录更新期间崩溃，

1118
01:02:40,070 --> 01:02:42,500
然后校验和就不会通过，

1119
01:02:42,500 --> 01:02:46,790
所以恢复 demon 会停止在那个记录。

1120
01:02:47,190 --> 01:02:48,900
那么日志中会有什么，

1121
01:02:48,900 --> 01:02:52,890
将是操作的正确前缀，

1122
01:02:53,070 --> 01:02:57,180
例如，创建文件 f 在这里，

1123
01:02:57,210 --> 01:02:59,310
也许创建文件 g 在那里，

1124
01:02:59,340 --> 01:03:01,830
但是创建文件 h 不在那里，

1125
01:03:02,190 --> 01:03:06,840
但是每个单独记录描述一个原子文件系统操作，

1126
01:03:07,050 --> 01:03:08,970
就在那里，而且是完整的。

1127
01:03:09,910 --> 01:03:11,470
所以接下来会发生的是，

1128
01:03:11,470 --> 01:03:17,140
我们应用在工作站上执行的操作前缀，

1129
01:03:17,260 --> 01:03:19,510
我们丢掉前缀的结尾，

1130
01:03:19,870 --> 01:03:21,340
或更新的结尾，

1131
01:03:21,340 --> 01:03:24,010
不是我们期望的，但完全没问题，

1132
01:03:24,010 --> 01:03:26,390
因为，在另一个案例中，

1133
01:03:26,390 --> 01:03:28,250
我们可能失去所有的更新，

1134
01:03:31,210 --> 01:03:32,350
但在第一种情况下，

1135
01:03:32,920 --> 01:03:34,450
我们在日志之前崩溃，

1136
01:03:34,450 --> 01:03:35,620
我们将一无所有。

1137
01:03:40,660 --> 01:03:41,410
这能理解吗？

1138
01:03:46,760 --> 01:03:50,660
好的，一个棘手的情况，

1139
01:03:50,690 --> 01:03:52,880
我们需要考虑，

1140
01:03:53,210 --> 01:03:54,650
这与一个事实有关，

1141
01:03:54,650 --> 01:03:58,700
Petal 在每个服务器上都有一个锁，或者在每个服务器上有一个日志。

1142
01:03:59,570 --> 01:04:01,250
所以我稍微讨论一下，

1143
01:04:01,340 --> 01:04:06,140
这些与你在阅读中看到的问题有关。

1144
01:04:06,760 --> 01:04:08,200
这是关于许多日志，

1145
01:04:08,560 --> 01:04:11,380
假设我们有工作站，

1146
01:04:12,160 --> 01:04:13,330
每个都有自己的日志，

1147
01:04:13,920 --> 01:04:17,850
这是工作站 1 ，工作站 2 ，工作站 3 。

1148
01:04:19,480 --> 01:04:23,920
工作站 1 在某一时刻删除文件 f ，

1149
01:04:23,920 --> 01:04:25,810
它是之前存在的，

1150
01:04:27,480 --> 01:04:35,250
然后工作站 2 创建 d/f ，

1151
01:04:35,460 --> 01:04:38,130
但是这个 create 写入自己的日志，

1152
01:04:38,190 --> 01:04:42,840
所以这个 delete 写入工作站 1 的日志，

1153
01:04:43,020 --> 01:04:45,840
这个 create 写入工作站 2 的日志。

1154
01:04:46,990 --> 01:04:53,700
现在，假设工作站 1 崩溃了，

1155
01:04:53,730 --> 01:04:59,100
然后工作站 3 恢复 demon 运行，

1156
01:05:07,600 --> 01:05:09,430
对于工作站 1 ，

1157
01:05:14,700 --> 01:05:17,190
可能出现坏的结果，

1158
01:05:17,190 --> 01:05:19,350
这将重放 delete ，

1159
01:05:19,960 --> 01:05:22,210
这将覆盖更改，

1160
01:05:22,210 --> 01:05:26,360
工作站 2 对 Petal 所做的。

1161
01:05:26,360 --> 01:05:27,470
所以这就是背景，

1162
01:05:28,130 --> 01:05:29,960
问题是这是如何解决的，

1163
01:05:29,990 --> 01:05:32,630
我认为我想解决的问题的方法是，

1164
01:05:32,630 --> 01:05:35,690
让你们在分解会议室待上几分钟，

1165
01:05:35,960 --> 01:05:39,380
互相讨论这个或任何 Petal 的方面，

1166
01:05:39,380 --> 01:05:40,430
如果你想的话。

1167
01:05:42,020 --> 01:05:47,680
所以， Lily 或任何其他助教，

1168
01:05:47,680 --> 01:05:50,020
所以把大家送到分解会议室。

1169
01:06:02,130 --> 01:06:03,210
我来做吧，还是。

1170
01:06:03,240 --> 01:06:03,750
好的，很好。

1171
01:06:04,350 --> 01:06:06,900
好的，酷。

1172
01:06:12,110 --> 01:06:13,880
我会关闭大约五分钟。

1173
01:06:13,880 --> 01:06:14,510
是的，五分钟。

1174
01:06:16,370 --> 01:06:16,760
好的。

1175
01:12:22,020 --> 01:12:22,860
大家都回来了吗？

1176
01:12:32,010 --> 01:12:36,660
好的，所以，简单地总结一下，

1177
01:12:36,660 --> 01:12:38,220
我们有 3 台工作站，

1178
01:12:38,520 --> 01:12:43,020
工作站 1 在某个时刻删除了日志中的文件，

1179
01:12:43,200 --> 01:12:48,150
工作站 2 在稍后创建文件 f ，

1180
01:12:48,180 --> 01:12:49,230
在他的日志里，

1181
01:12:49,620 --> 01:12:51,270
然后 1 崩溃，

1182
01:12:51,270 --> 01:12:55,380
工作站 3 运行 demon 对工作站 1 的日志，

1183
01:12:55,840 --> 01:12:57,370
当然，这将是一场灾难，

1184
01:12:57,370 --> 01:12:59,230
如果 delete 被重放，

1185
01:12:59,410 --> 01:13:01,930
因为后来的创建是在另一个工作站上进行的，

1186
01:13:01,930 --> 01:13:02,950
它在另一个日志中，

1187
01:13:02,980 --> 01:13:04,510
所以 demon 不知道这个，

1188
01:13:04,720 --> 01:13:06,430
这个问题怎么解决，

1189
01:13:07,670 --> 01:13:10,490
或者这场潜在的灾难怎么避免？

1190
01:13:14,590 --> 01:13:16,810
我们讨论的是版本号。

1191
01:13:17,050 --> 01:13:17,620
是的。

1192
01:13:19,300 --> 01:13:21,190
是的，如果你想的话，可以多说一点。

1193
01:13:21,820 --> 01:13:25,630
当然，这保证了，

1194
01:13:25,630 --> 01:13:26,950
因为我们有锁，

1195
01:13:26,950 --> 01:13:33,760
服务器 1 的操作已完成，

1196
01:13:34,930 --> 01:13:42,130
日志的版本号写在 Petal 中，

1197
01:13:42,430 --> 01:13:43,750
比如最后的操作，

1198
01:13:43,750 --> 01:13:50,420
所以，恢复 demon 不会对当前版本号之前的执行任何操作。

1199
01:13:50,780 --> 01:13:53,120
是的，这是绝对正确的，

1200
01:13:53,120 --> 01:13:54,560
所以总结一下，

1201
01:13:54,560 --> 01:13:56,880
所以我们有两个日志，

1202
01:13:56,880 --> 01:13:58,710
这很重要，

1203
01:13:58,710 --> 01:14:00,540
我们有一些文件系统状态，

1204
01:14:01,250 --> 01:14:02,720
它们在 Petal 中，

1205
01:14:02,720 --> 01:14:03,620
所以这些是日志，

1206
01:14:03,620 --> 01:14:05,270
然后这是实际的文件系统，

1207
01:14:07,740 --> 01:14:11,190
然后这是目录 d ，

1208
01:14:11,190 --> 01:14:15,150
目录 d 被修改，文件 f 被删除，

1209
01:14:15,150 --> 01:14:18,330
有一个日志编号 i ，比如 10 ，

1210
01:14:19,920 --> 01:14:22,680
这是工作站 2 ，

1211
01:14:22,680 --> 01:14:24,210
这是 d ，

1212
01:14:24,730 --> 01:14:28,420
这些删除 d 中的 f 或创建 d 中的 f ，

1213
01:14:28,420 --> 01:14:35,530
在这个条目中日志编号是什么，抱歉，版本号，

1214
01:14:37,840 --> 01:14:39,820
11 ？

1215
01:14:41,080 --> 01:14:42,580
11 是的，基本上是完全有序的，

1216
01:14:42,580 --> 01:14:45,070
锁协议确保了他们完全有序。

1217
01:14:45,620 --> 01:14:49,070
在包含元数据块的文件系统中，

1218
01:14:49,100 --> 01:14:51,200
例如，如果 f 的 inode 块，

1219
01:14:52,290 --> 01:14:56,730
inode f 的版本号将在磁盘中或 Petal ？

1220
01:15:04,490 --> 01:15:05,090
11 ？

1221
01:15:06,000 --> 01:15:06,870
是的，在这种情况下，

1222
01:15:06,870 --> 01:15:10,530
应用到文件系统的操作是 11 。

1223
01:15:11,540 --> 01:15:15,160
所以 demon 什么时候，

1224
01:15:15,190 --> 01:15:17,860
demon 遵守的规则是什么？

1225
01:15:20,520 --> 01:15:24,640
永远不要替换已经应用的东西。

1226
01:15:25,180 --> 01:15:26,860
是的，什么决定它是不是应用了？

1227
01:15:28,520 --> 01:15:29,930
版本号。

1228
01:15:30,320 --> 01:15:31,100
是的，版本号，

1229
01:15:31,100 --> 01:15:32,030
所以如果版本号，

1230
01:15:32,030 --> 01:15:33,800
只重放条目，

1231
01:15:33,800 --> 01:15:35,900
如果日志记录中的版本号，

1232
01:15:37,160 --> 01:15:43,340
日志版本号高于 inode 或元数据版本号，

1233
01:15:45,980 --> 01:15:48,930
然后进行重放，好的？

1234
01:15:49,970 --> 01:15:50,840
所以在这种情况下，

1235
01:15:50,840 --> 01:15:55,610
恢复 demon 在日志记录中看到版本号为 10 ，

1236
01:15:55,610 --> 01:15:59,030
小于 11 或等于 11 ，都无关紧要，

1237
01:15:59,120 --> 01:16:00,290
所以它不会重放，

1238
01:16:00,290 --> 01:16:01,520
所以，这个问题不会出现。

1239
01:16:02,380 --> 01:16:04,420
所以 10 是不是必须的，

1240
01:16:04,450 --> 01:16:10,510
是否 10 不在工作站 2 的日志中也是可以的？

1241
01:16:11,850 --> 01:16:13,830
是的，它不在那里。

1242
01:16:14,520 --> 01:16:15,660
所以，就像在，

1243
01:16:15,660 --> 01:16:22,200
因为工作站 2 在工作站 1 之后写入 inode ，

1244
01:16:22,200 --> 01:16:24,600
所以它的版本号为 11 ，

1245
01:16:24,780 --> 01:16:26,730
你要做的就是准备和更新，

1246
01:16:27,060 --> 01:16:29,190
更新记录中的版本号

1247
01:16:29,190 --> 01:16:33,940
始终是一加上 inode 中的当前版本号。

1248
01:16:37,960 --> 01:16:38,350
好的?

1249
01:16:38,380 --> 01:16:39,310
这是一个小问题，

1250
01:16:39,310 --> 01:16:40,900
d 代表什么？

1251
01:16:40,900 --> 01:16:43,540
它是目录，

1252
01:16:45,220 --> 01:16:46,930
在目录 d 中创建一个文件，

1253
01:16:46,930 --> 01:16:48,730
从目录 d 中删除一个文件，

1254
01:16:49,860 --> 01:16:53,430
更新必须包括一些有关目录的信息。

1255
01:16:57,440 --> 01:16:57,980
好的。

1256
01:16:58,220 --> 01:17:00,230
抱歉，我有个小问题，

1257
01:17:00,260 --> 01:17:05,360
所以版本号总是绑定到正在编辑的 inode 上吗？

1258
01:17:05,840 --> 01:17:06,500
是的。

1259
01:17:07,000 --> 01:17:07,510
好的。

1260
01:17:08,520 --> 01:17:11,370
当然，每次更新的版本号，

1261
01:17:11,370 --> 01:17:12,990
比如，目录有一个版本号，

1262
01:17:12,990 --> 01:17:14,190
文件有一个版本号，

1263
01:17:14,190 --> 01:17:15,930
这里显示的有点问题，

1264
01:17:16,290 --> 01:17:18,060
如果你回到日志记录中，

1265
01:17:18,830 --> 01:17:22,100
在这里，有一个更新的列表，

1266
01:17:22,100 --> 01:17:23,960
列表中的每个更新，

1267
01:17:23,960 --> 01:17:26,330
在新字节中完成版本号。

1268
01:17:28,590 --> 01:17:29,160
谢谢。

1269
01:17:32,440 --> 01:17:36,400
好的，退一步，结束这篇论文的讨论。

1270
01:17:38,320 --> 01:17:40,600
这可能是我们读到的第一篇论文，

1271
01:17:40,600 --> 01:17:43,030
系统本身并不是，

1272
01:17:43,030 --> 01:17:44,620
它不是主要的用途，

1273
01:17:44,620 --> 01:17:46,420
因此谈论这件事[]很有趣，

1274
01:17:46,630 --> 01:17:51,100
但这个系统的有趣之处在于它里面的想法，

1275
01:17:51,400 --> 01:17:59,440
所以缓存连贯性协议或缓存一致性协议，

1276
01:18:03,320 --> 01:18:09,440
分布式锁，锁服务器，租期，

1277
01:18:11,000 --> 01:18:14,930
授予，请求，撤销，

1278
01:18:15,620 --> 01:18:17,900
以及分布式恢复，

1279
01:18:18,980 --> 01:18:20,690
当一个工作站崩溃时，

1280
01:18:20,690 --> 01:18:24,680
另一个工作站上的 demon 进行恢复，

1281
01:18:25,220 --> 01:18:27,320
特别有趣的是，

1282
01:18:27,470 --> 01:18:30,110
有趣的是这三个部分之间的交互，

1283
01:18:32,140 --> 01:18:33,370
它们交互。

1284
01:18:35,180 --> 01:18:38,180
我们将在接下来的几篇论文中看到，

1285
01:18:38,300 --> 01:18:40,730
下周，不是，在周四，

1286
01:18:40,730 --> 01:18:42,800
但在那之后的论文，

1287
01:18:42,980 --> 01:18:44,120
我们将谈论

1288
01:18:44,120 --> 01:18:47,180
一些繁重的、相当复杂的事务系统，

1289
01:18:47,360 --> 01:18:51,200
我们也会看到这三个主题，

1290
01:18:51,410 --> 01:18:54,080
所以，希望这能帮助你阅读这些论文，

1291
01:18:54,080 --> 01:18:55,910
了解什么是缓存一致性，

1292
01:18:56,270 --> 01:18:58,070
什么是崩溃恢复，

1293
01:18:58,070 --> 01:19:00,920
以及分布式锁。

1294
01:19:02,160 --> 01:19:06,450
另一点可能很有趣的是，

1295
01:19:06,450 --> 01:19:08,580
Petal 很好，

1296
01:19:08,580 --> 01:19:12,480
对他们设计它的特定背景很有用，

1297
01:19:16,110 --> 01:19:18,630
论文的性能部分，

1298
01:19:18,630 --> 01:19:19,530
但很难理解，

1299
01:19:19,530 --> 01:19:21,720
因为这是从 1999 年开始的，

1300
01:19:21,720 --> 01:19:23,280
但我看了一下图表，

1301
01:19:23,490 --> 01:19:26,700
你将看到文件系统

1302
01:19:26,700 --> 01:19:29,340
工作负载可以随着工作站数量的增加而增加，

1303
01:19:29,490 --> 01:19:31,740
这正是我们努力的目标，

1304
01:19:32,010 --> 01:19:34,950
他们实现了这一目标，

1305
01:19:35,550 --> 01:19:38,010
无论如何，我希望你对这个设计感兴趣，

1306
01:19:38,010 --> 01:19:39,510
不像你通常的设计，

1307
01:19:39,510 --> 01:19:41,310
所以我希望会发人深省。

1308
01:19:42,340 --> 01:19:44,350
说到这里，我会停下来，

1309
01:19:44,650 --> 01:19:47,500
当然，如果你想问更多的问题，就留下来，

1310
01:19:47,830 --> 01:19:49,420
否则我们周四再见。

1311
01:19:53,400 --> 01:19:55,740
我能问你两个问题吗，

1312
01:19:55,740 --> 01:19:58,350
所以，我的第一个问题是，

1313
01:19:58,350 --> 01:20:01,920
一般而言，这里的缓存一致性协议，

1314
01:20:02,330 --> 01:20:07,820
它不是在两个地方有一个文件缓存，对吧？

1315
01:20:07,940 --> 01:20:08,420
是的。

1316
01:20:08,840 --> 01:20:12,050
好的，我的另一个问题是关于，

1317
01:20:12,290 --> 01:20:17,270
有一页有日志，

1318
01:20:17,420 --> 01:20:21,620
在那里你有日志记录。

1319
01:20:21,800 --> 01:20:24,080
是的，让我回到这里。

1320
01:20:24,080 --> 01:20:27,720
是的，我很好奇，

1321
01:20:27,720 --> 01:20:34,040
你说每一个记录都是原子的，

1322
01:20:35,170 --> 01:20:38,920
但每条记录也有一些更新，对吧？

1323
01:20:38,950 --> 01:20:42,760
是的，再一次，我认为论文有点含糊，

1324
01:20:42,760 --> 01:20:43,810
它到底是做什么的，

1325
01:20:43,840 --> 01:20:45,880
它要么始终适合 512 个字节，

1326
01:20:46,390 --> 01:20:50,920
然后单个扇区 512 字节是原子的，

1327
01:20:50,980 --> 01:20:54,160
或者他们使用这种校验和技巧，

1328
01:20:54,570 --> 01:20:59,220
所以，你读到[]扇区，

1329
01:20:59,610 --> 01:21:02,820
重新计算校验并将其与存储的校验和进行比较，

1330
01:21:02,820 --> 01:21:05,460
如果没错，那它一定是一个完整的记录。

1331
01:21:07,390 --> 01:21:09,430
好的，如果它少于，

1332
01:21:09,430 --> 01:21:11,230
如果不是，那你就玩这个技巧，

1333
01:21:11,230 --> 01:21:11,980
好的，我明白了。

1334
01:21:12,400 --> 01:21:14,560
是的，我不确定他们到底是做什么的。

1335
01:21:15,280 --> 01:21:18,310
好的，非常感谢。

1336
01:21:18,310 --> 01:21:18,940
不用谢。

1337
01:21:22,090 --> 01:21:23,320
还有什么问题吗？

1338
01:21:29,260 --> 01:21:34,060
如果你向后或向前看三张幻灯片？

1339
01:21:34,060 --> 01:21:35,630
好的，这个？

1340
01:21:35,660 --> 01:21:36,320
它是。

1341
01:21:36,910 --> 01:21:38,590
哦，也许倒退一张幻灯片，

1342
01:21:38,620 --> 01:21:40,720
有一节你谈到了，

1343
01:21:41,330 --> 01:21:45,230
如果在写入过程中发生崩溃，

1344
01:21:45,230 --> 01:21:47,900
我们得到日志中的前缀，

1345
01:21:47,900 --> 01:21:49,280
就像好的或什么东西，

1346
01:21:49,280 --> 01:21:51,320
你能重复一遍你的意思吗？

1347
01:21:51,590 --> 01:21:55,670
是的，好的，让我们回到最后一张图片，

1348
01:21:55,670 --> 01:21:58,760
我刚才在这里展示了，

1349
01:21:58,760 --> 01:21:59,810
所以这里有我们的，

1350
01:21:59,810 --> 01:22:05,870
所以工作站 1 可以执行很多很多文件系统操作，

1351
01:22:06,380 --> 01:22:09,440
它们中的每一个由这些日志中的一个描述，

1352
01:22:09,440 --> 01:22:10,700
由日志中的一个条目，

1353
01:22:11,210 --> 01:22:14,150
所以，第一个条目可能是创建文件 f ，

1354
01:22:14,150 --> 01:22:16,580
日志中的第二个条目可以是创建文件 g ，

1355
01:22:16,580 --> 01:22:19,550
第三个可能是创建，删除文件 f 。

1356
01:22:20,140 --> 01:22:22,090
所以有一个完整的操作序列，

1357
01:22:22,090 --> 01:22:28,060
因为记住工作站只是继续执行文件系统操作，

1358
01:22:28,060 --> 01:22:29,320
在它持有锁的时候，

1359
01:22:29,320 --> 01:22:31,180
而且没有其他人想要这把锁，

1360
01:22:31,590 --> 01:22:37,020
所以，锁可以是包含很多文件系统操作，

1361
01:22:37,110 --> 01:22:38,820
现在，对于每个文件系统操作，

1362
01:22:38,820 --> 01:22:40,950
对于每个单独的操作，有一个日志记录，

1363
01:22:42,180 --> 01:22:46,800
而日志记录是原子文件系统操作，

1364
01:22:46,800 --> 01:22:48,000
描述更改，

1365
01:22:48,000 --> 01:22:50,220
需要执行到真正的文件系统块，

1366
01:22:50,400 --> 01:22:53,760
以反映那个文件系统操作。

1367
01:22:54,590 --> 01:22:55,970
那么会发生什么，

1368
01:22:55,970 --> 01:22:59,510
撤销消息进入，

1369
01:22:59,630 --> 01:23:04,310
工作站 1 开始写入它的日志到 Petal ，

1370
01:23:04,550 --> 01:23:06,650
但这并不能一直持续到最后，

1371
01:23:06,650 --> 01:23:07,820
它只是碰巧崩溃了，

1372
01:23:07,820 --> 01:23:10,310
在中间的某个地方，任何地方，

1373
01:23:10,700 --> 01:23:11,810
在这种情况下，

1374
01:23:11,810 --> 01:23:17,740
工作站日志的前缀在磁盘上或在 Petal 中，

1375
01:23:18,530 --> 01:23:19,970
这意味着，

1376
01:23:19,970 --> 01:23:22,940
最后的几个文件系统操作只是日志，

1377
01:23:27,370 --> 01:23:29,890
并且只有前缀将被重放。

1378
01:23:31,300 --> 01:23:33,100
我明白了，并且我们只是说好的。

1379
01:23:33,340 --> 01:23:34,720
是的，我们接受这个结果。

1380
01:23:35,690 --> 01:23:36,500
知道了，谢谢。

1381
01:23:36,590 --> 01:23:38,780
因为我们早些时候已经接受了这一结果，

1382
01:23:38,810 --> 01:23:40,040
因为在这种情况下是可以的，

1383
01:23:40,040 --> 01:23:41,750
我们得到文件系统崩溃

1384
01:23:42,470 --> 01:23:45,110
在收到撤销消息之前或之后，

1385
01:23:45,110 --> 01:23:48,410
但它没有向 Petal 写入任何日志条目。

1386
01:23:56,790 --> 01:23:57,720
还有什么问题吗？

1387
01:24:01,880 --> 01:24:07,430
我有一个与 6.824 完全无关的问题，

1388
01:24:07,430 --> 01:24:14,810
但我想知道你是否知道下学期的 6.858 ，

1389
01:24:14,810 --> 01:24:20,210
我看到 Zeldovich 教授要教 6.S060 。

1390
01:24:20,210 --> 01:24:21,590
是的，我想我们，

1391
01:24:21,620 --> 01:24:27,080
目前的计划不会在秋季提供 6.858 ，

1392
01:24:27,440 --> 01:24:31,100
但我们希望能在春季推出。

1393
01:24:31,790 --> 01:24:32,840
好的，太棒了，

1394
01:24:32,900 --> 01:24:36,260
你知道 6.S060 是什么吗，

1395
01:24:36,260 --> 01:24:39,620
我找不到太多信息。

1396
01:24:39,620 --> 01:24:43,010
是的，这是个好问题，

1397
01:24:43,220 --> 01:24:47,690
这是一门本科生课程。

1398
01:24:48,380 --> 01:24:49,040
好的。

1399
01:24:49,560 --> 01:24:50,430
好的，很好。

1400
01:24:51,320 --> 01:24:56,690
所以，像 6.858 ，但是本科生的。

1401
01:24:57,020 --> 01:25:03,050
是的，也许是 6.857 和 6.858 的入门。

1402
01:25:04,960 --> 01:25:07,560
好的，编号是什么？

1403
01:25:08,070 --> 01:25:09,540
这是一个试验性的编号，

1404
01:25:09,540 --> 01:25:10,620
这是一个试验性的，

1405
01:25:10,620 --> 01:25:12,390
因为这个课还不存在，

1406
01:25:12,810 --> 01:25:13,980
并将提供，

1407
01:25:13,980 --> 01:25:16,200
目标是在秋季首次提供它。

1408
01:25:17,530 --> 01:25:22,610
好的，那么，是不是主要是因为，

1409
01:25:22,610 --> 01:25:26,840
6.858 是不是会保持它原来的样子，或者。

1410
01:25:26,930 --> 01:25:30,320
你在问我问题，我没有。

1411
01:25:30,320 --> 01:25:30,680
抱歉。

1412
01:25:30,680 --> 01:25:38,090
是的，我认为参与设计这门课的人，

1413
01:25:38,090 --> 01:25:40,010
或者参与 6.857 的人，

1414
01:25:40,010 --> 01:25:41,180
以及参与 6.858 的人。

1415
01:25:41,180 --> 01:25:41,600
是的。

1416
01:25:41,600 --> 01:25:42,980
我并没有参与其中。

1417
01:25:43,280 --> 01:25:43,820
好的。

1418
01:25:43,850 --> 01:25:44,630
还有一个原因，

1419
01:25:44,630 --> 01:25:49,040
他们正在努力制定课程，

1420
01:25:49,040 --> 01:25:52,460
当然，会对 6.858 6.857 进行一些[]。

1421
01:25:53,580 --> 01:25:55,080
好的，听起来不错。

1422
01:25:55,630 --> 01:25:59,410
但是 6.858 6.857 不会离开，这就是。

1423
01:26:01,960 --> 01:26:02,590
好的，谢谢。

1424
01:26:02,830 --> 01:26:03,400
不用谢。

1425
01:26:04,090 --> 01:26:05,770
我有个问题，

1426
01:26:05,770 --> 01:26:06,730
我不知道它是否简单，

1427
01:26:06,730 --> 01:26:11,470
但在论文中的页末，

1428
01:26:12,190 --> 01:26:14,320
在第七节之前，

1429
01:26:14,470 --> 01:26:17,500
他们谈到了一个失败案例，

1430
01:26:17,500 --> 01:26:20,770
就是租约到期了，

1431
01:26:20,770 --> 01:26:22,630
而且服务器并没有真的崩溃。

1432
01:26:22,840 --> 01:26:23,290
是的。

1433
01:26:23,410 --> 01:26:26,440
然后谈论，

1434
01:26:26,970 --> 01:26:29,070
基本上没有真正的解决方案。

1435
01:26:29,550 --> 01:26:31,260
嗯，有一个解决方案，

1436
01:26:31,260 --> 01:26:33,030
有一个真正的解决方案。

1437
01:26:33,030 --> 01:26:36,120
比如，人类的干预。

1438
01:26:36,730 --> 01:26:38,530
是的，好的，所以我认为这里的问题，

1439
01:26:38,530 --> 01:26:40,390
在论文主题中，

1440
01:26:40,390 --> 01:26:43,210
Petal 和 Frangipani 是独立设计的，

1441
01:26:43,600 --> 01:26:46,330
它有很多很好的特性，

1442
01:26:46,330 --> 01:26:48,040
这将有一个地方，

1443
01:26:48,040 --> 01:26:49,480
这将是非常有帮助的，

1444
01:26:49,480 --> 01:26:53,320
Petal 有一些支持来帮助 Frangipani ，

1445
01:26:53,760 --> 01:26:58,110
这个支持会在写入 Petal 上有一个时间戳，

1446
01:26:58,110 --> 01:27:01,710
Petal 可以看出写入是否太旧。

1447
01:27:04,010 --> 01:27:04,640
好的。

1448
01:27:05,120 --> 01:27:06,290
所以除非你这么做，

1449
01:27:06,290 --> 01:27:08,720
你需要[摆弄]边际。

1450
01:27:10,790 --> 01:27:11,420
好的。

1451
01:27:11,920 --> 01:27:13,810
如果会发生什么，

1452
01:27:14,610 --> 01:27:17,550
那个错误发生，

1453
01:27:17,550 --> 01:27:20,350
比如在边界之外。

1454
01:27:20,740 --> 01:27:22,030
它会很酷，

1455
01:27:22,600 --> 01:27:25,720
你得到的是较旧的写入，

1456
01:27:25,720 --> 01:27:26,920
出现在，

1457
01:27:27,340 --> 01:27:31,420
其他人可能在那个时刻获得那个文件上的锁，

1458
01:27:31,420 --> 01:27:32,410
开始写入它，

1459
01:27:32,470 --> 01:27:34,000
然后又出现了旧的写入，

1460
01:27:34,000 --> 01:27:35,980
基本上改写其中的某一部分。

1461
01:27:37,210 --> 01:27:37,840
好的。

1462
01:27:38,870 --> 01:27:40,160
所以，这将打破一致性。

1463
01:27:42,460 --> 01:27:43,090
了解了，谢谢。

1464
01:27:43,090 --> 01:27:43,390
不用谢。

1465
01:27:49,280 --> 01:27:52,820
好的，因为我们会停止了。

