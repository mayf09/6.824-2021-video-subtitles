1
00:00:06,030 --> 00:00:07,350
好的，下午好，

2
00:00:08,470 --> 00:00:11,080
声音检查，

3
00:00:12,790 --> 00:00:13,690
大家能听到我说话吗？

4
00:00:16,760 --> 00:00:18,170
是的。

5
00:00:18,230 --> 00:00:18,920
谢谢,

6
00:00:19,460 --> 00:00:20,150
好的，

7
00:00:20,150 --> 00:00:23,240
下午好，晚上好，早上好，晚上好，无论你在哪里，

8
00:00:23,570 --> 00:00:25,970
今天我要更多地谈谈 raft ，

9
00:00:27,110 --> 00:00:30,560
我们想要涵盖以下不同的主题，

10
00:00:30,860 --> 00:00:34,100
将与实验相关。

11
00:00:34,790 --> 00:00:38,180
所以，首先，我想更多地谈谈日志分叉，

12
00:00:39,120 --> 00:00:42,300
在上一节课结束时，我们遇到了一个[扣人心弦]的问题，

13
00:00:42,330 --> 00:00:44,160
我们进行了一次关于图 6 的讨论，

14
00:00:44,160 --> 00:00:46,080
我想恢复那次讨论。

15
00:00:46,710 --> 00:00:50,250
我想谈谈日志追赶和发生了什么，

16
00:00:50,280 --> 00:00:54,350
跟随者如何追赶，

17
00:00:54,980 --> 00:01:00,170
然后是一些持久化，比如什么状态必须，

18
00:01:01,240 --> 00:01:03,700
什么 raft 状态必须在存储中持久化，

19
00:01:03,700 --> 00:01:07,720
与 2c 和 2d 相关，

20
00:01:07,720 --> 00:01:11,800
并讨论状态到快照。

21
00:01:13,580 --> 00:01:16,860
是的，如果有任何问题，请随时提出来。

22
00:01:17,940 --> 00:01:19,770
最后，我想谈谈线性一致性，

23
00:01:19,770 --> 00:01:24,870
以及论文中经常提到的标准，

24
00:01:24,870 --> 00:01:26,700
在很多地方也会用到，

25
00:01:27,300 --> 00:01:29,520
这将让我们再谈一谈

26
00:01:29,520 --> 00:01:31,650
关于这些服务器如何使用 raft 。

27
00:01:32,490 --> 00:01:35,910
所以，这些就是我们计划谈论的话题，

28
00:01:36,000 --> 00:01:38,970
你现在有任何问题，请随时提问，

29
00:01:39,520 --> 00:01:41,770
当然，在任何时候都可以加入进来。

30
00:01:47,470 --> 00:01:51,010
好的，我们上周看过了，

31
00:01:51,010 --> 00:01:52,330
我们开始谈论 raft ，

32
00:01:52,330 --> 00:01:54,550
我们看到领导者完成工作

33
00:01:54,550 --> 00:01:59,080
将日志复制到跟随者上，

34
00:01:59,440 --> 00:02:03,700
但是由于领导者选举的崩溃，

35
00:02:03,880 --> 00:02:05,440
系统的状态，

36
00:02:05,440 --> 00:02:08,950
日志可能有很大的差异，

37
00:02:11,280 --> 00:02:14,130
图 6 是一个示例，

38
00:02:14,760 --> 00:02:18,090
为什么，怎么会发生这种事，

39
00:02:18,090 --> 00:02:20,370
领导者可能会停机，

40
00:02:20,370 --> 00:02:21,810
它们可能追加更多的条目，

41
00:02:21,810 --> 00:02:24,090
所以有很多不同的场景，

42
00:02:24,420 --> 00:02:27,720
我们的系统最终处于的，

43
00:02:27,720 --> 00:02:32,160
图 6 、图 7 显示了其中的一些，

44
00:02:32,280 --> 00:02:38,020
而这个图表出现的主要原因是，

45
00:02:38,020 --> 00:02:42,010
它强化了领导者选举规则，

46
00:02:49,940 --> 00:02:51,710
所以一旦领导者停机，

47
00:02:51,710 --> 00:02:54,110
我们需要选举一个新领导者，

48
00:02:54,110 --> 00:02:57,530
有一些限制是必须应用

49
00:02:57,770 --> 00:03:03,380
以确保我们最终能够在正确的日志上收敛。

50
00:03:04,040 --> 00:03:05,030
所以，首先，

51
00:03:05,060 --> 00:03:06,200
这其中的一部分是，

52
00:03:06,200 --> 00:03:09,280
任何领导者都需要获得多数，

53
00:03:10,620 --> 00:03:12,390
这是这个想法的一部分，

54
00:03:12,390 --> 00:03:17,280
为了避免脑裂的问题，

55
00:03:17,310 --> 00:03:19,230
在某种程度上我们可以确保，

56
00:03:19,230 --> 00:03:22,140
在之后的任何两次选举中，

57
00:03:22,380 --> 00:03:24,090
至少会有一个节点，

58
00:03:24,150 --> 00:03:28,350
它参与了这两个多数，

59
00:03:28,350 --> 00:03:31,680
因为两个多数必须重叠，

60
00:03:31,710 --> 00:03:33,840
而那个节点必须有

61
00:03:33,870 --> 00:03:37,680
最近的 term 上的操作。

62
00:03:38,520 --> 00:03:39,570
多数是重要的，

63
00:03:39,630 --> 00:03:42,210
但它实际上有点[微妙的]，

64
00:03:42,600 --> 00:03:45,000
你可能会认为，

65
00:03:45,000 --> 00:03:47,400
最长的日志应该足够了，

66
00:03:47,400 --> 00:03:50,040
因为最长的日志具有最多的信息，

67
00:03:50,040 --> 00:03:52,320
所以我们选择它为下一个领导者，

68
00:03:52,320 --> 00:03:53,640
然后我们就可以了。

69
00:03:53,880 --> 00:03:55,950
事实证明并非如此，

70
00:03:56,300 --> 00:04:02,420
领导者规则是有些微妙的，

71
00:04:02,420 --> 00:04:07,130
大多数加上至少是最新的，

72
00:04:07,130 --> 00:04:11,250
至少是最新的。

73
00:04:15,430 --> 00:04:19,390
所以，领导者选举开始运行，

74
00:04:19,600 --> 00:04:22,420
跟随者，

75
00:04:22,420 --> 00:04:24,790
候选者开始参与领导者选举，

76
00:04:24,790 --> 00:04:26,830
[接近]很多跟随者，

77
00:04:27,190 --> 00:04:32,110
而跟随者投了赞成票，

78
00:04:32,110 --> 00:04:36,700
如果候选者至少像它们一样是最新的。

79
00:04:37,480 --> 00:04:38,860
这意味着，

80
00:04:38,950 --> 00:04:43,900
最后一个日志条目必须具有相同的 term ，

81
00:04:44,110 --> 00:04:47,920
或者如果它们有相同的 term ，

82
00:04:47,950 --> 00:04:50,590
最长的一个会获得胜利。

83
00:04:51,680 --> 00:04:55,520
所以，这是领导者选举规则，

84
00:04:55,520 --> 00:04:58,070
我们上周看到了这个问题，

85
00:04:58,100 --> 00:04:59,420
作为家庭作业的一部分，

86
00:04:59,420 --> 00:05:00,350
（以下情况）会发生什么，

87
00:05:00,350 --> 00:05:02,450
如果这个节点，

88
00:05:02,450 --> 00:05:06,080
更糟糕的是领导者停机了，

89
00:05:06,080 --> 00:05:06,890
它消失了，

90
00:05:07,070 --> 00:05:08,810
谁可能成为领导者，

91
00:05:09,590 --> 00:05:11,570
很快就发现，

92
00:05:11,600 --> 00:05:14,720
有很多节点不能成为领导者，

93
00:05:14,720 --> 00:05:17,030
但在很多情况下，

94
00:05:17,030 --> 00:05:18,890
一些节点可能会成为领导者。

95
00:05:19,430 --> 00:05:20,780
尤其是，

96
00:05:20,780 --> 00:05:23,150
我们认为 a 可以成为领导者，

97
00:05:23,420 --> 00:05:25,550
c 可以成为领导者，

98
00:05:25,610 --> 00:05:26,840
d 可以成为领导者。

99
00:05:28,700 --> 00:05:30,890
然后，

100
00:05:30,890 --> 00:05:34,280
这可能是整个讨论中最重要的部分，

101
00:05:34,280 --> 00:05:35,510
谁能成为领导者。

102
00:05:35,540 --> 00:05:37,010
[]有一个问题。

103
00:05:37,310 --> 00:05:39,680
稍等一下。

104
00:05:43,110 --> 00:05:43,620
好的。

105
00:05:44,160 --> 00:05:46,320
所以谁能成为（领导者）是最重要的部分，

106
00:05:46,320 --> 00:05:49,740
有一些不同的场景，a 可以成为领导者，

107
00:05:49,770 --> 00:05:51,600
有一些场景， c 可以成为领导者，

108
00:05:51,600 --> 00:05:53,430
有一些场景， d 可以成为领导者。

109
00:05:54,580 --> 00:05:56,170
然后讨论集中了一点，

110
00:05:56,170 --> 00:05:59,410
比如，至少有一种特殊的情况，

111
00:05:59,410 --> 00:06:00,880
其中一个可以成为领导者，

112
00:06:00,940 --> 00:06:03,940
多种情况下成为领导者，

113
00:06:03,940 --> 00:06:07,090
特别关注这个讨论集中在 a ，

114
00:06:09,060 --> 00:06:12,600
因为 a 可以成为领导者的一种方式是，

115
00:06:12,600 --> 00:06:17,240
当 c 和 d 停机的时候，

116
00:06:21,540 --> 00:06:23,790
因为 c 和 d 都停机了，

117
00:06:24,060 --> 00:06:28,020
a 将与 b e 和 f 交互，

118
00:06:28,020 --> 00:06:30,930
形成一个数量为 4 的大多数，

119
00:06:31,230 --> 00:06:34,650
它有最新的日志，

120
00:06:34,650 --> 00:06:37,860
注意即使 f 是一个更长的日志，

121
00:06:38,190 --> 00:06:40,890
但它不是最新的一个，

122
00:06:41,100 --> 00:06:44,040
所以 a 成功成为领导者，

123
00:06:44,590 --> 00:06:46,090
然后事情从那里继续。

124
00:06:47,170 --> 00:06:49,450
但是有一个有趣的问题出现了，

125
00:06:49,450 --> 00:06:52,960
是否有其他情况下， a 可以成为领导者，

126
00:06:52,990 --> 00:06:56,440
或者有没有一种情况，即使 c 和 d 都是启动的，

127
00:06:59,270 --> 00:07:01,430
或者可联系，或者参与，

128
00:07:01,520 --> 00:07:03,710
有没有可能 a 成为领导者，

129
00:07:05,140 --> 00:07:07,300
所以当 c 和 d 是启动的，

130
00:07:07,300 --> 00:07:10,690
所以问题是 c 和 d 是否总是投票给 a ，

131
00:07:10,690 --> 00:07:11,920
如果 a 是候选人。

132
00:07:12,810 --> 00:07:16,350
事实证明，这有点复杂，

133
00:07:16,350 --> 00:07:18,090
这不是很直接的，

134
00:07:18,510 --> 00:07:20,670
所以，如果 a 开始这次选举，

135
00:07:20,700 --> 00:07:23,910
假设它在 term 7 开始选举，

136
00:07:27,310 --> 00:07:29,530
所以，如果它联系 c 和 d ，

137
00:07:29,590 --> 00:07:31,840
c 是[正常]的，

138
00:07:31,840 --> 00:07:36,700
因为 a 是至少是最新的，

139
00:07:40,250 --> 00:07:43,820
所以，我们将能够达到大多数，

140
00:07:43,820 --> 00:07:46,430
但是 d 是可能的，

141
00:07:46,670 --> 00:07:48,650
有一条额外的规则，

142
00:07:48,650 --> 00:07:52,820
如果 d 有，

143
00:07:52,820 --> 00:07:56,930
如果跟随者在更高的 term ，

144
00:07:56,930 --> 00:07:58,250
位于更高的 term ，

145
00:07:58,280 --> 00:08:00,020
它当前的 term 更高，

146
00:08:00,440 --> 00:08:02,420
那么这个候选人，

147
00:08:02,540 --> 00:08:04,850
那么它就可以停止选举，

148
00:08:04,850 --> 00:08:07,400
因为它会回应说，

149
00:08:07,400 --> 00:08:10,430
嘿，我的 term 比你高，

150
00:08:10,490 --> 00:08:12,350
我现在的 term 比你的 term 要高，

151
00:08:12,470 --> 00:08:14,180
所以，你必须成为一个跟随者，

152
00:08:14,210 --> 00:08:18,260
a 将从候选者改回跟随者。

153
00:08:18,760 --> 00:08:19,990
这是可以发生的，

154
00:08:19,990 --> 00:08:20,920
在 d 的情况下，

155
00:08:21,190 --> 00:08:24,280
这个 d 可能已经看到了 term a ，

156
00:08:24,310 --> 00:08:26,050
从这张图片我们不能很好地判断，

157
00:08:26,050 --> 00:08:27,640
结果到底会是什么，

158
00:08:27,850 --> 00:08:29,440
让我们假设这个例子，

159
00:08:29,650 --> 00:08:38,530
它已经运行了一次，并将 term 增加到 8 ，

160
00:08:38,620 --> 00:08:40,690
它没有成为成功的领导者，

161
00:08:40,750 --> 00:08:42,190
然后它的当前 term 是 8 ，

162
00:08:42,190 --> 00:08:46,490
当 a 要求它投票时，

163
00:08:46,640 --> 00:08:48,830
d 会拒绝，说我不会投票给你，

164
00:08:49,010 --> 00:08:51,140
此外， a 的当前 term ，

165
00:08:51,260 --> 00:08:52,730
a 将看到这个消息，

166
00:08:52,730 --> 00:08:54,290
它比 7 高，

167
00:08:54,440 --> 00:08:58,280
所以， a 会下台，成为一个跟随者，

168
00:08:58,370 --> 00:08:59,420
然后在后来的某个时候，

169
00:08:59,420 --> 00:09:03,380
假设 d 的选举定时器过期，

170
00:09:03,380 --> 00:09:04,460
那么它会运行。

171
00:09:05,740 --> 00:09:09,610
所以这个简短的故事，

172
00:09:09,610 --> 00:09:10,930
这张图片是这样的，

173
00:09:11,230 --> 00:09:12,640
这是绝对可能的，

174
00:09:12,640 --> 00:09:15,790
a c d 可以在不同类型的场景中成为领导者，

175
00:09:16,060 --> 00:09:19,240
这可能是摆脱这一局面的主要原因。

176
00:09:19,660 --> 00:09:20,950
教授。

177
00:09:21,100 --> 00:09:22,210
嗯。

178
00:09:22,570 --> 00:09:25,270
所以，我想问一下，

179
00:09:25,270 --> 00:09:27,970
因为我不确定我是否理解正确，

180
00:09:27,970 --> 00:09:31,480
你说 a 可能会在 term 7 当选，

181
00:09:31,900 --> 00:09:36,460
是不是有任何原因它不能在 term 7 当选，

182
00:09:37,580 --> 00:09:40,820
即使 d 停机了，对吧，

183
00:09:40,820 --> 00:09:48,310
因为像 d 已经在 term 7 获得了多数。

184
00:09:50,260 --> 00:09:52,240
d 在 7 中获得多数，

185
00:09:52,240 --> 00:09:56,080
因为它能够完成一些事情，

186
00:09:56,080 --> 00:09:57,790
所以你是对的，

187
00:09:57,790 --> 00:10:00,040
很好的观察，

188
00:10:00,340 --> 00:10:01,690
所以它必须是这样的，

189
00:10:01,690 --> 00:10:04,210
已经有很多人进入 term 7 ，

190
00:10:05,800 --> 00:10:07,630
而且这张图并不完整，

191
00:10:07,660 --> 00:10:09,910
我们不知道当前的 term 是什么，

192
00:10:09,910 --> 00:10:11,200
到目前为止人们所看到的。

193
00:10:11,720 --> 00:10:12,230
好的。

194
00:10:12,850 --> 00:10:13,300
好的？

195
00:10:14,340 --> 00:10:17,190
是的，我的意思是唯一的事情是，

196
00:10:17,370 --> 00:10:22,770
我认为大多数服务器已经在 term 7 投票给了某人，

197
00:10:22,770 --> 00:10:23,100
所以。

198
00:10:23,100 --> 00:10:25,380
当然， a 将进入 term 8 ，

199
00:10:25,950 --> 00:10:29,370
我们开始 term 8 的选举，

200
00:10:29,580 --> 00:10:30,840
但是出于同样的原因，

201
00:10:30,840 --> 00:10:32,760
d 可能已经在 9 了，

202
00:10:32,760 --> 00:10:36,720
这完全取决于当前的 term 是什么，

203
00:10:36,720 --> 00:10:38,580
这些参与者的身份是什么。

204
00:10:40,910 --> 00:10:42,350
但是主要结论，

205
00:10:42,350 --> 00:10:44,090
最主要的结论是，

206
00:10:44,330 --> 00:10:47,870
a 肯定可以成为领导者，当 c 和 d 掉线时，

207
00:10:48,420 --> 00:10:51,180
c 可以成为领导者， d 可以成为领导者。

208
00:10:54,100 --> 00:10:54,760
谢谢。

209
00:10:57,430 --> 00:11:03,080
好的，那么，我们现在知道，

210
00:11:03,080 --> 00:11:10,190
raft 可以处于日志分叉的状态，

211
00:11:10,250 --> 00:11:12,590
所以，这需要修复，

212
00:11:12,620 --> 00:11:16,130
raft 协议的一个关键组件是，

213
00:11:16,130 --> 00:11:19,370
做他们所说的日志[追赶]，

214
00:11:20,280 --> 00:11:22,860
所以我稍微谈一下。

215
00:11:30,700 --> 00:11:36,670
这就是你要在实验的 b 部分要处理的问题。

216
00:11:37,560 --> 00:11:42,030
所以我可能会更容易用这张图来说明，

217
00:11:43,590 --> 00:11:46,020
所以让我们，让它变得简单一点，

218
00:11:46,320 --> 00:11:47,880
我们有 3 台服务器，

219
00:11:49,790 --> 00:11:56,960
这是 S1 ，它有 term 3 在索引 10 中，

220
00:11:57,170 --> 00:12:04,210
索引 11 没有条目，以及 12 ，

221
00:12:04,210 --> 00:12:06,100
这里有 S2 ，

222
00:12:09,270 --> 00:12:13,650
S2 有条目 3 3 5 ，

223
00:12:15,380 --> 00:12:21,560
这是索引 10 11 12 和 13 ， 13 补全这个。

224
00:12:22,280 --> 00:12:26,160
这是 S4 ，抱歉， S3 ，

225
00:12:26,980 --> 00:12:34,700
让我们来看看场景 3 3 4 和 10 11 12 13 ，

226
00:12:36,080 --> 00:12:38,750
我不会展示 10 之前的索引，

227
00:12:40,190 --> 00:12:41,540
它们没什么关系。

228
00:12:42,280 --> 00:12:46,120
使用时间线，这些不同的服务器。

229
00:12:46,710 --> 00:12:49,050
让我们从假设开始，

230
00:12:49,050 --> 00:12:50,460
S2 成为领导者，

231
00:12:51,460 --> 00:12:56,250
因为它有最高的，它有最新的，

232
00:12:56,280 --> 00:12:59,220
它在最后一个日志条目中具有最高的 term 编号，

233
00:12:59,220 --> 00:13:00,210
所以，它成为了领导者。

234
00:13:00,750 --> 00:13:04,620
现在，我们需要这个协议是，

235
00:13:04,620 --> 00:13:06,540
用来同步这些日志，

236
00:13:06,930 --> 00:13:10,080
使用的方式是发送[]，

237
00:13:10,200 --> 00:13:12,450
要么追加条目，

238
00:13:12,480 --> 00:13:14,310
因为新的日志条目附加，

239
00:13:14,310 --> 00:13:15,420
或因为心跳，

240
00:13:15,420 --> 00:13:19,200
它是没有新条目的附加条目。

241
00:13:19,600 --> 00:13:21,970
所以我们假设领导者发送了心跳，

242
00:13:21,970 --> 00:13:23,080
事实上，它是这样做的，

243
00:13:23,080 --> 00:13:25,420
选举发出了一个心跳，

244
00:13:25,980 --> 00:13:27,630
所以它会发出心跳，

245
00:13:28,240 --> 00:13:30,910
心跳没有日志条目，

246
00:13:31,630 --> 00:13:35,170
但它表明了另外两个信息，

247
00:13:35,260 --> 00:13:36,760
也就是上一个 term ，

248
00:13:37,820 --> 00:13:41,360
所以上一个 term ，在本例中是 5 ，

249
00:13:42,830 --> 00:13:46,700
以及上一个索引，是 12 。

250
00:13:47,960 --> 00:13:52,010
所以领导者 S2 发送给 S3 ，

251
00:13:52,010 --> 00:13:53,180
S3 看到这个，

252
00:13:53,540 --> 00:13:56,390
会说，好的，看一下我的上一个 term ，

253
00:13:56,390 --> 00:14:01,190
不是 5 ，而是 4 ，

254
00:14:01,850 --> 00:14:05,480
所以，它会发回一条消息说不，

255
00:14:06,990 --> 00:14:09,570
我还活着，

256
00:14:09,570 --> 00:14:12,480
但是我不能做你的追加（操作），

257
00:14:13,280 --> 00:14:14,780
我不是最新的。

258
00:14:15,340 --> 00:14:20,440
现在 S2 有一些信息可以让它更新，

259
00:14:20,590 --> 00:14:23,050
它的工作方式是，

260
00:14:23,050 --> 00:14:25,390
有两个变量很重要，

261
00:14:25,450 --> 00:14:32,350
一个是，对于每个节点， S2 保持一个变量 nextIndex ，

262
00:14:36,760 --> 00:14:40,300
nextIndex 当它成为领导者时，会初始化它，

263
00:14:40,450 --> 00:14:43,580
这是一种乐观的变量，

264
00:14:44,030 --> 00:14:47,180
它假设日志是最新的，

265
00:14:47,900 --> 00:14:51,650
所以当 S2 成为领导者时，

266
00:14:51,680 --> 00:14:53,240
它将其设置为 13 ，

267
00:14:53,800 --> 00:14:56,650
与它本身的值一样。

268
00:14:57,870 --> 00:14:59,010
这是可以的，

269
00:14:59,310 --> 00:15:00,810
因为这只是个猜测，

270
00:15:00,840 --> 00:15:03,630
是 S3 可能在的（索引），

271
00:15:03,630 --> 00:15:04,800
S3 可能落后了，

272
00:15:04,800 --> 00:15:07,020
因为这个 no 消息，

273
00:15:07,290 --> 00:15:09,480
领导者会知道这个。

274
00:15:10,130 --> 00:15:12,410
所以，当它收到这个 no 消息，

275
00:15:13,740 --> 00:15:16,020
在未优化的版本中，

276
00:15:16,110 --> 00:15:18,510
所以我首先讨论未优化的版本，

277
00:15:22,650 --> 00:15:25,710
领导者只是对 nextIndex 减 1 ，

278
00:15:25,830 --> 00:15:28,170
所以它把 13 减到 12 ，

279
00:15:29,060 --> 00:15:32,390
然后在某个时刻，我们将发送另一个附加条目，

280
00:15:33,170 --> 00:15:34,190
而这一次，

281
00:15:34,190 --> 00:15:35,690
它实际上会说，

282
00:15:35,690 --> 00:15:37,160
好的，我们使 nextIndex 是 12 ，

283
00:15:37,190 --> 00:15:39,590
发送日志条目 5 ，

284
00:15:40,880 --> 00:15:46,080
以及上一个 term 3 ，

285
00:15:47,160 --> 00:15:51,780
而上一个的所以将是 11 。

286
00:15:53,700 --> 00:15:58,020
所以，当 S3 收到这条消息时，

287
00:15:58,020 --> 00:15:59,790
检查上一个 term 3 ，

288
00:15:59,790 --> 00:16:01,080
上一个索引是 11 ，

289
00:16:01,080 --> 00:16:02,040
一切都解决了，

290
00:16:02,370 --> 00:16:04,320
它看到追加 5 ，

291
00:16:04,350 --> 00:16:08,880
所以它会抹去 4 ，然后在里面插入一个 5 ，

292
00:16:09,300 --> 00:16:13,090
然后回复好的。

293
00:16:16,300 --> 00:16:17,980
因此，在这一点上，

294
00:16:18,010 --> 00:16:23,280
领导者日志是最新的，

295
00:16:23,280 --> 00:16:25,740
因为你收到了一条 ok 消息。

296
00:16:27,340 --> 00:16:31,000
第二个在这里扮演重要角色的变量，

297
00:16:31,240 --> 00:16:36,660
是 matchIndex ，也是 raft 维护的，

298
00:16:36,690 --> 00:16:39,750
领导者为每个跟随者维护的。

299
00:16:40,440 --> 00:16:42,540
所以 S3 有一个 nextIndex ，

300
00:16:42,540 --> 00:16:43,830
S1 有一个 nextIndex ，

301
00:16:43,830 --> 00:16:47,460
类似的， S1 S2 S3 还有一个 matchIndex ，

302
00:16:48,560 --> 00:16:49,310
这是一种，

303
00:16:49,310 --> 00:16:53,540
你可以认为这是悲观的或下限的，

304
00:16:55,140 --> 00:16:58,470
所以当领导者变为领导者时，

305
00:16:58,500 --> 00:17:00,360
它只将值设置为 0 ，

306
00:17:01,850 --> 00:17:04,580
用来表示当目前为止，

307
00:17:04,790 --> 00:17:09,200
S3 没有任何日志条目，

308
00:17:09,840 --> 00:17:15,270
所以，它还没有向应用程序传递任何日志条目，

309
00:17:15,570 --> 00:17:18,120
所以，对于 S2 ，还必须非常小心，

310
00:17:18,120 --> 00:17:20,220
它可以传递给应用程序的内容，

311
00:17:20,340 --> 00:17:22,290
它需要知道，

312
00:17:22,290 --> 00:17:24,750
至少大多数跟随者

313
00:17:24,750 --> 00:17:26,790
拥有特定日志条目的复制，

314
00:17:26,790 --> 00:17:27,690
然后条目才能交付。

315
00:17:29,460 --> 00:17:33,060
所以开始是悲观的，

316
00:17:33,360 --> 00:17:35,070
但是，一旦它知道了，

317
00:17:35,070 --> 00:17:42,180
例如，一旦它知道跟随者是好的，

318
00:17:42,180 --> 00:17:44,370
我们收到了附加消息的确认，

319
00:17:44,400 --> 00:17:49,410
它可以更新悲观或下限的 matchIndex ，

320
00:17:49,740 --> 00:17:52,350
从 0 到 13 ，

321
00:17:52,650 --> 00:17:54,450
因为它了解到，

322
00:17:54,450 --> 00:17:59,890
跟随者在 13 之前都是最新的，

323
00:17:59,890 --> 00:18:02,860
期望的 nextIndex 是 13 。

324
00:18:03,770 --> 00:18:05,210
在这个时间点上，

325
00:18:05,210 --> 00:18:08,840
它了解到两个不同的，

326
00:18:08,840 --> 00:18:13,880
日志条目 5 现在至少复制到两个节点上。

327
00:18:16,780 --> 00:18:18,520
你可能会觉得很好，

328
00:18:18,550 --> 00:18:20,380
它已经复制到两个节点中，

329
00:18:20,530 --> 00:18:22,240
我们可以交付给应用程序，

330
00:18:22,240 --> 00:18:24,010
因为大多数已经有它，

331
00:18:24,370 --> 00:18:26,500
我们处于很好的状态。

332
00:18:27,410 --> 00:18:31,100
不幸的是，事实并非如此，

333
00:18:31,160 --> 00:18:33,560
这几乎是真的，但不完全是真的，

334
00:18:34,280 --> 00:18:37,730
这与图 8 有关，

335
00:18:38,210 --> 00:18:39,830
所以我想稍微谈谈图 8 ，

336
00:18:39,830 --> 00:18:43,070
这里事情变得稍微复杂的真正原因，

337
00:18:43,070 --> 00:18:45,200
你也应该觉得有点可疑。

338
00:18:45,670 --> 00:18:52,900
所以这个领导者 S2 从 S3 的日志中擦除了值，

339
00:18:52,900 --> 00:18:54,640
有人把它放进去了，

340
00:18:55,200 --> 00:18:57,510
擦除它，

341
00:18:57,510 --> 00:19:00,720
是的，这看起来有点危险，

342
00:19:00,720 --> 00:19:06,240
所以有一个边界条件，

343
00:19:06,240 --> 00:19:09,600
在那里你必须小心一点，

344
00:19:09,600 --> 00:19:11,310
当你交付，

345
00:19:11,340 --> 00:19:13,590
当你定义一个消息提交时。

346
00:19:14,740 --> 00:19:16,360
事实证明，

347
00:19:16,720 --> 00:19:21,130
图 8 说明了这一点。

348
00:19:22,210 --> 00:19:27,420
所以，让我来讨论一下擦除日志条目。

349
00:19:31,430 --> 00:19:33,410
我们将看到的规则，

350
00:19:33,410 --> 00:19:37,550
当消息可以传递到应用程序时，

351
00:19:37,940 --> 00:19:44,060
比仅仅计算复制次数要稍微微妙一些。

352
00:19:47,100 --> 00:19:49,770
让我们看看，图 8 ，把它加载进来。

353
00:19:50,800 --> 00:19:51,940
好的，这是图 8 ，

354
00:19:52,000 --> 00:19:55,660
和通常的结构一样。

355
00:19:58,810 --> 00:20:04,450
好的，让我们回到聊天中的问题上来，

356
00:20:04,960 --> 00:20:07,360
所以这是图 8 ，

357
00:20:07,360 --> 00:20:10,510
让我们来看看这里的场景是什么，

358
00:20:10,510 --> 00:20:16,030
图 a 中，日志条目 1 被每个节点提交，

359
00:20:16,360 --> 00:20:24,730
在 term 2 ， S1 或 S2 成为领导者，

360
00:20:25,060 --> 00:20:28,720
它们提交或开始附加条目 2 ，

361
00:20:29,180 --> 00:20:30,830
还没有被提交，

362
00:20:30,860 --> 00:20:32,900
因为它不是绝对的大多数，

363
00:20:33,260 --> 00:20:35,000
那么实际上发生的，

364
00:20:35,000 --> 00:20:38,540
S5 肯定是断开的，[]这个 term 2 ，

365
00:20:38,900 --> 00:20:40,880
在 term 3 成为领导者，

366
00:20:40,910 --> 00:20:43,910
在它的日志中附加一个条目，

367
00:20:44,180 --> 00:20:45,440
这肯定是没有提交的，

368
00:20:45,440 --> 00:20:46,550
因为没有大多数，

369
00:20:46,730 --> 00:20:48,740
然后我们到达 c ，

370
00:20:48,770 --> 00:20:52,810
也许 S5 又断开了，

371
00:20:53,020 --> 00:20:56,830
S1 在 term 4 成为领导者，

372
00:20:56,980 --> 00:21:01,780
它开始复制日志条目 2 到其他节点，

373
00:21:02,620 --> 00:21:05,500
而且交付它，

374
00:21:05,500 --> 00:21:07,180
它会回来，

375
00:21:07,180 --> 00:21:09,070
像上一张幻灯片中显示的那样，

376
00:21:09,430 --> 00:21:13,090
它们在 S2 和 S3 中。

377
00:21:14,230 --> 00:21:18,940
事实证明，你可能会想，

378
00:21:18,940 --> 00:21:21,490
好的， S1 知道，

379
00:21:21,490 --> 00:21:27,730
3 个节点有这个特定条目的复制，

380
00:21:27,730 --> 00:21:29,290
所以我也许能交付它，

381
00:21:29,290 --> 00:21:31,270
事实证明这不是真的，

382
00:21:32,000 --> 00:21:40,300
还有更微妙的原因需要发生才能提交，

383
00:21:40,300 --> 00:21:42,220
也就是说，你只能提交。

384
00:21:42,370 --> 00:21:43,150
哦，抱歉，

385
00:21:46,750 --> 00:21:47,680
你可以提交

386
00:21:50,230 --> 00:22:03,820
在领导者在它的 term 提交一个条目之后，

387
00:22:09,990 --> 00:22:12,330
如果我们考虑这个数字 2 ，

388
00:22:12,570 --> 00:22:15,510
它不是，领导者在 term 4 ，

389
00:22:15,750 --> 00:22:20,490
所以，提交规则不允许

390
00:22:20,490 --> 00:22:24,030
将 2 提交到服务器，

391
00:22:24,240 --> 00:22:27,420
因为这是来自前一个 term ，

392
00:22:27,420 --> 00:22:28,440
而不是来自当前 term ，

393
00:22:28,560 --> 00:22:31,350
例如，你的代码用于确定

394
00:22:31,350 --> 00:22:33,990
是否可以将一些东西交付给 apply channel ，

395
00:22:33,990 --> 00:22:35,430
需要考虑到这个。

396
00:22:35,900 --> 00:22:38,750
你需要考虑的原因如 d 和 e 所示，

397
00:22:39,510 --> 00:22:42,420
基本上发生的是，

398
00:22:42,980 --> 00:22:50,570
S1 可能处于不同的情况下，

399
00:22:50,570 --> 00:22:55,010
其中 d 变成了，

400
00:22:56,440 --> 00:23:02,850
之后， d 成为领导者，

401
00:23:02,910 --> 00:23:06,180
例如 S1 断开，

402
00:23:06,420 --> 00:23:09,300
它可能会开始连接，

403
00:23:09,300 --> 00:23:10,890
它可以形成大多数，

404
00:23:11,040 --> 00:23:16,800
它开始将它的条目复制到，

405
00:23:17,350 --> 00:23:20,380
好的，它擦除了 2 ，

406
00:23:20,440 --> 00:23:22,600
复制它的 3 到，

407
00:23:22,660 --> 00:23:27,010
它的 term 3 的条目到之前是 2 的（地方），

408
00:23:27,070 --> 00:23:30,220
这就是我们在上一张幻灯片中谈到的擦除。

409
00:23:33,660 --> 00:23:34,290
所以我们会看到，

410
00:23:34,290 --> 00:23:38,280
尽管它是在大多数节点上，

411
00:23:38,280 --> 00:23:39,300
在大多数节点上，

412
00:23:39,330 --> 00:23:40,470
还是被擦除了。

413
00:23:41,370 --> 00:23:45,210
所以就是我在这里所说的规则，

414
00:23:45,330 --> 00:23:49,920
因为使用 e 描述，

415
00:23:50,160 --> 00:23:55,080
一旦 S3 S1 在它自己的 term 提交了条目，

416
00:23:55,830 --> 00:23:58,020
所以它知道每个，

417
00:23:58,050 --> 00:24:00,060
在它自己的 term ，有一个大多数，

418
00:24:00,210 --> 00:24:01,200
在这一点上，

419
00:24:01,200 --> 00:24:04,170
它可以把 4 交付给应用程序，

420
00:24:04,560 --> 00:24:06,030
结果就是，

421
00:24:06,090 --> 00:24:08,850
任何节点在前面的 term 中提交的

422
00:24:08,880 --> 00:24:11,910
也可以交付给应用程序。

423
00:24:13,040 --> 00:24:15,710
所以你在这里可以看到，日志条目的擦除，

424
00:24:15,740 --> 00:24:19,910
使提交规则稍微复杂一些。

425
00:24:20,460 --> 00:24:25,770
这是 raft 设计者们所做的设计决定，

426
00:24:25,770 --> 00:24:27,210
他们可以用不同的方式来做，

427
00:24:27,450 --> 00:24:28,770
他们本来可以计数，

428
00:24:28,860 --> 00:24:32,100
如果他们想的话，让 2 也存活，

429
00:24:32,220 --> 00:24:34,320
但他们决定采用这种方法，

430
00:24:34,320 --> 00:24:36,090
理由是，他们认为这更简单。

431
00:24:39,600 --> 00:24:43,050
好的，这是突然出现的，

432
00:24:43,080 --> 00:24:45,840
在实验的测试案例中，

433
00:24:46,080 --> 00:24:49,440
所以，你必须对提交规则稍微小心一些，

434
00:24:51,860 --> 00:24:53,030
然后你就能正确地实现它。

435
00:24:55,910 --> 00:25:00,350
好的，到目前为止，

436
00:25:00,380 --> 00:25:02,600
如果你回到这张图片，

437
00:25:02,600 --> 00:25:11,120
这个协议的优化版本有点令人沮丧，

438
00:25:11,120 --> 00:25:13,970
比如，如果你稍微想一想，

439
00:25:14,000 --> 00:25:18,410
让我们来看看 S1 发生了什么。

440
00:25:19,230 --> 00:25:22,920
让我们来看看，让我交换一下东西，

441
00:25:22,920 --> 00:25:25,470
让我们看看， S2 尝试使 S1 保持最新，

442
00:25:25,470 --> 00:25:26,700
也会做同样的事情，

443
00:25:27,210 --> 00:25:30,300
发送附加条目，使用空条目，

444
00:25:30,540 --> 00:25:33,960
发送上一个 term 5 ，

445
00:25:36,400 --> 00:25:39,610
和上一个索引 12 ，

446
00:25:40,160 --> 00:25:42,440
它会说不，

447
00:25:43,340 --> 00:25:48,410
真正的上一个索引是 10 在 term 3 ，

448
00:25:48,410 --> 00:25:49,880
所以，它会，

449
00:25:50,450 --> 00:25:55,880
这个会把它的 nextIndex 从 13 降到 12 ，

450
00:25:56,730 --> 00:25:58,650
然后我们再次做同样的事情，

451
00:25:59,130 --> 00:26:04,350
我想是发送日志条目 5 ，

452
00:26:04,350 --> 00:26:06,570
它会将上一个 term 设置为 3 ，

453
00:26:07,220 --> 00:26:09,890
上一个索引设置为 11 ，

454
00:26:10,740 --> 00:26:12,120
它会被拒绝，

455
00:26:13,050 --> 00:26:15,780
然后索引从 12 到 11 ，

456
00:26:16,880 --> 00:26:19,070
现在它成功了，

457
00:26:19,100 --> 00:26:20,120
我们在这里看到，

458
00:26:20,120 --> 00:26:22,370
对于每个日志条目，

459
00:26:22,400 --> 00:26:25,280
我们将对附加条目进行一次往返，

460
00:26:26,020 --> 00:26:28,930
事实证明，这可能是昂贵的，

461
00:26:28,960 --> 00:26:29,590
比如，

462
00:26:29,590 --> 00:26:31,330
真正的问题是，

463
00:26:31,330 --> 00:26:34,030
跟随者能远远落后吗？

464
00:26:35,310 --> 00:26:36,810
我来问一下，

465
00:26:36,810 --> 00:26:38,010
我们暂停一下，

466
00:26:38,010 --> 00:26:40,770
你可以思考这种情况，

467
00:26:41,070 --> 00:26:45,690
有没有可能一个跟随者可能远远落后于某个领导者？

468
00:26:49,110 --> 00:26:51,510
如果一台新机器加入集群？

469
00:26:52,060 --> 00:26:55,930
是的，新加入集群是一个很好的例子，还有其他的例子吗？

470
00:26:57,820 --> 00:27:01,510
一台机器崩溃了，很多 term 之后才重新上线。

471
00:27:01,630 --> 00:27:04,420
是的，没错，它可能在一天之后又回来了，

472
00:27:04,990 --> 00:27:06,460
它可能已经远远落后了，

473
00:27:06,940 --> 00:27:08,110
这意味着，

474
00:27:08,110 --> 00:27:10,300
在未优化版本的协议中，

475
00:27:10,300 --> 00:27:12,370
你需要对日志条目一个接一个的返回。

476
00:27:13,260 --> 00:27:14,490
所以这有点贵，

477
00:27:14,850 --> 00:27:18,330
所以，这篇论文讨论了一种优化，

478
00:27:18,330 --> 00:27:19,590
用来快速赶上。

479
00:27:30,740 --> 00:27:34,860
这个想法基本上是，

480
00:27:34,860 --> 00:27:39,510
不是像我之前说的那样后退，

481
00:27:39,510 --> 00:27:42,600
nextIndex 是乐观的，只是猜测，

482
00:27:42,600 --> 00:27:45,330
它不一定真的那么准确，

483
00:27:45,660 --> 00:27:48,330
所以观察到的是，

484
00:27:48,330 --> 00:27:50,850
我们不需要一个接一个地回去，

485
00:27:50,880 --> 00:27:53,370
让一个 term 回去也是完全可以的。

486
00:27:53,810 --> 00:27:55,700
这是符合逻辑的，

487
00:27:55,700 --> 00:27:57,470
也许这是一个节点，

488
00:27:57,470 --> 00:27:59,750
它是几个 term 之前，

489
00:27:59,750 --> 00:28:01,220
我们回退几个 term ，

490
00:28:01,220 --> 00:28:03,260
然后我们从那里开始扫描。

491
00:28:04,050 --> 00:28:06,570
好的，为了说明它是如何工作的，

492
00:28:06,930 --> 00:28:09,030
让我使用一个完整的例子，

493
00:28:09,330 --> 00:28:11,730
我使用两台服务器，

494
00:28:11,880 --> 00:28:14,910
即使可能需要 3 个才能获得大多数，

495
00:28:14,910 --> 00:28:16,920
但让我们假设还有第三个，

496
00:28:16,920 --> 00:28:18,480
它只是在正常运行。

497
00:28:19,260 --> 00:28:21,840
所以，这是 S1 ，这是 S2 ，

498
00:28:23,320 --> 00:28:29,650
假设这个节点有 5 5 5 ，

499
00:28:33,640 --> 00:28:38,470
这是 1 2 3 4 5 索引，

500
00:28:39,070 --> 00:28:47,080
假设 S2 有 4 以及全是 6 ，

501
00:28:47,260 --> 00:28:50,440
所以， S1 是非常落后的，

502
00:28:50,470 --> 00:28:54,460
因为真正对齐的只有第一个条目，

503
00:28:55,030 --> 00:28:57,730
第一个，也就是 term 4 。

504
00:28:58,390 --> 00:29:00,370
因此，在未优化的方案中，

505
00:29:00,370 --> 00:29:01,930
我们一个接一个地后退，

506
00:29:01,930 --> 00:29:03,550
一个接一个直到我们最终到达那里。

507
00:29:04,860 --> 00:29:07,410
为了优化这一点，

508
00:29:07,410 --> 00:29:09,660
论文描述了一种优化，

509
00:29:09,840 --> 00:29:12,900
不幸的是，性能并没有描述为

510
00:29:12,900 --> 00:29:15,030
如图 2 那么详细，

511
00:29:15,030 --> 00:29:15,720
所以实际上，

512
00:29:15,720 --> 00:29:19,170
在 2c 中，要通过 2c ，

513
00:29:19,170 --> 00:29:22,840
你必须要有这种优化，

514
00:29:22,840 --> 00:29:24,910
实现一个这种形式的优化，

515
00:29:25,090 --> 00:29:26,950
你可以自由地实现它，

516
00:29:26,950 --> 00:29:28,960
因为论文并没有非常准确地描述，

517
00:29:28,960 --> 00:29:30,340
你应该怎么做，

518
00:29:30,340 --> 00:29:31,810
然后你必须做一点工作。

519
00:29:32,020 --> 00:29:34,660
但它的基本思路如下，

520
00:29:35,060 --> 00:29:38,570
不只是投票或说不或是，

521
00:29:38,570 --> 00:29:40,310
如我们在之前的幻灯片看到的，

522
00:29:40,460 --> 00:29:44,480
拒绝，所以你说不，

523
00:29:45,150 --> 00:29:47,310
拒绝包括一点更多的信息，

524
00:29:47,580 --> 00:29:49,470
然后这些信息将

525
00:29:49,470 --> 00:29:51,930
帮助领导者更快地后退，

526
00:29:52,700 --> 00:29:57,560
所以包括他们所说的冲突 term ，

527
00:29:58,940 --> 00:30:01,070
作为对冲突索引的响应。

528
00:30:03,920 --> 00:30:09,650
这个冲突 term 基本上就是，

529
00:30:09,800 --> 00:30:13,040
让我说得更清楚一点，

530
00:30:13,040 --> 00:30:16,880
假设这是 S1 时间线，这是 S2 ，

531
00:30:17,620 --> 00:30:21,580
所以 S2 在 7 选举领导者，

532
00:30:21,580 --> 00:30:24,220
因为它有最新的日志，

533
00:30:24,670 --> 00:30:27,790
它向 S1 发送一个心跳消息，

534
00:30:28,220 --> 00:30:29,990
在心跳中，

535
00:30:29,990 --> 00:30:35,600
它会说上一个 term 是 6 ，

536
00:30:36,080 --> 00:30:40,760
以及上一个索引是 5 ，

537
00:30:42,620 --> 00:30:44,360
现在，当 S1 得到这个，

538
00:30:44,390 --> 00:30:47,960
查看这个日志，看到上一个 term 是 5 ，

539
00:30:48,840 --> 00:30:50,640
所以，不是，

540
00:30:50,640 --> 00:30:53,820
它会在回应中包含冲突 term ，

541
00:30:53,910 --> 00:30:57,960
term 在那个索引冲突，索引是 5 ，

542
00:30:58,630 --> 00:30:59,860
我们会找到条目，

543
00:31:00,190 --> 00:31:05,410
然后它还包括这个日志中这个 term 的第一个索引，

544
00:31:05,440 --> 00:31:08,380
所以我们查看这个 term 5 5 5 ，

545
00:31:08,380 --> 00:31:12,010
在日志中，和索引 5 一样的（term）第一次出现在索引 2 ，

546
00:31:12,070 --> 00:31:13,690
所以我们也会包括它，

547
00:31:14,020 --> 00:31:16,930
我们会把它送回给领导者，

548
00:31:16,930 --> 00:31:18,820
这里 S2 是领导者，

549
00:31:19,160 --> 00:31:23,670
所以我们要发回 5,2 ，

550
00:31:23,790 --> 00:31:25,650
这就是冲突信息，

551
00:31:26,070 --> 00:31:31,620
领导者使用这些信息向后跳到更远，

552
00:31:31,620 --> 00:31:33,660
事实上，它是从，

553
00:31:33,660 --> 00:31:42,140
所以最初它的猜测是 S1 的 nextIndex 是 6 ，

554
00:31:42,680 --> 00:31:44,210
根据这些信息，

555
00:31:44,210 --> 00:31:46,220
它的[缩小]为 2 ，

556
00:31:46,310 --> 00:31:47,690
所以它变成了 2 ，

557
00:31:48,020 --> 00:31:52,590
然后，下一个追加条目将包括从 2 开始的所有内容，

558
00:31:53,820 --> 00:31:56,640
所以它将包括 5 5 5 ，

559
00:31:58,140 --> 00:32:02,730
以及上一个 term 是 4 ，上一个索引是 1 ，

560
00:32:04,650 --> 00:32:07,350
现在 S1 可以[]，

561
00:32:07,350 --> 00:32:09,540
将新的日志条目复制到

562
00:32:09,540 --> 00:32:13,020
条目 2 3 4 5 上，更新为最新的。

563
00:32:14,200 --> 00:32:17,500
所以这减少了心跳的次数，

564
00:32:17,500 --> 00:32:20,350
为了追赶跟随者，

565
00:32:20,380 --> 00:32:23,020
一次一个 term 而不是一次一个条目。

566
00:32:30,850 --> 00:32:31,690
有什么问题吗？

567
00:32:33,430 --> 00:32:37,360
我们如何确保我们不会使带宽超载，

568
00:32:37,360 --> 00:32:38,860
想象一下，如果你有，

569
00:32:38,860 --> 00:32:42,490
你尝试发回所有这些日志条目，

570
00:32:42,490 --> 00:32:45,490
这导致了数据包过大的问题。

571
00:32:46,060 --> 00:32:47,290
是的，这是一个很好的问题，

572
00:32:47,290 --> 00:32:51,820
它表明了另一种方案，

573
00:32:51,820 --> 00:32:54,400
但是回到这里，

574
00:32:54,820 --> 00:32:57,940
除了做出这种乐观的猜测，

575
00:32:57,940 --> 00:32:59,380
为什么要猜测，

576
00:32:59,500 --> 00:33:00,580
只是发送所有东西，

577
00:33:00,820 --> 00:33:03,550
领导者可以发送它的所有日志，

578
00:33:03,670 --> 00:33:04,750
那就太好了，

579
00:33:04,750 --> 00:33:09,130
然后任何跟随者都可以找到它们需要的，对吧，

580
00:33:10,850 --> 00:33:14,180
这将是另一种实现方式，

581
00:33:14,180 --> 00:33:16,670
很可能我们不喜欢这种实现方式，

582
00:33:16,850 --> 00:33:18,560
因为日志可能很大，

583
00:33:18,770 --> 00:33:21,410
这将是一个问题。

584
00:33:22,260 --> 00:33:26,190
所以我想这里正在进行的猜测是，

585
00:33:26,460 --> 00:33:30,540
在通常的典型情况下，

586
00:33:30,570 --> 00:33:34,200
跟随者希望是足够近的，

587
00:33:34,200 --> 00:33:36,990
所以，回退几个条目就足够了，

588
00:33:37,630 --> 00:33:41,050
如果不是，那么我们可能会回退一个 term ，

589
00:33:41,380 --> 00:33:42,730
但不是所有 term 。

590
00:33:43,340 --> 00:33:46,490
所以，我们将发送一个 term 的日志条目，

591
00:33:46,490 --> 00:33:48,020
这可能会很多，

592
00:33:48,050 --> 00:33:48,830
这可能会很多，

593
00:33:48,830 --> 00:33:50,750
我们很快就会看到，我们如何绕过这一点，

594
00:33:51,470 --> 00:33:53,360
快照将帮助

595
00:33:53,360 --> 00:33:56,300
减少我们必须发送的日志条目的数量。

596
00:33:59,460 --> 00:34:00,210
有一个问题，

597
00:34:00,210 --> 00:34:05,040
你是否需要在实验 2c 中实现这种版本的优化方案，

598
00:34:05,040 --> 00:34:05,820
答案是肯定的。

599
00:34:06,860 --> 00:34:08,390
至少我相信，

600
00:34:08,390 --> 00:34:11,750
在没有实现一些优化的情况下，我无法通过测试。

601
00:34:13,970 --> 00:34:15,230
我有一个问题，

602
00:34:15,260 --> 00:34:17,480
在我的代码中，

603
00:34:17,480 --> 00:34:21,440
我通过后退到提交来进行优化，

604
00:34:21,650 --> 00:34:26,270
所以我在回复中包含了上次提交的索引，

605
00:34:26,270 --> 00:34:27,650
然后我从那里开始，

606
00:34:28,920 --> 00:34:31,020
这是不是更糟？

607
00:34:31,020 --> 00:34:32,370
你可能会遇到麻烦，

608
00:34:32,370 --> 00:34:37,410
测试记录了你发送的字节数，

609
00:34:37,880 --> 00:34:38,930
并给你一个预算，

610
00:34:38,930 --> 00:34:44,090
如果你把预算翻得太多，

611
00:34:44,360 --> 00:34:46,160
然后测试就会说，

612
00:34:46,160 --> 00:34:48,380
你发送了太多数据，

613
00:34:50,800 --> 00:34:52,540
因为你的方案可能是这样的，

614
00:34:52,540 --> 00:34:55,180
我认为你会发送比实际需要更多的数据，

615
00:34:55,750 --> 00:34:57,400
无论需要是什么意思，但是。

616
00:35:00,990 --> 00:35:02,460
聊天中有一个问题。

617
00:35:02,790 --> 00:35:05,940
是的，我是不是画错东西了，

618
00:35:05,940 --> 00:35:09,160
是的， 6 6 6 6 ，抱歉，谢谢，

619
00:35:10,490 --> 00:35:18,920
6 6 6 ，我不想让跟随者覆盖领导者的日志条目，

620
00:35:19,220 --> 00:35:19,970
抱歉，

621
00:35:20,540 --> 00:35:21,230
找得好。

622
00:35:24,880 --> 00:35:25,630
还有什么问题吗？

623
00:35:32,510 --> 00:35:33,110
好的。

624
00:35:40,300 --> 00:35:43,900
好的，那么让我来谈谈持久化。

625
00:35:45,370 --> 00:35:47,590
首先，我们在聊天中有一个问题。

626
00:35:48,010 --> 00:35:48,700
好的。

627
00:35:48,700 --> 00:35:51,540
他们想知道为什么拒绝必须

628
00:35:51,540 --> 00:35:55,080
将拒绝 term 和索引一起发回？

629
00:35:58,640 --> 00:36:02,600
好的，这很大程度上取决于你如何实现，

630
00:36:02,600 --> 00:36:05,810
你在领导者维持什么状态，

631
00:36:05,810 --> 00:36:08,000
以及领导者是如何决定回退的，

632
00:36:10,180 --> 00:36:12,790
你是否需要发送一些 term 回去，

633
00:36:12,790 --> 00:36:14,080
因为你需要[]，

634
00:36:14,290 --> 00:36:17,440
响应延迟很长一段时间，

635
00:36:17,440 --> 00:36:18,640
你当然应该拒绝，

636
00:36:18,640 --> 00:36:22,060
完全不相关的 term 信息。

637
00:36:25,410 --> 00:36:27,240
我知道这个回答有点含糊，

638
00:36:27,240 --> 00:36:30,330
但它在很大程度上取决于你如何实现它。

639
00:36:37,480 --> 00:36:39,940
好的，持久化，

640
00:36:45,970 --> 00:36:48,790
我们谈了一点持久化，

641
00:36:49,370 --> 00:36:51,950
在第一节 raft 课程中，

642
00:36:51,950 --> 00:36:55,340
我们注意到，

643
00:36:55,370 --> 00:36:59,330
跟随者每个 term 只能给一个候选者投票，

644
00:36:59,330 --> 00:37:03,410
所以，它需要记住投票给了谁，

645
00:37:03,410 --> 00:37:04,850
以及当前的 term 是什么，

646
00:37:05,590 --> 00:37:11,530
但是关于持久化还有一个更大的问题，

647
00:37:11,740 --> 00:37:14,260
其中一个问题提到了这一点，

648
00:37:14,260 --> 00:37:15,220
你们中的一个刚刚问到，

649
00:37:15,220 --> 00:37:18,010
也就是，重启后会发生什么？

650
00:37:21,640 --> 00:37:24,640
你可以想到两种可能的策略，

651
00:37:24,670 --> 00:37:26,710
一种策略是，

652
00:37:30,470 --> 00:37:32,120
策略 1 是，

653
00:37:32,790 --> 00:37:36,930
节点是新增的，

654
00:37:37,830 --> 00:37:44,640
新增，当一个节点崩溃并重新启动时，

655
00:37:44,640 --> 00:37:46,080
它只是不再参与了，

656
00:37:46,080 --> 00:37:51,650
它必须重新加入 raft 集群，

657
00:37:52,410 --> 00:37:54,480
这意味着，

658
00:37:54,570 --> 00:37:59,240
当重新加入时，你应该重放日志，

659
00:37:59,270 --> 00:38:02,180
必须接收日志中的每个条目，

660
00:38:02,300 --> 00:38:04,900
然后重放它们。

661
00:38:05,680 --> 00:38:10,150
当然，如果一个节点出现故障，

662
00:38:10,150 --> 00:38:13,270
或者节点停机一天或两天，

663
00:38:13,270 --> 00:38:15,730
或者即使它只是停机一会儿，

664
00:38:16,300 --> 00:38:18,910
但是这个系统已经启动一年了，

665
00:38:19,000 --> 00:38:22,150
这个数字意味着你必须重放大量日志条目，

666
00:38:22,360 --> 00:38:23,650
所以这有一点令人讨厌。

667
00:38:23,650 --> 00:38:26,950
所以，人们更喜欢策略 2 ，

668
00:38:27,040 --> 00:38:30,220
也就是你可以回退，

669
00:38:31,820 --> 00:38:34,010
可以再次参与其中，

670
00:38:35,070 --> 00:38:36,900
所以你追赶，

671
00:38:37,080 --> 00:38:39,840
你从持久化状态开始，

672
00:38:49,460 --> 00:38:53,300
想法是，这只是一次快速重启，

673
00:38:53,330 --> 00:38:56,600
你崩溃了，你可以从任何快速的网络故障恢复，

674
00:38:56,840 --> 00:39:00,530
也许其他的可以继续向前一个 term ，

675
00:39:00,710 --> 00:39:02,840
你拥有所有的状态，

676
00:39:02,990 --> 00:39:05,570
应该用来快速追赶。

677
00:39:06,070 --> 00:39:07,120
所以，真正的问题是，

678
00:39:07,120 --> 00:39:08,380
什么需要，

679
00:39:08,530 --> 00:39:11,980
什么状态需要持久化通过重新启动。

680
00:39:12,870 --> 00:39:15,330
我们已经讨论了投票给谁，

681
00:39:15,690 --> 00:39:17,280
这需要持久化，

682
00:39:19,510 --> 00:39:25,510
因为你不能在同一 term 内投票给其他候选人，

683
00:39:26,260 --> 00:39:30,070
但是 raft 包含了更多的信息，

684
00:39:30,190 --> 00:39:35,020
并且将日志保持在磁盘上或处于持久化状态，

685
00:39:35,560 --> 00:39:37,630
以及当前 term 。

686
00:39:42,820 --> 00:39:45,460
对于每个，我们都应该问自己这个问题，

687
00:39:47,210 --> 00:39:49,730
为什么要维持持久化状态，

688
00:39:49,730 --> 00:39:53,090
因为这意味着每当我们更新状态时，

689
00:39:53,090 --> 00:39:55,850
每当我们将条目附加到日志时，

690
00:39:55,940 --> 00:39:58,070
每当我们递增 term 时，

691
00:39:58,280 --> 00:40:00,680
或者每当我们修改 votedFor 时，

692
00:40:00,680 --> 00:40:03,770
我们必须写入磁盘或稳定存储，

693
00:40:03,770 --> 00:40:05,420
而稳定存储是很昂贵的，

694
00:40:05,600 --> 00:40:07,580
所以，很可能，

695
00:40:07,580 --> 00:40:14,120
例如，写入稳定存储可能会成为瓶颈。

696
00:40:15,800 --> 00:40:17,180
所以我们已经讨论了 votedFor ，

697
00:40:17,180 --> 00:40:19,820
所以我要讨论一下日志，

698
00:40:19,820 --> 00:40:22,700
为什么日志必须写入持久化存储，

699
00:40:24,580 --> 00:40:25,780
我们能不能重建。

700
00:40:38,760 --> 00:40:39,810
从另一方面来说，你有一个问题，

701
00:40:39,810 --> 00:40:41,610
假设我们不写入稳定存储，

702
00:40:41,610 --> 00:40:42,420
什么会被打破？

703
00:40:55,300 --> 00:40:58,960
是的，聊天室里有人回答这个问题，

704
00:40:58,960 --> 00:41:01,750
你可能会在丢失提交写入条目的大部分。

705
00:41:02,420 --> 00:41:05,030
所以这是一个场景，

706
00:41:05,060 --> 00:41:12,230
raft 复制操作到大多数节点上，

707
00:41:12,780 --> 00:41:16,980
所以大多数节点已经提交，

708
00:41:17,010 --> 00:41:22,920
已经交付，已经应用那个日志条目，

709
00:41:23,570 --> 00:41:26,630
所以领导者看到了提交，

710
00:41:26,840 --> 00:41:30,830
它通过 apply channel 交付操作消息给服务器，

711
00:41:31,010 --> 00:41:33,320
服务器执行这个操作，

712
00:41:33,470 --> 00:41:36,020
并让客户端知道操作已经成功。

713
00:41:37,550 --> 00:41:40,250
所以现在暴露了一个事实，

714
00:41:40,250 --> 00:41:44,720
[]复制到大多数节点的操作到客户端。

715
00:41:45,390 --> 00:41:47,220
所以如果我们不是，

716
00:41:47,220 --> 00:41:49,890
如果收到条目的跟随者，

717
00:41:49,890 --> 00:41:51,810
没有把它放到磁盘上，

718
00:41:52,050 --> 00:41:56,070
当重新启动时，它们仍然拥有它，

719
00:41:56,460 --> 00:41:57,930
我们可以遇到这种情况，

720
00:41:57,930 --> 00:41:59,910
就是聊天中的答案，

721
00:41:59,910 --> 00:42:02,790
我们丢失了已经提交条目的大多数，

722
00:42:02,790 --> 00:42:08,400
那个条目不会交付给其他副本到服务器，

723
00:42:08,400 --> 00:42:10,350
所以客户端会看到一些奇怪的东西，

724
00:42:10,350 --> 00:42:14,310
它看到一个已经完成的操作，稍晚一点（再次）出现，

725
00:42:14,400 --> 00:42:16,830
实际上操作还没有发生。

726
00:42:17,700 --> 00:42:18,900
所以，它很重要，

727
00:42:18,900 --> 00:42:20,520
这个在稳定存储上，

728
00:42:20,520 --> 00:42:23,310
我们向领导者承诺提交，

729
00:42:28,490 --> 00:42:30,320
我们不能回退这个承诺。

730
00:42:33,420 --> 00:42:33,960
好的?

731
00:42:34,930 --> 00:42:36,100
对于这个，有什么问题吗？

732
00:42:43,660 --> 00:42:47,380
为什么我们需要记住磁盘上的当前术语，

733
00:42:47,380 --> 00:42:49,360
为什么它需要稳定储存？

734
00:42:53,020 --> 00:42:54,790
嗯，这个 term ，

735
00:42:57,320 --> 00:42:59,300
你在每个 term 投票给不同的人，

736
00:42:59,300 --> 00:43:01,160
所以如果你不记住 term 是什么，

737
00:43:01,160 --> 00:43:02,300
那你不能，

738
00:43:02,570 --> 00:43:04,760
你不知道投票给了谁。

739
00:43:04,790 --> 00:43:05,660
是的，没错，

740
00:43:05,660 --> 00:43:06,860
你投票给了谁，

741
00:43:06,860 --> 00:43:09,680
这也是当前 term 总是要上升的问题，

742
00:43:10,070 --> 00:43:11,810
你不能在 term 中下降，

743
00:43:12,080 --> 00:43:13,520
因为你要使用它

744
00:43:13,520 --> 00:43:18,380
来检测过时的领导者和过时的候选人的 RPC ，

745
00:43:19,790 --> 00:43:21,020
它总是要上升的。

746
00:43:30,690 --> 00:43:31,320
好的?

747
00:43:34,550 --> 00:43:36,110
关于持久化，有什么问题吗？

748
00:43:45,360 --> 00:43:52,950
是的，更多是你放东西的方式，

749
00:43:52,950 --> 00:43:55,320
但是你说有两种策略，对吧，

750
00:43:55,560 --> 00:43:57,420
它们需要一个日志，

751
00:43:57,990 --> 00:44:01,260
并且从持久化状态开始。

752
00:44:01,710 --> 00:44:02,670
是的。

753
00:44:03,180 --> 00:44:08,250
我的意思是你描述的从持久化状态开始的方式，

754
00:44:11,030 --> 00:44:17,320
你是不是重放，

755
00:44:18,600 --> 00:44:21,270
我想这张幻灯片上没有说，

756
00:44:21,270 --> 00:44:23,550
比如，如果你假设，

757
00:44:23,550 --> 00:44:28,700
你显然也有一个快照。

758
00:44:29,180 --> 00:44:31,280
我还没有讨论快照，

759
00:44:31,310 --> 00:44:32,660
我们稍后会讨论这一点，

760
00:44:32,690 --> 00:44:34,550
这是下一个话题。

761
00:44:35,080 --> 00:44:35,830
好的，但是。

762
00:44:35,830 --> 00:44:36,700
重点是，

763
00:44:36,820 --> 00:44:39,820
好的，两种策略在节点崩溃之后，

764
00:44:39,850 --> 00:44:41,830
有两种方法可以处理那个节点，

765
00:44:41,920 --> 00:44:43,420
一种是有一个全新的节点，

766
00:44:43,450 --> 00:44:45,700
它从未在系统中出现过，

767
00:44:46,090 --> 00:44:47,050
所以，当它出现时，

768
00:44:47,050 --> 00:44:49,450
你把它添加到集群中，

769
00:44:49,450 --> 00:44:50,590
就像它是一个新节点，

770
00:44:50,590 --> 00:44:52,210
所以集群来自，

771
00:44:52,830 --> 00:44:55,320
假设你开始有七个节点，

772
00:44:55,350 --> 00:44:57,690
一个崩溃了，集群还有六个节点，

773
00:44:57,840 --> 00:44:59,100
它只是快乐地继续，

774
00:44:59,100 --> 00:45:02,430
无论其他节点做它们的应用程序和所有类似的事情，

775
00:45:02,580 --> 00:45:05,850
然后第二个节点会重新启动。

776
00:45:06,360 --> 00:45:09,270
所以有两种方式可以加入，

777
00:45:09,270 --> 00:45:10,110
一种方式是，

778
00:45:10,110 --> 00:45:12,420
我忘记所做的一切，

779
00:45:12,600 --> 00:45:15,030
我会再次加入集群，

780
00:45:15,030 --> 00:45:16,950
其他六个节点将带我到最新的，

781
00:45:17,070 --> 00:45:20,280
它们把日志发给我，我会重放操作，

782
00:45:21,700 --> 00:45:24,310
这可能会很昂贵，即使使用快照。

783
00:45:25,080 --> 00:45:27,060
所以第二种策略是，

784
00:45:27,060 --> 00:45:30,330
如果相同的节点 7 再次恢复，

785
00:45:30,540 --> 00:45:34,860
它试图用它的持久化状态重建，

786
00:45:35,960 --> 00:45:38,240
基本上是希望，

787
00:45:38,240 --> 00:45:42,710
比如，停机几纳秒、微秒或毫秒，

788
00:45:42,950 --> 00:45:44,870
根本没有什么需要追赶，

789
00:45:44,870 --> 00:45:46,700
因为它已经在状态中了。

790
00:45:48,700 --> 00:45:51,540
但它会，

791
00:45:52,160 --> 00:45:54,530
除了日志，

792
00:45:54,530 --> 00:45:56,120
还有一个状态机，对吧，

793
00:45:56,120 --> 00:45:58,490
用来[应用改变]。

794
00:45:58,520 --> 00:46:01,280
是的，让我们来谈谈这个，

795
00:46:01,280 --> 00:46:02,810
所以这是下一个话题。

796
00:46:05,610 --> 00:46:06,720
我想这里，

797
00:46:06,720 --> 00:46:09,270
那么关于服务恢复呢？

798
00:46:16,120 --> 00:46:18,850
对不起，我还有另一个关于持久化的问题。

799
00:46:19,210 --> 00:46:20,440
好的。

800
00:46:20,500 --> 00:46:23,410
服务器什么时候决定持久化？

801
00:46:24,170 --> 00:46:26,630
好的，好问题，

802
00:46:26,630 --> 00:46:27,470
你是怎么想的，

803
00:46:28,790 --> 00:46:29,900
我相信你已经想过这件事了。

804
00:46:33,190 --> 00:46:36,700
我认为一个简单的答案是

805
00:46:36,700 --> 00:46:39,580
每次这些变量中的一个发生变化，

806
00:46:39,580 --> 00:46:43,720
但这似乎是一件非常昂贵的事情。

807
00:46:44,080 --> 00:46:45,910
我认为这是正确的答案，

808
00:46:46,770 --> 00:46:48,570
每当这些变量中的一个发生变化，

809
00:46:48,570 --> 00:46:51,540
你要刷新到磁盘或写入，

810
00:46:51,540 --> 00:46:53,580
在我们的例子中，在实验中，

811
00:46:53,580 --> 00:46:56,280
你写入到持久化模块。

812
00:46:57,960 --> 00:46:58,680
好的，还有。

813
00:46:58,950 --> 00:47:03,120
例如，当领导者通过 start 接受一个条目，

814
00:47:03,480 --> 00:47:06,330
并追加到它的本地日志中，

815
00:47:06,360 --> 00:47:08,700
它必须持久化那个条目。

816
00:47:13,480 --> 00:47:16,990
是的，是否持久化工作也是逐步进行的，

817
00:47:17,020 --> 00:47:19,600
比如一旦你获得了新的日志条目，

818
00:47:19,840 --> 00:47:23,090
你附加或获取整个状态，

819
00:47:23,090 --> 00:47:24,830
并将其重写到文件中。

820
00:47:24,830 --> 00:47:27,590
好的，在现实生活中，你要追加，

821
00:47:27,590 --> 00:47:29,270
你不会重写整个日志，

822
00:47:29,270 --> 00:47:31,100
你只需要在日志中附加一个条目，

823
00:47:31,100 --> 00:47:33,260
这是日志很酷的原因之一，

824
00:47:33,500 --> 00:47:38,030
因为你只需要在末尾递增地追加，

825
00:47:38,480 --> 00:47:41,210
在我们的实验中，

826
00:47:41,210 --> 00:47:42,260
整件事都是假的，

827
00:47:42,290 --> 00:47:44,780
持久化并不是真正的持久化，

828
00:47:45,080 --> 00:47:50,840
它在崩溃之间保持对象，

829
00:47:50,840 --> 00:47:52,640
因为崩溃也是假的，

830
00:47:52,640 --> 00:47:56,060
测试器会停止节点，重启它们，

831
00:47:56,060 --> 00:47:57,620
给它们一个新的状态，

832
00:47:59,840 --> 00:48:02,210
但是在真正的系统中，你会附加，

833
00:48:02,970 --> 00:48:04,440
所以日志应该是一个文件，

834
00:48:04,470 --> 00:48:06,030
你可以在文件中附加一个条目。

835
00:48:07,500 --> 00:48:08,010
谢谢。

836
00:48:14,260 --> 00:48:16,660
是的，你将不得不，

837
00:48:16,660 --> 00:48:19,390
一个真正的系统，如果你附加日志条目，

838
00:48:19,390 --> 00:48:21,670
你的第一个附加日志条目，然后响应，

839
00:48:21,880 --> 00:48:23,170
所以，在附加条目中，

840
00:48:23,350 --> 00:48:25,540
如果你更新日志，

841
00:48:25,840 --> 00:48:28,790
所以，如果追加条目在跟随者上，

842
00:48:28,820 --> 00:48:30,590
接收一组新的日志条目，

843
00:48:30,590 --> 00:48:33,680
它会将它们附加到本地持久化日志中，

844
00:48:33,740 --> 00:48:34,970
然后它可以回复，

845
00:48:34,970 --> 00:48:38,540
因为在附加之前做出回应是错的，

846
00:48:38,540 --> 00:48:41,660
因为那样你可能会失去，

847
00:48:41,930 --> 00:48:43,190
如果你在追加之前响应，

848
00:48:43,190 --> 00:48:44,480
你可能会进入一种情况，

849
00:48:44,480 --> 00:48:47,420
刚好在真正的追加发生前，

850
00:48:47,420 --> 00:48:48,080
你崩溃了，

851
00:48:48,290 --> 00:48:51,020
所以你没有持久化日志条目，

852
00:48:51,200 --> 00:48:52,820
所以你会，

853
00:48:52,940 --> 00:48:55,340
你可能会丢失提交的条目。

854
00:49:00,250 --> 00:49:00,790
好的?

855
00:49:02,620 --> 00:49:04,690
好的，那么服务恢复呢，

856
00:49:05,170 --> 00:49:07,300
所以服务保持它自己的状态，

857
00:49:07,330 --> 00:49:09,190
例如，在实验 3 中，

858
00:49:09,190 --> 00:49:10,930
你实现一个键值存储，

859
00:49:11,320 --> 00:49:17,800
键值存储维护从键到值的 hash 映射，

860
00:49:17,950 --> 00:49:20,590
你需要重放那些状态。

861
00:49:21,160 --> 00:49:25,480
同样地，它有两种可能的方法，

862
00:49:25,870 --> 00:49:30,970
策略 1 是重放日志以重建状态，

863
00:49:34,190 --> 00:49:37,550
所以，基本上，

864
00:49:37,700 --> 00:49:40,220
这与上一张幻灯片中的策略 1 有些类似，

865
00:49:40,490 --> 00:49:41,960
你使用日志，

866
00:49:41,990 --> 00:49:44,630
重放日志中的所有条目，

867
00:49:44,630 --> 00:49:48,140
这应该创造出完全相同的状态，

868
00:49:48,500 --> 00:49:52,400
像以前一样，

869
00:49:52,430 --> 00:49:57,440
因为这种复制状态机方法的全部意义是，

870
00:49:57,830 --> 00:50:01,670
所有操作按整体顺序执行，

871
00:50:01,670 --> 00:50:03,080
操作没有[副作用]，

872
00:50:03,170 --> 00:50:05,270
所以如果你从同样的状态开始，

873
00:50:05,510 --> 00:50:07,520
然后重放所有的操作，

874
00:50:07,520 --> 00:50:09,410
你应该获得完全相同的状态，

875
00:50:09,530 --> 00:50:10,880
在任何其他节点，

876
00:50:12,480 --> 00:50:13,890
所以这是一种可能，

877
00:50:14,100 --> 00:50:16,980
这是重建状态的一种方式。

878
00:50:24,400 --> 00:50:26,260
当然，这很昂贵，

879
00:50:26,320 --> 00:50:30,100
如果这项服务已经运行了几年，

880
00:50:30,460 --> 00:50:34,540
然后你必须从开始时间重放日志，

881
00:50:34,540 --> 00:50:36,970
这并不是那么[令人向往]。

882
00:50:37,570 --> 00:50:42,190
所以人们并不遵循策略 1 ，

883
00:50:42,310 --> 00:50:43,840
而是遵循另一种策略，

884
00:50:43,840 --> 00:50:46,450
我们制作周期性的快照。

885
00:50:47,350 --> 00:50:49,240
这样做有两个原因，

886
00:50:49,510 --> 00:50:53,530
一个是以过去的方式重建服务状态，

887
00:50:53,650 --> 00:50:55,180
这样做的第二个原因是，

888
00:50:55,180 --> 00:50:58,420
为了能够压缩日志，

889
00:50:58,450 --> 00:51:04,960
甚至 raft 状态本身可以裁剪，

890
00:51:05,050 --> 00:51:07,240
从[前缀开始]可以裁剪。

891
00:51:07,830 --> 00:51:09,480
基本的[]是，

892
00:51:09,780 --> 00:51:12,570
如果应用程序运行了一段时间，

893
00:51:12,570 --> 00:51:16,590
它应用了前一千个操作或前一百万个操作，

894
00:51:16,830 --> 00:51:20,100
那么状态构建了那个点，

895
00:51:21,420 --> 00:51:29,440
这些状态将包含到 i 的所有操作，

896
00:51:30,900 --> 00:51:34,680
i 可能是一千或者一百万，无论什么，

897
00:51:35,070 --> 00:51:38,070
所以，考虑的一种方式是，

898
00:51:38,070 --> 00:51:45,240
状态复制和日志复制或重放之间存在[二元性]，

899
00:51:45,330 --> 00:51:49,710
你可以在一千次操作后保存状态，

900
00:51:49,710 --> 00:51:51,360
然后你得到完全相同的东西，

901
00:51:51,360 --> 00:51:56,580
重做从 0 到[]的每一次操作。

902
00:51:57,640 --> 00:51:59,770
这就意味着，

903
00:51:59,770 --> 00:52:01,030
一旦你有了快照，

904
00:52:01,030 --> 00:52:04,780
你将快照以持久状态存储在磁盘上，

905
00:52:05,110 --> 00:52:08,380
你可以裁剪，

906
00:52:08,380 --> 00:52:13,170
你可以通过 i 裁剪日志。

907
00:52:16,790 --> 00:52:19,700
所以，这允许你控制日志的大小，

908
00:52:19,760 --> 00:52:25,460
定期请求服务器执行快照，

909
00:52:25,460 --> 00:52:27,560
然后服务告诉 raft 库，

910
00:52:27,560 --> 00:52:29,630
是的，我已经通过 i 做了快照，

911
00:52:29,660 --> 00:52:31,190
然后 raft 可以说好的，

912
00:52:31,250 --> 00:52:34,940
我只需要记住直到 i 的任何东西，

913
00:52:35,580 --> 00:52:38,850
当然，这意味着快照必须存储在稳定存储上。

914
00:52:45,050 --> 00:52:46,730
这对恢复也有好处，

915
00:52:46,730 --> 00:52:49,040
这使我们的恢复方案变得更加复杂，

916
00:52:49,040 --> 00:52:50,900
比我在上一张幻灯片中描述的，

917
00:52:50,900 --> 00:52:52,490
它必须发生的是，

918
00:52:52,880 --> 00:52:58,580
当跟随者在快速重启后回来时，

919
00:52:58,580 --> 00:53:00,440
它加载它的持久化状态，

920
00:53:00,440 --> 00:53:02,300
它包括持久化状态，

921
00:53:02,300 --> 00:53:03,950
我们在上一张幻灯片中说的，

922
00:53:03,950 --> 00:53:05,060
这些信息，

923
00:53:05,600 --> 00:53:09,650
但是它的最近的快照，

924
00:53:10,040 --> 00:53:13,370
安装最近的，加载快照到内存中，

925
00:53:13,370 --> 00:53:14,240
服务所做的。

926
00:53:14,720 --> 00:53:17,570
然后我们可以重放任何日志条目，

927
00:53:17,570 --> 00:53:19,460
为了让跟随者成为最新的。

928
00:53:20,630 --> 00:53:21,410
好的?

929
00:53:29,350 --> 00:53:30,460
对于这个，有什么问题吗？

930
00:53:31,560 --> 00:53:34,440
我有一个问题，

931
00:53:34,440 --> 00:53:37,350
我不确定我能不能说得很清楚，

932
00:53:37,650 --> 00:53:41,560
但是我想，在我的印象中，

933
00:53:41,560 --> 00:53:46,120
所以我想这是不是打破了一些抽象层，

934
00:53:46,600 --> 00:53:51,520
以前存在于 raft 上的应用程序和 raft 本身之间，

935
00:53:51,520 --> 00:53:54,730
因为它现在需要理解状态机是如何，

936
00:53:54,820 --> 00:53:56,800
比如如何将命令应用到状态机，

937
00:53:56,800 --> 00:54:01,390
而不是只是把命令给一些外部状态机。

938
00:54:01,570 --> 00:54:04,330
是的，很好的观察，

939
00:54:04,360 --> 00:54:09,190
当然，这里有一些，

940
00:54:10,140 --> 00:54:12,960
raft 库和服务必须放在一起，

941
00:54:13,520 --> 00:54:16,310
因为首先，（如果）服务撒谎，

942
00:54:16,310 --> 00:54:19,190
它给出关于应用到什么程度的错误信息，

943
00:54:19,190 --> 00:54:21,380
然后我们将得到不一致的结果，

944
00:54:21,380 --> 00:54:23,870
我们不会假设谎言，

945
00:54:23,870 --> 00:54:25,310
但很明显情况就是这样，

946
00:54:25,430 --> 00:54:29,540
服务和 raft 库必须合作。

947
00:54:30,240 --> 00:54:34,230
而且你可以使用抽象[违规]，

948
00:54:34,230 --> 00:54:37,230
我认为他们这样做的原因是

949
00:54:37,230 --> 00:54:41,250
限制我们必须维护的 raft 库的状态数量，

950
00:54:41,790 --> 00:54:44,820
否则， raft 库不知道什么时候可以裁剪日志。

951
00:54:45,560 --> 00:54:47,630
所以没有办法绕过它，

952
00:54:47,630 --> 00:54:49,400
服务会告诉它，

953
00:54:49,400 --> 00:54:51,680
比如，我有一个通过 i 的快照，

954
00:54:51,710 --> 00:54:55,790
所以，你可以删除从 0 到 i 的日志条目。

955
00:54:57,840 --> 00:54:58,920
你会看到，

956
00:54:58,920 --> 00:55:01,710
所以这可能是一个很好的点，

957
00:55:01,710 --> 00:55:03,750
这将在 2d 中出现，

958
00:55:03,750 --> 00:55:10,080
实验 2d 将完全围绕快照和日志压缩，

959
00:55:10,080 --> 00:55:11,460
正如论文上所说的。

960
00:55:11,940 --> 00:55:15,990
这里必须有一个 API ，

961
00:55:16,020 --> 00:55:19,200
在服务器和 raft 之间，进行协作，

962
00:55:19,230 --> 00:55:21,720
基本上在 2a 和 2b 中，

963
00:55:21,720 --> 00:55:23,880
甚至在 2c 中，

964
00:55:23,880 --> 00:55:25,470
这个 API 是非常简单的，

965
00:55:25,770 --> 00:55:28,080
唯一存在的 API 是

966
00:55:28,080 --> 00:55:31,520
在 apply channel 上传递日志消息，

967
00:55:31,520 --> 00:55:34,910
几乎没有任何东西从服务到 raft ，

968
00:55:34,910 --> 00:55:37,100
除了服务可能会执行 start ，

969
00:55:37,370 --> 00:55:42,740
raft 使用 start 在日志中添加一个条目。

970
00:55:43,440 --> 00:55:45,660
在 2d 中，

971
00:55:45,810 --> 00:55:49,200
必须有更多的 API ，

972
00:55:49,200 --> 00:55:52,410
在服务和 raft 库之间，

973
00:55:53,040 --> 00:55:54,090
事实证明，

974
00:55:54,330 --> 00:55:57,030
你可以使用很多可能的方式设计这个 API ，

975
00:55:57,030 --> 00:55:58,500
有很多方法可以做到这一点，

976
00:55:58,530 --> 00:55:59,790
有很多方法，

977
00:55:59,790 --> 00:56:03,600
这篇论文并没有列出你应该使用什么 API ，

978
00:56:03,600 --> 00:56:05,790
论文没有提到这个，

979
00:56:06,240 --> 00:56:08,610
所以这取决于你，

980
00:56:08,730 --> 00:56:09,720
有时取决于我们，

981
00:56:09,720 --> 00:56:10,920
弄清楚 API ，

982
00:56:10,920 --> 00:56:14,220
为了能够做 2d ，

983
00:56:14,220 --> 00:56:18,150
我们必须在服务和 raft 之间声明一个 API 。

984
00:56:18,650 --> 00:56:19,970
你会看到，

985
00:56:19,970 --> 00:56:21,470
你今天所做的，

986
00:56:21,470 --> 00:56:25,160
那个 API 有一些[]，

987
00:56:25,160 --> 00:56:29,210
可能和你想象的不一样，

988
00:56:29,960 --> 00:56:33,320
我们必须选择一个 API ，

989
00:56:33,320 --> 00:56:39,950
在那个 API 中，一个操作叫做[条件安装]，

990
00:56:40,190 --> 00:56:43,310
它的语义，

991
00:56:43,310 --> 00:56:48,650
允许你以原子的方式修改 raft 状态和服务状态，

992
00:56:48,650 --> 00:56:49,970
在一个操作中。

993
00:56:51,060 --> 00:56:55,380
从某种程度上说，这个操作存在，

994
00:56:55,620 --> 00:57:01,060
用来限制抽象边界。

995
00:57:03,300 --> 00:57:03,810
好的?

996
00:57:04,460 --> 00:57:06,050
事实证明，你可以用不同的方式做到这一点，

997
00:57:06,050 --> 00:57:06,860
你并不需要，

998
00:57:06,890 --> 00:57:08,990
你可以用不同的方式写它，

999
00:57:08,990 --> 00:57:09,950
但是我们，

1000
00:57:10,310 --> 00:57:12,680
[]是一种更简单的方法。

1001
00:57:13,550 --> 00:57:15,380
但它会在 2d 后变得更加清晰。

1002
00:57:15,380 --> 00:57:16,400
你会发现，

1003
00:57:16,400 --> 00:57:20,810
在服务和 raft 之间存在某种互动，

1004
00:57:20,810 --> 00:57:22,400
在某种程度上，它们必须一起。

1005
00:57:28,700 --> 00:57:29,390
你如何重复，

1006
00:57:29,390 --> 00:57:32,240
当 raft 在快照进程中与服务通信时，

1007
00:57:32,480 --> 00:57:36,380
所以，快照是由服务驱动的，

1008
00:57:37,020 --> 00:57:39,660
所以服务每隔一段告诉 raft ，

1009
00:57:40,050 --> 00:57:42,480
我做了一个快照，这是我的快照，

1010
00:57:42,840 --> 00:57:46,050
这是一个包括通过 i 的所有操作的快照，

1011
00:57:46,800 --> 00:57:52,650
然后 raft 写入快照并裁剪日志到 i ，

1012
00:57:52,800 --> 00:57:55,500
并将所有这些信息写入磁盘。

1013
00:57:57,500 --> 00:58:00,920
这就是正常操作所有发生的事情，

1014
00:58:01,040 --> 00:58:03,410
定期快照。

1015
00:58:04,130 --> 00:58:06,020
然后是另一种情况，

1016
00:58:06,020 --> 00:58:09,140
你必须考虑当重启发生时。

1017
00:58:09,650 --> 00:58:11,360
所以，当跟随者重新启动时，

1018
00:58:11,360 --> 00:58:15,680
它是从持久化状态重启的，

1019
00:58:15,680 --> 00:58:17,360
所以包括它的快照，

1020
00:58:18,080 --> 00:58:20,480
所以，当跟随者重新启动时，

1021
00:58:20,480 --> 00:58:24,950
从一个持久化磁盘加载快照，

1022
00:58:24,950 --> 00:58:28,280
并重新构建应用程序状态，即键值存储，

1023
00:58:28,490 --> 00:58:29,960
你们将在实验 3 中完成这项工作，

1024
00:58:29,960 --> 00:58:31,430
这不是实验 2 的问题。

1025
00:58:32,140 --> 00:58:35,320
实验 2 唯一会有问题的是，

1026
00:58:35,350 --> 00:58:38,950
因为追随者，

1027
00:58:42,290 --> 00:58:44,660
因为日志被裁剪，

1028
00:58:44,660 --> 00:58:48,710
比如不是在日志中包含 0 到 i 的所有条目，

1029
00:58:49,260 --> 00:58:52,020
加上更多， i 到 n ，

1030
00:58:52,680 --> 00:58:56,130
日志从 i 到 n 被裁剪，

1031
00:58:57,760 --> 00:59:00,520
这是日志压缩的一部分，

1032
00:59:01,030 --> 00:59:02,860
但这也意味着，

1033
00:59:02,890 --> 00:59:04,870
如果跟随者远远落后，

1034
00:59:04,900 --> 00:59:07,180
例如，新节点加入系统，

1035
00:59:07,360 --> 00:59:12,760
并且没有日志的开头，也没有快照，

1036
00:59:13,350 --> 00:59:18,600
然后， raft 必须将快照传递给那个跟随者，

1037
00:59:19,460 --> 00:59:20,210
所以，在这种情况下，

1038
00:59:20,210 --> 00:59:22,280
跟随者是在 i 之前，

1039
00:59:22,610 --> 00:59:27,530
因为重新加入 raft 集群，

1040
00:59:27,650 --> 00:59:33,660
领导者必须设置快照给跟随者，

1041
00:59:33,660 --> 00:59:35,310
而跟随者从那里开始。

1042
00:59:36,280 --> 00:59:37,780
这一点将在 2d 中显现出来，

1043
00:59:37,780 --> 00:59:40,510
所以会有一个额外的 RPC ，

1044
00:59:40,540 --> 00:59:45,070
称为快照 RPC 或安装快照 RPC ，

1045
00:59:45,070 --> 00:59:46,690
这一点在论文中得到了描述，

1046
00:59:46,720 --> 00:59:48,790
然后你将在 2d 中实现。

1047
00:59:49,810 --> 00:59:53,420
事实上，这给我带来了一个好的观点，

1048
00:59:54,040 --> 00:59:57,230
让我去[]，

1049
00:59:57,230 --> 00:59:59,060
把我带到了家庭作业的问题上，

1050
00:59:59,210 --> 01:00:10,240
这是[等效]图 2 的安装快照 RPC ，

1051
01:00:10,240 --> 01:00:12,490
然后快照 RPC ，

1052
01:00:12,490 --> 01:00:17,200
你必须在 2d 中实现，

1053
01:00:17,560 --> 01:00:19,780
出现的一个问题是，

1054
01:00:19,780 --> 01:00:23,620
在今天的家庭作业问题中，

1055
01:00:23,770 --> 01:00:26,530
在 raft 是不可能的，

1056
01:00:26,530 --> 01:00:29,500
避免它的是不可能的，

1057
01:00:29,650 --> 01:00:31,810
状态机回滚，

1058
01:00:32,290 --> 01:00:34,990
比如，领导者可能发送，

1059
01:00:34,990 --> 01:00:38,620
也许一个旧的快照出现在一个跟随者那里，

1060
01:00:39,010 --> 01:00:43,810
这是否可能，如果可能，

1061
01:00:43,810 --> 01:00:46,690
如果跟随者安装那个快照，

1062
01:00:46,690 --> 01:00:49,690
然后隐式地回滚状态机，

1063
01:00:49,750 --> 01:00:51,790
也许它已经看到了更多信息，

1064
01:00:52,390 --> 01:00:54,610
当然这是不对的，

1065
01:00:54,610 --> 01:00:55,990
所以问题是，

1066
01:00:56,290 --> 01:00:58,390
raft 是如何绕过它的，

1067
01:00:58,720 --> 01:01:03,460
所以也许这里可以暂停一下，

1068
01:01:03,460 --> 01:01:09,370
你可以对作业问题进行几分钟的讨论，

1069
01:01:09,580 --> 01:01:10,930
然后我们回来，

1070
01:01:11,110 --> 01:01:14,620
我们将更多地讨论有关快照的内容。

1071
01:01:16,790 --> 01:01:18,560
Lily ，怎么样？

1072
01:01:19,470 --> 01:01:24,090
Lily 不在，不如我试试。

1073
01:01:24,360 --> 01:01:32,620
等一下，我得让你来主持，

1074
01:01:32,650 --> 01:01:33,610
然后你就可以了，

1075
01:01:35,320 --> 01:01:36,670
好的，你现在是主持人了。

1076
01:01:37,060 --> 01:01:38,320
好的。

1077
01:02:06,930 --> 01:02:08,310
好的，应该好了。

1078
01:02:08,400 --> 01:02:10,560
好的，谢谢。

1079
01:08:06,790 --> 01:08:09,790
我会继续，让你做主持人。

1080
01:08:09,820 --> 01:08:11,110
太好了，谢谢。

1081
01:08:35,730 --> 01:08:37,320
让我看看，分享我的屏幕。

1082
01:08:54,160 --> 01:08:56,230
好的，所有人在线了吗，

1083
01:08:59,980 --> 01:09:00,880
我们继续，

1084
01:09:00,880 --> 01:09:03,100
有人能回答就好了。

1085
01:09:05,080 --> 01:09:07,210
好的，我听到了。

1086
01:09:07,630 --> 01:09:08,200
好的，很好，

1087
01:09:08,260 --> 01:09:11,050
我听说，有时候人们，

1088
01:09:11,050 --> 01:09:12,280
因为这里有分组会议室，

1089
01:09:12,280 --> 01:09:14,050
[]很快就中断了，

1090
01:09:15,280 --> 01:09:22,040
不过，助教[]会议室[]，

1091
01:09:23,080 --> 01:09:24,700
我不知道该怎么做，

1092
01:09:25,450 --> 01:09:29,050
我想容错的课程有点[不幸的]，

1093
01:09:29,050 --> 01:09:30,520
人们直接掉线了。

1094
01:09:32,590 --> 01:09:35,320
好的，所以任何，

1095
01:09:35,320 --> 01:09:39,520
我认为这一次的家庭作业问题是很合理的，

1096
01:09:39,520 --> 01:09:40,840
必须是这种情况，

1097
01:09:40,840 --> 01:09:44,620
你不能安装旧的快照，

1098
01:09:44,650 --> 01:09:48,940
因为项服务可能有更新的快照，

1099
01:09:48,940 --> 01:09:50,320
可能已经回复了客户端，

1100
01:09:50,320 --> 01:09:52,090
说操作成功了，

1101
01:09:52,640 --> 01:09:55,310
然后，如果你要恢复旧的快照，

1102
01:09:55,310 --> 01:09:57,590
然后你会回到状态，

1103
01:09:57,590 --> 01:09:58,340
客户机会看到，

1104
01:09:58,340 --> 01:10:00,170
这里有旧版本的服务器，

1105
01:10:00,170 --> 01:10:02,060
所以这肯定不是合法的，

1106
01:10:02,810 --> 01:10:04,490
所以有一点，

1107
01:10:04,550 --> 01:10:06,260
你应该拒绝所有快照，

1108
01:10:06,260 --> 01:10:08,540
但你必须稍微小心一点，

1109
01:10:08,540 --> 01:10:12,950
如果跟随者的日志超出了快照的范围，

1110
01:10:12,950 --> 01:10:17,390
你必须将剩余的部分保留在日志中，

1111
01:10:17,720 --> 01:10:20,510
因为你已经向领导者承诺了，

1112
01:10:20,510 --> 01:10:22,220
你已经接受了一条消息，

1113
01:10:22,220 --> 01:10:25,970
所以，你不能删除其余的日志，

1114
01:10:25,970 --> 01:10:29,990
那些不是快照所覆盖的。

1115
01:10:30,710 --> 01:10:31,220
好的?

1116
01:10:35,210 --> 01:10:38,210
好的，让我回来。

1117
01:10:41,220 --> 01:10:42,960
我们有个问题。

1118
01:10:42,990 --> 01:10:44,280
好的，继续。

1119
01:10:44,890 --> 01:10:47,860
所以在论文上说，

1120
01:10:47,890 --> 01:10:50,290
如果跟随者接收到快照，

1121
01:10:50,470 --> 01:10:52,360
这是它的日志的前缀，

1122
01:10:53,620 --> 01:10:58,900
由快照覆盖的日志条目被删除，

1123
01:10:58,900 --> 01:10:59,950
但其余的都保留下来。

1124
01:11:00,010 --> 01:11:00,880
是的。

1125
01:11:01,150 --> 01:11:03,250
在这种情况下，

1126
01:11:04,480 --> 01:11:09,250
是否状态机不会被覆盖，在这种情况下。

1127
01:11:09,920 --> 01:11:11,480
好的，有趣的问题是，

1128
01:11:11,480 --> 01:11:17,630
快照如何与状态机通信，

1129
01:11:17,630 --> 01:11:19,640
正如你将在实验 3 中看到的，

1130
01:11:19,640 --> 01:11:20,990
它通过 apply channel ，

1131
01:11:22,080 --> 01:11:26,640
所以，状态机通过 apply channel 获得一个快照，

1132
01:11:27,090 --> 01:11:29,850
然后它来做正确的事情。

1133
01:11:32,030 --> 01:11:32,570
好的。

1134
01:11:33,060 --> 01:11:33,420
好的?

1135
01:11:36,370 --> 01:11:37,150
好的，很好。

1136
01:11:37,240 --> 01:11:39,970
我有一个后续的问题，抱歉，

1137
01:11:40,270 --> 01:11:41,740
虽然我有一点，

1138
01:11:41,740 --> 01:11:43,000
这对我来说是有意义的，

1139
01:11:43,060 --> 01:11:44,650
让我感到困惑的是，

1140
01:11:44,650 --> 01:11:51,970
在图 13 中，方框描述安装快照 RPC ，

1141
01:11:53,000 --> 01:11:54,860
在第 6 条，它说，

1142
01:11:54,890 --> 01:11:59,480
如果现有日志条目与最新包含的条目有相同的索引和 term ，

1143
01:12:04,890 --> 01:12:07,900
稍等，我可能看错了。

1144
01:12:08,050 --> 01:12:10,450
好的，你先想着它怎么样，看看。

1145
01:12:10,450 --> 01:12:13,360
（如果）我有问题，我会再问。

1146
01:12:13,360 --> 01:12:14,080
我会把它[离线]，

1147
01:12:14,080 --> 01:12:15,670
如果你需要的话，我们在课后做。

1148
01:12:16,900 --> 01:12:19,360
好的，我想回去几分钟，

1149
01:12:19,360 --> 01:12:20,350
我们剩下的，

1150
01:12:20,350 --> 01:12:22,420
讨论如何使用 raft ，

1151
01:12:22,780 --> 01:12:25,690
这是我们在这里已经讨论过的问题，

1152
01:12:27,500 --> 01:12:28,820
关于服务器，

1153
01:12:28,940 --> 01:12:31,850
所以，我再次将重点放在复制键值服务上，

1154
01:12:31,850 --> 01:12:33,440
这将是实验 3 的主题。

1155
01:12:34,130 --> 01:12:38,570
所以，让我们回到几乎第一张幻灯片上，

1156
01:12:38,570 --> 01:12:41,660
我在 raft 课程开始时画的，

1157
01:12:41,660 --> 01:12:46,760
这是我们的方框，与三个复制相对应，

1158
01:12:48,680 --> 01:12:54,330
每个复制都有分成两个部分，

1159
01:12:54,330 --> 01:12:55,650
一个是服务部分，

1160
01:13:01,180 --> 01:13:04,280
一个是 raft 库，

1161
01:13:04,280 --> 01:13:08,210
我们知道它们通过 apply channel 通信，

1162
01:13:08,660 --> 01:13:12,930
除了信息从 raft 流向服务。

1163
01:13:16,000 --> 01:13:20,730
所以，客户端与服务进行交互，

1164
01:13:20,730 --> 01:13:22,140
而不是直接使用 raft ，

1165
01:13:22,440 --> 01:13:24,030
所以我们这里有个客户端，

1166
01:13:24,580 --> 01:13:26,200
它发送操作，

1167
01:13:26,200 --> 01:13:28,570
比如 put 操作或 get 操作给服务，

1168
01:13:28,720 --> 01:13:30,970
服务接收这个操作，

1169
01:13:31,120 --> 01:13:36,660
它对那个操作调用 start ，

1170
01:13:36,660 --> 01:13:42,060
然后 raft 和其他 raft 库[聊天]，

1171
01:13:42,600 --> 01:13:44,340
消息可能回来，

1172
01:13:44,340 --> 01:13:45,990
在操作提交后的某个时刻，

1173
01:13:45,990 --> 01:13:48,360
然后 raft 会说，

1174
01:13:48,360 --> 01:13:50,850
好的，这个操作已经准备提交了，

1175
01:13:51,060 --> 01:13:52,560
通过 apply channel 发送它，

1176
01:13:52,680 --> 01:13:56,880
然后服务执行这个操作，并发回响应，

1177
01:13:56,880 --> 01:13:59,670
在它执行完操作后，向客户端返回响应，

1178
01:13:59,670 --> 01:14:05,460
好的， get 20 的值是这个，

1179
01:14:05,460 --> 01:14:08,280
所以这是一个 get 操作或 put ，

1180
01:14:09,500 --> 01:14:11,780
这是 get 的值，

1181
01:14:11,810 --> 01:14:14,090
或者 ok ， put 成功。

1182
01:14:14,660 --> 01:14:15,050
好的?

1183
01:14:15,750 --> 01:14:17,820
我们还在上一节课中发现，

1184
01:14:18,300 --> 01:14:20,280
可能是这样的，

1185
01:14:20,280 --> 01:14:24,060
客户端向服务发送 RPC ，

1186
01:14:24,060 --> 01:14:25,920
而 RPC 丢失了，

1187
01:14:26,040 --> 01:14:27,930
所以客户端必须重新发送，

1188
01:14:28,420 --> 01:14:30,370
在重新发送的时候，

1189
01:14:30,370 --> 01:14:32,350
领导者可能不再是领导者了。

1190
01:14:33,080 --> 01:14:34,160
所以在这种情况下，

1191
01:14:34,160 --> 01:14:36,560
它必须将自己重定向到另一个领导者，

1192
01:14:37,070 --> 01:14:38,930
所以这里有一些代码

1193
01:14:38,930 --> 01:14:40,130
关于考虑这件事的方法。

1194
01:14:40,620 --> 01:14:42,570
在客户端有一些代码，

1195
01:14:42,690 --> 01:14:46,410
对复制状态机有一些了解，

1196
01:14:46,410 --> 01:14:48,060
它维护着一些信息，

1197
01:14:48,060 --> 01:14:49,680
它维护着比如谁是领导者，

1198
01:14:49,980 --> 01:14:52,020
还有谁是其他的跟随者，

1199
01:14:52,540 --> 01:14:56,020
所以如果有必要，可以在它们之间切换。

1200
01:14:57,690 --> 01:14:58,320
我们也，

1201
01:14:58,320 --> 01:15:00,990
上一次我们谈到了它的可能性，

1202
01:15:00,990 --> 01:15:03,270
操作是可以重复的，

1203
01:15:03,270 --> 01:15:09,050
因为客户端可能会向服务发送一个 put 操作，

1204
01:15:09,350 --> 01:15:14,210
客户端没有收到响应，

1205
01:15:14,450 --> 01:15:16,100
但是服务收到了，

1206
01:15:16,100 --> 01:15:20,750
所以它遍历整个操作序列，

1207
01:15:20,750 --> 01:15:24,530
开始 raft 追加，

1208
01:15:24,530 --> 01:15:26,600
通过 raft 活动，

1209
01:15:26,600 --> 01:15:28,310
然后将其发送给 apply channel 。

1210
01:15:28,890 --> 01:15:31,620
所以，客户端可能会发送第二个消息，

1211
01:15:33,240 --> 01:15:36,540
对于重复，

1212
01:15:36,540 --> 01:15:40,860
可能也会通过 raft 库，

1213
01:15:40,860 --> 01:15:42,030
在 apply channel 中出现，

1214
01:15:42,030 --> 01:15:44,850
所以你必须做一些重复检测，

1215
01:15:44,850 --> 01:15:46,140
有多种方式可以做到，

1216
01:15:46,140 --> 01:15:47,850
但无论哪种方式，你都必须做重复检测。

1217
01:15:48,520 --> 01:15:51,910
所以，除了维护一些信息，

1218
01:15:51,910 --> 01:15:55,180
关于领导者和跟随者是谁，

1219
01:15:55,330 --> 01:15:57,850
put 和 get 也有一个 id ，

1220
01:15:58,340 --> 01:15:59,990
与之相关联的 id ，

1221
01:15:59,990 --> 01:16:02,840
我们将保留最后一个 id ，

1222
01:16:02,840 --> 01:16:04,580
它在试图通过，

1223
01:16:04,730 --> 01:16:07,160
它用来做重复检测。

1224
01:16:08,560 --> 01:16:11,110
这一小段代码通常被称为 clerk ，

1225
01:16:11,880 --> 01:16:14,760
clerk 与服务交互，

1226
01:16:14,760 --> 01:16:16,110
它会做一些工作，

1227
01:16:16,110 --> 01:16:18,510
与[]服务进行协作，

1228
01:16:18,510 --> 01:16:20,220
我们有多个客户端，

1229
01:16:20,870 --> 01:16:27,320
都有 clerk 库，就是一个 Go 包，

1230
01:16:27,560 --> 01:16:33,120
客户端使用 put 和 get 通过那个接口，

1231
01:16:33,120 --> 01:16:35,850
在 clerk 中维护这些 id ，

1232
01:16:36,150 --> 01:16:39,720
或者为外部的 put get 操作维持一个 id ，

1233
01:16:39,720 --> 01:16:42,510
还有关于谁是集群的一部分的信息。

1234
01:16:43,060 --> 01:16:43,540
好的?

1235
01:16:44,560 --> 01:16:45,340
这能理解吗？

1236
01:16:46,090 --> 01:16:47,710
这是一种基本的结构，

1237
01:16:47,710 --> 01:16:50,260
raft 如何[融入]一幅更大的图景。

1238
01:16:51,520 --> 01:16:54,820
一个总是被提出来的问题是，

1239
01:16:54,820 --> 01:16:56,950
保证是什么，

1240
01:16:56,980 --> 01:17:01,660
由服务和 clerk 一起向客户端做出的（保证）

1241
01:17:01,660 --> 01:17:03,220
关于这些 put 和 get 操作。

1242
01:17:05,040 --> 01:17:07,800
所以，这意味着什么是正确的标准。

1243
01:17:11,940 --> 01:17:15,570
到目前为止，我们描述的方式是，

1244
01:17:15,570 --> 01:17:17,010
我们对这个很草率，

1245
01:17:17,190 --> 01:17:18,840
或者我对这个很草率，

1246
01:17:19,200 --> 01:17:20,820
我说过，

1247
01:17:20,820 --> 01:17:23,770
应该像一台机器那样，

1248
01:17:32,820 --> 01:17:35,370
即使这样，定义也有一点不准确，

1249
01:17:35,370 --> 01:17:36,180
因为会发生什么，

1250
01:17:36,180 --> 01:17:40,290
如果两个客户端同时执行 put 或 get 操作，

1251
01:17:40,290 --> 01:17:43,740
这些操作的正确结果到底是什么，

1252
01:17:43,740 --> 01:17:45,960
所以我们需要更精确，

1253
01:17:45,990 --> 01:17:46,860
我觉得，

1254
01:17:47,190 --> 01:17:49,320
可能像一台机器是正确的直觉，

1255
01:17:49,320 --> 01:17:52,050
但我们需要更精确的定义。

1256
01:17:52,500 --> 01:17:56,370
这个定义在论文中的术语，

1257
01:17:56,460 --> 01:17:59,100
被称为线性一致性，

1258
01:18:04,410 --> 01:18:07,290
线性化规定了

1259
01:18:07,290 --> 01:18:11,340
put 和 get 操作可以返回的值，

1260
01:18:11,870 --> 01:18:15,260
特别是 put 返回操作，

1261
01:18:15,260 --> 01:18:16,550
以及 get 可以返回什么，

1262
01:18:17,250 --> 01:18:20,730
它表示，什么东西是允许返回的，

1263
01:18:20,730 --> 01:18:22,680
什么东西是不允许返回的，

1264
01:18:22,710 --> 01:18:24,570
与你的实现方式无关，

1265
01:18:24,840 --> 01:18:26,550
它只是纯粹的规范。

1266
01:18:27,660 --> 01:18:30,540
线性一致性由三个部分组成，

1267
01:18:31,530 --> 01:18:33,390
线性化一致性是指，

1268
01:18:33,390 --> 01:18:35,670
如果你看到一些操作序列，

1269
01:18:35,700 --> 01:18:37,590
其中一些正在执行，

1270
01:18:37,890 --> 01:18:38,820
必须是这种情况，

1271
01:18:38,820 --> 01:18:39,930
这里有一个整体顺序，

1272
01:18:40,080 --> 01:18:42,990
所以你可以按整体顺序安排所有的操作，

1273
01:18:52,350 --> 01:18:53,670
put 或 set 操作。

1274
01:18:55,730 --> 01:18:59,720
第二，它必须实时匹配，

1275
01:19:06,260 --> 01:19:07,580
我的意思是，

1276
01:19:07,580 --> 01:19:11,690
如果一个操作在第二个操作开始之前完成，

1277
01:19:12,520 --> 01:19:15,400
即使这些操作在不同的机器，

1278
01:19:15,400 --> 01:19:17,740
必须是这样，在这个整体顺序中，

1279
01:19:17,950 --> 01:19:21,160
第一个操作出现在第二个操作之前，

1280
01:19:24,280 --> 01:19:25,420
这能说得通吧，

1281
01:19:25,420 --> 01:19:26,950
如果它的行为像一台机器一样，

1282
01:19:26,950 --> 01:19:29,590
你在一个操作只有开始另一个操作，

1283
01:19:29,860 --> 01:19:34,300
那么一台机器将始终返回第一个操作的结果。

1284
01:19:34,630 --> 01:19:36,370
最后是读取操作，

1285
01:19:37,090 --> 01:19:38,320
就像我们的示例中，

1286
01:19:38,320 --> 01:19:41,140
键值服务器只有一个读取操作 get ，

1287
01:19:41,560 --> 01:19:50,190
但读操作应始终返回最后一次写入的结果。

1288
01:19:56,040 --> 01:19:57,360
所以在我们的例子中，

1289
01:19:57,360 --> 01:19:59,280
我们有 get 操作，

1290
01:19:59,280 --> 01:20:04,530
而 put 操作发生在它之前，

1291
01:20:04,530 --> 01:20:06,210
并且首先完成，

1292
01:20:06,210 --> 01:20:12,540
那么 get 操作应该观察到最后一次 put 。

1293
01:20:12,940 --> 01:20:13,480
好的?

1294
01:20:14,020 --> 01:20:17,560
所以这是三个条件，

1295
01:20:17,560 --> 01:20:21,340
用来确定系统是否具有线性一致性。

1296
01:20:21,990 --> 01:20:24,510
你也可以考虑线性一致性，

1297
01:20:24,510 --> 01:20:25,860
就像一台机器那样。

1298
01:20:26,530 --> 01:20:28,510
所以让我说得更具体一点，

1299
01:20:28,510 --> 01:20:29,830
因为这有一点抽象。

1300
01:20:30,610 --> 01:20:35,260
人们对线性一致性的思考方式

1301
01:20:35,260 --> 01:20:37,420
或者证明系统具有线性一致性

1302
01:20:37,420 --> 01:20:40,360
是查看历史或执行，

1303
01:20:40,630 --> 01:20:46,230
然后看看你是否能利用历史，

1304
01:20:46,230 --> 01:20:48,150
如果你能把它变成一个整体顺序，

1305
01:20:48,180 --> 01:20:52,110
即使这些操作可能是并发执行的。

1306
01:20:52,790 --> 01:20:55,970
让我给你们举一个例子，一个微不足道的例子，

1307
01:20:56,690 --> 01:21:00,920
假设我们有三个客户端 C1 C2 C3 ，

1308
01:21:01,250 --> 01:21:02,780
它们做一些 put 和 get ，

1309
01:21:03,390 --> 01:21:05,730
所以通常的方式，

1310
01:21:05,730 --> 01:21:09,150
它必须有操作开始的起点，

1311
01:21:09,900 --> 01:21:12,360
以及在操作结束时的终点。

1312
01:21:12,960 --> 01:21:18,060
所以，当客户端从服务获得响应时，

1313
01:21:18,840 --> 01:21:23,070
所以我们假设这个写操作到变量 x ，

1314
01:21:23,560 --> 01:21:24,670
我们给它写入 1 。

1315
01:21:25,830 --> 01:21:27,540
所以，客户端 1 在某个时刻开始，

1316
01:21:27,540 --> 01:21:30,060
写操作对变量 x 写入 1 ，

1317
01:21:30,390 --> 01:21:32,580
并在这里的某一时刻结束。

1318
01:21:33,330 --> 01:21:40,080
也许有第二个，写入 2 。

1319
01:21:40,600 --> 01:21:42,610
然后可能我们有所有的操作，

1320
01:21:42,610 --> 01:21:44,020
具有线性一致性是，

1321
01:21:44,020 --> 01:21:45,490
当操作同时发生时，

1322
01:21:45,490 --> 01:21:49,120
所以一些操作是在另一个操作完成之前开始的，

1323
01:21:49,120 --> 01:21:52,090
例如，我们可能具有以下操作，

1324
01:21:52,090 --> 01:21:53,440
客户端 2 执行读取操作，

1325
01:21:53,440 --> 01:21:54,910
在我们的情况下，是一个 get ，

1326
01:21:55,600 --> 01:21:57,790
是一个读取 x ，

1327
01:21:57,790 --> 01:21:59,980
并且这个操作返回的值是 2 。

1328
01:22:00,940 --> 01:22:03,670
然后我们遇到了类似的情况，

1329
01:22:03,670 --> 01:22:05,620
当客户端 3 开始一个操作，

1330
01:22:05,620 --> 01:22:09,960
一个读取操作，读取 x ，并返回 1 ，

1331
01:22:11,370 --> 01:22:13,980
让我把画得更清楚一点，

1332
01:22:15,660 --> 01:22:18,460
这个操作返回

1333
01:22:18,460 --> 01:22:21,910
在写入 2 操作结束前，

1334
01:22:22,180 --> 01:22:24,100
对于 Rx1 也是一样的，

1335
01:22:24,100 --> 01:22:25,780
然后出现的问题是，

1336
01:22:26,020 --> 01:22:29,410
这是线性一致性的执行吗。

1337
01:22:30,800 --> 01:22:32,480
如果是线性一致的，

1338
01:22:32,480 --> 01:22:33,680
那么这意味着，

1339
01:22:33,710 --> 01:22:35,720
这种情况也可以发生在一台机器上。

1340
01:22:37,000 --> 01:22:38,920
那么，这种情况会发生在一台机器上吗？

1341
01:22:39,940 --> 01:22:41,770
我们可以像抽象的思考它，

1342
01:22:41,770 --> 01:22:42,910
而不是真正地，

1343
01:22:45,220 --> 01:22:46,600
这是不是合法的结果，

1344
01:22:46,600 --> 01:22:50,980
我们需要看的是 C2 和 C3 的结果，

1345
01:22:51,220 --> 01:22:53,710
这是不是合法的执行。

1346
01:22:54,520 --> 01:22:56,500
我不确定，

1347
01:22:56,500 --> 01:22:57,580
我不知道这意味着什么，

1348
01:22:57,580 --> 01:23:01,420
write 花费这么长时间。

1349
01:23:03,030 --> 01:23:03,390
好的。

1350
01:23:03,390 --> 01:23:05,400
花费长时间带来的影响。

1351
01:23:06,070 --> 01:23:09,820
如果你从客户端的角度考虑，

1352
01:23:09,820 --> 01:23:12,490
它向服务发送请求，

1353
01:23:12,490 --> 01:23:13,960
所以这是写入的开始，

1354
01:23:14,550 --> 01:23:18,450
我在某个时刻从服务中得到返回值，

1355
01:23:18,450 --> 01:23:19,650
就是写入的结束。

1356
01:23:20,960 --> 01:23:22,910
所以在这中间发生了很多事情，

1357
01:23:22,910 --> 01:23:24,290
它传递给服务，

1358
01:23:24,290 --> 01:23:25,940
服务传递给 raft ，

1359
01:23:25,940 --> 01:23:28,370
raft 到 apply channel 等等，

1360
01:23:28,400 --> 01:23:29,270
发生了很多事情，

1361
01:23:29,300 --> 01:23:30,470
我们真正关心的是，

1362
01:23:30,470 --> 01:23:32,720
在某个时刻这个实现做了什么响应。

1363
01:23:34,120 --> 01:23:35,290
所以你可以想想，

1364
01:23:35,290 --> 01:23:37,450
这里有三个并发客户端，

1365
01:23:37,450 --> 01:23:39,850
它们发布了并发操作，

1366
01:23:39,850 --> 01:23:41,980
我们想知道这是否是合法的结果。

1367
01:23:44,900 --> 01:23:48,440
我认为这不可能发生在一台机器上，

1368
01:23:48,440 --> 01:23:56,990
因为写入 2 完成在读取开始之后，

1369
01:23:57,750 --> 01:23:59,850
哦，抱歉，是的，没错，

1370
01:23:59,940 --> 01:24:03,780
但是写操作应该在读操作之前发生，

1371
01:24:04,350 --> 01:24:06,960
在这种情况下，

1372
01:24:09,130 --> 01:24:12,010
它不会发生，如果写入开始，

1373
01:24:12,580 --> 01:24:16,540
如果写入完成在读取开始之前，是的。

1374
01:24:16,930 --> 01:24:20,950
是的，所以人们考虑的一种方式是，

1375
01:24:21,160 --> 01:24:22,120
我们可以移动，

1376
01:24:22,150 --> 01:24:24,370
我们必须构建一个整体顺序，

1377
01:24:24,700 --> 01:24:26,230
我们可以构建一个整体顺序，

1378
01:24:26,230 --> 01:24:28,240
所有的操作都排成一列，

1379
01:24:28,480 --> 01:24:30,820
那么这是一段有效的线性一致性历史。

1380
01:24:31,290 --> 01:24:33,870
所以，让我们来构建一个整体顺序，

1381
01:24:33,990 --> 01:24:36,150
然后回到你刚才问的这个问题，

1382
01:24:36,840 --> 01:24:40,470
所以这是一个整体顺序，

1383
01:24:41,240 --> 01:24:43,310
所以，我将首先执行写入操作（Wx1），

1384
01:24:43,520 --> 01:24:52,160
然后是 Rx1 ，然后是 Wx2 ，然后是 Rx2 。

1385
01:24:52,720 --> 01:24:53,620
这是一个整体顺序，

1386
01:24:53,620 --> 01:24:56,020
现在所有的操作都是按顺序进行的，

1387
01:24:56,660 --> 01:25:00,620
我们需要检查整体顺序是否正确，

1388
01:25:00,980 --> 01:25:03,290
对应于线性一致性定义，

1389
01:25:03,500 --> 01:25:04,580
它必须是这样的，

1390
01:25:04,580 --> 01:25:06,080
操作开始，

1391
01:25:06,700 --> 01:25:10,060
如果一个操作在某个操作之后开始，

1392
01:25:10,060 --> 01:25:12,280
结果是它在整体顺序中靠后。

1393
01:25:12,280 --> 01:25:13,840
所以我们来看看这个，

1394
01:25:14,370 --> 01:25:15,240
让我们来看看这个，

1395
01:25:15,240 --> 01:25:19,050
这个必须在 Wx1 之后开始，

1396
01:25:19,050 --> 01:25:21,630
这在整体顺序中是正确的，

1397
01:25:23,210 --> 01:25:29,170
Rx1 必须在 Wx1 之后开始，

1398
01:25:29,170 --> 01:25:31,690
因为它返回了这个值，

1399
01:25:31,690 --> 01:25:34,300
在整体顺序中，也是这样的，

1400
01:25:35,360 --> 01:25:38,210
Rx2 必须在 Wx2 之后开始，

1401
01:25:38,210 --> 01:25:41,760
因为它观察到这个写入的结果，

1402
01:25:41,790 --> 01:25:43,920
这也是好的，

1403
01:25:44,750 --> 01:25:45,560
我们可以，

1404
01:25:45,560 --> 01:25:47,120
一种考虑它的方式是，

1405
01:25:47,120 --> 01:25:49,190
即使它们以这种方式执行，

1406
01:25:49,190 --> 01:25:50,600
我们必须重新安排，

1407
01:25:50,600 --> 01:25:53,420
以符合整体顺序。

1408
01:25:54,140 --> 01:25:56,390
所以，如果我们考虑这个，

1409
01:25:56,510 --> 01:25:59,540
这是一个完全合法执行，

1410
01:26:00,140 --> 01:26:02,840
操作[]顺序，

1411
01:26:02,930 --> 01:26:05,360
就像是一台机器做的，

1412
01:26:05,360 --> 01:26:10,160
所以一台机器可以执行 Wx1 Rx1 Wx2 Rx2 ，

1413
01:26:10,460 --> 01:26:11,660
都是可以的。

1414
01:26:14,390 --> 01:26:14,990
好的?

1415
01:26:15,710 --> 01:26:17,960
所以，让我们考虑一下

1416
01:26:17,960 --> 01:26:19,850
非线性一致性的历史。

1417
01:26:20,720 --> 01:26:22,340
让我看看第二个，

1418
01:26:29,360 --> 01:26:32,750
我会回到第一个的，

1419
01:26:32,750 --> 01:26:35,720
别担心，如果还没有理解，

1420
01:26:35,960 --> 01:26:37,160
但这是另一个。

1421
01:26:37,520 --> 01:26:39,170
我有 C1 ，

1422
01:26:40,060 --> 01:26:43,240
同样的 Wx1 ，

1423
01:26:43,840 --> 01:26:48,670
然后这里是 Wx2 ，

1424
01:26:48,670 --> 01:26:56,750
然后会有一个读取 x1 ，

1425
01:26:57,730 --> 01:26:59,980
抱歉， Rx2 ，

1426
01:27:00,950 --> 01:27:04,100
然后我有 C2 C3

1427
01:27:04,670 --> 01:27:12,340
C3 开始另一个读取并返回 1 。

1428
01:27:14,610 --> 01:27:16,860
这里的[]是，

1429
01:27:17,310 --> 01:27:20,250
不可能构建一个整体顺序，

1430
01:27:20,280 --> 01:27:22,920
与线性一致性匹配，

1431
01:27:23,480 --> 01:27:26,120
一种方式，

1432
01:27:26,120 --> 01:27:29,930
一个指示是这个读取返回 x1 ，

1433
01:27:30,050 --> 01:27:33,110
在返回 2 的读取之后开始，

1434
01:27:33,790 --> 01:27:35,890
稍后我会把它说得更精确一点，

1435
01:27:35,890 --> 01:27:39,130
但在一个真正的单机系统中，

1436
01:27:39,160 --> 01:27:40,750
这不可能发生，

1437
01:27:40,750 --> 01:27:42,730
因为这意味着，

1438
01:27:42,730 --> 01:27:46,150
这个值在 RX2 和 RX1 之间发生了改变，

1439
01:27:46,450 --> 01:27:50,830
通过我们在白板上的几个操作，

1440
01:27:50,920 --> 01:27:52,270
情况必须是这样的，

1441
01:27:53,090 --> 01:27:56,150
这个 RX1 在那次写入之后发生，

1442
01:27:57,260 --> 01:28:01,820
而这次写入肯定是在那次写入之后发生的，

1443
01:28:02,090 --> 01:28:03,200
因为它们，

1444
01:28:03,200 --> 01:28:07,490
在那里，我们必须尊重 C1 单机顺序，

1445
01:28:08,360 --> 01:28:12,950
所以不可能把 RX1 放到整体顺序中，

1446
01:28:13,010 --> 01:28:18,860
根据这张图片，它应该在 Rx1 之后，

1447
01:28:19,420 --> 01:28:23,230
但这是不可能的，

1448
01:28:23,560 --> 01:28:26,260
因为如果它在 Rx1 之后，

1449
01:28:26,260 --> 01:28:28,480
也意味着在 Wx2 之后，

1450
01:28:28,510 --> 01:28:32,590
所以它一定是写入 2 ，而不是 1 。

1451
01:28:33,740 --> 01:28:35,690
所以这不是线性一致性的，

1452
01:28:35,720 --> 01:28:39,580
不是可线性化的执行历史。

1453
01:28:45,820 --> 01:28:47,410
另一种说法是，

1454
01:28:47,590 --> 01:28:50,080
这里的 Rx 返回的，

1455
01:28:50,110 --> 01:28:53,430
返回了旧的值，

1456
01:28:53,430 --> 01:28:54,690
这是不允许的，

1457
01:28:57,940 --> 01:28:59,620
如果机器行为像一台机器，

1458
01:28:59,620 --> 01:29:01,600
或者复制服务器的行为像一台机器。

1459
01:29:02,520 --> 01:29:04,140
所以我会回到这里，

1460
01:29:04,140 --> 01:29:06,660
在下周的课程上，

1461
01:29:06,660 --> 01:29:07,890
当我们谈到 zookeeper 时，

1462
01:29:08,160 --> 01:29:10,260
因为这是非常重要的，

1463
01:29:10,260 --> 01:29:11,730
这种线性一致性的概念，

1464
01:29:11,730 --> 01:29:14,400
在论文中出现，

1465
01:29:14,550 --> 01:29:17,640
这种旧值的概念也会出现。

1466
01:29:19,800 --> 01:29:21,600
因为我的时间快到了，

1467
01:29:21,600 --> 01:29:23,370
我下周再继续。

1468
01:29:24,540 --> 01:29:25,230
好的?

1469
01:29:29,260 --> 01:29:30,520
有什么更多的问题，

1470
01:29:30,520 --> 01:29:32,920
人们需要离开，请随意离开，

1471
01:29:33,040 --> 01:29:34,900
我希望你已经这么做了，

1472
01:29:35,320 --> 01:29:39,100
我不想你错过其他的课程。

1473
01:29:40,230 --> 01:29:42,560
这是不是一个考虑因素，

1474
01:29:42,560 --> 01:29:47,430
什么类型的一致性被认为是强一致性。

1475
01:29:47,640 --> 01:29:51,630
这被认为是强一致性，

1476
01:29:52,360 --> 01:29:57,280
对什么是强一致性的准确定义，

1477
01:29:58,360 --> 01:30:01,150
就像我们关于什么是强一致性的直觉是，

1478
01:30:01,150 --> 01:30:03,040
表现得像一台机器一样，

1479
01:30:03,040 --> 01:30:07,300
人们在技术文献中使用的准确定义就是线性一致性。

1480
01:30:12,420 --> 01:30:17,010
他们是如何决定这个性质，

1481
01:30:17,010 --> 01:30:19,590
比如他们为什么决定这个性质？

1482
01:30:19,830 --> 01:30:21,270
有几件事，

1483
01:30:21,270 --> 01:30:23,940
一个原因，

1484
01:30:23,940 --> 01:30:25,590
好的，所以这是有道理的，

1485
01:30:25,590 --> 01:30:27,780
如果你从这个角度来看，

1486
01:30:28,730 --> 01:30:29,780
你希望行为，

1487
01:30:29,780 --> 01:30:32,900
你希望复制系统的行为类似于单台计算机

1488
01:30:33,700 --> 01:30:35,290
或复制计算机，

1489
01:30:35,290 --> 01:30:36,910
并且你希望只允许输出

1490
01:30:36,910 --> 01:30:39,970
对应于单台计算机可以完成的执行，

1491
01:30:40,210 --> 01:30:44,260
线性一致性是非常直观的定义。

1492
01:30:45,020 --> 01:30:49,280
数据库世界也有一些其他术语，比如可串行化，

1493
01:30:49,280 --> 01:30:52,550
这也是一个将在后面的学期中出现的术语，

1494
01:30:52,910 --> 01:30:57,560
基本上线性一致性和串行化之间的唯一区别是，

1495
01:30:57,560 --> 01:31:01,010
可串行化不需要实时匹配。

1496
01:31:02,980 --> 01:31:06,310
所以，人们对强一致性有不同的定义，

1497
01:31:06,310 --> 01:31:10,540
如果你愿意，我们最有可能看到的就是线性一致性，

1498
01:31:10,540 --> 01:31:13,150
最接近于机器的行为，

1499
01:31:13,150 --> 01:31:15,160
复制机器像一台机器。

1500
01:31:20,750 --> 01:31:21,590
谢谢。

1501
01:31:21,770 --> 01:31:22,430
不用谢。

1502
01:31:24,760 --> 01:31:25,900
我有一个问题，

1503
01:31:27,530 --> 01:31:30,860
网络分区期间会发生什么的问题，

1504
01:31:31,880 --> 01:31:35,780
所以我知道，如果一个领导者完全被分隔了，

1505
01:31:36,020 --> 01:31:37,340
它们最终会[爬]出来，

1506
01:31:37,340 --> 01:31:42,350
但如果它们有一些跟随者的话，

1507
01:31:42,380 --> 01:31:43,910
它们将继续保持为领导者，

1508
01:31:44,480 --> 01:31:45,830
它们不能提交任何东西，

1509
01:31:45,830 --> 01:31:47,030
因为它们是少数，

1510
01:31:47,450 --> 01:31:48,410
它们将成为一位新的领导者，

1511
01:31:48,410 --> 01:31:48,890
它们将会，

1512
01:31:48,980 --> 01:31:53,770
那么，那个领导者会不会意识到，

1513
01:31:53,770 --> 01:31:55,420
也许它是一个旧的领导者，

1514
01:31:55,630 --> 01:31:57,100
或者我们只是假设，

1515
01:31:57,310 --> 01:31:59,620
最终如果分区消失，

1516
01:32:01,820 --> 01:32:02,810
它会修复，

1517
01:32:02,810 --> 01:32:05,600
因为我担心如果有客户端与旧的领导者交互，

1518
01:32:06,320 --> 01:32:07,550
那个客户端会做什么。

1519
01:32:09,450 --> 01:32:11,430
不，

1520
01:32:11,430 --> 01:32:14,040
好的，这是一个关于这张图片很好的问题，

1521
01:32:14,040 --> 01:32:14,940
希望这能有所帮助，

1522
01:32:15,560 --> 01:32:19,010
所以客户端访问这个节点，

1523
01:32:19,010 --> 01:32:19,970
比如谁是领导者，

1524
01:32:20,640 --> 01:32:21,480
你看这张图，

1525
01:32:21,510 --> 01:32:23,010
我再确认一下，你可以看到。

1526
01:32:23,010 --> 01:32:24,270
我可以看到。

1527
01:32:24,360 --> 01:32:26,670
我们假设第一个方框是领导者，

1528
01:32:26,790 --> 01:32:28,110
客户端访问了那个领导者，

1529
01:32:28,320 --> 01:32:30,840
那个领导者不能提交任何操作，

1530
01:32:31,690 --> 01:32:34,810
所以，它不会提交 apply channel 上的任何东西，

1531
01:32:34,810 --> 01:32:37,210
所以它永远不会对客户端做出回应，

1532
01:32:37,540 --> 01:32:40,960
因为它的操作没有被执行，

1533
01:32:41,660 --> 01:32:44,780
所以客户端只会重试，永远重试，

1534
01:32:46,230 --> 01:32:50,460
直到客户端可能尝试另一个，

1535
01:32:50,460 --> 01:32:54,700
其他跟随者之一，

1536
01:32:54,700 --> 01:32:58,540
它保持着，它也在组之中，

1537
01:32:58,880 --> 01:33:03,320
或者直到网络恢复，

1538
01:33:04,660 --> 01:33:06,790
然后领导者提交一个操作。

1539
01:33:06,970 --> 01:33:07,510
明白了，

1540
01:33:07,540 --> 01:33:10,540
等等，所以领导者不马上回复那些，

1541
01:33:10,540 --> 01:33:12,040
说我收到了你的请求，

1542
01:33:12,680 --> 01:33:14,240
还是要等到提交后。

1543
01:33:14,870 --> 01:33:18,140
不，在实验 3 中，客户端不知道提交，

1544
01:33:18,140 --> 01:33:20,030
直到处理了请求，

1545
01:33:20,640 --> 01:33:23,850
这意味着操作通过 raft 运行，

1546
01:33:23,850 --> 01:33:25,260
从 apply channel 出来，

1547
01:33:25,260 --> 01:33:26,940
并由服务执行。

1548
01:33:27,630 --> 01:33:28,290
好的。

1549
01:33:33,330 --> 01:33:33,750
这能理解吗？

1550
01:33:33,750 --> 01:33:36,450
是的，所以客户端可以实现一个超时，

1551
01:33:36,450 --> 01:33:38,340
在一段时间内，

1552
01:33:38,340 --> 01:33:39,930
它们没有收到提交，

1553
01:33:40,020 --> 01:33:42,420
也许我应该尝试另一个节点，

1554
01:33:42,600 --> 01:33:44,430
然后如果它得到了新的领导者

1555
01:33:44,430 --> 01:33:46,020
或跟随者变成新的领导者，

1556
01:33:46,200 --> 01:33:48,570
它就会恢复正常。

1557
01:33:48,570 --> 01:33:52,260
例如，那是这个 clerk 所做的，

1558
01:33:52,780 --> 01:33:56,470
服务之外的地方，做你刚才所说的。

1559
01:33:56,950 --> 01:34:00,460
明白了，好的，谢谢。

1560
01:34:01,070 --> 01:34:01,580
不用谢。

1561
01:34:02,410 --> 01:34:04,480
抱歉，你能再重复一遍吗， cleak 是怎么做的？

1562
01:34:05,640 --> 01:34:08,070
clerk 就是一个 stub ，

1563
01:34:08,070 --> 01:34:11,130
是一个客户端连接的小的库，

1564
01:34:11,400 --> 01:34:12,840
客户端调用 put 和 get ，

1565
01:34:13,170 --> 01:34:16,410
clert 是它交互的接口，

1566
01:34:16,410 --> 01:34:18,090
clerk 可以保留一些信息，

1567
01:34:18,630 --> 01:34:22,410
比如谁是 raft 集群的一部分，

1568
01:34:22,560 --> 01:34:25,170
谁是领导者，谁是跟随者，

1569
01:34:25,170 --> 01:34:27,360
至少它认为是领导者和跟随者，

1570
01:34:28,210 --> 01:34:32,260
当它向服务发送 RPC 时，

1571
01:34:32,260 --> 01:34:33,400
发送给领导者，

1572
01:34:33,400 --> 01:34:34,720
它认为的现任领导者，

1573
01:34:35,580 --> 01:34:38,790
当前的领导者，

1574
01:34:38,790 --> 01:34:40,080
领导者可能会回应说，

1575
01:34:40,080 --> 01:34:42,300
比如，嘿，我不是领导者，应该发送到其他地方，

1576
01:34:42,910 --> 01:34:46,060
然后，它会尝试其他（节点），并更新信息。

1577
01:34:46,640 --> 01:34:51,230
我们还将标记每个 put 和 get 操作，

1578
01:34:51,230 --> 01:34:52,550
它从客户端接收的，

1579
01:34:52,550 --> 01:34:54,710
并以唯一 id 发送到服务，

1580
01:34:55,130 --> 01:34:58,430
所以服务可以执行重复检测。

1581
01:34:59,460 --> 01:35:00,900
这些都是在实验 3 中出现的，

1582
01:35:00,900 --> 01:35:03,690
所以你会在那里看到，

1583
01:35:04,690 --> 01:35:06,520
在实验 2 中，没有真正的 clerk ，

1584
01:35:07,070 --> 01:35:10,820
因为测试在 raft 接口的上面，

1585
01:35:10,820 --> 01:35:13,130
并不是通过 clerk 交互，

1586
01:35:13,130 --> 01:35:15,200
但在实验 3 中，会通过 clerk 进行交互。

1587
01:35:16,320 --> 01:35:19,470
那么客户端如何生成唯一 id ，

1588
01:35:20,100 --> 01:35:21,930
我认为它们会彼此冲突。

1589
01:35:22,050 --> 01:35:24,000
随机的，很大的随机数字。

1590
01:35:25,660 --> 01:35:27,520
好的，所以我们只是猜测和希望，

1591
01:35:27,550 --> 01:35:31,090
而不是真正地保证，比如增量。

1592
01:35:31,300 --> 01:35:33,130
有一种方法可以让它更有保障，

1593
01:35:33,130 --> 01:35:37,030
例如，获取 IP 地址并附加一个随机数。

1594
01:35:41,070 --> 01:35:43,440
一个关于家庭作业的问题？

1595
01:35:43,560 --> 01:35:43,980
嗯。

1596
01:35:44,250 --> 01:35:46,530
所以我想它可以在时间回退，

1597
01:35:46,530 --> 01:35:47,700
比如我读论文，

1598
01:35:47,700 --> 01:35:51,420
它在第 12 页写着，

1599
01:35:51,420 --> 01:35:54,300
它说如果有冲突，

1600
01:35:54,300 --> 01:35:56,880
跟随者只需丢弃整个日志，

1601
01:35:56,880 --> 01:35:58,920
以及前面的快照，

1602
01:36:00,110 --> 01:36:02,210
所以我想知道为什么。

1603
01:36:02,330 --> 01:36:06,290
再一次，让我猜猜，

1604
01:36:06,290 --> 01:36:09,170
我不太清楚你说的到底是什么，

1605
01:36:09,170 --> 01:36:10,160
我得再查一下。

1606
01:36:10,460 --> 01:36:12,320
哦，在第 12 页，

1607
01:36:12,320 --> 01:36:16,040
在第 12 页的末尾，这里的第二栏，

1608
01:36:16,040 --> 01:36:17,750
倒数第二段。

1609
01:36:18,230 --> 01:36:21,290
所以日志可以回退，但状态机不能。

1610
01:36:21,500 --> 01:36:25,340
哦，日志可以回退，但状态机不能，

1611
01:36:25,460 --> 01:36:28,910
状态机是提交的条目，是吗。

1612
01:36:30,320 --> 01:36:32,690
是的，日志可以回退，

1613
01:36:32,690 --> 01:36:36,140
因为未提交的条目，我们可以回退，

1614
01:36:36,140 --> 01:36:38,630
就像我们之前谈到的擦除问题。

1615
01:36:40,560 --> 01:36:45,180
好的，所以日志可以回退，而不是状态机，

1616
01:36:45,180 --> 01:36:48,150
就是你已经做出的提交。

1617
01:36:48,390 --> 01:36:51,390
是的，日志永远不会回退，

1618
01:36:51,420 --> 01:36:53,700
永远不会[]已经提交的操作，

1619
01:36:53,700 --> 01:36:56,760
它只能擦除未提交的操作。

1620
01:36:56,790 --> 01:36:59,490
是的，没错，好的。

1621
01:36:59,580 --> 01:37:00,930
所以，这是你要问的问题。

1622
01:37:01,620 --> 01:37:04,200
我可以问一个关于第三张幻灯片的问题吗？

1623
01:37:04,380 --> 01:37:04,860
是的。

1624
01:37:04,860 --> 01:37:06,660
在这个之前的那个，

1625
01:37:08,050 --> 01:37:12,100
所以你能快速介绍一下吗，

1626
01:37:12,100 --> 01:37:14,830
在写入时， matchIndex 是怎么做的，

1627
01:37:14,860 --> 01:37:17,320
比如，当 S2 与 S3 通信时。

1628
01:37:17,960 --> 01:37:18,320
好的。

1629
01:37:18,350 --> 01:37:20,990
所以它从 0 开始。

1630
01:37:21,230 --> 01:37:24,290
是的，所以 S2 和谁通信？

1631
01:37:24,970 --> 01:37:25,720
S3.

1632
01:37:25,930 --> 01:37:27,040
是的，所以，好的，

1633
01:37:27,040 --> 01:37:30,160
所以这里的 matchIndex 是 0 ，

1634
01:37:30,160 --> 01:37:32,470
所以， m 写下来是 0 。

1635
01:37:33,350 --> 01:37:33,980
嗯。

1636
01:37:34,460 --> 01:37:36,020
好的，然后你返回，

1637
01:37:36,020 --> 01:37:37,700
所以 matchIndex 保持为 0 。

1638
01:37:38,940 --> 01:37:39,510
好的。

1639
01:37:40,280 --> 01:37:42,470
什么都没有，但现在它可以回退，

1640
01:37:42,470 --> 01:37:43,520
那么这意味着什么，

1641
01:37:45,800 --> 01:37:48,380
这意味着它发送什么，

1642
01:37:48,380 --> 01:37:52,700
它为索引 13 发送心跳，

1643
01:37:53,290 --> 01:38:02,390
S3 回应 ok ，

1644
01:38:02,780 --> 01:38:03,710
所以这意味着，

1645
01:38:03,710 --> 01:38:07,340
S3 是最新的，直到 13 ，

1646
01:38:07,340 --> 01:38:10,670
它的 nextIndex 预计是 14 。

1647
01:38:11,500 --> 01:38:14,020
所以， S2 现在知道，

1648
01:38:14,020 --> 01:38:18,520
在这个消息之后，它的日志直到 13 都匹配。

1649
01:38:19,880 --> 01:38:21,920
它是到 13 还是到 12 ？

1650
01:38:22,370 --> 01:38:24,410
它匹配到 13 ，

1651
01:38:24,410 --> 01:38:28,040
所以，下一个要发送的内容是索引 13 。

1652
01:38:28,940 --> 01:38:33,110
所以， nextIndex 和 matchIndex 会是 13 ？

1653
01:38:33,200 --> 01:38:35,780
是的， nextIndex 还没有使用，也就是空的。

1654
01:38:37,290 --> 01:38:37,980
好的。

1655
01:38:38,560 --> 01:38:40,450
所以方式，

1656
01:38:40,450 --> 01:38:43,330
无论哪种方式，

1657
01:38:43,330 --> 01:38:44,500
你要么保存最后一个，

1658
01:38:44,500 --> 01:38:46,450
或者第一个会是，

1659
01:38:46,630 --> 01:38:49,030
或者第一个 next 是 1 ，

1660
01:38:49,030 --> 01:38:51,430
在这种情况下，他们[使用]第一个下一个。

1661
01:38:53,410 --> 01:38:54,190
所以在这种情况下，

1662
01:38:54,190 --> 01:38:57,400
下一次它们都是 13 。

1663
01:38:57,610 --> 01:39:00,970
是的，所以你可以考虑这个阶段，

1664
01:39:00,970 --> 01:39:03,100
比如，在所有绿色的东西都发生之前，

1665
01:39:03,490 --> 01:39:14,740
3 的 matchIndex 是 13 ，

1666
01:39:15,300 --> 01:39:22,030
并且本身 2 的 matchIndex 也是 13 。

1667
01:39:24,280 --> 01:39:28,860
明白了，太棒了，谢谢。

1668
01:39:28,950 --> 01:39:29,490
不用谢。

1669
01:39:31,840 --> 01:39:34,780
我能问你一个后续问题吗，

1670
01:39:34,960 --> 01:39:39,610
所以，当它发现匹配的东西时，

1671
01:39:39,820 --> 01:39:43,510
例如，在这里的位置 11 上，

1672
01:39:43,660 --> 01:39:45,160
它看到了匹配，

1673
01:39:45,220 --> 01:39:51,290
那么可以保证之前的一切也是匹配的。

1674
01:39:51,680 --> 01:39:52,700
是的，对，因为，

1675
01:39:52,700 --> 01:39:55,340
稍等，让我再确认一下，你在说这个消息。

1676
01:39:56,920 --> 01:39:59,920
是的，比如你检查时，它说 ok 。

1677
01:40:00,160 --> 01:40:02,710
是的，

1678
01:40:02,710 --> 01:40:04,210
因为这是整个原因，

1679
01:40:04,210 --> 01:40:08,290
前一个 term 或前一个索引与跟随者通信，

1680
01:40:08,650 --> 01:40:11,860
为了再次检查它只会回复 ok ，

1681
01:40:12,040 --> 01:40:13,210
如果确实是这种情况，

1682
01:40:13,210 --> 01:40:16,900
在前一索引 11 返回了 3 ，

1683
01:40:18,200 --> 01:40:19,040
如果这是真的，

1684
01:40:19,040 --> 01:40:21,440
意味着之前的一切都必须匹配，

1685
01:40:21,560 --> 01:40:22,400
就是这样的，

1686
01:40:22,400 --> 01:40:26,540
无论他们的[声明]是什么，

1687
01:40:28,100 --> 01:40:30,200
这个变量初始化保持不变，

1688
01:40:30,200 --> 01:40:32,330
如果某样东西在一个索引上匹配，

1689
01:40:32,330 --> 01:40:34,550
在那个之前的任何东西都必须匹配。

1690
01:40:36,320 --> 01:40:38,330
哦，好的，这对我来说[]。

1691
01:40:40,530 --> 01:40:44,730
我还有一个跟这个问题有关的后续问题，

1692
01:40:44,730 --> 01:40:48,180
在这节课上，我写的问题，

1693
01:40:48,450 --> 01:40:53,160
我问了有关快照的写入时复制的问题，

1694
01:40:53,250 --> 01:40:57,000
我想我不明白复制是什么意思，

1695
01:40:57,000 --> 01:41:00,480
是页表还是什么。

1696
01:41:00,480 --> 01:41:03,900
我想我已经回复了你的电子邮件。

1697
01:41:04,110 --> 01:41:06,210
是的，我收到了电子邮件，但是。

1698
01:41:06,750 --> 01:41:11,370
好的，等一下，

1699
01:41:11,850 --> 01:41:14,970
[]，这个，

1700
01:41:15,670 --> 01:41:21,820
好的，场景是快照可能会很昂贵，

1701
01:41:21,850 --> 01:41:23,860
因为快照可能很大，

1702
01:41:24,280 --> 01:41:28,600
上千兆字节的键值页表，

1703
01:41:28,600 --> 01:41:32,740
抱歉，是上千兆字节的存储，

1704
01:41:33,290 --> 01:41:36,860
然后你需要把上千兆字节写入磁盘，

1705
01:41:37,710 --> 01:41:39,330
当你向磁盘中写入数据时，

1706
01:41:39,540 --> 01:41:41,130
如果你不做点聪明的事，

1707
01:41:41,310 --> 01:41:44,040
你不能处理任何其他 put 和 get 操作，

1708
01:41:44,370 --> 01:41:48,270
通过 channel 来的，

1709
01:41:48,270 --> 01:41:51,420
让我拿出这张图片。

1710
01:41:52,010 --> 01:41:55,070
很好，所以服务决定在某个时刻设置检查点，

1711
01:41:55,070 --> 01:41:57,260
你必须将千兆字节写入磁盘，

1712
01:41:57,260 --> 01:41:57,920
这太昂贵了。

1713
01:41:58,510 --> 01:42:02,770
所以我想报纸暗示的计划，

1714
01:42:03,340 --> 01:42:05,620
服务说做的，

1715
01:42:06,320 --> 01:42:07,940
它调用 fork ，

1716
01:42:10,880 --> 01:42:14,060
所以当它想创建一个检查点时，它调用 fork ，

1717
01:42:15,080 --> 01:42:17,570
然后 fork 复制那个进程，

1718
01:42:17,570 --> 01:42:20,210
现在我们运行了操作系统，

1719
01:42:21,070 --> 01:42:23,770
我们现在有两个进程，

1720
01:42:24,100 --> 01:42:27,250
对应于这个应用程序，

1721
01:42:27,580 --> 01:42:29,680
服务 raft ，服务 raft ，

1722
01:42:30,930 --> 01:42:33,420
这个是复制，子进程，

1723
01:42:34,520 --> 01:42:36,590
操作系统使用写入时复制，

1724
01:42:38,040 --> 01:42:40,230
所以，当它复制第二个进程时，

1725
01:42:40,680 --> 01:42:43,890
只复制页表，不复制物理内存，

1726
01:42:45,220 --> 01:42:48,730
所以，这两个进程共享相同的物理内存，

1727
01:42:52,420 --> 01:42:55,270
其中包含我们的键值存储。

1728
01:42:56,540 --> 01:42:58,760
所以现在的想法是，

1729
01:42:58,760 --> 01:43:00,260
当子进程开始运行时，

1730
01:43:00,350 --> 01:43:03,770
它开始创建检查点或快照，

1731
01:43:03,980 --> 01:43:06,770
我可以写下键值，

1732
01:43:07,880 --> 01:43:10,070
键值存储到磁盘。

1733
01:43:11,430 --> 01:43:15,090
同时，父进程可以开始

1734
01:43:15,090 --> 01:43:18,880
处理新的 get 和 put 操作，

1735
01:43:21,860 --> 01:43:23,630
因为如果它执行 put 操作，

1736
01:43:24,220 --> 01:43:25,180
它想要修改，

1737
01:43:25,180 --> 01:43:31,620
它将写入与键值存储对应的页面，

1738
01:43:31,650 --> 01:43:33,270
这会导致页面错误，

1739
01:43:33,270 --> 01:43:34,950
操作系统将出现页面错误，

1740
01:43:34,950 --> 01:43:38,820
所以操作系统将在那个时刻复制页面，

1741
01:43:39,060 --> 01:43:42,330
然后，第一个[]进程可以更新，

1742
01:43:42,960 --> 01:43:44,790
这对子进程来说都是透明的，

1743
01:43:44,820 --> 01:43:48,660
子进程拥有整个地址空间的一致性快照

1744
01:43:48,660 --> 01:43:49,620
在 fork 的时候。

1745
01:43:50,790 --> 01:43:54,060
所以，这允许父进程和子进程同时运行，

1746
01:43:54,060 --> 01:43:56,310
仍然可以创建一致性快照，

1747
01:43:56,580 --> 01:44:00,150
而父进程处理新的 put 和 get 操作。

1748
01:44:02,340 --> 01:44:03,870
这样说清楚了吗，好吗？

1749
01:44:03,870 --> 01:44:05,040
哦，好的，我明白了，

1750
01:44:05,040 --> 01:44:10,890
所以，写入时复制，内存持有键值存储，

1751
01:44:11,730 --> 01:44:13,440
好的，我明白了，

1752
01:44:13,440 --> 01:44:14,910
是的，这已经很清楚了，

1753
01:44:14,910 --> 01:44:15,870
非常感谢。

1754
01:44:16,170 --> 01:44:16,800
不用谢。

1755
01:44:20,920 --> 01:44:21,790
还有什么问题吗？

1756
01:44:23,750 --> 01:44:25,850
是的，我有一个，

1757
01:44:25,880 --> 01:44:29,000
我想这是一种奇怪的场景，

1758
01:44:29,000 --> 01:44:30,230
我不确定这是否能，

1759
01:44:31,390 --> 01:44:32,680
但是如果，

1760
01:44:32,740 --> 01:44:35,140
所以想象一下，我们总是在同一个 term ，

1761
01:44:35,720 --> 01:44:41,420
然后在某个时刻，一些节点断开，

1762
01:44:41,420 --> 01:44:42,770
但它们仍然是同一个 term ，

1763
01:44:42,860 --> 01:44:44,360
领导者仍在同一个 term ，

1764
01:44:44,510 --> 01:44:49,870
然后在某个时刻，它们会创建快照，

1765
01:44:50,230 --> 01:44:52,540
然后所有日志都会被压缩，

1766
01:44:53,120 --> 01:44:54,620
然后它们继续前进，

1767
01:44:54,620 --> 01:44:57,350
现在，日志再次被填充，

1768
01:44:57,350 --> 01:45:01,980
然后，假设添加了 15 个日志，

1769
01:45:02,280 --> 01:45:05,760
然后在 10 之后，它们压缩了它们，

1770
01:45:06,030 --> 01:45:08,670
然后它们又回到了索引 5 ，

1771
01:45:08,670 --> 01:45:10,830
然后其他节点重新加入，

1772
01:45:11,010 --> 01:45:13,170
它们也处于同一 term 的索引 5 。

1773
01:45:14,870 --> 01:45:16,280
这是个问题吗，

1774
01:45:16,280 --> 01:45:17,510
比如，如何，

1775
01:45:18,500 --> 01:45:22,670
这就像是它们处于快照[]或。

1776
01:45:23,350 --> 01:45:26,770
好的，所以旧的快照对应一个索引，所以。

1777
01:45:26,860 --> 01:45:27,250
是的。

1778
01:45:27,460 --> 01:45:30,970
所以，好的，让我们画一下你的场景，

1779
01:45:30,970 --> 01:45:34,180
所以，我们有一个服务器有一些日志，

1780
01:45:35,780 --> 01:45:38,480
我觉得，你说的是 10 ，

1781
01:45:38,780 --> 01:45:40,370
它在 10 做了一个快照。

1782
01:45:41,380 --> 01:45:42,160
是的。

1783
01:45:43,080 --> 01:45:44,820
是的，所以我们说，

1784
01:45:44,820 --> 01:45:49,860
所以前 9 个操作，可能包括 10 在快照中。

1785
01:45:52,490 --> 01:45:58,600
然后，有另一个节点是相同的 term ，

1786
01:45:59,220 --> 01:46:01,320
所以所有这些条目都有相同的 term ，

1787
01:46:01,320 --> 01:46:06,350
不管怎样，比如 1 1 1 1 1 1 1 1 1 。

1788
01:46:06,380 --> 01:46:07,340
是的。

1789
01:46:07,840 --> 01:46:10,960
所以，这个节点，

1790
01:46:10,960 --> 01:46:12,610
但这个节点只到 10 ，

1791
01:46:12,610 --> 01:46:14,080
然后这个到 15 。

1792
01:46:14,770 --> 01:46:15,490
我们看看,

1793
01:46:16,380 --> 01:46:17,340
我想这就是你想说的，

1794
01:46:17,340 --> 01:46:19,650
这里是 1 ，这里是 1 。

1795
01:46:24,430 --> 01:46:27,940
好的，我想我的想法是，

1796
01:46:28,000 --> 01:46:29,800
有一个我可以回答的问题，

1797
01:46:29,950 --> 01:46:31,090
当你做一个快照时，

1798
01:46:31,090 --> 01:46:32,980
你是重置你的索引还是继续计数？

1799
01:46:32,980 --> 01:46:33,640
继续计数。

1800
01:46:35,280 --> 01:46:36,330
哦，好的，

1801
01:46:37,050 --> 01:46:38,700
我想象它像一个数组，

1802
01:46:39,030 --> 01:46:41,670
你看到你的索引回退了，

1803
01:46:42,180 --> 01:46:44,970
所以，你可能会有，

1804
01:46:45,000 --> 01:46:48,690
两个不同的条目在同一个 term 中有相同的索引。

1805
01:46:48,690 --> 01:46:50,580
是的，这是不允许的。

1806
01:46:50,580 --> 01:46:52,920
好的，我明白了。

1807
01:46:53,540 --> 01:46:56,810
所以，好的，这是有道理的。

1808
01:46:56,810 --> 01:46:58,790
当你重置索引的时候。

1809
01:46:58,820 --> 01:47:01,190
当你切割日志的这一部分时，

1810
01:47:01,580 --> 01:47:03,020
索引保持为 10 。

1811
01:47:03,700 --> 01:47:04,660
明白了，明白了。

1812
01:47:04,960 --> 01:47:07,120
所以，当你在 2d 中做这个时，

1813
01:47:07,120 --> 01:47:08,620
这可能有点烦人，

1814
01:47:09,100 --> 01:47:13,360
因为你可能利用了日志的起始值为 0 ，

1815
01:47:13,690 --> 01:47:15,340
你现在要得到的是，

1816
01:47:15,340 --> 01:47:17,620
0 的开始可能是 10 ，

1817
01:47:18,430 --> 01:47:21,370
人们不得不。

1818
01:47:21,370 --> 01:47:22,690
你有某种偏移量。

1819
01:47:22,780 --> 01:47:25,870
是的，你必须在所有地方加上那个偏移量。

1820
01:47:26,550 --> 01:47:29,010
是的，然后是最后一件事，

1821
01:47:29,010 --> 01:47:30,990
我认为我之前感到困惑的原因

1822
01:47:31,080 --> 01:47:35,790
是在实验 2 的代码中。

1823
01:47:35,940 --> 01:47:36,240
嗯。

1824
01:47:36,240 --> 01:47:37,590
有一个注释说，

1825
01:47:37,590 --> 01:47:41,500
我们应该立即从 start 返回。

1826
01:47:41,830 --> 01:47:44,170
是的，哦，是的。

1827
01:47:45,240 --> 01:47:46,410
我的意思是，

1828
01:47:46,500 --> 01:47:48,600
好的，让我回到这张图片上。

1829
01:47:49,310 --> 01:47:51,710
它会变得很拥挤，

1830
01:47:53,510 --> 01:47:55,610
所以我们得到一个操作，

1831
01:47:55,610 --> 01:47:58,250
然后我们进行 start 操作，我们调用 start 。

1832
01:47:59,480 --> 01:48:02,930
哦，立即返回并不一定意味着回复，是不是。

1833
01:48:02,930 --> 01:48:05,270
是的，就是这样，

1834
01:48:05,270 --> 01:48:07,880
它只是意味着回复到服务，

1835
01:48:07,910 --> 01:48:08,810
而不是对客户端。

1836
01:48:10,450 --> 01:48:14,650
我明白了，好的，

1837
01:48:14,680 --> 01:48:20,080
是的，我想在假设下，返回总是回复，

1838
01:48:20,110 --> 01:48:21,850
但并不总是这样。

1839
01:48:21,850 --> 01:48:22,840
不，不是这样的，

1840
01:48:22,840 --> 01:48:25,030
我认为这会在 lab 3 变得更清楚，

1841
01:48:25,030 --> 01:48:26,470
比在 lab 2 中，

1842
01:48:26,800 --> 01:48:30,130
实验 2 有点奇怪，没有应用程序。

1843
01:48:31,100 --> 01:48:34,670
好的，谢谢，

1844
01:48:34,700 --> 01:48:35,990
这真的很有帮助。

1845
01:48:35,990 --> 01:48:37,310
不客气。

1846
01:48:37,310 --> 01:48:37,940
非常感谢。

1847
01:48:40,120 --> 01:48:41,140
好好休息。

1848
01:48:41,140 --> 01:48:41,560
你也是。

1849
01:48:42,040 --> 01:48:42,370
再见。

1850
01:48:42,550 --> 01:48:43,420
祝实验好运。

