1
00:00:00,920 --> 00:00:01,910
你们可能注意到了，

2
00:00:01,910 --> 00:00:08,420
我在共享屏幕上放的网页部分，

3
00:00:09,200 --> 00:00:11,090
大部分课程是跟据课程表的，

4
00:00:11,210 --> 00:00:13,580
我稍后再说这件事，

5
00:00:13,580 --> 00:00:17,300
但是，希望你能找到链接，然后找到课程表。

6
00:00:18,080 --> 00:00:22,640
稍后，我会更详细地谈到这个。

7
00:00:24,370 --> 00:00:26,920
好的，那么今天的计划是什么。

8
00:00:30,280 --> 00:00:33,340
我会讨论一下，什么是分布式系统。

9
00:00:34,300 --> 00:00:35,290
它是什么，

10
00:00:36,610 --> 00:00:39,400
或许还有一些背景信息，

11
00:00:39,430 --> 00:00:45,440
分布式系统在过去几十年里是如何发展的。

12
00:00:46,780 --> 00:00:52,420
然后是一些你想知道的课程结构，

13
00:00:57,450 --> 00:01:03,630
然后讨论我们在整个学期中会反复出现的主题。

14
00:01:05,580 --> 00:01:09,030
我们看这些主题中的第一个，

15
00:01:09,030 --> 00:01:14,040
也就是今天的案例研究， mapreduce 论文，

16
00:01:14,800 --> 00:01:16,750
这也是第一个实验的主题，

17
00:01:16,780 --> 00:01:19,570
你可以从 Piazza 上看到，

18
00:01:19,570 --> 00:01:25,300
我们在 Piazza 上发布了一个实验，一个链接，

19
00:01:25,300 --> 00:01:28,930
你可以去做，直到下周五。

20
00:01:30,580 --> 00:01:32,380
好的，让我们从基础开始，

21
00:01:32,410 --> 00:01:35,470
讨论一下什么是分布式系统。

22
00:01:45,390 --> 00:01:49,170
可能从一些图片开始会比较容易，

23
00:01:49,590 --> 00:01:50,970
这个是互联网，

24
00:01:54,100 --> 00:01:58,760
连接很多客户端，也许还有服务器，

25
00:01:59,150 --> 00:02:02,120
可能是完整数据中心的服务器，

26
00:02:09,790 --> 00:02:10,750
客户端，

27
00:02:12,470 --> 00:02:16,130
以及数据中心本身内部是分布式系统，

28
00:02:16,130 --> 00:02:18,350
通过内部网络连接，

29
00:02:18,770 --> 00:02:22,580
数据中心本身可能通过内部连接，

30
00:02:22,580 --> 00:02:23,900
在互联网之外，

31
00:02:24,320 --> 00:02:28,520
很多计算机通过网络连接，

32
00:02:28,520 --> 00:02:31,400
从非正式的角度来说，我认为它是，

33
00:02:31,400 --> 00:02:32,750
分布式系统是，

34
00:02:32,750 --> 00:02:38,350
多个计算机通过网络连接，

35
00:02:38,650 --> 00:02:42,490
所以它们只能通过发送或接收数据包进行交互，

36
00:02:43,270 --> 00:02:45,040
而不是多处理器，

37
00:02:45,040 --> 00:02:46,840
那里可以通过共享内存来做交互，

38
00:02:47,050 --> 00:02:49,780
它们合作来提供一些服务。

39
00:02:53,060 --> 00:02:57,260
这是四个关键词，

40
00:02:57,590 --> 00:02:59,990
定义了分布式系统。

41
00:03:00,650 --> 00:03:05,150
通常，你可能没有意识到分布式系统的交互性，

42
00:03:05,150 --> 00:03:07,160
你可能在使用一些客户端，

43
00:03:07,160 --> 00:03:08,510
比如， Zoom 客户端，

44
00:03:08,870 --> 00:03:11,390
但是在 Zoom 客户端的背后，

45
00:03:11,390 --> 00:03:14,120
有巨大的数据中心或多个数据中心，

46
00:03:14,120 --> 00:03:16,730
来支持这个分布式应用。

47
00:03:17,590 --> 00:03:18,820
从某些方面来说，

48
00:03:18,820 --> 00:03:22,150
我们不会有这些使用 Zoom 的课程，

49
00:03:22,150 --> 00:03:23,350
如果有更多，

50
00:03:23,350 --> 00:03:25,510
如果没有分布式系统，

51
00:03:25,690 --> 00:03:31,960
所以，它们通常作为基础设施的主干，来支持应用程序。

52
00:03:34,040 --> 00:03:34,670
好的?

53
00:03:37,750 --> 00:03:41,560
那么为什么分布式系统很有趣，

54
00:03:41,560 --> 00:03:46,900
或者分布式系统的主要作用是什么。

55
00:03:50,500 --> 00:03:52,810
一般来说，

56
00:03:52,840 --> 00:03:55,630
有四个主要原因。

57
00:03:56,160 --> 00:04:00,990
一个是用来连接物理上分离的机器，

58
00:04:12,440 --> 00:04:13,820
你可能有，

59
00:04:15,320 --> 00:04:17,930
关系到我们所有人，

60
00:04:17,930 --> 00:04:19,670
正如我们在简介中看到的，

61
00:04:19,670 --> 00:04:21,350
或者在不同的地方看到的，

62
00:04:21,380 --> 00:04:29,360
我们通过笔记本电脑或手机或 iPad

63
00:04:29,360 --> 00:04:30,800
连接到一些服务器，

64
00:04:30,800 --> 00:04:33,380
它们可能位于世界上完全不同的地方。

65
00:04:34,270 --> 00:04:41,050
这可能是你关心分布式系统的基本原因，

66
00:04:41,050 --> 00:04:43,960
因为你有两台在物理空间上分隔的机器，

67
00:04:43,960 --> 00:04:44,860
你想连接它们，

68
00:04:45,740 --> 00:04:47,270
一旦你把它们连接起来，

69
00:04:47,270 --> 00:04:48,710
还有一个额外的好处，

70
00:04:48,710 --> 00:04:51,530
它可以允许用户之间的共享。

71
00:04:54,020 --> 00:04:56,750
所以如果你和我可以连接到同一台计算机，

72
00:04:56,780 --> 00:04:58,460
那么我们就可以共享数据了，

73
00:04:58,670 --> 00:05:03,710
这使得各种合作成为可能，

74
00:05:03,710 --> 00:05:05,990
无论是文件共享，

75
00:05:05,990 --> 00:05:08,330
还是共享屏幕，

76
00:05:08,330 --> 00:05:12,290
还是共享计算基础设施，

77
00:05:12,290 --> 00:05:13,490
这些都是可以的，

78
00:05:13,490 --> 00:05:16,040
因为我们可以连接到物理上分隔的机器。

79
00:05:17,140 --> 00:05:19,480
这可能是一个非常重要的原因，

80
00:05:19,600 --> 00:05:21,880
但还有其他几个非常重要的原因。

81
00:05:21,880 --> 00:05:30,540
一个是，通过并行来提高性能，

82
00:05:33,670 --> 00:05:35,890
我们今天布置的论文，

83
00:05:35,890 --> 00:05:37,690
第一个实验的主题是什么，

84
00:05:37,690 --> 00:05:38,770
mapreduce 论文，

85
00:05:38,860 --> 00:05:40,480
是这方面一个很好的示例，

86
00:05:40,690 --> 00:05:42,820
但另一个示例是，

87
00:05:42,850 --> 00:05:45,970
例如有很多 Zoom 的会话同时发生，

88
00:05:46,090 --> 00:05:48,520
zoom.com 必须全部支持，

89
00:05:48,670 --> 00:05:52,030
它需要大量的计算机来提高性能，

90
00:05:52,030 --> 00:05:55,990
来支持所有这些并行的 Zoom 会话。

91
00:05:57,200 --> 00:05:59,780
另一个重要原因是容忍错误，

92
00:06:06,020 --> 00:06:10,520
因为计算机可能在物理上是分开的，

93
00:06:10,580 --> 00:06:12,110
有一部分可能会宕机，

94
00:06:12,110 --> 00:06:15,590
希望不会影响到另一部分服务，

95
00:06:15,710 --> 00:06:17,720
以便始终能够提供服务，

96
00:06:17,930 --> 00:06:19,370
可以获得高可用性，

97
00:06:20,100 --> 00:06:23,310
我们将把它作为这门课的一个重要主题。

98
00:06:23,940 --> 00:06:27,240
然后最后一个是，

99
00:06:27,240 --> 00:06:30,660
在某种程度上，也是利用了物理上的隔离，

100
00:06:30,870 --> 00:06:32,880
就是会获得安全性，

101
00:06:36,880 --> 00:06:43,470
例如，如果你有一个非常敏感的服务，

102
00:06:43,830 --> 00:06:47,430
这个服务用来管理你的客户的密码，

103
00:06:47,430 --> 00:06:50,490
用来登录到你的服务，

104
00:06:50,490 --> 00:06:55,470
你肯定想保护那台机器，

105
00:06:55,470 --> 00:06:57,150
不与其他任何人分享，

106
00:06:57,150 --> 00:06:59,880
或者不与任何其他程序共享，在它上面运行任何应用程序，

107
00:07:00,090 --> 00:07:03,030
所以你对这台机器要有很少的接口，

108
00:07:03,480 --> 00:07:05,910
它让你得到更好的安全性，

109
00:07:05,910 --> 00:07:08,400
因为你只需要保护一个小的接口，

110
00:07:08,520 --> 00:07:13,170
所以，通过把东西放在不同的计算机上，进行隔离，

111
00:07:13,500 --> 00:07:15,510
你可能会得到，

112
00:07:15,510 --> 00:07:17,160
这是获得安全性的重要一步。

113
00:07:18,170 --> 00:07:23,660
这些是我认为的四个主要原因，

114
00:07:23,660 --> 00:07:27,710
为什么分布式系统如此流行。

115
00:07:28,520 --> 00:07:30,770
我要稍微讨论一下，

116
00:07:30,770 --> 00:07:35,060
给出一些分布式系统的历史背景，

117
00:07:35,360 --> 00:07:37,010
[]从哪里来，

118
00:07:37,010 --> 00:07:41,930
以及近几十年来发生了什么。

119
00:07:50,750 --> 00:07:53,660
基本上分布式系统是，

120
00:07:53,660 --> 00:07:56,900
就像我们现在看到的或者我们认识到的方式，

121
00:07:56,900 --> 00:08:00,920
它们可能是随着局域网出现开始的，

122
00:08:05,180 --> 00:08:08,000
在 80 年代初。

123
00:08:11,560 --> 00:08:14,980
比如，在麻省理工学院有一个校园网络，

124
00:08:14,980 --> 00:08:19,780
连接到工作站，比如 Athena 集群，

125
00:08:19,780 --> 00:08:22,000
连接到 Athena 服务器，比如 AFS ，

126
00:08:22,390 --> 00:08:25,930
那是一种典型的分布式系统，

127
00:08:25,930 --> 00:08:28,780
AFS 也可以追溯到那段时间，

128
00:08:29,680 --> 00:08:32,290
当然，互联网也在那里，

129
00:08:32,320 --> 00:08:35,710
但当时没有大规模的互联网应用，

130
00:08:35,710 --> 00:08:38,110
像我们现在使用它们的方式，

131
00:08:38,110 --> 00:08:44,110
互联网规模的分布式系统主要是 DNS ，即域名服务系统，

132
00:08:44,110 --> 00:08:45,250
我们仍然在使用，

133
00:08:45,490 --> 00:08:46,570
然后还有电子邮件。

134
00:08:48,740 --> 00:08:52,160
所以在早期，当我学习分布式系统时，

135
00:08:52,160 --> 00:08:54,980
这些都是主要的例子，

136
00:08:55,370 --> 00:08:57,440
是我们必须讨论的。

137
00:08:57,470 --> 00:08:59,630
现在情况发生了很大的变化，

138
00:08:59,750 --> 00:09:00,770
从 20 世纪 80 年代以来，

139
00:09:00,770 --> 00:09:04,160
分布式系统的重要性大大增加了，

140
00:09:04,310 --> 00:09:07,280
有一点很重要，

141
00:09:07,460 --> 00:09:09,620
它就是数据中心，

142
00:09:09,620 --> 00:09:15,770
数据中心的兴起，是与大型网站相伴而生的。

143
00:09:19,380 --> 00:09:25,860
我们这里谈论的大概是 20 世纪 90 年代或 90 年代初的情况。

144
00:09:26,480 --> 00:09:28,220
所以发生的事情是，

145
00:09:28,220 --> 00:09:30,800
在 80 年代末的某个时候，

146
00:09:30,800 --> 00:09:37,880
80 年代，政府或国会允许互联网上的商业行为，

147
00:09:38,150 --> 00:09:40,280
然后导致了繁荣，

148
00:09:40,520 --> 00:09:43,130
开始有大型网站，

149
00:09:43,130 --> 00:09:45,530
为大量用户提供支持。

150
00:09:45,940 --> 00:09:48,250
那些时候的应用程序，

151
00:09:48,250 --> 00:09:52,040
比如，网络搜索，

152
00:09:52,040 --> 00:09:54,800
能够搜索所有不同的网页，

153
00:09:54,800 --> 00:09:57,170
在万维网上的网页，

154
00:09:57,500 --> 00:09:59,420
还有购物和。

155
00:10:00,820 --> 00:10:05,200
这些应用程序产生了两种情况，

156
00:10:05,200 --> 00:10:06,760
一个是巨大的数据集，

157
00:10:06,760 --> 00:10:09,100
使用索引来支持网络搜索，

158
00:10:09,100 --> 00:10:11,260
将互联网上的所有网页写入索引，

159
00:10:11,650 --> 00:10:14,590
这意味着收集爬取所有的网页，

160
00:10:14,590 --> 00:10:16,150
然后计算倒排索引，

161
00:10:16,150 --> 00:10:18,220
然后你可以把它用在搜索引擎上，

162
00:10:18,910 --> 00:10:20,770
这是海量的数据，

163
00:10:20,800 --> 00:10:22,150
不能放在一台计算机上，

164
00:10:22,210 --> 00:10:24,760
以及执行第一次索引的计算量，

165
00:10:24,760 --> 00:10:27,490
对于同一台计算机也太多了，

166
00:10:27,520 --> 00:10:30,520
所以，数据中心应运而生，

167
00:10:30,520 --> 00:10:31,660
公司开始，

168
00:10:31,870 --> 00:10:33,790
将大量的计算机放到数据中心，

169
00:10:33,790 --> 00:10:35,860
让它可以支持这种类型的应用程序，

170
00:10:37,020 --> 00:10:38,460
这是第一个，大量数据。

171
00:10:38,670 --> 00:10:40,770
第二个是，大量用户，

172
00:10:41,610 --> 00:10:45,540
大型网站拥有数亿用户，这并不少见，

173
00:10:45,540 --> 00:10:48,810
这需要大量的机器来支持所有这些用户。

174
00:10:50,060 --> 00:10:55,250
所以，我们看到在一段时间内有大量的创新，

175
00:10:55,250 --> 00:10:57,170
我们还在继续，

176
00:10:57,530 --> 00:11:01,040
我们读到的一些论文，比如 mapreduce 论文，

177
00:11:01,040 --> 00:11:03,920
就是从那段时间开始的。

178
00:11:05,930 --> 00:11:09,470
整个事情加速发展，

179
00:11:09,470 --> 00:11:11,900
随着云计算的出现，

180
00:11:18,400 --> 00:11:22,180
早在 2000 年的中后期，

181
00:11:22,630 --> 00:11:27,610
所以，我们在这里看到的用户或客户，

182
00:11:27,790 --> 00:11:32,140
将他们的计算和数据转移到数据中心，

183
00:11:32,140 --> 00:11:33,520
还有其他人，

184
00:11:33,520 --> 00:11:37,930
比如你所知道的亚马逊、谷歌、微软这样的公司，

185
00:11:38,440 --> 00:11:43,510
所以人们很多日常的计算，

186
00:11:43,510 --> 00:11:46,810
过去运行在他们桌面或笔记本上的，

187
00:11:46,810 --> 00:11:48,700
转到了云计算上，

188
00:11:48,700 --> 00:11:50,170
应用程序变更，

189
00:11:50,170 --> 00:11:54,070
不是在本地计算机上运行应用程序，

190
00:11:54,070 --> 00:11:56,140
而是在云上运行应用程序。

191
00:11:56,880 --> 00:11:59,940
这意味着这些数据中心可能需要进一步增长，

192
00:12:00,000 --> 00:12:03,240
并支持新的应用程序，

193
00:12:04,390 --> 00:12:10,630
不仅如此，客户将它们的计算转为云计算，

194
00:12:11,160 --> 00:12:13,350
也开始运行自己的大型网站，

195
00:12:13,680 --> 00:12:17,790
并且自己进行大量的计算，

196
00:12:17,790 --> 00:12:23,550
机器学习有很大的数据集，或任何其他类型的计算，

197
00:12:23,880 --> 00:12:25,680
所以你可以看到，

198
00:12:25,680 --> 00:12:30,120
用户自己想要建立大规模的分布式系统，

199
00:12:30,120 --> 00:12:31,890
这意味着云提供商，

200
00:12:31,890 --> 00:12:34,350
开始建设大量的基础设施，

201
00:12:34,350 --> 00:12:40,560
允许其他人向上扩展他们的分布式系统到大量机器上，

202
00:12:40,560 --> 00:12:44,820
实现高并行，高性能，

203
00:12:44,820 --> 00:12:45,990
并存储大量数据。

204
00:12:46,810 --> 00:12:51,610
所以，现在的状态是，

205
00:12:51,610 --> 00:12:55,630
这是一个非常活跃的研究领域，

206
00:12:55,690 --> 00:12:57,310
在发展中也是如此。

207
00:13:00,550 --> 00:13:03,070
实际上，这很困难，也很活跃，

208
00:13:03,070 --> 00:13:07,530
跟上发展是很困难的，

209
00:13:07,590 --> 00:13:09,510
有很多发展，

210
00:13:09,510 --> 00:13:11,550
即使在这门课中，

211
00:13:11,550 --> 00:13:14,460
我们将花费整个学期来学习分布式系统，

212
00:13:14,460 --> 00:13:17,310
我们只能看到，

213
00:13:17,310 --> 00:13:22,620
所有东西中的一小部分，

214
00:13:22,650 --> 00:13:25,560
所有人们已经在实践中建立的分布式系统。

215
00:13:27,490 --> 00:13:29,740
有一件事对我们来说很酷，

216
00:13:29,800 --> 00:13:34,330
对于分布式系统的老师或学生，

217
00:13:34,330 --> 00:13:37,120
早期构建这些数据中心的人员，

218
00:13:37,300 --> 00:13:41,170
尽管他们是为自己的内部基础设施建立分布式系统，

219
00:13:41,200 --> 00:13:42,490
他们发表了关于这方面的论文，

220
00:13:42,640 --> 00:13:45,040
我们可以读这些论文，

221
00:13:45,040 --> 00:13:47,320
所以在这学期里，

222
00:13:47,320 --> 00:13:49,000
我们会读很多这样的论文，

223
00:13:49,000 --> 00:13:54,160
是由面临大规模分布式系统的挑战的人们发表的，

224
00:13:54,280 --> 00:13:57,460
我们可以看到他们是如何解决的，并从中学习。

225
00:13:58,160 --> 00:14:01,100
随着云计算的出现，这一速度进一步加快，

226
00:14:01,100 --> 00:14:04,040
在数据中心的早期，

227
00:14:04,100 --> 00:14:05,780
这些服务中有许多是内部的，

228
00:14:05,810 --> 00:14:12,260
比如微软、谷歌、亚马逊或雅虎，它们自己，

229
00:14:12,410 --> 00:14:13,970
随着云计算的兴起，

230
00:14:14,000 --> 00:14:17,240
这些服务变成了其他人使用的公共服务，

231
00:14:17,330 --> 00:14:21,290
所以突然之间，有了更多的系统基础设施，

232
00:14:21,440 --> 00:14:24,650
有很好的文档和可用性，

233
00:14:24,890 --> 00:14:28,640
所以我们也会研究其中的一些案例。

234
00:14:29,320 --> 00:14:32,470
所以如果你回顾这 40 年，

235
00:14:32,470 --> 00:14:34,540
这是巨大的涨幅，

236
00:14:34,540 --> 00:14:36,820
分布式计算的重要性，

237
00:14:36,880 --> 00:14:38,200
就像我之前说的，

238
00:14:38,320 --> 00:14:42,820
我在 20 世纪 80 年代完成了分布式系统方面的博士论文，

239
00:14:42,940 --> 00:14:45,130
这是一个重要的领域，

240
00:14:45,220 --> 00:14:48,820
在重要性上，它并没有让我大吃一惊，

241
00:14:48,820 --> 00:14:54,130
在实用上，更多局限于这样的局域集群。

242
00:14:54,480 --> 00:15:01,170
现在你知道，它在研究领域和发展领域一样蓬勃发展。

243
00:15:04,000 --> 00:15:07,930
关于分布式系统的历史背景，有什么问题吗？

244
00:15:15,660 --> 00:15:18,570
好的，让我来谈谈这些挑战，

245
00:15:19,180 --> 00:15:25,030
你会在实验里看到它们。

246
00:15:26,340 --> 00:15:29,310
那么，为什么这么难，

247
00:15:31,290 --> 00:15:38,910
值得花费一个学期来学习。

248
00:15:39,150 --> 00:15:44,130
有两件事导致分布式系统很难，

249
00:15:44,130 --> 00:15:48,370
一是有很多并发的部分。

250
00:15:54,180 --> 00:15:55,290
那些数据仓库，

251
00:15:55,290 --> 00:16:00,090
今天的计算机会并行运行数十万台计算机，

252
00:16:00,090 --> 00:16:01,710
有时候都在同样的工作上，

253
00:16:01,890 --> 00:16:03,510
我们今天看了 mapreduce 论文，

254
00:16:03,510 --> 00:16:05,010
是从 90 年代初开始的，

255
00:16:05,250 --> 00:16:08,730
2000 台机器处理同一个问题，

256
00:16:09,330 --> 00:16:11,520
所以有很多并发，

257
00:16:12,040 --> 00:16:13,270
很多并发软件，

258
00:16:13,270 --> 00:16:14,590
很多事情同时发生，

259
00:16:14,590 --> 00:16:16,300
很难推论出，

260
00:16:16,300 --> 00:16:21,460
理解为什么事情是正确的。

261
00:16:22,380 --> 00:16:25,020
更难的是，

262
00:16:25,020 --> 00:16:30,340
分布式系统必须处理部分故障，

263
00:16:38,860 --> 00:16:42,130
这些机器中的一台可能真的会宕机，

264
00:16:42,220 --> 00:16:44,650
但这并不意味着整个[比赛]停止，

265
00:16:44,650 --> 00:16:48,160
其他的机器可能会继续运行，

266
00:16:48,160 --> 00:16:51,760
可能接管发生故障的机器的一些负载。

267
00:16:52,600 --> 00:16:57,640
这两件事一起导致了复杂性，

268
00:16:58,210 --> 00:17:02,680
这让理解系统是否正常工作变得越来越困难，

269
00:17:03,570 --> 00:17:06,450
尤其是部分故障让事情变得非常复杂，

270
00:17:06,660 --> 00:17:10,770
因为系统的一个部分可能认为系统的另一个部分出现故障，

271
00:17:10,860 --> 00:17:12,390
但事实并非如此，

272
00:17:12,390 --> 00:17:14,130
有一种可能发生的事情是，

273
00:17:14,130 --> 00:17:15,150
有一个网络分区，

274
00:17:15,480 --> 00:17:20,310
所以分布式系统的两边继续计算，

275
00:17:20,520 --> 00:17:22,890
可能与客户端交互，

276
00:17:22,890 --> 00:17:25,710
甚至可能与同一组客户端交互，

277
00:17:25,710 --> 00:17:27,540
因为客户端可以访问两个部分，

278
00:17:27,540 --> 00:17:29,850
但是两部分之间不能互相访问，

279
00:17:30,450 --> 00:17:34,200
这就是所谓的脑裂，

280
00:17:34,290 --> 00:17:40,560
这让设计分布式系统协议变得很复杂，

281
00:17:40,560 --> 00:17:41,160
正如我们将看到的。

282
00:17:42,160 --> 00:17:45,040
所以这是某种深层次的智力问题，

283
00:17:45,520 --> 00:17:49,060
然后我发现各种挑战的方面，

284
00:17:49,090 --> 00:17:54,750
要实现性能优势是很困难的，

285
00:17:54,750 --> 00:18:00,190
理论上在分布式系统中可能实现的。

286
00:18:05,560 --> 00:18:06,220
到目前为止，

287
00:18:06,220 --> 00:18:08,680
我们一直在谈论你想要增加容量，

288
00:18:08,680 --> 00:18:10,120
或者你想要并行运行，

289
00:18:10,120 --> 00:18:11,140
你购买更多的机器，

290
00:18:11,170 --> 00:18:12,760
或者购买另一个数据中心，

291
00:18:12,970 --> 00:18:18,940
当然，只有任务完全并行，

292
00:18:18,940 --> 00:18:19,660
这种方式可行吗，

293
00:18:19,690 --> 00:18:22,360
通常在实践中，事实并非如此，

294
00:18:22,360 --> 00:18:26,050
所以实现这样的高吞吐量，

295
00:18:26,080 --> 00:18:28,780
吞吐量随机器数量的增加而增加，

296
00:18:28,840 --> 00:18:31,570
这并不是直截了当的。

297
00:18:34,840 --> 00:18:37,540
让我转到下一个话题，

298
00:18:37,540 --> 00:18:41,590
为什么你要选择 6.824 。

299
00:18:49,340 --> 00:18:52,400
我认为有四个原因，

300
00:18:52,460 --> 00:18:53,990
一是很有趣，

301
00:18:58,410 --> 00:19:00,930
它是困难的技术问题，

302
00:19:00,930 --> 00:19:02,610
有非常强大的解决方案，

303
00:19:03,760 --> 00:19:10,800
问题很困难，但是解决方案很强大，

304
00:19:11,660 --> 00:19:14,360
我们会在整个学期看到这些解决方案。

305
00:19:20,220 --> 00:19:22,470
第二个原因是，在现实世界中使用，

306
00:19:28,450 --> 00:19:30,550
人们很希望，

307
00:19:30,550 --> 00:19:33,220
理解并能构建分布式系统。

308
00:19:33,840 --> 00:19:36,780
如果你是研究生或者考虑研究的本科生，

309
00:19:36,810 --> 00:19:37,770
这是个很棒的领域，

310
00:19:37,800 --> 00:19:39,750
因为这是一个非常活跃的研究领域，

311
00:19:43,520 --> 00:19:45,260
还有许多悬而未决的问题，

312
00:19:46,400 --> 00:19:50,360
我们会在这学期遇到它们，

313
00:19:50,570 --> 00:19:53,030
所以这是一个很好的研究领域。

314
00:19:53,180 --> 00:19:55,070
最后，如果你喜欢构建东西，

315
00:19:55,130 --> 00:19:57,710
这是一种独特的编程风格，

316
00:19:57,710 --> 00:20:00,770
所以，在 6.824 的情况下，

317
00:20:00,770 --> 00:20:02,510
你会获得实际经验，

318
00:20:02,720 --> 00:20:08,230
通过构建实验室中的分布式系统，

319
00:20:08,230 --> 00:20:10,420
你会发现它是，

320
00:20:10,720 --> 00:20:14,350
一是很难把它们弄对，

321
00:20:14,620 --> 00:20:18,610
它建立了另一种编程技巧类型，

322
00:20:18,610 --> 00:20:20,350
那些在过去可能做不到的事情。

323
00:20:23,580 --> 00:20:25,860
让我在这里暂停一下，看看有没有什么问题，

324
00:20:27,020 --> 00:20:29,570
也可以在聊天中发言，

325
00:20:29,810 --> 00:20:30,920
我会看聊天，

326
00:20:30,920 --> 00:20:31,940
如果有什么问题，

327
00:20:31,940 --> 00:20:33,500
或者有人举手，

328
00:20:33,500 --> 00:20:34,790
如果你有任何问题，

329
00:20:35,390 --> 00:20:40,880
我相信助教们也会注意聊天中的举手，

330
00:20:40,880 --> 00:20:42,350
如果我错过了什么，

331
00:20:42,350 --> 00:20:44,030
他们会提醒我。

332
00:20:45,500 --> 00:20:48,140
到目前为止，任何问题清楚吗？

333
00:20:55,390 --> 00:20:58,810
我理解安静就是清楚了。

334
00:21:01,190 --> 00:21:03,410
让我简单谈谈课程结构，

335
00:21:04,920 --> 00:21:08,550
在对分布式系统进行了快速介绍之后。

336
00:21:14,460 --> 00:21:16,110
课程结构如下，

337
00:21:16,290 --> 00:21:19,390
我们有像今天这样的讲座，

338
00:21:19,630 --> 00:21:21,820
集中在大的想法上，

339
00:21:24,660 --> 00:21:28,320
讲座通常是由我们看到的论文推动的，

340
00:21:29,360 --> 00:21:32,990
这些论文通常是案例研究，

341
00:21:33,080 --> 00:21:36,230
是我们在课上会讲到的重要的想法，

342
00:21:39,130 --> 00:21:44,890
论文都发布在日程表页面上，

343
00:21:44,890 --> 00:21:47,380
对于大多数论文，

344
00:21:47,380 --> 00:21:50,950
我们要求你回答一个问题，同时也要问一个问题，

345
00:21:51,070 --> 00:21:56,050
我们试着在讲座中回答这些问题，

346
00:21:56,140 --> 00:21:57,490
所以重要的是，

347
00:21:57,490 --> 00:21:59,080
我们这么做的部分原因是，

348
00:21:59,080 --> 00:22:02,620
因为我们想让你在讲座前看一下论文，

349
00:22:02,860 --> 00:22:06,250
这样我们可以更深入地了解这些论文，

350
00:22:06,900 --> 00:22:11,790
所以，我强烈建议你们在上课前阅读它们。

351
00:22:13,580 --> 00:22:17,720
课程的另一个组成部分是实验，

352
00:22:18,470 --> 00:22:22,280
编程实验，一共有四个，

353
00:22:23,260 --> 00:22:24,730
它们被分成了几部分，

354
00:22:24,730 --> 00:22:26,920
但是四个主要的。

355
00:22:26,920 --> 00:22:28,510
一个是 mapreduce 实验，

356
00:22:28,810 --> 00:22:31,720
我们今天发布，下周五需要提交，

357
00:22:32,280 --> 00:22:36,150
你要构建自己的 mapreduce 库，

358
00:22:36,950 --> 00:22:40,460
与论文中描述的一致。

359
00:22:40,940 --> 00:22:45,800
第二个实验是重点在复制的实验，

360
00:22:45,830 --> 00:22:50,210
在存在故障和分区网络的情况下，

361
00:22:50,510 --> 00:22:57,010
我们使用称为 raft 的协议来实现复制。

362
00:23:02,040 --> 00:23:04,620
这是一个由多个部分组成的实验，

363
00:23:04,620 --> 00:23:06,810
但到了最后，你有一个库，

364
00:23:06,810 --> 00:23:12,150
可以用来构建复制状态机，

365
00:23:12,150 --> 00:23:18,340
也就是复制状态机或多台机器，

366
00:23:18,340 --> 00:23:19,870
如果其中一个宕机，

367
00:23:19,870 --> 00:23:21,070
其中一台机器宕机，

368
00:23:21,070 --> 00:23:23,560
而服务会继续运行，

369
00:23:24,440 --> 00:23:28,550
你将使用这个库构建一个复制服务，

370
00:23:28,550 --> 00:23:41,810
实际上，你将在实验 3 中构建一个复制键值服务。

371
00:23:41,960 --> 00:23:45,290
实验 3 中使用多台机器，

372
00:23:45,290 --> 00:23:48,230
提供容错能力，让应用构建一个服务，

373
00:23:48,740 --> 00:23:51,680
不幸的是，正如我们看到的，

374
00:23:51,680 --> 00:23:54,680
仅仅使用复制并不能带来更高的性能，

375
00:23:54,680 --> 00:23:59,410
因为这些机器必须按特定的顺序执行，

376
00:23:59,800 --> 00:24:02,830
所以，为了真正获得性能，

377
00:24:02,830 --> 00:24:08,050
在实验 4 里，你可以构建分片键值服务，

378
00:24:13,380 --> 00:24:17,400
它是由实验 3 中的多个实例组成，

379
00:24:17,640 --> 00:24:24,450
并发运行并负责一个分片的键值服务，

380
00:24:24,690 --> 00:24:26,070
这样你会得到并行性，

381
00:24:26,130 --> 00:24:30,090
所以，你可以使用它来提高吞吐量，

382
00:24:31,460 --> 00:24:35,660
另外，我们将移动键或键值对，

383
00:24:35,660 --> 00:24:37,220
从一台机器到另一台机器，

384
00:24:37,220 --> 00:24:39,080
以响应负载变化。

385
00:24:41,240 --> 00:24:45,710
所以实验 2 3 4 是有递进关系的，

386
00:24:45,950 --> 00:24:47,900
所以如果你在实验 2 中有一个 bug ，

387
00:24:47,900 --> 00:24:49,730
可能会在实验 4 里影响你，

388
00:24:50,380 --> 00:24:53,710
我们为它们三个提供了测试用例，

389
00:24:53,710 --> 00:24:55,300
所有的测试用例都是公开的，

390
00:25:03,040 --> 00:25:04,960
我们在那些测试案例中给你打分，

391
00:25:04,990 --> 00:25:06,340
所以你提交了解决方案，

392
00:25:06,340 --> 00:25:07,990
我们在我们的电脑上做同样的测试，

393
00:25:08,230 --> 00:25:11,110
复查你是否通过了测试，

394
00:25:11,500 --> 00:25:14,020
如果你通过了所有的测试，你会得到满分，

395
00:25:14,700 --> 00:25:19,290
这些测试用例是很困难的，

396
00:25:19,440 --> 00:25:26,970
我们会尝试检查你的系统中的各个角落，

397
00:25:27,390 --> 00:25:30,600
所以，它们是很难通过的，

398
00:25:30,600 --> 00:25:33,420
它们也很难调试，

399
00:25:33,450 --> 00:25:36,750
你可能会在某个角落发生错误，

400
00:25:36,840 --> 00:25:38,880
可能很难追踪到，

401
00:25:38,880 --> 00:25:41,190
什么时候发生的，为什么会发生，

402
00:25:41,310 --> 00:25:42,540
让你来修复它，

403
00:25:42,960 --> 00:25:45,690
所以的建议是尽早开始实验，

404
00:25:45,930 --> 00:25:47,790
通常情况下，

405
00:25:47,790 --> 00:25:50,280
如果你在前一两天开始，

406
00:25:50,490 --> 00:25:53,700
你会很难通过所有测试，

407
00:25:53,850 --> 00:25:57,750
因为你可能会卡住，调试一个特殊的方面，

408
00:25:57,750 --> 00:26:01,380
就没有时间让其他测试用例正常工作了。

409
00:26:04,230 --> 00:26:08,130
有一个可选的项目，

410
00:26:10,840 --> 00:26:14,740
除了做实验 4 ，你可以做另一个项目，

411
00:26:14,800 --> 00:26:16,840
这个项目的想法是，

412
00:26:16,840 --> 00:26:20,920
你可以和两三个同学组成一组一起工作，

413
00:26:21,100 --> 00:26:23,290
然后做一个你们自己的项目，

414
00:26:23,350 --> 00:26:26,980
这些项目是以前的相同类型的系统，

415
00:26:26,980 --> 00:26:28,600
我们在论文中看到的，

416
00:26:28,690 --> 00:26:31,060
你提出了一个你想要构建的，

417
00:26:31,330 --> 00:26:33,370
我们会给你一些反馈，

418
00:26:33,400 --> 00:26:37,720
我们会告诉你们，也许你应该做实验 4 ，

419
00:26:38,140 --> 00:26:40,300
但如果你对做项目很感兴趣，

420
00:26:40,300 --> 00:26:41,980
我们当然鼓励这个，

421
00:26:41,980 --> 00:26:44,200
你现在就应该开始思考，

422
00:26:44,500 --> 00:26:46,390
然后我们能讨论一下，

423
00:26:46,390 --> 00:26:49,240
然后选定做些很酷的事。

424
00:26:50,760 --> 00:26:56,820
好的，最后，这门课程还有两次考试，

425
00:26:58,280 --> 00:27:01,790
一个在期中，

426
00:27:01,790 --> 00:27:03,350
另一个在期末，

427
00:27:03,620 --> 00:27:06,470
我们希望你完成所有实验，

428
00:27:06,800 --> 00:27:09,800
提交论文的读写作业，

429
00:27:09,800 --> 00:27:11,450
然后还有两次考试，

430
00:27:11,960 --> 00:27:16,250
如果你看一下 6.828, 6.824 的网页，

431
00:27:16,430 --> 00:27:21,860
你会看到不同部分在评分方面的分配，

432
00:27:21,860 --> 00:27:23,270
实验是最重要的，

433
00:27:23,660 --> 00:27:26,570
两次考试是 20% 或 30% ，

434
00:27:26,570 --> 00:27:28,490
然后还有一些课堂活动，

435
00:27:29,420 --> 00:27:31,730
但是详情在网页上。

436
00:27:32,870 --> 00:27:36,590
为了帮你通过这个学期，

437
00:27:36,590 --> 00:27:39,620
我们有优秀的课程工作人员，

438
00:27:39,620 --> 00:27:42,320
我们有 4 名助教，

439
00:27:42,320 --> 00:27:43,430
我们有办公时间，

440
00:27:43,790 --> 00:27:46,460
为了帮助你通过实验，

441
00:27:47,090 --> 00:27:48,740
让我来简单[介绍一下]，

442
00:27:48,770 --> 00:27:50,960
或许助教们可以自我介绍一下，

443
00:27:51,380 --> 00:27:53,330
你至少知道他们是谁。

444
00:27:53,360 --> 00:27:55,160
Lily ，你想先说吗？

445
00:27:56,830 --> 00:28:01,360
当然，我是 Lily ，我是 PDOS 的三年级研究生，

446
00:28:01,360 --> 00:28:02,980
Frans 是我的导师，

447
00:28:02,980 --> 00:28:06,370
所以我知道他教得有多好，

448
00:28:06,370 --> 00:28:07,270
所以你们可以学到很多，

449
00:28:07,660 --> 00:28:10,840
是的，我很期待这学期和你一起工作，

450
00:28:11,420 --> 00:28:13,490
下一个我交给 David 。

451
00:28:15,460 --> 00:28:16,630
大家好，我是 David ，

452
00:28:16,630 --> 00:28:18,430
我是第二学期的学生，

453
00:28:18,430 --> 00:28:20,530
我在去年春天参加了 6.824 ，

454
00:28:20,530 --> 00:28:22,480
当时一半是面对面，一半是远程，

455
00:28:22,750 --> 00:28:25,870
希望这学期我们能得到最好的[]，

456
00:28:25,900 --> 00:28:26,410
我很兴奋，

457
00:28:27,760 --> 00:28:28,660
是的，然后是 Jose 。

458
00:28:29,580 --> 00:28:33,390
我是 Jose ，我是四年级研究生，

459
00:28:33,390 --> 00:28:35,580
致力于解决机器学习问题，

460
00:28:35,610 --> 00:28:38,640
我读研究生的第一年上了这门课，

461
00:28:38,640 --> 00:28:40,170
我真的很享受它，

462
00:28:40,530 --> 00:28:42,390
是的，接下来是 Cel 。

463
00:28:44,920 --> 00:28:47,410
是的，我是 Cel ，我用这个发音，

464
00:28:47,470 --> 00:28:50,110
我是 PDOS 的第一届硕士研究生，

465
00:28:50,110 --> 00:28:51,160
像其他人一样，

466
00:28:51,190 --> 00:28:54,100
几年前我上过这门课，

467
00:28:54,130 --> 00:28:55,300
并且很开心，

468
00:28:55,300 --> 00:28:57,760
所以我很高兴能帮助大家学习它。

469
00:29:01,480 --> 00:29:02,350
好的，谢谢,

470
00:29:02,770 --> 00:29:04,540
在聊天中有一个问题，

471
00:29:04,660 --> 00:29:09,520
实验的分布式系统是如何运行的，

472
00:29:09,520 --> 00:29:11,470
机器系统是模拟的吗，

473
00:29:11,500 --> 00:29:17,080
是的，我们是通过运行许多不同的进程来模拟许多机器，

474
00:29:17,170 --> 00:29:20,770
实际上，这些实验有自己的 RPC 库，

475
00:29:21,010 --> 00:29:25,780
假装你在不同的物理机器上运行，

476
00:29:25,780 --> 00:29:28,930
但实际上，你在同一台机器上运行许多许多进程。

477
00:29:33,740 --> 00:29:35,540
好的，到目前为止，有什么问题吗，

478
00:29:35,630 --> 00:29:39,650
在我继续讨论一些技术内容之前。

479
00:29:41,820 --> 00:29:45,630
实验 4 的结果，

480
00:29:45,720 --> 00:29:51,330
它与现有的任何程序类似吗？

481
00:29:51,880 --> 00:29:53,950
是的，你要构建的东西，

482
00:29:53,950 --> 00:29:57,460
与一些流行的键值服务很像，

483
00:29:57,460 --> 00:30:00,640
比如 redis 或者其他的，

484
00:30:00,670 --> 00:30:02,650
会有不同之处，

485
00:30:02,650 --> 00:30:05,680
当我们在这学期学习的过程中，

486
00:30:05,920 --> 00:30:08,590
但键值服务是非常有名的，

487
00:30:08,590 --> 00:30:13,180
是数据中心内部的公共服务，

488
00:30:13,180 --> 00:30:16,720
很多公司都在运行，其中一些知名公司，

489
00:30:16,720 --> 00:30:17,950
很多人在使用，

490
00:30:18,340 --> 00:30:20,500
它们都在处理相同的问题，

491
00:30:20,500 --> 00:30:22,360
如同你在实验中处理的问题，

492
00:30:22,720 --> 00:30:26,350
我们将构建一个具有相当强语义的应用程序，

493
00:30:26,680 --> 00:30:29,980
一些比人们实践中更强的语义，

494
00:30:29,980 --> 00:30:32,350
我们也会讨论为什么会发生，

495
00:30:32,350 --> 00:30:34,840
但是，是的，这与人们在实践中所做的非常接近，

496
00:30:35,630 --> 00:30:37,850
例如， raft 在实践中得到了广泛的应用。

497
00:30:42,320 --> 00:30:43,370
还有其他问题吗？

498
00:30:49,340 --> 00:30:51,740
是的，也是关于实验的问题，

499
00:30:51,770 --> 00:30:56,270
如果我们在实验 2 中有一个 bug ，

500
00:30:56,270 --> 00:30:59,720
可能没有被测试用例发现，

501
00:31:00,110 --> 00:31:05,990
我们会得到一个答案吗，用于后续的实验，

502
00:31:05,990 --> 00:31:07,610
还是我们继续使用我们的代码。

503
00:31:08,080 --> 00:31:10,810
是的，你将继续使用你的代码，

504
00:31:11,750 --> 00:31:16,430
我们尽了最大努力让实验测试尽可能好，

505
00:31:16,430 --> 00:31:21,170
但我相信有些情况下很难完成这项工作，

506
00:31:21,700 --> 00:31:25,510
每次我们发现我们遗漏的东西，

507
00:31:25,510 --> 00:31:27,160
我们会改进测试，

508
00:31:27,550 --> 00:31:30,100
所以你构建的，一旦你通过了测试，

509
00:31:30,400 --> 00:31:32,470
我们乐观地认为你已经实现了，

510
00:31:32,470 --> 00:31:34,570
可以支持其他用例，

511
00:31:34,570 --> 00:31:36,160
我们要学本学期剩余时间所做的。

512
00:31:38,940 --> 00:31:43,110
人们重写一次或两次的情况并不少见，

513
00:31:43,660 --> 00:31:46,270
你将在实验 2 和实验 3 中看到，

514
00:31:46,270 --> 00:31:47,290
这个结构体，

515
00:31:47,290 --> 00:31:49,870
你必须花相当多的时间

516
00:31:49,870 --> 00:31:52,600
来考虑应用程序或库的结构，

517
00:31:53,050 --> 00:31:55,480
随着你的学习，

518
00:31:55,720 --> 00:31:57,340
你可能想要回去重新做一次。

519
00:31:58,020 --> 00:32:00,210
为了帮助你们，

520
00:32:00,210 --> 00:32:03,090
今年我们要做一些与过去几年不同的事情，

521
00:32:03,270 --> 00:32:05,400
我将举办几场问答讲座，

522
00:32:05,400 --> 00:32:09,360
我们将分享我们的解决方案，

523
00:32:09,360 --> 00:32:11,340
或者我们将演示我们的解决方案，

524
00:32:11,340 --> 00:32:15,030
希望能告诉你一些关于，

525
00:32:15,060 --> 00:32:16,230
你可以从中学习，

526
00:32:16,230 --> 00:32:18,360
看看与你自己的解决方案有什么不同，

527
00:32:18,360 --> 00:32:21,420
或许能为未来的实验获得一些想法。

528
00:32:27,160 --> 00:32:28,060
还有其他问题吗？

529
00:32:34,740 --> 00:32:35,400
好的?

530
00:32:36,300 --> 00:32:38,010
再说一遍，随时可以打断我，

531
00:32:38,070 --> 00:32:41,160
我想让它更具互动性，

532
00:32:41,490 --> 00:32:42,900
我们可能会上几节课，

533
00:32:42,900 --> 00:32:44,100
但我们能到达那里。

534
00:32:46,180 --> 00:32:50,250
好的，我想讨论一下，

535
00:32:50,820 --> 00:32:53,970
为今天的案例研究做准备，

536
00:32:54,180 --> 00:32:55,380
但在此之前，

537
00:32:55,380 --> 00:32:58,950
我想说一下对这门课的一些看法，

538
00:32:58,950 --> 00:33:00,990
我们在这门课的重点将放在基础设施上，

539
00:33:01,110 --> 00:33:03,330
你可以从实验中或多或少地看出这一点，

540
00:33:03,330 --> 00:33:05,520
就是我们刚讨论过的，

541
00:33:07,190 --> 00:33:08,960
所以会有人

542
00:33:08,960 --> 00:33:11,930
在这些分布式系统上编写应用程序，

543
00:33:11,930 --> 00:33:14,930
我们完全不关心应用程序，

544
00:33:15,260 --> 00:33:17,300
我们主要关注

545
00:33:17,300 --> 00:33:19,700
支持这些应用程序的基础架构，

546
00:33:20,060 --> 00:33:22,850
基础设施分为三个不同的类别，

547
00:33:22,850 --> 00:33:24,050
或者非常宽泛地说，

548
00:33:24,080 --> 00:33:30,760
存储基础架构，比如键值服务器、文件系统等。

549
00:33:30,820 --> 00:33:41,200
计算框架，用来编排或构建分布式应用程序，

550
00:33:41,380 --> 00:33:44,830
比如经典的例子是 mapreduce ，

551
00:33:44,830 --> 00:33:46,390
我们稍后会谈到。

552
00:33:46,780 --> 00:33:49,450
然后第三类是通信，

553
00:33:53,570 --> 00:33:56,240
我们在通信上花费更少的时间，

554
00:33:56,240 --> 00:33:59,870
它更多是关于 6.829 网络系统的话题，

555
00:34:00,230 --> 00:34:01,640
但它会出现，

556
00:34:01,670 --> 00:34:02,630
从某种意义上说，

557
00:34:02,630 --> 00:34:07,190
网络系统和分布式系统之间是有关联的。

558
00:34:07,520 --> 00:34:10,880
这是一个重要的话题，

559
00:34:10,880 --> 00:34:16,790
比如，第一天我们将讨论远程过程调用 RPC ，

560
00:34:17,160 --> 00:34:21,450
这是所有实验构建的基础，

561
00:34:21,480 --> 00:34:24,270
这是一种通信模式，

562
00:34:24,270 --> 00:34:25,680
这里的问题是，

563
00:34:25,890 --> 00:34:29,130
RPC 系统提供了什么样的语义，

564
00:34:29,460 --> 00:34:32,010
最多一次，恰好一次，至少一次，

565
00:34:32,340 --> 00:34:35,070
我们将在周四的课程中讨论这一点，

566
00:34:35,280 --> 00:34:40,110
这就是通信和分布式系统关联的地方。

567
00:34:40,980 --> 00:34:42,540
查看这三个种类，

568
00:34:42,540 --> 00:34:45,720
存储，可以持久地存储数据，

569
00:34:46,080 --> 00:34:48,810
计算，用来运行计算，

570
00:34:48,810 --> 00:34:51,630
通信，用来在不同的部分互相通信，

571
00:34:52,080 --> 00:34:54,180
所以这是三个基本的事情，

572
00:34:54,180 --> 00:34:57,300
我们构建分布式系统。

573
00:34:57,450 --> 00:34:59,850
我们寻找某种抽象，

574
00:34:59,850 --> 00:35:04,080
已被证明对构建分布式系统非常有帮助，

575
00:35:06,040 --> 00:35:10,630
有些抽象，比如远程过程调用或 mapreduce 库，

576
00:35:10,690 --> 00:35:13,960
或者存储系统，比如键值服务。

577
00:35:14,850 --> 00:35:17,940
通常我们的目标是，

578
00:35:17,940 --> 00:35:20,730
为了使分布式抽象

579
00:35:20,730 --> 00:35:24,480
看起来非常像普通的标准顺序抽象，

580
00:35:24,480 --> 00:35:26,130
你已经熟悉的，

581
00:35:26,130 --> 00:35:27,870
比如，我们构建一个存储系统，

582
00:35:28,290 --> 00:35:30,660
我们希望我们的分布式存储系统

583
00:35:30,660 --> 00:35:36,630
或多或少像单机顺序存储服务器一样，

584
00:35:36,630 --> 00:35:38,610
像笔记本电脑上的常规文件系统一样，

585
00:35:39,120 --> 00:35:40,530
除了，

586
00:35:40,530 --> 00:35:43,260
我们希望存储系统有更强的容错性，

587
00:35:43,290 --> 00:35:45,060
因为它们使用复制，

588
00:35:45,090 --> 00:35:46,560
可能会有更高的性能，

589
00:35:46,560 --> 00:35:48,060
因为它有很多机器，

590
00:35:48,300 --> 00:35:51,810
我们要找的系统的行为类似于，

591
00:35:51,810 --> 00:35:54,870
我们要找的抽象类似于单个机器。

592
00:35:55,800 --> 00:35:58,260
但是在实践中是很难做到的，

593
00:35:58,710 --> 00:36:00,030
你会看到，

594
00:36:00,030 --> 00:36:01,740
它看起来像，但不完全是，

595
00:36:01,770 --> 00:36:06,240
这是一个会多次出现的主题。

596
00:36:06,900 --> 00:36:13,970
实际上，这引出了课上会反复出现的主题，

597
00:36:14,770 --> 00:36:16,870
我们会一遍又一遍地看到。

598
00:36:23,230 --> 00:36:29,610
主要主题是容错，这并不令人惊讶，

599
00:36:31,150 --> 00:36:33,160
这有两个方面，

600
00:36:33,310 --> 00:36:36,610
定义一下容错是什么意思。

601
00:36:36,610 --> 00:36:38,830
一个是可用性，

602
00:36:39,580 --> 00:36:41,800
所以我们研究技术，

603
00:36:44,600 --> 00:36:50,240
我们研究使系统高可用的技术，

604
00:36:50,270 --> 00:36:52,490
所以我们的意思是，

605
00:36:52,490 --> 00:36:57,290
它们在失败的情况下继续提供它们的服务，

606
00:36:57,680 --> 00:37:00,260
这通常被表示为多个数字 9 ，

607
00:37:00,830 --> 00:37:02,690
0.999 的可靠性，

608
00:37:02,990 --> 00:37:07,070
所以这是容错的一个方面。

609
00:37:07,070 --> 00:37:09,470
我们关心容错的第二个方面，

610
00:37:09,470 --> 00:37:11,600
我们称为可恢复性，

611
00:37:17,880 --> 00:37:20,760
当机器崩溃或故障时，

612
00:37:20,970 --> 00:37:25,590
我们想在它重新启动后返回系统，

613
00:37:25,590 --> 00:37:27,390
这样我们可以保持可用性，

614
00:37:27,420 --> 00:37:29,460
因为如果我们不修复系统，

615
00:37:29,550 --> 00:37:32,190
然后所有的机器都会一个接一个宕机，

616
00:37:32,280 --> 00:37:33,540
直到没有机器，

617
00:37:33,540 --> 00:37:34,800
然后我们就没有服务了，

618
00:37:34,800 --> 00:37:37,830
所以重要的是我们要修复分布式系统，

619
00:37:37,980 --> 00:37:39,660
我们修复分布式系统的方式是，

620
00:37:39,660 --> 00:37:41,520
在机器重新启动时，

621
00:37:41,670 --> 00:37:44,580
我们需要恢复它的状态，

622
00:37:44,580 --> 00:37:47,400
然后我们开始重新参与分布式系统，

623
00:37:47,400 --> 00:37:49,920
这实际上很难，

624
00:37:49,980 --> 00:37:51,900
这是个困难的方面。

625
00:37:52,600 --> 00:37:56,620
可用性的关键技术是复制，

626
00:37:59,800 --> 00:38:05,290
我们用来实现可恢复性的关键技术是，

627
00:38:05,290 --> 00:38:07,510
日志或事务这样的东西，

628
00:38:08,670 --> 00:38:11,340
将东西写入持久存储器，

629
00:38:13,150 --> 00:38:15,280
这样当电力中断，

630
00:38:15,280 --> 00:38:16,900
机器重启之后，

631
00:38:16,900 --> 00:38:21,760
数据还在磁盘上，

632
00:38:26,700 --> 00:38:28,590
这就是容错方面。

633
00:38:29,400 --> 00:38:33,600
第二部分是所谓的一致性，

634
00:38:38,840 --> 00:38:42,650
这个协议是，

635
00:38:42,650 --> 00:38:46,490
服务器对操作提供，

636
00:38:46,610 --> 00:38:49,130
在具有并发性和故障的情况下，

637
00:38:49,670 --> 00:38:55,490
所以粗略地说，当我们考虑一致性时，

638
00:38:55,490 --> 00:39:02,870
理想的行为是与任何一台机器都提供的行为相同，

639
00:39:02,870 --> 00:39:07,280
所以，我们有一个复制的容错高性能文件系统在多台机器上，

640
00:39:07,370 --> 00:39:10,550
它的行为几乎与时序机器相同，

641
00:39:11,150 --> 00:39:15,440
所以这里的关键问题是某种形式。

642
00:39:15,470 --> 00:39:19,960
假设我们有一个键值服务器做 get 操作，

643
00:39:21,480 --> 00:39:26,480
返回最后一个 put 的值，

644
00:39:34,380 --> 00:39:35,790
如果你运行一台机器，

645
00:39:35,940 --> 00:39:38,160
完全没有并发操作，

646
00:39:38,160 --> 00:39:39,990
一个接一个地执行操作，

647
00:39:39,990 --> 00:39:41,610
比如 put put put ，

648
00:39:41,610 --> 00:39:43,080
然后 get get get ，

649
00:39:43,470 --> 00:39:46,470
当然，这个问题很难回答，

650
00:39:46,470 --> 00:39:50,040
你会假设 get 将返回最后一次 put 存储的值，

651
00:39:50,780 --> 00:39:53,750
但是一旦我们有了并发和失败，

652
00:39:53,750 --> 00:39:55,010
我们有很多机器，

653
00:39:55,220 --> 00:39:57,530
这其实不是非常明显，

654
00:39:57,530 --> 00:40:02,240
什么样的方式，什么样的协议是好的，

655
00:40:02,240 --> 00:40:04,820
我们会看到很多不同的协议，

656
00:40:04,850 --> 00:40:07,340
我们看到一些有很强的一致性，

657
00:40:07,340 --> 00:40:10,010
行为几乎就像一台顺序机器，

658
00:40:10,130 --> 00:40:13,940
或者一些有非常宽松的保证，

659
00:40:14,270 --> 00:40:18,560
提供非常不同的[]，

660
00:40:18,560 --> 00:40:21,170
比如，它们提供最终一致性，

661
00:40:21,200 --> 00:40:27,080
最终你会看到 get 会返回 put 的结果，

662
00:40:27,080 --> 00:40:27,980
但不是立即的。

663
00:40:28,800 --> 00:40:32,910
原因是，有不同类型的一致性，

664
00:40:32,940 --> 00:40:34,860
与性能直接相关，

665
00:40:37,670 --> 00:40:41,660
通常分布式系统的目标之一是提供高性能，

666
00:40:41,660 --> 00:40:44,840
比如扩展多台机器，

667
00:40:44,990 --> 00:40:47,750
为了实现性能，

668
00:40:47,840 --> 00:40:52,220
这与一致性和容错性是冲突的，

669
00:40:52,810 --> 00:40:55,990
为了达到强一致性，

670
00:40:55,990 --> 00:40:58,270
需要不同机器之间的通信，

671
00:40:58,360 --> 00:41:00,340
这可能会降低性能，

672
00:41:00,490 --> 00:41:03,070
类似地，为了实现容错，

673
00:41:03,070 --> 00:41:04,450
我们需要复制数据，

674
00:41:04,480 --> 00:41:07,600
意味着我们必须将数据从一台机器传送到另一台机器，

675
00:41:08,020 --> 00:41:11,710
如果我们将机器数据也写入持久久存储器，

676
00:41:12,010 --> 00:41:13,930
这个操作是很昂贵的，

677
00:41:14,330 --> 00:41:17,300
所以，复制会降低性能。

678
00:41:18,270 --> 00:41:22,230
所以，同时实现这些是三件事情，

679
00:41:22,440 --> 00:41:24,450
这是非常困难的，

680
00:41:24,480 --> 00:41:26,580
人们在实践中所做的是，

681
00:41:26,580 --> 00:41:27,600
他们做了不同的权衡，

682
00:41:27,600 --> 00:41:30,540
他们牺牲一些一致性来获得更好的性能，

683
00:41:30,540 --> 00:41:32,640
或者（牺牲）一些容错性来获得更好的性能，

684
00:41:32,880 --> 00:41:35,220
所以我们会在整个学期中看到，

685
00:41:35,310 --> 00:41:37,830
很多的不同类型的设计，

686
00:41:38,010 --> 00:41:41,670
用不同的方式进行权衡。

687
00:41:44,010 --> 00:41:45,420
稍微说明一下性能，

688
00:41:45,420 --> 00:41:47,010
它有两个方面，

689
00:41:47,010 --> 00:41:48,840
一个是吞吐量，

690
00:41:50,290 --> 00:41:53,710
你买更多的机器，

691
00:41:53,740 --> 00:41:56,170
希望吞吐量能随着机器数量的增加而增加，

692
00:41:56,440 --> 00:41:59,350
但是性能还有另一个方面，

693
00:41:59,380 --> 00:42:01,150
基本上很难实现，

694
00:42:01,180 --> 00:42:02,620
这就是低延迟，

695
00:42:05,640 --> 00:42:07,860
这一点在一些网站中尤为重要，

696
00:42:07,860 --> 00:42:09,840
你有几千台机器，

697
00:42:09,840 --> 00:42:13,380
当你点击 url ，会有一个用户请求，

698
00:42:13,380 --> 00:42:16,080
需要很多这样的机器参与，

699
00:42:16,500 --> 00:42:18,480
如果其中一台机器非常慢，

700
00:42:18,480 --> 00:42:20,730
也许它有一些机械故障，

701
00:42:20,730 --> 00:42:23,640
可能磁盘不是百分之百正常工作，

702
00:42:23,640 --> 00:42:28,470
或者其他一些方面工作不正常，

703
00:42:28,560 --> 00:42:32,910
一台慢的机器可能会导致整个用户体验变慢，

704
00:42:33,480 --> 00:42:35,880
这通常被称为尾部延迟。

705
00:42:37,540 --> 00:42:43,510
这个[担心]，会在整个学起不断出现，

706
00:42:43,510 --> 00:42:44,830
当我们讨论不同的机器时，

707
00:42:44,830 --> 00:42:48,850
甚至出现在今天的论文中， mapreduce 论文。

708
00:42:50,180 --> 00:42:52,610
所以另一个最后的话题会出现很多次，

709
00:42:52,670 --> 00:42:55,730
至少在课堂上，

710
00:42:55,730 --> 00:43:02,590
特别是实验的实现方面，

711
00:43:02,590 --> 00:43:06,250
这就是如何管理并发性，

712
00:43:06,250 --> 00:43:10,270
如何实现远程过程调用，

713
00:43:10,270 --> 00:43:12,790
自己构建分布式系统，

714
00:43:12,790 --> 00:43:15,400
会面临严重的实现挑战，

715
00:43:15,400 --> 00:43:18,820
这会在整个学期一遍又一遍地出现。

716
00:43:19,970 --> 00:43:20,930
部分原因是，

717
00:43:20,930 --> 00:43:23,390
我们希望获得性能、一致性和容错性，

718
00:43:23,390 --> 00:43:26,180
减少并发中的失败，

719
00:43:26,210 --> 00:43:28,430
这使得[磁盘]驱动器变得非常复杂。

720
00:43:30,740 --> 00:43:32,000
这些都是主要的话题，

721
00:43:33,050 --> 00:43:37,780
对这部分，有什么问题吗？

722
00:43:44,790 --> 00:43:47,160
好的，那我们开始深入研究，

723
00:43:47,550 --> 00:43:50,340
看第一个案例研究，

724
00:43:50,490 --> 00:43:53,130
通过 mapreduce 论文。

725
00:44:02,580 --> 00:44:07,230
这是 6.824 中的许多话题的解释，

726
00:44:07,230 --> 00:44:09,630
我们要讨论容错，

727
00:44:09,630 --> 00:44:12,840
我们要讨论性能和尾部延迟，

728
00:44:13,020 --> 00:44:16,770
我们在整个学期中会看到的各种问题，

729
00:44:16,770 --> 00:44:19,170
我们将看到一个系统来处理这一问题。

730
00:44:20,040 --> 00:44:23,700
很多话题都很好地说明了这一点，

731
00:44:28,340 --> 00:44:30,290
这篇论文也很有影响力，

732
00:44:35,650 --> 00:44:40,240
虽然 Google 内部并没有完全使用本文描述的 mapreduce ，

733
00:44:40,240 --> 00:44:44,590
他们使用从这个 mapreduce 派生的系统，

734
00:44:44,770 --> 00:44:46,570
他们仍然在日常使用，

735
00:44:46,720 --> 00:44:51,820
还有其他库类似 mapreduce ，

736
00:44:51,820 --> 00:44:53,650
它们被广泛使用，

737
00:44:54,010 --> 00:44:59,290
它还启发了 mapreduce 之外的不同类型的计算模型，

738
00:44:59,380 --> 00:45:02,350
我们会在本学期晚些时候看到一两个，

739
00:45:02,350 --> 00:45:04,210
所以是很有影响力的论文。

740
00:45:06,360 --> 00:45:09,120
最后，这是实验 1 的话题，

741
00:45:09,240 --> 00:45:11,670
是讨论它的另一个很好的理由。

742
00:45:12,400 --> 00:45:15,940
你们中很多人可能已经看过 mapreduce 论文，

743
00:45:15,940 --> 00:45:18,100
在 6.033 课程中，

744
00:45:18,100 --> 00:45:20,710
如果你是麻省理工的本科生，

745
00:45:20,710 --> 00:45:22,810
否则你可能会在其他地方看到，

746
00:45:23,050 --> 00:45:28,690
但是我们要比 6.033 稍微深入一点，

747
00:45:28,690 --> 00:45:31,660
因为你必须实现自己的 mapreduce 库，

748
00:45:31,660 --> 00:45:36,190
而且和往常一样，当你实现一些东西时，

749
00:45:37,320 --> 00:45:41,190
你之前可能不会认真考虑的问题，

750
00:45:41,190 --> 00:45:42,600
会突然冒出来。

751
00:45:43,210 --> 00:45:44,440
所以到了最后，

752
00:45:44,440 --> 00:45:46,330
你会真正理解 mapreduce 。

753
00:45:50,080 --> 00:45:51,130
有什么问题吗？

754
00:46:04,480 --> 00:46:08,530
好的，让我给你一点关于这篇论文的背景，

755
00:46:08,560 --> 00:46:13,390
这篇论文是由 Google 的两位工程师撰写的，

756
00:46:14,370 --> 00:46:15,570
非常有名，

757
00:46:15,870 --> 00:46:20,190
背景是早期的数据中心，

758
00:46:20,580 --> 00:46:23,370
Google 有一个搜索引擎，

759
00:46:23,610 --> 00:46:27,810
需要构建万维网的反向索引，

760
00:46:27,810 --> 00:46:30,720
允许用户查询互联网，

761
00:46:31,320 --> 00:46:35,790
而这些计算要跑好几个小时，

762
00:46:42,480 --> 00:46:45,210
处理 TB 级别的数据，

763
00:46:49,600 --> 00:46:58,310
多个小时计算，在 TB 级别的数据上。

764
00:47:01,320 --> 00:47:07,600
所以考虑网络索引，网络爬行，特别是网络索引，

765
00:47:08,500 --> 00:47:09,910
其中一个[]应用程序，

766
00:47:10,330 --> 00:47:15,250
Google 在内部构建这样的应用程序，

767
00:47:15,400 --> 00:47:18,880
Sanjay 和 Jeffrey Dean ，两个[]，

768
00:47:19,150 --> 00:47:21,520
他们在这方面很在行，

769
00:47:21,520 --> 00:47:23,110
但他们发现，

770
00:47:23,350 --> 00:47:25,720
还有许多其他谷歌工程师

771
00:47:25,720 --> 00:47:28,660
也想要编写这种类型的应用程序，

772
00:47:28,660 --> 00:47:31,210
他们希望编写自己的数据分析

773
00:47:31,330 --> 00:47:33,910
针对所有被爬行的网页，

774
00:47:34,390 --> 00:47:39,760
他们意识到编写这类应用程序是很困难的，

775
00:47:39,850 --> 00:47:43,570
因为如果你在许多机器上运行多个小时的计算，

776
00:47:43,660 --> 00:47:47,650
很有可能其中一台机器会在计算过程中崩溃，

777
00:47:47,890 --> 00:47:51,490
所以，你必须制定一些容错计划，

778
00:47:51,550 --> 00:47:54,310
一旦你开始这么做，

779
00:47:54,310 --> 00:47:57,820
就要求你已经掌握了类似 6.824 的课程，

780
00:47:58,030 --> 00:48:02,080
并且能够构建这种复杂的系统，

781
00:48:02,380 --> 00:48:07,740
他们的目标是走出这种困境，

782
00:48:07,770 --> 00:48:19,650
并使它对非专业人士编写分布式应用程序变得容易。

783
00:48:20,700 --> 00:48:27,030
这就是这篇论文的动机，

784
00:48:27,030 --> 00:48:29,310
以及为什么你对此非常兴奋。

785
00:48:29,460 --> 00:48:30,840
所以他们采取的方法，

786
00:48:32,180 --> 00:48:34,370
mapreduce 采用的是，

787
00:48:34,430 --> 00:48:37,460
它不是一个通用库，

788
00:48:37,460 --> 00:48:39,890
你不能接受任何应用程序，

789
00:48:39,890 --> 00:48:44,000
使用 mapreduce 使其具有容错能力，

790
00:48:44,620 --> 00:48:47,710
它必须写成一种特殊的格式，

791
00:48:47,710 --> 00:48:50,800
也就是使用 map 函数和 reduce 函数，

792
00:48:51,220 --> 00:48:54,320
这些函数是函数式的或无状态的，

793
00:48:55,130 --> 00:49:01,520
但是这些都是程序员编写的顺序代码，

794
00:49:03,920 --> 00:49:10,580
这两个函数， map 和 reduce 函数是一种框架，

795
00:49:10,640 --> 00:49:15,610
mapreduce 框架处理所有分布式的[]。

796
00:49:25,110 --> 00:49:27,600
它将安排应用程序

797
00:49:27,600 --> 00:49:30,600
或程序的二进制文件在多台计算机上运行，

798
00:49:30,600 --> 00:49:32,760
或安装在多台机器上，

799
00:49:32,760 --> 00:49:34,200
并处理负载平衡，

800
00:49:34,440 --> 00:49:36,660
它处理的是某些速度很慢的机器，

801
00:49:36,780 --> 00:49:39,150
它处理崩溃的机器，

802
00:49:39,270 --> 00:49:40,740
所以应用程序编写者，

803
00:49:40,740 --> 00:49:42,810
编写 mapreduce 函数的人，

804
00:49:42,840 --> 00:49:44,760
根本不必担心这个，

805
00:49:45,500 --> 00:49:48,980
他们透明地得到了所有东西。

806
00:49:49,830 --> 00:49:51,750
为了实现这一点，

807
00:49:51,810 --> 00:49:54,300
这个库不是通用的，

808
00:49:54,510 --> 00:49:56,610
比如，您想要编写一个键值服务，

809
00:49:56,670 --> 00:49:58,050
你可以使用 mapreduce 库，

810
00:49:58,050 --> 00:50:00,660
因为它假设一种特殊的计算模型，

811
00:50:00,810 --> 00:50:02,670
你的应用必须符合这一点，

812
00:50:03,210 --> 00:50:05,340
这个计算模型像

813
00:50:05,340 --> 00:50:07,290
他们在 Google 经常看到的一些东西，

814
00:50:07,290 --> 00:50:10,920
比如人们想要做大数据分析，

815
00:50:10,920 --> 00:50:13,320
在整个世界的所有网页上，

816
00:50:14,060 --> 00:50:17,570
有许多类型的计算需要处理大量数据，

817
00:50:17,810 --> 00:50:20,360
并根据这些数据计算值。

818
00:50:21,130 --> 00:50:25,330
这就是 mapreduce 的目标应用程序类型。

819
00:50:26,190 --> 00:50:30,780
关于这篇论文的上下文和动机，有什么问题吗？

820
00:50:41,770 --> 00:50:43,720
好的，让我继续。

821
00:50:45,200 --> 00:50:49,670
所以，让我先画一个抽象视图，

822
00:50:56,460 --> 00:50:58,260
然后我们将深入探讨更多细节。

823
00:50:59,080 --> 00:51:03,310
所以，你需要了解背景，

824
00:51:03,430 --> 00:51:07,480
并理解 mapreduce 是如何工作的，

825
00:51:07,480 --> 00:51:10,210
当你在做实验 1 的时候，这是非常重要的。

826
00:51:10,690 --> 00:51:12,310
这里有一堆输入文件，

827
00:51:12,370 --> 00:51:16,810
比如 f1 f2 f3 ，

828
00:51:17,240 --> 00:51:19,460
当然，在 Google 的案例中，会有更多，

829
00:51:19,460 --> 00:51:21,560
但是只是出于教学上的原因，

830
00:51:21,560 --> 00:51:26,600
还有我能展示的大小，

831
00:51:26,600 --> 00:51:28,580
我只有三个文件。

832
00:51:29,310 --> 00:51:36,240
对于每个文件，都是由 map 函数处理的，

833
00:51:36,240 --> 00:51:38,220
由程序员编写的，

834
00:51:38,520 --> 00:51:42,060
并产生一些输出，中间输出，

835
00:51:42,330 --> 00:51:46,980
比如，讨论 mapreduce 的经典案例是字数统计，

836
00:51:47,310 --> 00:51:52,350
计算一个词在数据集中出现的次数，

837
00:51:52,350 --> 00:51:54,540
或者数据集包含很多文件，

838
00:51:55,050 --> 00:52:00,180
比如，我们正在对文件一运行字数统计函数，

839
00:52:00,300 --> 00:52:06,360
它为每个单词生成键值对，

840
00:52:06,390 --> 00:52:10,230
键值对包含单词作为键和计数 1 ，

841
00:52:11,990 --> 00:52:15,230
如果 a 在文件 f1 中出现多次，

842
00:52:15,230 --> 00:52:19,640
它会包含多个键值对 a,1 。

843
00:52:21,460 --> 00:52:24,370
可能这个文件包含很多单词，

844
00:52:24,370 --> 00:52:27,100
可能会包含 a,1 和 b,1 ，

845
00:52:27,340 --> 00:52:28,450
这个文件包含两个词，

846
00:52:29,170 --> 00:52:30,340
类似的，

847
00:52:30,340 --> 00:52:35,050
map 函数对文件 f2 做同样的事情，

848
00:52:35,050 --> 00:52:36,280
并产生一些键值对，

849
00:52:36,280 --> 00:52:41,030
假设可能只有 b 这个词在文件中出现了一次。

850
00:52:42,040 --> 00:52:47,620
map 函数也会处理文件 f3 ，

851
00:52:48,010 --> 00:52:50,020
让我们假设，

852
00:52:50,020 --> 00:52:53,470
我们假设 a 只出现了一次，

853
00:52:53,740 --> 00:52:56,260
并且词 c 出现一次。

854
00:52:57,780 --> 00:53:00,870
所以这些 map 函数都是并行运行的，

855
00:53:00,960 --> 00:53:02,580
彼此完全独立，

856
00:53:02,580 --> 00:53:04,440
它们之间没有通信，

857
00:53:04,470 --> 00:53:05,850
在它们的输入文件上，

858
00:53:06,210 --> 00:53:08,490
所以这将给我们带来高吞吐量，

859
00:53:08,520 --> 00:53:11,970
或者扩展更大的数据集，

860
00:53:12,450 --> 00:53:14,700
他们在这些中间值中产生，

861
00:53:14,730 --> 00:53:16,230
这些键值对，

862
00:53:16,860 --> 00:53:19,680
a,1 b,1 或者 a,1 c,2 。

863
00:53:21,270 --> 00:53:25,140
然后，第二步通常称为 shuffle ，

864
00:53:25,350 --> 00:53:30,870
也就是在每一行上运行 reduce 函数。

865
00:53:31,320 --> 00:53:33,870
所以在这里我们得到了所有的一排 a ，

866
00:53:34,460 --> 00:53:37,670
我们将运行 reduce 函数，

867
00:53:39,830 --> 00:53:43,640
reduce 函数使用一个键，

868
00:53:43,670 --> 00:53:44,750
聚合所有，

869
00:53:45,770 --> 00:53:49,280
reduce 函数获取输入，键加上聚合值，

870
00:53:49,280 --> 00:53:55,490
聚合从不同 map 中输出的组合值，

871
00:53:55,490 --> 00:53:56,330
所以在这种情况下，

872
00:53:56,600 --> 00:54:00,170
reduce 函数会获取两个中间结果，

873
00:54:00,170 --> 00:54:03,860
键 a 和两个值 1 1 。

874
00:54:04,480 --> 00:54:07,000
在这种情况下，在字数统计的情况下，

875
00:54:07,000 --> 00:54:07,750
我们只要把它们加起来，

876
00:54:07,780 --> 00:54:09,910
所以它会产生值，

877
00:54:10,330 --> 00:54:12,490
键值对 a,2 。

878
00:54:13,310 --> 00:54:17,330
我们所做的，

879
00:54:17,330 --> 00:54:21,200
我们对每一行执行 reduce ，

880
00:54:22,510 --> 00:54:25,390
所以这会产生 b,2 ，

881
00:54:25,600 --> 00:54:29,050
然后最后一个是 c,1 。

882
00:54:30,350 --> 00:54:34,010
一旦我们做了 shuffle ，

883
00:54:34,010 --> 00:54:36,680
这些 reduce 函数可以完全彼此独立地运行，

884
00:54:36,710 --> 00:54:40,460
它们可以处理任何它们的行数据，

885
00:54:40,670 --> 00:54:42,500
并且完成它，

886
00:54:42,950 --> 00:54:45,650
所以唯一非常昂贵的部分，

887
00:54:45,650 --> 00:54:48,020
是这个中间的 shuffle ，

888
00:54:48,470 --> 00:54:53,240
reduce 函数需要

889
00:54:54,430 --> 00:54:57,640
从每个 mapper 获取它们的输入，

890
00:54:58,270 --> 00:54:59,890
当所有的 mapper 都完成后，

891
00:54:59,890 --> 00:55:02,200
reduce 函数需要，

892
00:55:02,200 --> 00:55:05,980
需要联系每个 mapper ，

893
00:55:06,010 --> 00:55:10,300
提取输出，

894
00:55:10,330 --> 00:55:12,700
reduce 函数对应的 map 的输出，

895
00:55:13,060 --> 00:55:16,030
按照键进行排序，

896
00:55:16,030 --> 00:55:17,950
然后运行 reduce 函数。

897
00:55:18,670 --> 00:55:20,920
所以我们假设，

898
00:55:20,920 --> 00:55:22,780
就像论文指出的那样，

899
00:55:22,810 --> 00:55:24,460
昂贵的操作是，

900
00:55:24,580 --> 00:55:27,400
在 mapper 和 reducer 之间的 shuffle 数据，

901
00:55:30,640 --> 00:55:33,570
对于这个抽象图，有什么问题吗？

902
00:55:38,790 --> 00:55:39,240
好的？

903
00:55:39,810 --> 00:55:41,250
抱歉，我有个问题，

904
00:55:41,700 --> 00:55:45,300
那么，是不是，

905
00:55:45,300 --> 00:55:50,040
我知道不是所有的问题都可以在 mapreduce 阶段表达出来，

906
00:55:50,040 --> 00:55:54,300
但是比如数组进行排序，

907
00:55:54,480 --> 00:55:56,460
有没有可能。

908
00:55:56,670 --> 00:56:01,530
是的，排序是他们在论文中谈论得最多的应用之一，

909
00:56:01,560 --> 00:56:05,460
这是完全由 mapreduce 完成的，

910
00:56:05,460 --> 00:56:08,250
你可以将输入文件拆分成很多部分，

911
00:56:08,250 --> 00:56:12,570
mapper 对这些部分排序，

912
00:56:12,840 --> 00:56:16,830
然后，他们拆分输出为 r 个桶，

913
00:56:17,100 --> 00:56:20,610
然后每个 reduce 函数对 r 个桶进行排序，

914
00:56:21,300 --> 00:56:22,920
给出一个完整的文件。

915
00:56:25,720 --> 00:56:26,530
我明白了，好的。

916
00:56:28,090 --> 00:56:29,890
在这种情况下很有趣，

917
00:56:29,890 --> 00:56:36,700
因为输入、中间值和输出的大小相同，

918
00:56:37,030 --> 00:56:38,950
其他一些函数，比如 map 函数，

919
00:56:38,950 --> 00:56:44,440
可能会将中间状态减少为比输入尺寸小得多的值，

920
00:56:44,440 --> 00:56:47,170
在排序的情况中，不是这种情况。

921
00:56:49,770 --> 00:56:51,390
好的，我们来看论文，

922
00:56:51,390 --> 00:56:54,930
让你知道如何编写它们。

923
00:56:58,230 --> 00:57:00,240
好的，看我能不能。

924
00:57:03,000 --> 00:57:07,840
那太烦人了，我的菜单丢了。

925
00:57:08,460 --> 00:57:10,110
稍等一下。

926
00:57:22,050 --> 00:57:24,510
好吧，这不是很好，

927
00:57:24,510 --> 00:57:25,470
给我点时间，

928
00:57:25,950 --> 00:57:26,940
在这里，

929
00:57:27,540 --> 00:57:29,280
所以我们保存。

930
00:57:30,610 --> 00:57:32,650
好的，这里是 mapreduce 。

931
00:57:35,260 --> 00:57:37,300
好的，大家能看到这个吗？

932
00:57:41,650 --> 00:57:43,060
好的，这里有几个问题，

933
00:57:45,790 --> 00:57:47,650
让我暂且不提这些问题，

934
00:57:47,650 --> 00:57:51,820
稍后我们会更详细地讨论，

935
00:57:52,760 --> 00:57:56,390
如果我没有回答你的问题，请再问一遍。

936
00:57:56,980 --> 00:57:58,150
所以我想做的第一件事是，

937
00:57:58,150 --> 00:58:01,540
查看论文中的一个关于 map 和 reduce 函数的示例，

938
00:58:01,780 --> 00:58:03,700
对应于字数统计示例，

939
00:58:03,700 --> 00:58:05,470
在某种程度上[抽象地]讨论。

940
00:58:06,030 --> 00:58:10,740
这是 map 和 reduce 函数，

941
00:58:10,740 --> 00:58:14,460
你可以看到 map 函数获取 key value ，

942
00:58:14,670 --> 00:58:16,650
key 在这里并不重要，

943
00:58:16,650 --> 00:58:19,140
它是文档名称，比如 f1 或 f2 ，

944
00:58:19,350 --> 00:58:22,590
value 字符串是文件的内容，

945
00:58:23,120 --> 00:58:26,870
所有在文件 f1 中出现的单词，

946
00:58:27,560 --> 00:58:28,850
它是遍历，

947
00:58:28,850 --> 00:58:32,810
伪代码遍历文件中的单词，

948
00:58:33,020 --> 00:58:34,520
作为中间值，

949
00:58:34,520 --> 00:58:38,990
发出这些 a,1 b,1 c,1 等。

950
00:58:39,680 --> 00:58:41,150
从程序员的角度来看，

951
00:58:41,180 --> 00:58:44,690
根本不会看到这些中间键值对，

952
00:58:44,840 --> 00:58:47,540
你只需编写这个简单的 map 函数。

953
00:58:48,960 --> 00:58:52,770
然后， reduce 函数大概是这样的，

954
00:58:52,770 --> 00:58:55,690
它获取两个参数，

955
00:58:55,690 --> 00:58:57,340
比如 key 是 a ，

956
00:58:57,640 --> 00:59:01,480
并且在这种情况下，字数统计的 values 是 1 1 1 1 ，

957
00:59:01,480 --> 00:59:06,430
是单词 a 在中间输出中出现的次数，

958
00:59:06,920 --> 00:59:08,660
这个函数的作用是，

959
00:59:08,660 --> 00:59:12,350
它只是遍历 values 列表，

960
00:59:12,350 --> 00:59:15,350
然后加 1 ，加 1 ，加 1 ，加 1 ，

961
00:59:15,470 --> 00:59:17,300
然后是最终结果。

962
00:59:18,880 --> 00:59:22,630
这是你可以从这段代码中看到的，

963
00:59:22,630 --> 00:59:24,340
程序员基本上总是编写，

964
00:59:24,340 --> 00:59:27,340
[完整的]简单的顺序代码，

965
00:59:27,670 --> 00:59:30,160
不可否认，这个应用程序非常简单，

966
00:59:30,340 --> 00:59:34,180
但是更复杂的应用程序的代码也是简单的，

967
00:59:34,180 --> 00:59:36,070
顺序可能是更多的代码，

968
00:59:36,070 --> 00:59:37,870
但它还是简单的顺序代码。

969
00:59:38,640 --> 00:59:41,460
在这段代码中，程序员根本不用担心，

970
00:59:41,460 --> 00:59:42,750
机器可能会崩溃，

971
00:59:42,780 --> 00:59:44,490
可能会有负载均衡，

972
00:59:44,550 --> 00:59:47,280
这些都是由 mapreduce 库的处理的。

973
00:59:48,990 --> 00:59:50,700
所以希望，

974
00:59:50,700 --> 00:59:52,590
我认为这已经被证明是真的，

975
00:59:52,590 --> 00:59:56,670
这让很多人编写分布式应用程序，

976
00:59:56,670 --> 01:00:01,830
并处理海量数据集，完全没有办法放在一台机器上，

977
01:00:02,860 --> 01:00:04,750
比如，整个万维网。

978
01:00:07,260 --> 01:00:08,040
这能理解吗，

979
01:00:08,040 --> 01:00:12,560
关于程序员能看到什么。

980
01:00:15,440 --> 01:00:18,350
好的，让我们来谈谈实现的问题。

981
01:00:22,740 --> 01:00:25,080
我用的是论文上的这个图表，

982
01:00:28,340 --> 01:00:31,250
我们有了用户程序，

983
01:00:31,250 --> 01:00:35,930
用户程序就像我们刚才看到的 map 和 reduce 函数，

984
01:00:35,930 --> 01:00:40,130
你把 map 和 reduce 函数提交给，

985
01:00:40,580 --> 01:00:44,690
你链接它与 mapreduce 库，形成二进制文件，

986
01:00:45,020 --> 01:00:48,410
然后把这个交给 Google 作业调度器，

987
01:00:48,410 --> 01:00:52,610
它会找到很多机器，

988
01:00:52,820 --> 01:00:55,910
在那里运行他们称为 worker 的东西，

989
01:00:56,340 --> 01:00:59,460
调度器将会，

990
01:00:59,490 --> 01:01:02,340
比如在我们稍后会看到评估中，

991
01:01:02,340 --> 01:01:04,200
这里大约有 1800 台机器，

992
01:01:04,350 --> 01:01:05,970
在这 1800 台机器上，

993
01:01:05,970 --> 01:01:08,310
调度器将运行 worker 进程，

994
01:01:08,460 --> 01:01:11,310
它会实际来工作，

995
01:01:11,310 --> 01:01:15,690
并在适当的时候调用 map 和 reduce 函数。

996
01:01:16,850 --> 01:01:19,520
还有另一个重要的进程，

997
01:01:19,550 --> 01:01:21,560
在论文中称为 master 进程，

998
01:01:21,560 --> 01:01:23,210
在实验中称为协调器，

999
01:01:23,390 --> 01:01:27,380
协调器[]编排 workers ，

1000
01:01:27,380 --> 01:01:32,360
把 map 工作交给它们，

1001
01:01:32,360 --> 01:01:33,560
关于术语，

1002
01:01:33,560 --> 01:01:38,510
下面是一个完整的 mapreduce 作业，

1003
01:01:38,630 --> 01:01:46,010
确定的 reduce 或确定的 map 则称为任务。

1004
01:01:47,430 --> 01:01:55,620
所以协调器会把文件分配给特定的 worker ，

1005
01:01:55,620 --> 01:02:00,810
然后， worker 在那个特定文件上调用 map 函数，

1006
01:02:00,900 --> 01:02:03,060
它会产生一些中间结果，

1007
01:02:03,460 --> 01:02:04,720
这里的中间结果，

1008
01:02:04,720 --> 01:02:10,210
这些中间结果存储在机器的本地盘上，

1009
01:02:10,210 --> 01:02:12,190
实际运行那个 map 函数的机器。

1010
01:02:13,720 --> 01:02:18,250
当 worker 已经完成运行了特定的 map 函数，

1011
01:02:18,400 --> 01:02:21,250
就会告诉 master ，我完成了 map 函数，

1012
01:02:21,400 --> 01:02:26,950
并告诉 master 中间结果在哪里。

1013
01:02:27,930 --> 01:02:32,820
然后，当所有 map 都完成时，

1014
01:02:32,910 --> 01:02:36,630
协调器会开始运行 reduce 函数，

1015
01:02:36,840 --> 01:02:42,240
reduce 函数将收集来自不同 mapper 的中间结果，

1016
01:02:42,270 --> 01:02:47,640
从结果记录中指定的位置，

1017
01:02:48,270 --> 01:02:50,580
获取数据，按键排序，

1018
01:02:50,610 --> 01:02:52,920
然后 reduce 运行，

1019
01:02:52,920 --> 01:02:57,690
在每个 key 和 values 列表上调用 reduce 函数，

1020
01:02:58,700 --> 01:03:00,710
这会产生一个输出文件，

1021
01:03:00,890 --> 01:03:04,550
每个 reduce 函数有一个输出文件，

1022
01:03:04,820 --> 01:03:07,280
你可以聚合输出文件，

1023
01:03:07,280 --> 01:03:09,890
连接输出文件以获得最终输出。

1024
01:03:11,440 --> 01:03:12,820
这就是结构，

1025
01:03:13,240 --> 01:03:17,710
输入文件在一个全局文件系统中，称为 GFS ，

1026
01:03:18,250 --> 01:03:20,560
Google 现在使用的是不同的全球文件系统，

1027
01:03:20,560 --> 01:03:22,900
但这个论文使用的是 GFS ，

1028
01:03:22,900 --> 01:03:25,360
我们下周会看 GFS 的内容，

1029
01:03:25,630 --> 01:03:27,760
输出文件也会发送到 GFS ，

1030
01:03:28,060 --> 01:03:31,330
中间文件不保存在 GFS 中，

1031
01:03:31,330 --> 01:03:35,800
它们存储在 worker 运行的本地机器上。

1032
01:03:38,680 --> 01:03:42,550
关于调度器的粗略实现，有什么问题吗？

1033
01:03:45,130 --> 01:03:49,120
我有一个关于远程读取文件的问题，

1034
01:03:49,210 --> 01:03:51,100
在远程读取进程中，

1035
01:03:51,100 --> 01:03:54,940
文件是否会传输到 reducer ？

1036
01:03:55,180 --> 01:03:58,030
是的，

1037
01:03:58,150 --> 01:04:01,300
中间结果生成或存储在

1038
01:04:01,300 --> 01:04:06,810
运行 map 函数的机器的磁盘上，

1039
01:04:06,900 --> 01:04:08,790
然后 reduce 出来，

1040
01:04:08,790 --> 01:04:13,740
从每个 mapper 获取 key 的集合。

1041
01:04:14,980 --> 01:04:17,830
在这里，数据是通过网络传输的，

1042
01:04:18,190 --> 01:04:20,680
所以网络通信发生在这里，

1043
01:04:24,990 --> 01:04:27,180
这里很少有网络通信，

1044
01:04:27,180 --> 01:04:28,920
完全没有网络通信的原因，

1045
01:04:28,980 --> 01:04:30,360
是因为 worker ，

1046
01:04:30,360 --> 01:04:37,740
协调器给 worker 分配文件的方式是，

1047
01:04:37,860 --> 01:04:42,060
worker 在同一台机器上运行，

1048
01:04:42,270 --> 01:04:45,840
每台机器都同时运行 worker 进程和 GFS 进程，

1049
01:04:46,170 --> 01:04:48,960
worker 发送，

1050
01:04:48,960 --> 01:04:55,170
map 函数运行在文件存储在 GFS 的机器上，

1051
01:04:55,640 --> 01:04:58,220
这相当于本地读取，

1052
01:04:58,220 --> 01:05:00,050
通过 GFS 到本地磁盘，

1053
01:05:00,260 --> 01:05:07,190
然后文件产生或 map 产生中间文件

1054
01:05:07,190 --> 01:05:08,330
也存储在本地磁盘上，

1055
01:05:08,330 --> 01:05:11,360
所以在图片的这部分没有发生通信。

1056
01:05:12,520 --> 01:05:13,870
然后当 reduce 函数运行时，

1057
01:05:14,020 --> 01:05:16,630
它们通过网络获取文件，

1058
01:05:16,630 --> 01:05:18,370
然后写入 GFS ，

1059
01:05:20,460 --> 01:05:22,890
这里会有一些网络通信，

1060
01:05:22,890 --> 01:05:25,830
当 worker 产生文件到全局文件系统时。

1061
01:05:29,130 --> 01:05:31,080
我还有一个问题，

1062
01:05:31,410 --> 01:05:38,160
协调器是否负责对数据进行分区，

1063
01:05:38,160 --> 01:05:46,000
并将数据放到每个 worker 或机器上？

1064
01:05:46,030 --> 01:05:50,410
不，不是， mapreduce 运行用户程序，

1065
01:05:50,410 --> 01:05:55,030
比如我想在 f1 f2 f3 f4 上运行，

1066
01:05:55,060 --> 01:05:56,170
所有这些输入文件，

1067
01:05:57,060 --> 01:05:59,640
这些输入文件在 GFS 中，

1068
01:06:00,380 --> 01:06:03,110
作为工作规范的一部分，

1069
01:06:03,110 --> 01:06:05,840
通常会说哪些文件需要处理。

1070
01:06:07,650 --> 01:06:08,220
好的。

1071
01:06:13,540 --> 01:06:18,700
抱歉，排序是怎么工作的，

1072
01:06:18,940 --> 01:06:22,780
比如谁做排序，怎么做。

1073
01:06:22,780 --> 01:06:26,080
mapreduce 库进行的一些排序，

1074
01:06:26,110 --> 01:06:29,440
在传递给到 reduce 函数之前，

1075
01:06:30,210 --> 01:06:32,130
比如，中间结果可能有，

1076
01:06:32,130 --> 01:06:36,690
比如所有的中间结果键 a b c 到一个 worker ，

1077
01:06:37,700 --> 01:06:43,340
这里有很多键值对，

1078
01:06:43,340 --> 01:06:49,280
比如 a,1 b,1 另一个 a,1 ，

1079
01:06:49,400 --> 01:06:52,010
还有 c,1 。

1080
01:06:52,420 --> 01:06:54,790
mapreduce 库所做的是，

1081
01:06:54,790 --> 01:06:56,140
它首先按键排序，

1082
01:06:56,170 --> 01:06:58,090
所以首先把所有的 a 放在一起，

1083
01:06:58,090 --> 01:06:59,080
然后所有的 b 放在一起，

1084
01:06:59,080 --> 01:07:00,400
然后所有的 c 在一起，

1085
01:07:00,520 --> 01:07:04,060
然后将来自单个键的所有值连接在一起，

1086
01:07:04,090 --> 01:07:05,860
并将其传递给 reduce 函数。

1087
01:07:08,630 --> 01:07:09,380
谢谢。

1088
01:07:17,880 --> 01:07:21,120
好的，现在我想稍微谈谈容错，

1089
01:07:21,300 --> 01:07:24,060
所以回到。

1090
01:07:32,840 --> 01:07:35,600
我可以问一个关于 mapreduce 论文的问题吗？

1091
01:07:36,620 --> 01:07:39,380
一个更大的想法，

1092
01:07:39,710 --> 01:07:45,110
很多函数式编程可以归结为 mapreduce 问题？

1093
01:07:45,740 --> 01:07:46,190
是的。

1094
01:07:46,370 --> 01:07:48,320
好的。

1095
01:07:48,380 --> 01:07:50,300
好的。

1096
01:07:50,630 --> 01:07:52,220
实际上，这个名字暗示了，

1097
01:07:52,220 --> 01:07:55,610
因为 map 和 reduce 函数的概念，

1098
01:07:55,610 --> 01:07:57,950
在函数式编程语言中非常常见，

1099
01:07:58,720 --> 01:08:01,510
并且在函数式编程语言中广泛使用，

1100
01:08:01,630 --> 01:08:03,370
或任何类型的函数式编程风格，

1101
01:08:03,400 --> 01:08:07,510
这就是灵感的来源。

1102
01:08:10,990 --> 01:08:11,590
好的?

1103
01:08:12,180 --> 01:08:14,370
那么现在转到容错性，

1104
01:08:14,460 --> 01:08:21,750
这个想法是，如果一个 worker 失败了，

1105
01:08:22,310 --> 01:08:25,880
然后协调器注意到 worker 失败了，

1106
01:08:25,880 --> 01:08:28,790
然后重启那个任务，

1107
01:08:29,310 --> 01:08:39,250
协调器重新运行 map 和 reduce 函数，

1108
01:08:42,340 --> 01:08:44,470
当然，协调器本身不会重新运行它们，

1109
01:08:44,470 --> 01:08:46,090
但协调器会说，

1110
01:08:46,090 --> 01:08:48,700
那个特定的 map 函数需要再次运行，

1111
01:08:48,970 --> 01:08:51,400
因为对协调器来说，

1112
01:08:51,400 --> 01:08:57,430
它交给任务的机器没有响应，

1113
01:08:57,610 --> 01:08:58,930
所以困难的事情是，

1114
01:08:58,930 --> 01:09:01,360
如果机器在一定时间内没有响应，

1115
01:09:01,420 --> 01:09:03,550
协调器就假设机器崩溃了。

1116
01:09:06,190 --> 01:09:13,360
这意味着当另一个 worker 空闲时，

1117
01:09:13,360 --> 01:09:15,550
在寻找一个新的任务，

1118
01:09:15,760 --> 01:09:17,500
它会分发相同的任务，

1119
01:09:17,500 --> 01:09:20,080
之前分发的，然后再次分发。

1120
01:09:21,460 --> 01:09:24,730
这就是容错的基本方案，

1121
01:09:24,910 --> 01:09:27,610
如果协调器没有收到，

1122
01:09:27,610 --> 01:09:31,840
worker 反馈任务已经完成了，

1123
01:09:32,020 --> 01:09:33,610
我们将重新运行该任务。

1124
01:09:34,180 --> 01:09:35,380
所以，立即出现一个问题，

1125
01:09:35,500 --> 01:09:38,890
map 函数是否可以运行两次，

1126
01:09:41,530 --> 01:09:42,610
甚至完成两次，

1127
01:09:50,160 --> 01:09:51,900
在这个框架里有没有可能，

1128
01:09:51,900 --> 01:09:54,780
一个特定的 map 会运行两次。

1129
01:09:55,850 --> 01:09:56,870
我想是的，

1130
01:09:56,870 --> 01:09:59,360
因为如果机器坏了，

1131
01:09:59,360 --> 01:10:02,380
你并不能区分是在哪个点，

1132
01:10:02,380 --> 01:10:08,250
多少个 map 任务已经执行了，

1133
01:10:08,670 --> 01:10:12,600
在 mapreduce 实际完成的过程中，

1134
01:10:12,600 --> 01:10:16,500
所以我想你需要重新运行所有任务。

1135
01:10:17,440 --> 01:10:21,430
是的，我们通常一次只考虑这一项任务，

1136
01:10:21,430 --> 01:10:24,520
比如机器完成一个任务，

1137
01:10:24,520 --> 01:10:27,010
然后向协调器请求下一个任务，

1138
01:10:27,040 --> 01:10:28,420
这可能是另一个 map 任务。

1139
01:10:28,960 --> 01:10:31,810
所以当协调器没有收到回应，

1140
01:10:31,990 --> 01:10:35,650
它会让另一个 worker 也运行那个 map 任务，

1141
01:10:35,770 --> 01:10:38,170
它可能是你提出的这种情况，

1142
01:10:38,170 --> 01:10:42,190
第一台机器实际上并没有崩溃，

1143
01:10:42,600 --> 01:10:44,190
只是碰到了网络分区，

1144
01:10:44,190 --> 01:10:47,820
或者比如协调器不能与机器通信，

1145
01:10:47,850 --> 01:10:50,760
但实际上，它仍然在运行 map 任务，

1146
01:10:51,120 --> 01:10:53,730
它会产生一组中间结果。

1147
01:10:54,460 --> 01:10:57,730
所以，同一个 map 函数可以运行两次，

1148
01:10:58,150 --> 01:11:03,520
所以 map 和 reduce 是编程式的原因之一，

1149
01:11:03,790 --> 01:11:05,290
是因为（这种执行两次的情况）是可以的，

1150
01:11:05,290 --> 01:11:06,730
如果它是一个函数是程序，

1151
01:11:06,760 --> 01:11:09,970
如果你使用相同的输入上运行相同的程序，

1152
01:11:10,360 --> 01:11:12,670
如果你使用相同的输入上运行函数程序，

1153
01:11:12,670 --> 01:11:14,440
它会产生完全相同的输出。

1154
01:11:14,840 --> 01:11:17,030
所以它运行两次很重要，

1155
01:11:17,060 --> 01:11:21,080
在这两种情况下，产生的输出是完全相同的，

1156
01:11:21,770 --> 01:11:25,730
这就是函数式方面非常重要的地方，

1157
01:11:26,720 --> 01:11:28,730
它必须是函数式性的或确定性的。

1158
01:11:33,080 --> 01:11:36,200
每次运行 map 函数都必须产生相同的输出，

1159
01:11:36,200 --> 01:11:40,850
因为会使用其中的一个到总的计算中。

1160
01:11:42,580 --> 01:11:44,530
类似的， reduce 函数可以运行两次吗？

1161
01:11:59,920 --> 01:12:01,450
是的，我想是的。

1162
01:12:01,960 --> 01:12:03,580
是的，出于同样的原因，

1163
01:12:03,640 --> 01:12:07,510
我的意思是，机器运行 reduce 函数和 map 任务没有什么不同，

1164
01:12:07,510 --> 01:12:09,400
从容错的角度来看，

1165
01:12:09,400 --> 01:12:12,310
map 任务和 reduce 任务之间并没有太大的区别，

1166
01:12:12,580 --> 01:12:17,170
如果运行 reduce 任务的机器没有反馈，

1167
01:12:17,170 --> 01:12:19,870
但也完成了工作，

1168
01:12:19,900 --> 01:12:22,660
另一台机器可能也在运行相同的 reduce 函数，

1169
01:12:24,060 --> 01:12:25,320
它们将产生输出。

1170
01:12:25,890 --> 01:12:27,990
现在有趣的方面是，

1171
01:12:28,110 --> 01:12:31,740
这两个 reduced 函数都会写入，

1172
01:12:31,740 --> 01:12:34,710
将最终输出文件写入 GFS ，

1173
01:12:35,300 --> 01:12:37,310
如果你注意到它，

1174
01:12:37,610 --> 01:12:39,800
你会注意到它们所做的是，

1175
01:12:39,800 --> 01:12:43,310
它们首先在全局文件系统中的产生一个中间文件，

1176
01:12:43,310 --> 01:12:44,750
然后进行原子重命名，

1177
01:12:47,670 --> 01:12:54,610
将文件重命名为实际的最终名称，

1178
01:12:55,620 --> 01:12:57,510
因为它是原子的，

1179
01:12:57,510 --> 01:12:59,640
这两个 reduce 函数中的一个将获胜，

1180
01:12:59,880 --> 01:13:01,950
但谁获胜并不重要，

1181
01:13:01,950 --> 01:13:03,900
因为它们会产生完全相同的结果，

1182
01:13:03,900 --> 01:13:04,710
因为它们是函数式的。

1183
01:13:08,470 --> 01:13:09,850
我想确认一下，

1184
01:13:09,910 --> 01:13:13,270
如果我们有一台机器正在执行 map 任务，

1185
01:13:13,270 --> 01:13:16,540
一台机器可以做多个 map 任务，

1186
01:13:16,540 --> 01:13:19,120
假设它正在执行 10 个 map 任务，

1187
01:13:19,330 --> 01:13:21,130
它在第七个任务中，

1188
01:13:21,370 --> 01:13:22,960
然后由于某种原因，它失败了，

1189
01:13:23,110 --> 01:13:24,970
然后 master 知道这台机器失败了，

1190
01:13:25,330 --> 01:13:29,950
然后 master 将安排所有 7 个已经完成的 map 任务，

1191
01:13:29,950 --> 01:13:32,980
分布式的重新执行，

1192
01:13:33,010 --> 01:13:35,230
可能分散在不同的 map 机器上。

1193
01:13:35,500 --> 01:13:37,960
是的，除了，这是对的，

1194
01:13:37,960 --> 01:13:41,080
虽然我认为它通常一次只有一个 map 函数，

1195
01:13:41,380 --> 01:13:46,150
所以，基本上一台机器运行一个 map 函数或一个 reduce 函数，而不是多个。

1196
01:13:47,680 --> 01:13:48,640
好的，谢谢。

1197
01:13:48,790 --> 01:13:52,870
但是在 worker 完成 map 任务后，

1198
01:13:53,440 --> 01:13:57,880
它是否会直接将其文件写入其他机器可见的位置，

1199
01:13:57,880 --> 01:14:01,270
或者它只是将文件保存在文件系统中。

1200
01:14:01,270 --> 01:14:01,810
它保存，

1201
01:14:01,810 --> 01:14:05,080
map 函数总是在本地磁盘上产生结果，

1202
01:14:05,260 --> 01:14:07,570
所以它在本地文件系统中。

1203
01:14:08,420 --> 01:14:12,440
好的，所以即使你一次只做一个 map 任务，

1204
01:14:12,650 --> 01:14:14,750
在你做了多次的场景下，

1205
01:14:14,780 --> 01:14:18,470
然后机器崩溃，你会丢失中间的工作，是吗。

1206
01:14:18,470 --> 01:14:20,240
不，它位于文件系统中，

1207
01:14:20,240 --> 01:14:21,560
所以当机器恢复时，

1208
01:14:21,590 --> 01:14:23,330
可能东西就在那里。

1209
01:14:24,090 --> 01:14:25,560
哦，我明白了。

1210
01:14:25,980 --> 01:14:28,200
所以这些数据是持久化保存的。

1211
01:14:29,070 --> 01:14:30,090
哦，我明白了，好的。

1212
01:14:32,140 --> 01:14:34,600
并且 map 或 reduce 函数直接访问

1213
01:14:34,600 --> 01:14:37,810
包含中间结果的机器。

1214
01:14:38,550 --> 01:14:41,580
好的，让我快速谈谈其他几个失败，

1215
01:14:47,140 --> 01:14:49,570
你们问的问题都是很棒的问题，

1216
01:14:49,810 --> 01:14:51,310
这一切都会显现出来，

1217
01:14:51,310 --> 01:14:52,990
当你实现 mapreduce 时，

1218
01:14:52,990 --> 01:14:55,540
你必须决定你要怎么做。

1219
01:14:56,630 --> 01:14:57,890
所以还有其他几件事，

1220
01:14:57,890 --> 01:15:10,510
协调器会失败吗？我不这样认为。

1221
01:15:11,180 --> 01:15:11,690
没错，

1222
01:15:11,930 --> 01:15:18,800
就像，是猫，

1223
01:15:18,800 --> 01:15:20,270
协调器不能失败，

1224
01:15:20,690 --> 01:15:22,340
所以当协调器失败时，

1225
01:15:22,340 --> 01:15:23,870
整个作业必须重新运行。

1226
01:15:24,670 --> 01:15:27,040
在这个特殊的实现中，

1227
01:15:27,040 --> 01:15:29,620
他们没有协调器失败的计划，

1228
01:15:30,620 --> 01:15:35,510
这使更强的容错性更困难，

1229
01:15:35,570 --> 01:15:37,040
因为它是一种状态，

1230
01:15:37,100 --> 01:15:38,600
一种被修改的状态，

1231
01:15:38,600 --> 01:15:41,810
每次 map 函数完成或 reduce 函数完成时，

1232
01:15:42,080 --> 01:15:44,660
所以它是更复杂的，

1233
01:15:44,660 --> 01:15:49,280
所以，这个特殊的库，协调器不能失败。

1234
01:15:50,160 --> 01:15:51,930
我们在后面的学期会看到技术，

1235
01:15:52,020 --> 01:15:54,180
我们可以用它来使协调器容错，

1236
01:15:54,180 --> 01:15:54,870
如果我们愿意，

1237
01:15:54,870 --> 01:15:56,220
但他们决定不这么做。

1238
01:15:57,050 --> 01:15:58,730
他们决定不这么做的一个原因是，

1239
01:15:58,730 --> 01:16:00,380
因为一台机器，

1240
01:16:00,830 --> 01:16:02,120
他们希望，

1241
01:16:02,120 --> 01:16:05,480
运行协调器的那台机器不太会崩溃，

1242
01:16:05,480 --> 01:16:06,500
更可能的是，

1243
01:16:06,500 --> 01:16:10,070
运行 map 程序的数千台机器中的一台很可能会崩溃。

1244
01:16:11,780 --> 01:16:12,350
好的?

1245
01:16:13,140 --> 01:16:14,250
那么慢的 worker 呢？

1246
01:16:21,180 --> 01:16:22,470
另一种类型的失败，

1247
01:16:22,500 --> 01:16:25,470
讨论机器可能会慢的问题，

1248
01:16:25,470 --> 01:16:27,480
因为在上面运行的其他计算一样，

1249
01:16:27,480 --> 01:16:29,520
比如 GFS 也在同一台机器上运行，

1250
01:16:29,700 --> 01:16:32,400
可能它会使用大量的机器周期或带宽，

1251
01:16:33,020 --> 01:16:36,320
或者可能硬件本身的问题。

1252
01:16:36,960 --> 01:16:38,370
他们有做什么特别的事吗？

1253
01:16:39,430 --> 01:16:41,590
我想我读过一些关于，

1254
01:16:41,590 --> 01:16:45,460
当工作接近尾声时，

1255
01:16:45,460 --> 01:16:50,080
协调器将剩余的任务分配给另外的机器，

1256
01:16:50,080 --> 01:16:53,950
防止有机器落后的情况，

1257
01:16:53,950 --> 01:16:57,160
然后他们会取先完成的结果。

1258
01:16:58,570 --> 01:17:00,160
是的，速度慢的 worker 称为 straggler ，

1259
01:17:01,700 --> 01:17:06,100
他们所做的是备份任务，

1260
01:17:06,490 --> 01:17:08,350
比如，当他们接近，

1261
01:17:08,380 --> 01:17:09,130
实际上，你会看到，

1262
01:17:09,130 --> 01:17:10,600
当计算快要完成时，

1263
01:17:10,600 --> 01:17:12,730
比如剩下几个 reduce 任务，

1264
01:17:12,730 --> 01:17:15,040
或者剩下几个 map 任务，

1265
01:17:15,040 --> 01:17:18,520
协调器只是运行第二个实例，

1266
01:17:18,520 --> 01:17:20,560
或者那个任务的第三个实例，

1267
01:17:20,560 --> 01:17:21,610
在另一台机器上。

1268
01:17:22,080 --> 01:17:22,890
这完全没问题，

1269
01:17:22,890 --> 01:17:24,300
这样做完全没问题，对吧，

1270
01:17:24,300 --> 01:17:25,470
因为它是函数式的，

1271
01:17:25,590 --> 01:17:29,820
所以我们多次运行相同的计算是没有问题的，

1272
01:17:29,820 --> 01:17:32,430
因为它产生完全相同的输出，

1273
01:17:32,430 --> 01:17:33,720
因为它的输入是相同的，

1274
01:17:33,870 --> 01:17:39,630
希望这些实例中的一个能很快结束，

1275
01:17:39,720 --> 01:17:44,460
因此，性能不受制于最慢的 worker ，

1276
01:17:44,700 --> 01:17:47,430
而是那些被复制的中最快的。

1277
01:17:49,480 --> 01:17:51,640
所以这是其中一个问题，

1278
01:17:51,640 --> 01:17:55,360
这是一个应对 straggler 的普遍做法，

1279
01:17:55,360 --> 01:17:56,560
为了处理尾部延迟，

1280
01:17:56,710 --> 01:18:00,910
就是试着复制任务，

1281
01:18:00,910 --> 01:18:03,760
然后获取第一个完成的。

1282
01:18:08,580 --> 01:18:11,610
好了，我想是时候结束了，

1283
01:18:11,640 --> 01:18:15,540
你可以去上其他的课，

1284
01:18:15,570 --> 01:18:16,980
但这些是一些主要问题，

1285
01:18:17,040 --> 01:18:19,260
出现在 mapreduce 库中的，

1286
01:18:19,260 --> 01:18:21,720
你很可能会艰难地进行，

1287
01:18:21,720 --> 01:18:24,540
实现 mapreduce 库最困难的部分，

1288
01:18:24,840 --> 01:18:27,030
是做容错方面的工作，

1289
01:18:27,210 --> 01:18:28,800
但是你应该记住，

1290
01:18:28,800 --> 01:18:29,730
当你这样做时，

1291
01:18:29,910 --> 01:18:32,940
所有使用或将要使用你的库的程序员，

1292
01:18:32,940 --> 01:18:34,980
不用考虑所有的分布性，

1293
01:18:35,250 --> 01:18:38,280
那些你必须去处理的。

1294
01:18:38,640 --> 01:18:40,320
所以你处于不幸的情况，

1295
01:18:40,410 --> 01:18:43,200
你不是 mapreduce 论文的目标，

1296
01:18:43,260 --> 01:18:45,990
让你轻松编写 mapreduce 程序，

1297
01:18:46,290 --> 01:18:49,200
你在[等式]的另一边，

1298
01:18:49,200 --> 01:18:51,030
你必须面对这种分布性，

1299
01:18:51,030 --> 01:18:52,470
并成为一名专家。

1300
01:18:54,410 --> 01:18:54,950
好的?

1301
01:18:55,500 --> 01:18:57,630
我会在这里一段时间，

1302
01:18:57,630 --> 01:18:59,610
所以如果你们想走，可以随意，

1303
01:18:59,610 --> 01:19:01,860
如果你想问更多的问题，

1304
01:19:01,860 --> 01:19:02,850
可以随意提问，

1305
01:19:04,870 --> 01:19:05,980
我们星期四再见。

