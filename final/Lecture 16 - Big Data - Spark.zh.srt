1
00:00:00,000 --> 00:00:03,450
我们将谈论的是 Spark ，

2
00:00:03,840 --> 00:00:07,200
所以这几乎可以追溯到学期开始，

3
00:00:07,620 --> 00:00:11,130
我们在那里谈了很多关于 mapreduce 的事情，

4
00:00:11,130 --> 00:00:14,130
事实上，在实验 1 你实现了 mapreduce .

5
00:00:14,940 --> 00:00:19,650
事实上，非正式的，

6
00:00:19,650 --> 00:00:26,800
Spark 是 Hadoop 的继任者，

7
00:00:28,830 --> 00:00:35,930
Hadoop 是 mapreduce 的开源版本。

8
00:00:38,610 --> 00:00:40,890
所以我认为今天，

9
00:00:40,890 --> 00:00:45,960
人们通常会使用 Spark 而不是 Hadoop 。

10
00:00:46,640 --> 00:00:48,620
所以它有广泛的应用，

11
00:00:52,860 --> 00:00:55,950
它被广泛用于数据科学计算，

12
00:00:55,950 --> 00:00:58,650
所以人们有大量的数据，

13
00:00:58,680 --> 00:01:00,660
需要对其进行一些计算，

14
00:01:00,840 --> 00:01:02,370
需要大量的机器，

15
00:01:02,550 --> 00:01:06,870
Spark 是为这个特殊的情况而设计的，

16
00:01:07,230 --> 00:01:10,320
它由一家名为 Databricks 的公司商业化，

17
00:01:12,250 --> 00:01:15,910
Matei Zaharia 是作者，

18
00:01:15,910 --> 00:01:19,060
这篇论文的主要作者，他的博士论文，

19
00:01:19,180 --> 00:01:20,980
和其他一些人一起开始，

20
00:01:20,980 --> 00:01:25,510
Databricks 公司将 Spark 商业化，

21
00:01:25,540 --> 00:01:30,760
但它也支持 Apache 开源 Spark 版本，

22
00:01:33,010 --> 00:01:35,590
它是一个很流行的开源项目，

23
00:01:36,310 --> 00:01:39,220
或非常流行的开源项目。

24
00:01:39,400 --> 00:01:44,230
它取代 Hadoop 的一个原因是，

25
00:01:44,230 --> 00:01:46,480
因为它支持更广泛的，

26
00:01:47,610 --> 00:01:50,370
比 mapreduce 更广泛的应用程序，

27
00:01:52,410 --> 00:01:55,590
尤其是非常擅长这些迭代。

28
00:01:57,070 --> 00:01:57,910
糟糕，发生了什么，

29
00:02:00,800 --> 00:02:04,280
一些东西可能崩溃了，

30
00:02:04,310 --> 00:02:05,180
稍等一下。

31
00:02:36,270 --> 00:02:41,220
好的，幸运的是[状态很好]。

32
00:02:42,340 --> 00:02:45,580
好的，所以它支持广泛的应用，

33
00:02:45,700 --> 00:02:48,010
尤其擅长迭代应用，

34
00:02:48,010 --> 00:02:51,610
所以，如果应用程序需要执行多轮 mapreduce 操作，

35
00:02:51,610 --> 00:02:52,990
如果你有一个应用程序，

36
00:02:52,990 --> 00:02:54,850
需要先执行一轮 mapreduce ，

37
00:02:54,850 --> 00:02:58,480
然后再执行一轮 mapreduce 计算，

38
00:02:58,900 --> 00:03:00,130
Spark 很适合它，

39
00:03:00,400 --> 00:03:01,600
它很擅长的原因是，

40
00:03:01,600 --> 00:03:04,510
因为它将中间结果保存在内存中，

41
00:03:04,510 --> 00:03:08,200
这是很好编程支持。

42
00:03:09,140 --> 00:03:13,550
在某些方面，

43
00:03:13,550 --> 00:03:17,180
如果之前的论文和这篇论文之间有任何联系，

44
00:03:17,180 --> 00:03:18,350
基本上没有，

45
00:03:18,500 --> 00:03:23,420
但它们都是针对内存计算的，

46
00:03:28,000 --> 00:03:30,280
对于可以存储在内存中的数据集，

47
00:03:30,850 --> 00:03:32,710
在之前的论文和 FaRM 论文中，

48
00:03:32,710 --> 00:03:35,260
是关于在内存中的数据库，

49
00:03:35,290 --> 00:03:38,410
这里是数据科学计算的数据集，

50
00:03:38,410 --> 00:03:40,150
用于你想做的数据科学计算。

51
00:03:42,860 --> 00:03:45,800
当然，自从 2012 年这篇论文发表以来，

52
00:03:45,800 --> 00:03:48,200
发生了很多事情，

53
00:03:48,230 --> 00:03:53,340
Spark 并不是与 Scala 捆绑在一起，

54
00:03:53,340 --> 00:03:54,780
像论文中描述的那样，

55
00:03:54,780 --> 00:03:56,760
比如，还有其他语言前端，

56
00:03:57,240 --> 00:03:58,860
但更重要的是，

57
00:03:58,860 --> 00:04:05,280
在这篇论文中定义的 RDD 有点过时了，

58
00:04:05,280 --> 00:04:10,320
被数据帧所取代，

59
00:04:10,440 --> 00:04:12,600
但是考虑数据帧的方式，

60
00:04:12,600 --> 00:04:13,830
在我看来，

61
00:04:13,830 --> 00:04:18,180
这是带有显示列的 RDD ，

62
00:04:18,540 --> 00:04:23,700
RDD 的所有好想法也适用于数据帧。

63
00:04:24,480 --> 00:04:26,310
所以这节课剩下的部分，

64
00:04:26,310 --> 00:04:28,380
我只想谈谈 RDD ，

65
00:04:28,380 --> 00:04:34,410
并将它们等同于数据帧。

66
00:04:36,540 --> 00:04:38,460
在我继续之前，有什么问题吗？

67
00:04:46,200 --> 00:04:48,060
然后快速提出另一点，

68
00:04:48,060 --> 00:04:51,180
也许这项研究真的很成功，

69
00:04:52,380 --> 00:04:53,340
被广泛应用，

70
00:04:53,580 --> 00:04:59,550
Matei 也获得了 ACM 博士论文奖，

71
00:04:59,550 --> 00:05:03,060
对于这篇论文，都是关于 Spark 的。

72
00:05:04,300 --> 00:05:07,660
对于一篇博士论文来说，这是相当不寻常的，

73
00:05:07,660 --> 00:05:09,040
产生这样的影响。

74
00:05:16,470 --> 00:05:17,040
好的?

75
00:05:18,580 --> 00:05:21,940
所以我想讨论 Spark ，

76
00:05:21,940 --> 00:05:24,910
通过查看一些示例，

77
00:05:24,940 --> 00:05:27,370
因为我觉得最好，

78
00:05:27,370 --> 00:05:30,700
你了解编程模型，

79
00:05:31,960 --> 00:05:33,760
这是基于 RDD 的，

80
00:05:34,240 --> 00:05:36,910
我想最好是查看示例，

81
00:05:40,330 --> 00:05:43,600
你能最好的了解 RDD 。

82
00:05:44,050 --> 00:05:46,150
所以让我举一些例子，

83
00:05:46,150 --> 00:05:47,200
在论文中的，

84
00:05:48,070 --> 00:05:49,870
然后我们走一遍。

85
00:05:51,260 --> 00:05:53,360
拿出这个，

86
00:05:53,960 --> 00:05:58,090
让我们从这里开始，一个非常简单的例子。

87
00:05:58,600 --> 00:06:02,110
所以想法是，

88
00:06:02,720 --> 00:06:04,670
在这个例子中，

89
00:06:04,670 --> 00:06:09,140
首先，你可以互动地使用 Spark ，

90
00:06:09,170 --> 00:06:12,980
你可以在工作站或笔记本电脑上开始 Spark ，

91
00:06:13,280 --> 00:06:16,670
开始与 Spark 互动，

92
00:06:16,940 --> 00:06:20,990
使用输入命令的方式。

93
00:06:21,480 --> 00:06:23,550
那么现在这个命令做了什么，

94
00:06:23,580 --> 00:06:26,610
这会创建一个 RDD ，

95
00:06:26,610 --> 00:06:30,690
称这个为 RDD ， lines 是 RDD ，

96
00:06:30,990 --> 00:06:35,700
我这里表示 RDD 存储在 HDFS 中，

97
00:06:35,940 --> 00:06:41,410
HDFS 可能有许多分区

98
00:06:41,410 --> 00:06:42,850
对于这个文件，

99
00:06:42,880 --> 00:06:47,560
例如，第一个 1000 或 100 万条记录在分区 1 上，

100
00:06:47,560 --> 00:06:50,170
下一个 100 万在分区 2 ，

101
00:06:50,170 --> 00:06:52,090
接下来的 100 万在分区 3 ，

102
00:06:52,630 --> 00:06:58,630
这个 RDD lines 代表了这组分区，

103
00:07:00,070 --> 00:07:04,960
当运行这行或输入这行并回车，

104
00:07:04,990 --> 00:07:06,460
什么都不会发生，

105
00:07:06,580 --> 00:07:11,500
这就是论文所说的懒惰计算，

106
00:07:12,010 --> 00:07:13,960
事实上，计算在稍晚一些执行，

107
00:07:13,960 --> 00:07:15,550
我们稍后会看到什么时候，

108
00:07:15,880 --> 00:07:17,650
但在这个特定的点上，

109
00:07:17,740 --> 00:07:19,660
唯一发生的事情是，

110
00:07:19,660 --> 00:07:23,650
RDD 中有一个 lines 对象。

111
00:07:24,640 --> 00:07:29,860
而且 RDD 支持广泛的操作，

112
00:07:30,070 --> 00:07:33,460
我们可以看一下它支持的一些操作。

113
00:07:37,440 --> 00:07:41,610
是的，它有， RDD 有一个 API ，

114
00:07:41,610 --> 00:07:44,070
事实证明， API 的方法

115
00:07:44,100 --> 00:07:46,980
或者 RDD 上的方法在两个类中，

116
00:07:47,340 --> 00:07:50,340
一个是 Actions ，

117
00:07:50,770 --> 00:07:55,540
Actions 是会导致计算发生的操作，

118
00:07:56,380 --> 00:07:59,050
所以，所有懒惰的构建计算

119
00:07:59,140 --> 00:08:01,060
都发生在你运行 Action 的时间点，

120
00:08:01,210 --> 00:08:03,640
比如，你运行 count 或 collect ，

121
00:08:03,850 --> 00:08:08,590
然后， Spark 计算将被执行。

122
00:08:09,780 --> 00:08:14,250
所有其他 API 或方法都是 Transformations ，

123
00:08:14,580 --> 00:08:18,630
它们把一个 RDD 变成另一个 RDD ，

124
00:08:18,780 --> 00:08:22,980
每个 RDD 都是只读的或不可变的，

125
00:08:23,470 --> 00:08:26,480
所以，你不能修改 RDD ，

126
00:08:26,600 --> 00:08:31,520
只能从现有的 RDD 生成新的 RDD 。

127
00:08:31,910 --> 00:08:33,440
所以如果我们看第二行，

128
00:08:33,530 --> 00:08:37,070
这创建了第二个 RDD ， RDD errors ，

129
00:08:37,550 --> 00:08:43,430
这是通过在 lines RDD 上运行过滤器创建的，

130
00:08:44,240 --> 00:08:48,200
所以 lines RDD 只读，

131
00:08:49,220 --> 00:08:51,080
你可以对它运行 filter 方法，

132
00:08:51,080 --> 00:08:51,830
在这种情况下，

133
00:08:51,830 --> 00:08:54,920
过滤出所有记录，

134
00:08:54,920 --> 00:08:58,490
所以以消息 ERROR 或字符串 ERROR 开头的行，

135
00:08:58,730 --> 00:09:00,560
这代表一个新的 RDD ，

136
00:09:00,800 --> 00:09:04,490
同样，在这一点上，并没有计算出任何东西，

137
00:09:04,490 --> 00:09:08,300
只是一个[配方]或创建一个数据流，

138
00:09:08,390 --> 00:09:12,470
或者论文中所说的计算迭代图。

139
00:09:22,040 --> 00:09:25,460
此外，当计算开始运行时，

140
00:09:25,550 --> 00:09:26,420
它还没有运行，

141
00:09:26,420 --> 00:09:27,980
但当它开始运行时，

142
00:09:28,160 --> 00:09:31,100
这些操作是流水线的，

143
00:09:31,100 --> 00:09:33,260
这个的意思是，

144
00:09:33,260 --> 00:09:37,730
比如，在第一阶段，计算这个 lines ，

145
00:09:37,880 --> 00:09:41,150
第一阶段将读取一些记录，

146
00:09:41,150 --> 00:09:43,940
例如，从第一个分区，

147
00:09:44,410 --> 00:09:47,920
然后，对它进行处理，

148
00:09:47,920 --> 00:09:50,410
如果有什么东西，然后移交给第二阶段，

149
00:09:50,530 --> 00:09:53,350
第二阶段会做这个 filter ，

150
00:09:53,890 --> 00:10:00,550
所以在第二阶段，这个 filter 将运行，

151
00:10:00,670 --> 00:10:05,440
找出 lines 中匹配的，

152
00:10:05,770 --> 00:10:09,520
用它产生新的 RDD ，

153
00:10:09,610 --> 00:10:13,540
只包含以（ERROR）开头的 lines ，

154
00:10:13,600 --> 00:10:15,160
以字符串 ERROR 开头的 lines 。

155
00:10:16,670 --> 00:10:20,720
当第二个 RDD ，第二个阶段运行，

156
00:10:20,720 --> 00:10:24,620
第一阶段从文件系统中获取下一组记录，

157
00:10:24,950 --> 00:10:27,140
然后再把它们带到第二阶段，

158
00:10:27,170 --> 00:10:29,660
随着你越走越远，

159
00:10:29,660 --> 00:10:31,970
你有越来越多的阶段在你的管道中，

160
00:10:31,970 --> 00:10:34,970
或者你的迭代图，

161
00:10:35,060 --> 00:10:38,480
所有这些阶段将会并行运行，

162
00:10:38,850 --> 00:10:43,030
这就是我所说的流水线转换。

163
00:10:45,990 --> 00:10:51,830
好的，所以，这行描述了，

164
00:10:51,830 --> 00:10:56,720
如何创建 errors RDD ，

165
00:10:56,870 --> 00:10:59,540
然后这一行，

166
00:10:59,570 --> 00:11:04,010
告诉 Spark 在内存中保留这个 RDD 的复制，

167
00:11:04,500 --> 00:11:11,190
如果后续计算运行，使用 errors 做更多，

168
00:11:11,430 --> 00:11:17,070
Spark 会将原始的 RDD 保存在内存中，

169
00:11:17,070 --> 00:11:19,830
这样，它可以与以后的计算共享，

170
00:11:19,830 --> 00:11:22,230
例如，如果你想要重用错误文件，

171
00:11:22,530 --> 00:11:25,230
那么错误文件将存储在内存中，

172
00:11:25,230 --> 00:11:27,600
不需要从文件中重建，

173
00:11:27,600 --> 00:11:30,030
从 HDFS 中，

174
00:11:30,120 --> 00:11:33,690
允许你运行第二次计算。

175
00:11:34,920 --> 00:11:38,100
即使在这个简单的例子中，

176
00:11:38,100 --> 00:11:41,130
你会发现这和 mapreduce 有很大的不同，

177
00:11:41,400 --> 00:11:44,940
在 mapreduce 作业中，你运行计算，它结束，

178
00:11:45,150 --> 00:11:48,630
然后，如果你想对数据重新做一些事情，

179
00:11:48,720 --> 00:11:51,210
你必须从文件系统重新读取它，

180
00:11:51,210 --> 00:11:54,540
而使用这个 persist 方法，

181
00:11:54,750 --> 00:12:00,090
Spark 可以避免必须从磁盘重新读取数据，

182
00:12:00,090 --> 00:12:01,230
节省了很多时间。

183
00:12:06,110 --> 00:12:07,190
到目前为止，有什么问题吗？

184
00:12:08,480 --> 00:12:12,410
所以，当错误文件从 P1 中提取出来时，

185
00:12:12,410 --> 00:12:16,310
然后另一个错误文件从 P2 中提取出来，

186
00:12:16,400 --> 00:12:18,890
所以我的理解是，这是并行发生的？

187
00:12:18,920 --> 00:12:20,600
是的，所以你可以考虑它，

188
00:12:20,600 --> 00:12:24,290
就像在 mapreduce 中，有很多 worker ，

189
00:12:24,620 --> 00:12:26,750
worker 在每个分区上工作，

190
00:12:27,940 --> 00:12:31,450
调度者会发送工作

191
00:12:31,450 --> 00:12:32,770
给每个 worker ，

192
00:12:32,860 --> 00:12:38,050
作业是一个属于分区的任务，

193
00:12:38,230 --> 00:12:44,290
worker 开始获取一个任务，

194
00:12:44,290 --> 00:12:45,100
然后开始运行。

195
00:12:45,710 --> 00:12:48,110
所以，你可以在分区之间获得并行性，

196
00:12:48,320 --> 00:12:50,750
你也会得到流水线中的各个阶段之间的并行性。

197
00:12:52,580 --> 00:12:53,540
我明白了，谢谢。

198
00:12:57,220 --> 00:12:57,580
是什么。

199
00:12:57,640 --> 00:12:58,030
抱歉。

200
00:12:58,030 --> 00:12:58,750
你能听见我说话吗？

201
00:12:58,900 --> 00:13:04,480
lineage 和事务日志有什么不同，

202
00:13:04,480 --> 00:13:05,350
我们之前看到的，

203
00:13:05,350 --> 00:13:08,260
它是否只是操作的粒度？

204
00:13:09,000 --> 00:13:12,930
正如我们看到的，日志是严格的线性的，

205
00:13:12,930 --> 00:13:14,670
到目前为止我们看到的例子，

206
00:13:14,670 --> 00:13:17,820
lineage 也是线性的，

207
00:13:17,820 --> 00:13:20,610
但我们稍后会看到使用 fork 的例子，

208
00:13:21,200 --> 00:13:26,870
其中一个阶段依赖于多个不同的 RDD ，

209
00:13:26,870 --> 00:13:29,180
这在日志中不具有代表性。

210
00:13:31,350 --> 00:13:33,810
它们有一些相似之处，

211
00:13:33,810 --> 00:13:36,270
比如你从开始状态开始，

212
00:13:36,270 --> 00:13:38,040
所有的操作都是确定性的，

213
00:13:38,040 --> 00:13:39,540
然后，你会得到，

214
00:13:39,660 --> 00:13:41,100
如果你应用所有这些操作，

215
00:13:41,100 --> 00:13:44,040
将得到某种确定性的结束状态，

216
00:13:44,370 --> 00:13:46,800
所以在这个意义上，有一些相似之处，

217
00:13:46,800 --> 00:13:49,230
但是，我觉得它们很不一样。

218
00:13:51,870 --> 00:13:53,400
我也有一个问题，

219
00:13:53,400 --> 00:13:55,860
在这个 filter 的例子中，

220
00:13:56,910 --> 00:14:00,030
它只需在每个分区上应用 filter ，

221
00:14:00,030 --> 00:14:04,170
但有时，比如我看到 transformation 也包含 join 或 sort 。

222
00:14:04,170 --> 00:14:05,940
好的，让我们稍微谈一下，我稍后会谈到 sort 和 join ，

223
00:14:09,700 --> 00:14:12,520
它们显然要复杂得多。

224
00:14:13,620 --> 00:14:19,290
所以，这个 persist 是不是我们开始计算的时候？

225
00:14:19,530 --> 00:14:22,830
不，没有东西计算出来，仍然是所有的描述，

226
00:14:22,830 --> 00:14:24,000
让我们进一步讨论一下。

227
00:14:24,880 --> 00:14:29,170
让我们来看看产生计算的东西。

228
00:14:32,730 --> 00:14:38,730
所以，这是两个导致计算的命令，

229
00:14:38,730 --> 00:14:41,100
所以这个命令将导致计算，

230
00:14:41,100 --> 00:14:43,920
因为它包含 count ，这是一个操作，

231
00:14:44,070 --> 00:14:48,240
这个命令将导致计算， collect 是一个操作。

232
00:14:50,210 --> 00:14:54,140
所以你可以，

233
00:14:54,560 --> 00:14:56,120
所以我们看，

234
00:14:56,120 --> 00:14:57,920
所以它们显示两个命令的原因，

235
00:14:57,920 --> 00:15:00,500
因为它们证明了你可以重复使用 errors ，

236
00:15:00,800 --> 00:15:05,390
所以，如果你看一下这个计算，

237
00:15:05,720 --> 00:15:08,930
然后你可以画出谱系图，

238
00:15:08,930 --> 00:15:10,940
开始是 lines ，

239
00:15:12,510 --> 00:15:15,870
我们运行了一个 filter ，

240
00:15:18,450 --> 00:15:20,010
糟糕，抱歉，

241
00:15:20,040 --> 00:15:22,050
让我写的稍微不同一点，

242
00:15:22,050 --> 00:15:23,460
在 lines 上有一个 filter ，

243
00:15:24,260 --> 00:15:26,030
我们看到产生 errors ，

244
00:15:28,630 --> 00:15:30,400
或者这是一种描述，如何获得 errors ，

245
00:15:30,700 --> 00:15:33,670
然后在这种情况下，还有另一个 filter ，

246
00:15:34,580 --> 00:15:36,380
它是 HDFS 的 filter ，

247
00:15:37,400 --> 00:15:39,440
这会产生另一个 RDD ，

248
00:15:39,470 --> 00:15:41,810
RDD 在这里并没有明确的名称，

249
00:15:42,020 --> 00:15:44,630
但它产生了另一个 RDD ，

250
00:15:44,630 --> 00:15:47,000
所以我打算把它叫做 HDFS ，

251
00:15:47,750 --> 00:15:49,640
因为 filter 在 HDFS 上，

252
00:15:50,210 --> 00:15:53,180
然后，我们看到有一个 map ，

253
00:15:53,820 --> 00:15:55,950
这又产生了另一个 RDD ，

254
00:15:55,980 --> 00:16:02,040
再次，这个 RDD 在这里没有名字，它是匿名的，

255
00:16:02,070 --> 00:16:04,260
我要给它起个名字，就是 time ，

256
00:16:05,760 --> 00:16:11,520
因为把每一个行分为三部分，

257
00:16:11,520 --> 00:16:13,470
从中拿出第三部分，

258
00:16:13,470 --> 00:16:15,150
那正好就是 time ，

259
00:16:15,740 --> 00:16:21,920
然后，有一个最后的操作，就是 collect ，

260
00:16:22,190 --> 00:16:26,630
它统计所有的 time 出现的次数，

261
00:16:26,660 --> 00:16:32,600
或者在 time RDD 产生的条目的数量。

262
00:16:33,470 --> 00:16:34,070
好的?

263
00:16:34,400 --> 00:16:37,550
所以这就是这一点，

264
00:16:37,550 --> 00:16:40,550
在这里返回，

265
00:16:40,550 --> 00:16:45,980
在用户界面或交互用户界面中，

266
00:16:45,980 --> 00:16:47,240
在这一点上，

267
00:16:47,240 --> 00:16:53,570
Spark 会收集很多 worker ，

268
00:16:53,870 --> 00:16:56,840
给它们发送工作，

269
00:16:56,840 --> 00:17:01,160
或者通知调度器需要执行作业，

270
00:17:01,430 --> 00:17:06,200
这个谱系图中需要执行的任务的描述。

271
00:17:13,400 --> 00:17:16,550
所以我们可以稍微思考一下是如何执行的，

272
00:17:16,550 --> 00:17:17,720
所以让我画一张图，

273
00:17:22,190 --> 00:17:23,450
图片如下所示，

274
00:17:23,450 --> 00:17:25,820
这就是所谓的驱动，这是很常见的事情，

275
00:17:26,790 --> 00:17:29,610
用户输入的程序，

276
00:17:30,000 --> 00:17:37,080
它从收集很多 worker ，很多机器开始，

277
00:17:37,800 --> 00:17:41,160
几乎与 mapreduce 中的一样。

278
00:17:42,460 --> 00:17:45,340
这里会有 HDFS ，

279
00:17:45,490 --> 00:17:47,410
lines 文件，

280
00:17:47,410 --> 00:17:55,760
有分区， P1 P2 之类，等等。

281
00:17:55,790 --> 00:17:59,660
通常分区的数量大于 worker 的数量，

282
00:17:59,660 --> 00:18:00,590
抱歉，数量，

283
00:18:01,190 --> 00:18:03,230
是的，分区的数量大于 worker 的数量 ，

284
00:18:03,230 --> 00:18:05,300
有负载平衡，

285
00:18:06,020 --> 00:18:08,600
比如一个分区很小，而另一个分区很大，

286
00:18:08,630 --> 00:18:11,330
你不想让 worker 无所事事。

287
00:18:11,940 --> 00:18:13,920
基本上调度器，

288
00:18:14,400 --> 00:18:20,910
有一个调度器运行计算，

289
00:18:20,910 --> 00:18:24,210
它有谱系图的信息。

290
00:18:25,820 --> 00:18:27,500
所以 worker 加入，

291
00:18:27,590 --> 00:18:32,370
driver 分发代码， Spark 程序，

292
00:18:32,550 --> 00:18:34,260
我们刚刚构建的，

293
00:18:34,500 --> 00:18:36,450
worker 去找调度者，

294
00:18:36,450 --> 00:18:38,610
说，我应该在哪个分区工作。

295
00:18:39,240 --> 00:18:45,860
然后，它们作为流水线的一部分运行，

296
00:18:46,780 --> 00:18:47,890
所以我们看看这个，

297
00:18:47,890 --> 00:18:49,360
让我把这个画得稍有不同，

298
00:18:49,360 --> 00:18:50,830
所以我在这里有更多的空间。

299
00:18:52,600 --> 00:18:54,580
所以我们看到有很多阶段，

300
00:18:54,970 --> 00:18:56,800
然后最后一个阶段是，

301
00:18:57,250 --> 00:19:00,310
最后一个操作是 collect 阶段。

302
00:19:02,560 --> 00:19:08,350
所以在我们刚才看到的这个场景中，

303
00:19:08,440 --> 00:19:14,410
collect 阶段当然需要从所有分区收集数据，

304
00:19:14,410 --> 00:19:15,940
所以原则上，

305
00:19:16,120 --> 00:19:18,310
我们画一条绿线，

306
00:19:18,520 --> 00:19:20,140
基本上这一切，

307
00:19:20,600 --> 00:19:23,510
都是在一个独立的分区上执行的，

308
00:19:24,100 --> 00:19:28,150
所以每个 worker 会从调度器得到这些任务中的一个，

309
00:19:28,180 --> 00:19:30,580
运行东西，

310
00:19:30,580 --> 00:19:36,400
最后产生一个 time RDD ，

311
00:19:37,270 --> 00:19:43,420
当调度者确定所有 time ，

312
00:19:43,660 --> 00:19:45,160
所有这些阶段，

313
00:19:45,160 --> 00:19:46,270
这被称为阶段，

314
00:19:48,080 --> 00:19:49,880
如果所有阶段都已完成，

315
00:19:49,910 --> 00:19:52,850
所有区间产生了 time ，

316
00:19:52,970 --> 00:19:58,700
然后它会运行 collect 操作做加法，

317
00:19:58,940 --> 00:20:02,480
从每个分区获取信息，

318
00:20:02,690 --> 00:20:05,330
用来计算 collect ，

319
00:20:05,330 --> 00:20:07,370
这不是 collect ，

320
00:20:07,370 --> 00:20:11,520
这是 count ，很抱歉。

321
00:20:15,500 --> 00:20:18,440
所以，思考这个问题的一种方式是，

322
00:20:18,440 --> 00:20:21,680
这有点像 mapreduce ，

323
00:20:21,680 --> 00:20:22,970
其中有 map 阶段，

324
00:20:22,970 --> 00:20:25,070
然后你有 shuffle ，

325
00:20:25,220 --> 00:20:26,960
然后运行 reduce 阶段，

326
00:20:26,960 --> 00:20:32,060
而 count 在这种方式上几乎是一样的，

327
00:20:32,180 --> 00:20:34,670
在论文中，他们提到这一点的方式是，

328
00:20:34,790 --> 00:20:38,330
这个依赖关系称为宽依赖，

329
00:20:39,230 --> 00:20:44,090
因为 action 或 transformation 依赖多个分区，

330
00:20:44,540 --> 00:20:48,470
这些称为窄依赖，

331
00:20:48,740 --> 00:20:53,990
因为这个 RDD ，

332
00:20:53,990 --> 00:20:57,020
为了制作这个 RDD ，只依赖于另一个，

333
00:20:57,320 --> 00:21:01,580
只依赖于父分区，

334
00:21:01,670 --> 00:21:04,730
只需一个父分区就能计算它。

335
00:21:05,970 --> 00:21:10,020
一般来说，你会希望计算有窄依赖，

336
00:21:10,020 --> 00:21:12,600
因为它们可以在没有任何通信的情况下在本地运行，

337
00:21:12,960 --> 00:21:17,010
在宽依赖之前，你可能需要 collect ，

338
00:21:17,010 --> 00:21:20,670
你可能需要从父分区收集，

339
00:21:20,670 --> 00:21:25,350
或者你可能必须从所有机器的父 RDD 收集分区。

340
00:21:25,840 --> 00:21:27,370
教授。

341
00:21:27,400 --> 00:21:28,210
嗯。

342
00:21:28,240 --> 00:21:29,620
我有个问题，

343
00:21:29,620 --> 00:21:34,900
所以在论文中，它说窄依赖，

344
00:21:35,470 --> 00:21:39,130
父 RDD 的每个分区，

345
00:21:39,490 --> 00:21:43,450
用作最多是子 RDD 的一个分区，

346
00:21:43,870 --> 00:21:48,730
但它没有说任何关于控制的事情，

347
00:21:49,300 --> 00:21:50,800
比如，

348
00:21:51,250 --> 00:22:00,280
它没有说子分区最多只使用一个父分区。

349
00:22:00,550 --> 00:22:02,290
是的，没错，因为。

350
00:22:02,290 --> 00:22:05,680
是的，如果一个子分区使用多个父分区，

351
00:22:05,680 --> 00:22:07,060
那么它就是一个宽依赖。

352
00:22:08,310 --> 00:22:09,720
如果一个父分区，抱歉。

353
00:22:10,200 --> 00:22:14,790
如果子分区使用分区，

354
00:22:14,790 --> 00:22:17,820
如果多个父分区，

355
00:22:18,030 --> 00:22:19,980
那么它就是一个宽依赖。

356
00:22:20,750 --> 00:22:23,480
例如在 count 的情况下，

357
00:22:23,510 --> 00:22:28,310
你有 time 分区。

358
00:22:29,100 --> 00:22:29,580
是的。

359
00:22:30,770 --> 00:22:35,030
count 操作将收集所有来自它们的数据。

360
00:22:35,720 --> 00:22:36,380
是的。

361
00:22:36,800 --> 00:22:38,570
所以如果 count RDD ，

362
00:22:39,110 --> 00:22:40,940
它不是，这只是一个 action ，

363
00:22:41,090 --> 00:22:42,170
但即使是我们在 RDD ，

364
00:22:42,170 --> 00:22:46,220
那么这将需要与所有的父分区交互。

365
00:22:46,780 --> 00:22:48,220
我的意思是，

366
00:22:48,220 --> 00:22:51,520
我想恰恰相反，

367
00:22:52,020 --> 00:22:54,600
我想这可能像是，

368
00:22:55,600 --> 00:22:59,560
我是说，我真的很困惑，

369
00:23:00,700 --> 00:23:03,880
在论文中，在这个特定的问题上，

370
00:23:03,880 --> 00:23:05,620
但正如上面所说，

371
00:23:05,680 --> 00:23:11,470
父 RDD 的每个分区至多由一个子分区使用，

372
00:23:12,760 --> 00:23:16,570
但它没有说子分区使用最多。

373
00:23:17,920 --> 00:23:21,790
我不确定你为什么会对此感到困惑，

374
00:23:21,790 --> 00:23:25,090
所以，我们可以推迟这件事，然后回来讨论它。

375
00:23:25,740 --> 00:23:26,430
好的。

376
00:23:26,430 --> 00:23:29,670
我认为关键的是观察到有两种依赖，

377
00:23:29,670 --> 00:23:31,140
宽的和窄的，

378
00:23:31,410 --> 00:23:34,770
宽的涉及到通信，

379
00:23:34,770 --> 00:23:40,620
因为它们必须，

380
00:23:41,010 --> 00:23:44,310
从父分区收集信息。

381
00:23:45,990 --> 00:23:47,040
好的?

382
00:23:47,430 --> 00:23:47,910
谢谢。

383
00:23:50,100 --> 00:23:52,020
我有一个关于接口的问题，

384
00:23:53,280 --> 00:23:55,260
在前面一两张幻灯片上，

385
00:23:55,260 --> 00:23:58,200
如果我们不调用 errors.persist ，会发生什么？

386
00:23:59,610 --> 00:24:02,100
如果你没有，那么，

387
00:24:02,100 --> 00:24:05,880
第二个计算，

388
00:24:06,090 --> 00:24:11,900
比如这个计算，将从头开始重新计算 errors ，

389
00:24:12,530 --> 00:24:15,020
如果你运行这个工作负载，

390
00:24:15,850 --> 00:24:19,690
Spark 会重新计算 errors ，

391
00:24:19,690 --> 00:24:21,970
从开始文件开始。

392
00:24:23,030 --> 00:24:23,990
知道了，谢谢。

393
00:24:25,360 --> 00:24:28,510
关于这一点，我有一个问题，

394
00:24:28,570 --> 00:24:32,290
对于不调用 persist 的分区，

395
00:24:32,590 --> 00:24:34,450
在 mapreduce 的情况中，

396
00:24:34,450 --> 00:24:37,210
我们把它们存储在中间文件中，

397
00:24:37,240 --> 00:24:42,610
但我们仍然将它们存储在本地文件系统中，

398
00:24:42,640 --> 00:24:44,170
比如，在 mapreduce 的情况下，

399
00:24:44,350 --> 00:24:47,650
我们在这里存储中间文件吗，

400
00:24:47,650 --> 00:24:50,050
我们不持久化在某些持久存储中，

401
00:24:50,050 --> 00:24:54,070
或者我们只是将整个流保存在内存中？

402
00:24:54,220 --> 00:24:56,770
默认情况下，整个流都在内存中，

403
00:24:56,770 --> 00:24:59,920
除非你可以提供，

404
00:24:59,920 --> 00:25:02,200
有一个例外，

405
00:25:02,200 --> 00:25:04,870
我们稍后会更详细地讨论，

406
00:25:05,260 --> 00:25:10,640
你可以看到这里的 persist ，

407
00:25:11,090 --> 00:25:14,480
这个 persist 使用另一个标志，我认为是 reliable ，

408
00:25:15,570 --> 00:25:21,390
然后，集合存储在 HDFS 中，这个称为检查点。

409
00:25:22,760 --> 00:25:23,570
我明白了，谢谢。

410
00:25:26,930 --> 00:25:28,940
关于分区，我有一个简短的问题，

411
00:25:29,090 --> 00:25:34,670
对于分区， RDD 最初，

412
00:25:34,670 --> 00:25:39,350
是否最初 HDFS 对它们分区，

413
00:25:39,500 --> 00:25:43,460
为每个 worker 操作是 Spark 处理。

414
00:25:43,460 --> 00:25:47,780
这个 lines 在 HDFS 中，

415
00:25:47,780 --> 00:25:53,150
分区是由 HDFS 中的文件直接定义的，

416
00:25:53,750 --> 00:25:55,340
你可以重复，

417
00:25:55,400 --> 00:25:59,390
你很快就会看到，可能是阶段在这样做，

418
00:25:59,540 --> 00:26:01,640
例如使用散列分区技巧，

419
00:26:02,090 --> 00:26:06,530
你还可以定义自己的分区程序，

420
00:26:06,530 --> 00:26:10,400
提供一个分区程序对象或抽象。

421
00:26:12,880 --> 00:26:15,250
所以，它已经由 HDFS 处理，

422
00:26:15,250 --> 00:26:16,960
但如果你想为 Spark 再来一次，

423
00:26:16,960 --> 00:26:17,740
那么你可以。

424
00:26:19,180 --> 00:26:20,860
当然，文件也是创建于，

425
00:26:21,010 --> 00:26:26,500
这个文件可能有旁边的日志系统创建，

426
00:26:26,500 --> 00:26:28,180
并且产生不同的分区，

427
00:26:28,330 --> 00:26:30,340
或者如果你愿意，你可以重新洗牌。

428
00:26:31,060 --> 00:26:31,960
理解了，谢谢。

429
00:26:35,280 --> 00:26:40,330
好的，那么，

430
00:26:41,130 --> 00:26:41,970
所以让我，

431
00:26:41,970 --> 00:26:44,160
所以这是执行模型，

432
00:26:44,160 --> 00:26:47,400
我想讨论一下容错。

433
00:26:47,980 --> 00:26:49,690
所以让我们回到，

434
00:26:49,690 --> 00:26:51,280
这种容错，

435
00:26:51,280 --> 00:26:53,650
我们担心的是容错性是，

436
00:26:53,710 --> 00:26:58,740
也许其中一个 worker 可能会崩溃，

437
00:26:58,740 --> 00:27:02,070
那个 worker 已经计算了一些分区，

438
00:27:02,310 --> 00:27:04,170
所以我们需要重新执行，

439
00:27:04,680 --> 00:27:10,200
基本上这个方案和 mapreduce 是一样的，

440
00:27:10,440 --> 00:27:14,880
如果一个 worker 崩溃，我们需要，

441
00:27:15,000 --> 00:27:17,730
在 mapreduce 中， map 任务需要重新执行，

442
00:27:17,730 --> 00:27:20,370
可能 reduce 任务也需要重新执行，

443
00:27:20,850 --> 00:27:23,100
在这里，任务稍微复杂一些，

444
00:27:23,130 --> 00:27:25,170
因为像这些阶段，

445
00:27:25,440 --> 00:27:28,740
这意味着，如果一个 worker 失败了，

446
00:27:28,740 --> 00:27:30,240
我们可能得重新计算那个阶段。

447
00:27:31,230 --> 00:27:33,960
所以，让我们更多地谈谈这一点，

448
00:27:34,200 --> 00:27:36,360
从容错的角度来看，

449
00:27:36,360 --> 00:27:37,980
这是我们想要实现的目标。

450
00:27:39,600 --> 00:27:40,740
这个与之前的不同，

451
00:27:40,740 --> 00:27:45,360
你在实验 2 或实验 3 实现的或 Paxos ，

452
00:27:45,360 --> 00:27:48,000
稳定存储以及之类的东西，

453
00:27:48,300 --> 00:27:53,190
这里，我们担心的是 worker 的崩溃，

454
00:27:56,270 --> 00:28:02,350
worker 丢失了内存，

455
00:28:04,040 --> 00:28:05,630
这意味着丢失分区，

456
00:28:10,720 --> 00:28:15,970
后面的计算部分可能依赖于这个分区，

457
00:28:16,150 --> 00:28:21,400
所以，我们需要重新读取或重新计算这个分区。

458
00:28:21,400 --> 00:28:24,130
所以，解决方案与 mapreduce 中的很像，

459
00:28:24,310 --> 00:28:28,420
调度器在某个时刻注意到没有得到答案，

460
00:28:29,360 --> 00:28:33,340
然后重新运行那个分区的阶段。

461
00:28:44,200 --> 00:28:46,240
最酷的部分是，

462
00:28:46,270 --> 00:28:48,220
像在 mapreduce 中一样，

463
00:28:48,460 --> 00:28:51,880
如果我们查看这里 Transformations 的所有 API ，

464
00:28:52,000 --> 00:28:54,100
所有这些转换都是函数式的，

465
00:28:57,400 --> 00:28:59,290
所以它们接受一个输入，

466
00:28:59,380 --> 00:29:00,910
它们将 RDD 作为输入，

467
00:29:00,910 --> 00:29:02,770
它们产生另一个 RDD 作为输出，

468
00:29:03,040 --> 00:29:05,350
是完全确定性的。

469
00:29:05,840 --> 00:29:08,450
就像在 mapreduce 中，

470
00:29:08,450 --> 00:29:12,380
这些 map 和 reduce 是函数式计算，

471
00:29:12,380 --> 00:29:18,140
如果重启一个阶段，来自同一输入的一系列转换，

472
00:29:18,230 --> 00:29:20,000
然后，你将产生相同的输出，

473
00:29:20,210 --> 00:29:24,550
所以，你重新创建相同的分区，

474
00:29:28,520 --> 00:29:30,320
重新创建分区就可以了。

475
00:29:34,020 --> 00:29:34,590
好的?

476
00:29:37,600 --> 00:29:39,970
抱歉，这就是为什么它们是不变的吗？

477
00:29:40,300 --> 00:29:42,700
我想这是它们不变的原因。

478
00:29:48,240 --> 00:29:50,250
好的，有一个棘手的例子，

479
00:29:50,430 --> 00:29:52,050
我想谈谈，

480
00:29:52,500 --> 00:29:56,730
对于窄（依赖）的容错，

481
00:29:57,890 --> 00:30:01,160
与我们以前在 mapreduce 中看到的一样，

482
00:30:01,160 --> 00:30:05,270
但是，棘手的情况是宽依赖。

483
00:30:12,670 --> 00:30:17,020
所以假设我们有一些转换，

484
00:30:19,850 --> 00:30:25,040
其中一个转换依赖于，

485
00:30:25,130 --> 00:30:26,060
这就像是，

486
00:30:26,240 --> 00:30:29,090
这里有一个 worker ，这里有另一个 worker ，以及另一个 worker ，

487
00:30:31,240 --> 00:30:42,380
其中一个阶段依赖于多个父分区，

488
00:30:42,890 --> 00:30:45,530
所以我们假设这可以是一个 join ，

489
00:30:45,530 --> 00:30:47,480
或者我们以后会看到其他的操作，

490
00:30:48,170 --> 00:30:51,920
我们在收集许多分区的信息，

491
00:30:52,130 --> 00:30:56,330
从那里创建一个 RDD ，

492
00:30:56,540 --> 00:31:00,620
那个 RDD 可能被 map 使用，并继续，

493
00:31:01,250 --> 00:31:06,080
所以现在假设我们是 worker ，我们在这里坠毁，

494
00:31:07,590 --> 00:31:10,530
然后我们需要重建这个 RDD ，

495
00:31:15,640 --> 00:31:17,500
我们继续，

496
00:31:17,500 --> 00:31:21,160
这意味着，我们也可以重新计算这个 RDD ，

497
00:31:21,520 --> 00:31:23,830
为了重新计算这个 worker 的 RDD ，

498
00:31:23,890 --> 00:31:27,130
这意味着我们还需要其他 worker 上的分区。

499
00:31:27,820 --> 00:31:37,210
所以重新构建，重新执行计算，

500
00:31:37,210 --> 00:31:39,970
在一个 worker ，一个分区上，

501
00:31:40,000 --> 00:31:45,610
可能会导致这些也需要重新计算。

502
00:31:47,290 --> 00:31:49,780
当然，你可以部分并行地做这件事，

503
00:31:49,780 --> 00:31:50,710
你可以要求，

504
00:31:50,710 --> 00:31:53,590
请开始重新计算这个，重新计算那个，

505
00:31:53,890 --> 00:31:58,270
然后再次产生最终的 RDD ，

506
00:31:58,270 --> 00:31:59,560
但是当然，

507
00:31:59,560 --> 00:32:07,360
一个 worker 失败可能导致许多分区的重新计算，

508
00:32:08,960 --> 00:32:13,580
这有一点浪费。

509
00:32:14,060 --> 00:32:16,040
所以，解决方案是，

510
00:32:16,100 --> 00:32:17,930
作为一名程序员，

511
00:32:18,140 --> 00:32:26,690
你可以检查点或持久化 RDD 的稳定存储，

512
00:32:27,520 --> 00:32:29,020
所以你可能会决定，

513
00:32:29,020 --> 00:32:32,710
例如，这是一个 RDD，

514
00:32:33,460 --> 00:32:36,400
你不想在失败的情况下重新计算，

515
00:32:36,400 --> 00:32:39,310
因为它需要重新计算所有不同的分区，

516
00:32:39,520 --> 00:32:42,070
你可能希望对这个 RDD 设置检查点。

517
00:32:48,960 --> 00:32:50,610
然后这个阶段，

518
00:32:50,610 --> 00:32:54,390
当这个计算需要重新执行的时候，

519
00:32:54,600 --> 00:32:59,640
将读取来自检查点的分区的结果，

520
00:32:59,760 --> 00:33:03,090
而不是从头开始重新计算它们。

521
00:33:03,450 --> 00:33:06,810
这就是 Spark 支持检查点的原因，

522
00:33:06,810 --> 00:33:13,720
这就是他们对宽依赖的容错故事。

523
00:33:17,800 --> 00:33:18,850
对于这个，有什么问题吗？

524
00:33:21,000 --> 00:33:22,740
我有一个问题，

525
00:33:25,290 --> 00:33:31,520
所以你使用一般的持久化，

526
00:33:31,520 --> 00:33:34,580
但是他们也提到了一个 RELIABLE 标志。

527
00:33:34,700 --> 00:33:35,180
嗯。

528
00:33:35,510 --> 00:33:36,680
所以我想知道，

529
00:33:37,320 --> 00:33:41,040
比如，只持久化和使用 RELIABLE 标志有什么不同？

530
00:33:41,770 --> 00:33:44,500
持久化只是意味着你将 RDD 保存在内存中，

531
00:33:44,710 --> 00:33:46,090
你不会把它扔掉，

532
00:33:47,200 --> 00:33:51,340
所以你可以在以后的计算中重复使用它，在内存中使用，

533
00:33:51,730 --> 00:33:55,090
检查点或 RELIABLE 标志意味着，

534
00:33:56,210 --> 00:34:00,920
你将整个 RDD 的副本写入 HDFS ，

535
00:34:05,560 --> 00:34:08,410
而 HDFS 是持久或稳定的存储文件系统。

536
00:34:12,170 --> 00:34:15,860
有没有一种方法可以告诉 Spark 不再持久化某些东西，

537
00:34:16,130 --> 00:34:19,490
因为，如果你持久化了 RDD ，

538
00:34:19,760 --> 00:34:21,920
而且你做了大量的计算，

539
00:34:22,400 --> 00:34:25,010
但是后面的计算不在使用那个 RDD ，

540
00:34:26,080 --> 00:34:29,050
你可能会把它永远留在内存中。

541
00:34:29,780 --> 00:34:33,020
是的，我想你可以，

542
00:34:33,140 --> 00:34:37,190
或者 Spark 使用了一个通用的策略，

543
00:34:37,190 --> 00:34:38,630
他们稍微谈了一下这件事，

544
00:34:38,900 --> 00:34:41,810
如果真的没有空间了，

545
00:34:42,020 --> 00:34:48,200
它们可能会将一些 RDD 放到 HDFS 或删除它们，

546
00:34:48,230 --> 00:34:51,650
论文对他们的具体计划有点含糊。

547
00:34:54,010 --> 00:34:54,520
谢谢。

548
00:34:55,000 --> 00:34:56,710
当然，当计算结束时，

549
00:34:56,740 --> 00:35:02,350
用户退出，或停止你的驱动，

550
00:35:02,350 --> 00:35:05,770
那么我想那些 RDD 肯定已经从内存中消失了。

551
00:35:11,060 --> 00:35:11,660
好的?

552
00:35:13,940 --> 00:35:17,990
好的，这就是 Spark 的故事，

553
00:35:18,020 --> 00:35:22,970
我们看到了 RDD 是什么，

554
00:35:23,000 --> 00:35:26,120
我们看到了执行是如何工作的，

555
00:35:26,360 --> 00:35:28,910
我们看到了容错计划是如何工作的。

556
00:35:29,210 --> 00:35:32,900
我想谈的另一个例子，

557
00:35:32,960 --> 00:35:36,680
展示 Spark 闪耀的地方，

558
00:35:36,890 --> 00:35:38,780
这是一个迭代的例子。

559
00:35:40,240 --> 00:35:42,310
所以在包含迭代结构的计算中，

560
00:35:46,060 --> 00:35:48,400
而我想要谈的是 PageRank 。

561
00:35:52,900 --> 00:35:57,820
我想你们大多数人都熟悉某种形式的 PageRank ，

562
00:35:58,060 --> 00:36:05,230
这是一个对网页赋予权重或重要性的算法，

563
00:36:05,620 --> 00:36:10,210
这取决于指向网页的链接的数量，

564
00:36:10,210 --> 00:36:15,660
例如，如果你有一个网页 U1 ，指向它自己，

565
00:36:16,110 --> 00:36:18,780
你可能有一个网页 U3 ，

566
00:36:18,990 --> 00:36:20,310
所以我将使用一个例子，

567
00:36:20,310 --> 00:36:21,690
以及网页 U2 ，

568
00:36:22,050 --> 00:36:26,580
U2 有到自己和到 U3 的链接，

569
00:36:26,820 --> 00:36:29,460
也许 U3 有到 U1 的链接。

570
00:36:30,310 --> 00:36:35,050
基本上 PageRank 是基于这些连接性的算法，

571
00:36:35,230 --> 00:36:38,170
计算网页的重要性，

572
00:36:38,380 --> 00:36:43,510
PageRank 是早期的一个算法，

573
00:36:43,510 --> 00:36:46,270
驱动 Google 搜索机器，

574
00:36:46,330 --> 00:36:49,870
从这个意义上说，如果你有一个搜索结果，

575
00:36:49,870 --> 00:36:51,520
你对搜索结果排名的方式是，

576
00:36:51,520 --> 00:36:55,150
如果搜索结果出现在更重要的网页上，

577
00:36:55,150 --> 00:36:58,150
那个结果会在列表中提升到更高的位置，

578
00:36:58,570 --> 00:37:01,810
这是早期的原因之一，

579
00:37:01,810 --> 00:37:05,560
Google 搜索引擎会产生更好的搜索结果，

580
00:37:05,560 --> 00:37:07,510
更重要的信息，

581
00:37:07,510 --> 00:37:09,130
或更重要的网页是在顶部。

582
00:37:11,150 --> 00:37:22,730
所以，论文介绍了 Spark 中 PageRank 的实现。

583
00:37:26,780 --> 00:37:34,340
所以这是 Spark 的 PageRank 实现，

584
00:37:34,430 --> 00:37:38,390
像之前那样，这只是一个描述，

585
00:37:38,390 --> 00:37:41,120
所以我们来看一下每一行，

586
00:37:42,200 --> 00:37:47,600
这些只是如何计算 PageRank 的方法，

587
00:37:47,810 --> 00:37:50,270
在这个示例中，

588
00:37:50,270 --> 00:37:53,250
如果你在后面做 ranks.collect ，

589
00:37:53,730 --> 00:37:59,040
然后，计算会在机器集群上进行，

590
00:37:59,310 --> 00:38:03,480
并使用我们之前看到的某种执行模式。

591
00:38:04,320 --> 00:38:08,880
所以我想更详细地介绍一个这个例子，

592
00:38:09,090 --> 00:38:10,740
为了得到一种感觉，

593
00:38:10,740 --> 00:38:12,240
为了得到更好的感觉，

594
00:38:12,240 --> 00:38:14,700
为什么 Spark 在迭代的情况下是闪耀的。

595
00:38:15,530 --> 00:38:20,150
所以，这里有两个 RDD ，

596
00:38:20,150 --> 00:38:23,360
我也会谈论一些在 Spark 中很酷的优化，

597
00:38:23,390 --> 00:38:25,730
其中之一是 links RDD ，

598
00:38:25,730 --> 00:38:30,500
links 表示了图的连接，

599
00:38:30,500 --> 00:38:33,830
准确地说，它可能有一条线，

600
00:38:33,860 --> 00:38:38,300
我将这样写它，每行一个 URL ，

601
00:38:38,300 --> 00:38:39,680
所以这是 U1 ，

602
00:38:39,860 --> 00:38:44,540
它有两个出链接 U1 U3 ，

603
00:38:51,620 --> 00:38:53,210
我在这里漏掉了一个链接。

604
00:38:54,240 --> 00:38:59,140
然后是 U2 条目，

605
00:38:59,140 --> 00:39:01,930
指向 U2 和 U3 。

606
00:39:04,660 --> 00:39:10,040
这里有一个条目 U3 指向 U1 。

607
00:39:13,030 --> 00:39:16,630
所以这是对万维网的的描述，

608
00:39:17,080 --> 00:39:19,630
当然我的小的例子，

609
00:39:19,630 --> 00:39:20,920
我有三个网页，

610
00:39:21,130 --> 00:39:24,370
但如果在 Google 的规模上运行这项工作，

611
00:39:24,370 --> 00:39:25,990
你会有十亿个网页，

612
00:39:26,410 --> 00:39:31,900
所以这个文件是巨大的，它被分到不同分区。

613
00:39:33,340 --> 00:39:34,720
这就是 links 。

614
00:39:35,240 --> 00:39:39,950
然后 ranks 是一个类似的文件，

615
00:39:39,950 --> 00:39:42,620
它包含这些网页的当前排名，

616
00:39:42,920 --> 00:39:44,540
所以你可以认为这些是，

617
00:39:44,540 --> 00:39:47,910
U1 逗号，它的排名，

618
00:39:48,150 --> 00:39:51,990
我们假设排名初始为 1.0 ，

619
00:39:52,320 --> 00:39:54,840
然后这是 1.0 ，

620
00:39:55,510 --> 00:39:59,800
然后 U2 1.0 ，

621
00:40:00,420 --> 00:40:03,510
U3 1.0 。

622
00:40:04,970 --> 00:40:07,730
我们看到 links ，

623
00:40:08,060 --> 00:40:11,240
links 是保存在内存中，

624
00:40:11,300 --> 00:40:13,940
这与 error 文件的方式相同，

625
00:40:13,940 --> 00:40:16,100
我们之前看到的 error RDD 。

626
00:40:17,840 --> 00:40:22,550
然后 ranks ，它被初始化为某些东西，

627
00:40:22,550 --> 00:40:28,970
然后是迭代次数的描述，

628
00:40:28,970 --> 00:40:32,600
以产生新的 ranks RDD 。

629
00:40:33,490 --> 00:40:36,700
你可以看到这是如何进行的，

630
00:40:37,240 --> 00:40:39,520
我们注意到的一件事是，

631
00:40:39,670 --> 00:40:42,070
links 在每次迭代中都会被重复使用，

632
00:40:43,190 --> 00:40:46,940
links 与 ranks join ，

633
00:40:47,030 --> 00:40:50,210
join 这个是什么意思，

634
00:40:50,210 --> 00:40:54,590
这个操作创建一个 RDD ，

635
00:40:55,010 --> 00:40:56,960
我们想知道 RDD 是什么样子的，

636
00:40:56,960 --> 00:40:58,310
RDD 看起来会像，

637
00:40:58,400 --> 00:41:05,260
U1 以及 ranks join links 文件，

638
00:41:05,260 --> 00:41:10,390
所以会是 U1, U1 U2, U3 ，

639
00:41:10,390 --> 00:41:13,700
出链接加上 U1 的排名，

640
00:41:13,730 --> 00:41:17,150
我要把它写成 R1 。

641
00:41:17,880 --> 00:41:20,010
RDD 就是在这里产生的，

642
00:41:20,070 --> 00:41:22,410
所以对于 U2 也是一样的，

643
00:41:22,410 --> 00:41:31,530
对于 U3 ，是 U1 和 R3 ，

644
00:41:32,540 --> 00:41:34,190
基本上合并这两个，

645
00:41:34,190 --> 00:41:37,130
字面上基于 key 连接两个文件。

646
00:41:38,120 --> 00:41:38,750
好的？

647
00:41:39,860 --> 00:41:43,460
然后它在这里运行一个 flatMap 的计算，

648
00:41:43,460 --> 00:41:47,540
而 flatMap 本身内部有一个 links 的映射，

649
00:41:47,750 --> 00:41:50,030
所以它会运行，

650
00:41:50,060 --> 00:41:52,490
[]会运行通过这个列表，

651
00:41:52,820 --> 00:41:59,180
将排名划分到出 URL 。

652
00:41:59,960 --> 00:42:04,820
所以它会创造了三元组的形式，

653
00:42:05,090 --> 00:42:07,550
让我用绿色来写，

654
00:42:07,580 --> 00:42:12,980
U1 R1/2 ，

655
00:42:15,120 --> 00:42:20,080
U1 或者 U3 的出链接，

656
00:42:20,080 --> 00:42:22,360
所以给 U1 1 ， U3 1 ，

657
00:42:22,360 --> 00:42:27,310
这是 U3 R1/2 ，等等，

658
00:42:27,310 --> 00:42:28,990
它创造了这种三元组的形式，

659
00:42:28,990 --> 00:42:30,610
所以它计算出，

660
00:42:30,610 --> 00:42:33,880
划分排名到出边上，

661
00:42:34,030 --> 00:42:39,850
把这些 ranks 的值给出边，

662
00:42:39,850 --> 00:42:40,900
所以出边，

663
00:42:40,900 --> 00:42:44,770
所以我们有一个很大的 RDD 包含这种格式，

664
00:42:46,600 --> 00:42:50,890
产生 contribs RDD 。

665
00:42:53,130 --> 00:42:55,890
然后是最后一步，

666
00:42:55,920 --> 00:42:57,960
我认为它首先是 reduceByKey ，

667
00:42:58,200 --> 00:43:01,050
所以把所有 U1 放在一起，

668
00:43:01,230 --> 00:43:02,190
然后对它们相加，

669
00:43:02,190 --> 00:43:03,990
所以这样的结果是，

670
00:43:03,990 --> 00:43:08,820
所有的权重或分数权重，

671
00:43:08,820 --> 00:43:11,610
U1 收到的都会加起来，

672
00:43:12,030 --> 00:43:16,800
U1 当然会收到自己的权重，

673
00:43:16,920 --> 00:43:19,650
这个，与 U3 相关，

674
00:43:20,380 --> 00:43:22,000
所以加起来，

675
00:43:22,000 --> 00:43:25,610
会有 R1/2 ，

676
00:43:25,790 --> 00:43:28,160
R3/1 ，

677
00:43:29,480 --> 00:43:32,720
这就是创造出来的总和。

678
00:43:33,510 --> 00:43:35,670
这给了我们一份总和列表，

679
00:43:35,670 --> 00:43:37,050
然后再把它们加起来，

680
00:43:37,560 --> 00:43:39,240
并计算成最终的值。

681
00:43:43,000 --> 00:43:45,340
它产生了新的 ranks RDD ，

682
00:43:45,340 --> 00:43:46,960
它有相同的形状，

683
00:43:46,990 --> 00:43:50,500
像我们之前看到的，也就是这个，

684
00:43:51,130 --> 00:43:54,070
对于每个网页，都有一个数字。

685
00:43:57,670 --> 00:43:58,390
这能理解吗？

686
00:44:00,840 --> 00:44:05,070
所以，这样的描述是很有趣的，

687
00:44:05,070 --> 00:44:07,170
首先，你可以看到，

688
00:44:07,170 --> 00:44:10,020
PageRank 的描述相当精确，

689
00:44:10,440 --> 00:44:11,940
这是一个例子，

690
00:44:11,940 --> 00:44:15,450
如果你以 mapreduce 样式运行过这个，

691
00:44:15,450 --> 00:44:19,320
那意味着这个循环的每一次迭代，

692
00:44:19,320 --> 00:44:20,310
在迭代结束时，

693
00:44:20,310 --> 00:44:22,680
你将结果存储在文件系统中，

694
00:44:23,010 --> 00:44:28,770
然后你重新读取结果给下一次迭代，

695
00:44:28,830 --> 00:44:33,570
在这个 Spark 系统中，

696
00:44:33,660 --> 00:44:37,410
每一次迭代都直接在内存中运行，将结果留在内存中，

697
00:44:37,410 --> 00:44:39,390
所以下一次迭代可以在那里找到它，

698
00:44:40,050 --> 00:44:45,060
此外，这些 links 文件在所有迭代之间是共享的。

699
00:44:46,380 --> 00:44:48,240
好的，为了更有意义一点，

700
00:44:48,240 --> 00:44:49,110
比如为什么，

701
00:44:49,110 --> 00:44:51,480
还有一个很酷的，

702
00:44:52,120 --> 00:44:53,470
查看它的方式是，

703
00:44:53,470 --> 00:44:57,750
查看这个计算的谱系图。

704
00:44:59,770 --> 00:45:02,620
让我们来看一下谱系图，

705
00:45:06,440 --> 00:45:14,840
所以这是 PageRank 的谱系图。

706
00:45:16,380 --> 00:45:19,080
所以我想指出几件事，

707
00:45:19,380 --> 00:45:21,960
首先，这些谱系图是动态的，

708
00:45:22,410 --> 00:45:23,010
糟糕，

709
00:45:27,010 --> 00:45:30,500
随着迭代的次数不断增长，

710
00:45:30,950 --> 00:45:36,140
当调度器计算新的阶段时，

711
00:45:36,140 --> 00:45:38,510
然后，它继续前进，

712
00:45:38,510 --> 00:45:41,030
我们可以看到阶段是什么，

713
00:45:41,030 --> 00:45:48,930
因为，循环的每一次迭代都是一个阶段，

714
00:45:48,930 --> 00:45:55,890
并且会将转换的一部分附加到谱系图中。

715
00:45:56,500 --> 00:45:59,890
所以我们看到这是输入文件，这是 links ，

716
00:46:00,220 --> 00:46:02,860
正如我们所看到的， links 创造了一些，

717
00:46:02,920 --> 00:46:04,450
然后保存在内存中，

718
00:46:04,480 --> 00:46:06,430
不是在磁盘中，而是在内存中，

719
00:46:06,610 --> 00:46:08,500
并且被多次重复使用，

720
00:46:08,500 --> 00:46:12,250
比如每一次循环迭代， ranks 会被重新使用，

721
00:46:12,550 --> 00:46:14,650
再次，把它与 mapreduce 比较，

722
00:46:14,650 --> 00:46:16,720
如果你写过这个使用 mapreduce 方式，

723
00:46:16,750 --> 00:46:17,920
你没有这个重新使用，

724
00:46:17,950 --> 00:46:20,950
这当然是非常出色的性能，

725
00:46:20,950 --> 00:46:23,470
因为正如我们之前所说的， links ，

726
00:46:23,560 --> 00:46:25,510
它是一个巨大的文件，

727
00:46:25,510 --> 00:46:30,250
相当于世界中每个网页的一行。

728
00:46:32,100 --> 00:46:35,700
另一个观察到有趣的事情是，

729
00:46:35,850 --> 00:46:37,590
我们在这里看到了宽依赖，

730
00:46:37,590 --> 00:46:38,910
这是一个宽依赖，

731
00:46:41,470 --> 00:46:43,180
可能是宽依赖，

732
00:46:43,270 --> 00:46:45,610
稍后我会对此做得更复杂一些，

733
00:46:46,260 --> 00:46:48,750
因为这些 contribs ，

734
00:46:48,750 --> 00:46:52,560
当我们生成 contribs 中间结果，

735
00:46:52,560 --> 00:46:55,260
它是一个 ranks 和 links 的 join ，

736
00:46:55,800 --> 00:47:01,050
所以它需要来自 links 的分区，

737
00:47:01,110 --> 00:47:03,300
而且它需要来自 ranks 的分区，

738
00:47:03,300 --> 00:47:10,920
来计算分区， contrib 分区，抱歉。

739
00:47:11,760 --> 00:47:15,390
所以，这需要一些网络通信，

740
00:47:15,990 --> 00:47:20,940
但他们有一种巧妙的优化，

741
00:47:23,840 --> 00:47:28,010
这是对早些时候关于分区的问题的回应，

742
00:47:28,220 --> 00:47:36,290
你可以指定分区 RDD ，使用 hash 分区。

743
00:47:38,960 --> 00:47:41,780
这意味着，

744
00:47:41,780 --> 00:47:44,720
links 和 ranks 文件，

745
00:47:45,050 --> 00:47:48,290
这两个 RDD 将以相同的方式分区，

746
00:47:48,290 --> 00:47:51,440
它们是按键或 hash 键分区的。

747
00:47:51,470 --> 00:47:54,680
所以我们回来看之前的图片，

748
00:47:55,210 --> 00:48:01,300
ranks 的键是 U1 U2 U3 ，

749
00:48:01,570 --> 00:48:06,750
links 的键，

750
00:48:06,750 --> 00:48:09,300
抱歉， ranks 的键是 U1 U2 U3 ，

751
00:48:09,450 --> 00:48:13,530
links 的键也是 U1 U2 U3 。

752
00:48:14,140 --> 00:48:16,960
客户端为了优化，

753
00:48:16,960 --> 00:48:20,140
这是数据库文献中的标准优化，

754
00:48:20,320 --> 00:48:23,560
如果你按键分区 links 和 ranks ，

755
00:48:23,650 --> 00:48:26,860
那么这个 U1 会在一台机器上，

756
00:48:28,310 --> 00:48:30,260
也许 U1 也在一台机器上，

757
00:48:32,680 --> 00:48:34,870
ranks 也会是一样的，

758
00:48:34,870 --> 00:48:36,730
U1 在一台机器上，

759
00:48:36,730 --> 00:48:39,340
事实上， U1 会在同一台机器上，

760
00:48:39,700 --> 00:48:43,750
以及 links U2 U3 。

761
00:48:45,710 --> 00:48:51,050
所以，即使这个 join 在感知上是宽依赖，

762
00:48:51,110 --> 00:48:53,750
它可以像窄依赖一样执行，

763
00:48:53,750 --> 00:48:57,140
因为计算这两个的 join ，

764
00:48:57,290 --> 00:49:02,450
对于 U1 ，对于第一个分区 P1 ，

765
00:49:02,600 --> 00:49:07,280
你只需查看 links 的 P1 和 ranks 的 P1 ，

766
00:49:07,490 --> 00:49:12,000
因为键是以相同的方式散列到同一台机器上的。

767
00:49:12,640 --> 00:49:18,070
所以调度器或程序员可以指定这些散列分区，

768
00:49:18,370 --> 00:49:19,360
调度器看到，

769
00:49:19,390 --> 00:49:22,960
join 使用散列分区，

770
00:49:22,960 --> 00:49:25,150
相同的散列分区，

771
00:49:25,300 --> 00:49:28,720
因此不需要做这个宽依赖，

772
00:49:28,720 --> 00:49:31,720
不需要像 mapreduce 那样做一个完整的屏障，

773
00:49:31,840 --> 00:49:34,150
我可以把这当做窄依赖。

774
00:49:35,120 --> 00:49:37,760
所以，这很酷，

775
00:49:38,540 --> 00:49:41,000
然后，再一次，

776
00:49:41,000 --> 00:49:43,040
如果一台机器出现故障，

777
00:49:43,040 --> 00:49:45,080
我们早些时候谈过这个问题，

778
00:49:45,110 --> 00:49:47,540
这可能是痛苦的，

779
00:49:47,540 --> 00:49:51,590
因为你可能需要重新执行许多循环或一次迭代，

780
00:49:51,920 --> 00:49:55,100
所以，如果你可能认真地写这个，

781
00:49:55,100 --> 00:49:57,560
然后，程序员可能会说，

782
00:49:57,560 --> 00:50:03,630
比如每 10 次迭代，就是检查点，

783
00:50:11,260 --> 00:50:15,880
这样你就不必从头开始重新计算了。

784
00:50:16,540 --> 00:50:20,290
哦，所以我们并不是每次都重新计算 links 或其他东西，

785
00:50:20,500 --> 00:50:21,940
比如我们不持久化，抱歉。

786
00:50:22,870 --> 00:50:24,340
我们不持久化，一点也不，

787
00:50:25,030 --> 00:50:27,700
唯一持久化的只有 links ，

788
00:50:27,700 --> 00:50:30,310
这是唯一有 persist 调用的东西。

789
00:50:31,100 --> 00:50:32,210
哦，我们做了持久化。

790
00:50:32,600 --> 00:50:33,470
links ，我们做了。

791
00:50:33,800 --> 00:50:34,280
好的。

792
00:50:35,760 --> 00:50:37,470
但不是中间的 RDD ，

793
00:50:38,470 --> 00:50:40,270
因为它们基本上每次都是新的 RDD ，

794
00:50:40,270 --> 00:50:42,100
比如 ranks 1 是一个新的 RDD ，

795
00:50:42,100 --> 00:50:44,050
ranks 2 是一个新的 RDD 。

796
00:50:45,990 --> 00:50:51,210
但你偶尔可能想持久化它们，保存到 HDFS 中，

797
00:50:51,210 --> 00:50:53,640
如果你有一个故障，

798
00:50:53,640 --> 00:50:57,510
你不必回到迭代循环 0 来计算所有东西。

799
00:51:01,370 --> 00:51:02,420
好的，这能理解吗？

800
00:51:03,350 --> 00:51:07,790
哦，抱歉，不同的 contribs ，它们可以并行计算吗？

801
00:51:08,490 --> 00:51:10,170
在不同的分区上，是的。

802
00:51:11,500 --> 00:51:15,610
因为这条线是垂直向下的。

803
00:51:15,700 --> 00:51:20,130
垂直向下的，是流水线，

804
00:51:20,130 --> 00:51:22,170
只有两种类型的并行，

805
00:51:22,170 --> 00:51:23,490
有阶段并行，

806
00:51:23,550 --> 00:51:26,070
以及不同分区之间的并行性，

807
00:51:26,340 --> 00:51:29,400
我们可以考虑整个事情，

808
00:51:29,640 --> 00:51:32,850
在不同的分区上运行多次。

809
00:51:45,300 --> 00:51:46,620
所以，在这种情况下，

810
00:51:46,620 --> 00:51:50,310
在最后的 collect 是唯一的宽（依赖）。

811
00:51:50,520 --> 00:51:52,380
是的，没错，

812
00:51:52,500 --> 00:51:54,180
collect 是唯一的，

813
00:51:55,080 --> 00:51:57,450
不管什么，这里我们有更多的分区，

814
00:51:58,420 --> 00:51:59,920
我把这张图片弄乱了，

815
00:51:59,920 --> 00:52:03,010
但会从每一个获取。

816
00:52:09,120 --> 00:52:09,630
好的？

817
00:52:10,080 --> 00:52:12,600
我希望大家都能看到这很酷，

818
00:52:13,300 --> 00:52:16,030
仅仅通过表达这些计算，

819
00:52:16,030 --> 00:52:18,940
以及谱系图或数据流计算，

820
00:52:19,120 --> 00:52:21,850
调度器有一个组织，

821
00:52:21,880 --> 00:52:26,200
比如这个[]散列分区，

822
00:52:26,500 --> 00:52:28,660
我们获得很多的并行性，

823
00:52:28,690 --> 00:52:30,640
我们也可以重复使用，

824
00:52:30,640 --> 00:52:33,610
我们可以将一个 RDD 的结果保存在内存中，

825
00:52:33,610 --> 00:52:35,530
这样我们可以在下一次迭代中重复使用它，

826
00:52:35,920 --> 00:52:37,480
你可以看到，

827
00:52:37,480 --> 00:52:39,010
这些技术结合在一起，

828
00:52:39,010 --> 00:52:42,040
将给你带来显著的性能优化，

829
00:52:44,640 --> 00:52:49,800
并允许你表达更强大或更有趣的计算。

830
00:52:52,420 --> 00:52:54,790
也许我总结一下这节课。

831
00:53:02,100 --> 00:53:05,820
所以有几件事，

832
00:53:06,760 --> 00:53:13,230
RDD 是由函数式转换创建的，

833
00:53:19,110 --> 00:53:22,650
它们以谱系图的形式聚集在一起，

834
00:53:23,510 --> 00:53:25,580
你可以把它想象成一个数据流图，

835
00:53:26,140 --> 00:53:30,910
这允许重复使用，

836
00:53:32,890 --> 00:53:36,250
它还允许通过调度器进行一些巧妙的组织。

837
00:53:41,600 --> 00:53:44,840
而且它也更，

838
00:53:44,840 --> 00:53:55,130
它的表现力比 mapreduce 本身更强，

839
00:53:58,290 --> 00:54:02,010
这带来了良好的性能，

840
00:54:02,010 --> 00:54:03,990
因为很多数据都留在内存中。

841
00:54:14,790 --> 00:54:17,250
所以，如果你对此感到兴奋，

842
00:54:17,250 --> 00:54:18,030
你可以试一下，

843
00:54:18,120 --> 00:54:22,380
你可以下载 Spark palyground ，然后写一些程序，

844
00:54:22,380 --> 00:54:24,750
或者去 databricks.com ，

845
00:54:24,750 --> 00:54:25,890
创建账户，

846
00:54:25,890 --> 00:54:30,000
然后你可以运行 Spark 计算，在他们的集群上。

847
00:54:31,030 --> 00:54:33,490
所以如果你对此很兴奋，并想试一试，

848
00:54:33,490 --> 00:54:35,050
要做到这一点很容易，

849
00:54:35,470 --> 00:54:37,870
不像 FaRM ，你不能操作，

850
00:54:38,200 --> 00:54:41,170
但是这个，你可以出去试一试。

851
00:54:41,650 --> 00:54:44,530
好了，说到这里，我想今天在这里停止，

852
00:54:44,530 --> 00:54:49,420
那些想留下来问更多问题的人，

853
00:54:49,420 --> 00:54:50,890
请随意这样做，

854
00:54:51,190 --> 00:54:53,830
我唯一想提醒人们的是，

855
00:54:53,860 --> 00:54:59,050
4b 的最后期限还有点远，

856
00:54:59,050 --> 00:55:02,140
但我只想提醒大家， 4b 是相当棘手的，

857
00:55:02,170 --> 00:55:04,240
需要一点设计，

858
00:55:04,240 --> 00:55:06,040
所以，不要开始得太晚。

859
00:55:06,660 --> 00:55:08,940
就这些，我会在周二见你。

860
00:55:14,450 --> 00:55:17,150
再一次，我很乐意回答问题。

861
00:55:18,560 --> 00:55:19,160
谢谢。

862
00:55:21,010 --> 00:55:24,070
我有一个关于检查点的问题，

863
00:55:24,220 --> 00:55:27,940
我想他们提到了自动检查点，

864
00:55:28,300 --> 00:55:32,230
使用关于每次计算所需时间的数据，

865
00:55:34,320 --> 00:55:36,750
我不太确定他们这么说是什么意思，

866
00:55:36,750 --> 00:55:40,620
但是，他们将针对什么进行优化。

867
00:55:41,300 --> 00:55:43,280
可以创建一个完整的检查点，

868
00:55:43,280 --> 00:55:44,840
这是一种优化，

869
00:55:45,020 --> 00:55:47,600
创建检查点是昂贵的，

870
00:55:48,220 --> 00:55:50,680
需要时间，

871
00:55:51,100 --> 00:55:54,670
但在重新执行时，如果机器出现故障，

872
00:55:54,700 --> 00:55:55,780
也要花很多时间，

873
00:55:56,520 --> 00:55:59,160
比如，如果你从不做检查点，

874
00:55:59,160 --> 00:56:01,920
那么你要从头开始计算，

875
00:56:02,540 --> 00:56:04,520
但如果你定期创建检查点，

876
00:56:04,520 --> 00:56:07,310
你不需要重复计算，

877
00:56:07,310 --> 00:56:08,840
你在检查点之前所做的，

878
00:56:08,840 --> 00:56:10,550
但检查点需要时间，

879
00:56:11,640 --> 00:56:13,680
所以，如果你频繁地创建检查点，

880
00:56:13,680 --> 00:56:15,030
你不需要重新计算很多东西，

881
00:56:15,030 --> 00:56:16,740
但你把所有的时间都花在了创建检查点上。

882
00:56:18,060 --> 00:56:22,300
所以这里有一个优化问题，

883
00:56:22,600 --> 00:56:24,160
你想要创建检查点，

884
00:56:24,160 --> 00:56:29,710
一些间隔，重新计算。

885
00:56:32,060 --> 00:56:36,770
好的，所以可能计算检查点，需要非常大的计算。

886
00:56:36,800 --> 00:56:38,840
是的，或者在 PageRank 的情况中，

887
00:56:38,840 --> 00:56:41,570
也许每 10 次迭代做一次。

888
00:56:44,800 --> 00:56:45,580
谢谢。

889
00:56:46,030 --> 00:56:48,100
当然，这取决于，是否决定创建检查点，

890
00:56:48,100 --> 00:56:51,340
如果检查点很小，你可以创建检查点频繁一点，

891
00:56:52,260 --> 00:56:54,090
但是在 PageRank 的情况中，

892
00:56:54,090 --> 00:56:55,710
那个检查点会很大，

893
00:56:56,600 --> 00:57:01,250
每个网页都会有一行或一条记录。

894
00:57:03,310 --> 00:57:04,900
理解了，谢谢。

895
00:57:05,110 --> 00:57:05,590
不用谢。

896
00:57:07,300 --> 00:57:09,670
我有一个关于 driver 的问题，

897
00:57:10,150 --> 00:57:11,470
应用是不是，

898
00:57:11,470 --> 00:57:15,550
driver 是不是在客户端，

899
00:57:15,580 --> 00:57:15,910
或者。

900
00:57:15,910 --> 00:57:16,240
是的。

901
00:57:16,720 --> 00:57:17,440
好的。

902
00:57:17,530 --> 00:57:18,910
是的， driver 。

903
00:57:19,150 --> 00:57:19,840
如果它崩溃了，

904
00:57:19,840 --> 00:57:21,760
我们会丢掉整个图，

905
00:57:21,760 --> 00:57:22,420
这没问题，

906
00:57:22,420 --> 00:57:24,400
因为这是应用程序。

907
00:57:25,140 --> 00:57:26,670
是的，我也不知道会发生什么，

908
00:57:26,670 --> 00:57:30,030
因为调度器有[]，

909
00:57:31,140 --> 00:57:34,830
调度器容错，

910
00:57:35,160 --> 00:57:37,080
所以我不知道会发生什么，

911
00:57:37,080 --> 00:57:39,360
也许你可以重新连接，我不知道。

912
00:57:43,940 --> 00:57:47,780
我有一个关于为什么依赖优化的问题，

913
00:57:47,780 --> 00:57:50,570
你提到他们会进行散列分区，

914
00:57:50,570 --> 00:57:51,680
这是怎么回事？

915
00:57:52,490 --> 00:57:53,840
好的，我再多说一点，

916
00:57:53,840 --> 00:57:54,530
所以这不是，

917
00:57:54,530 --> 00:57:56,300
散列不是今天的主题，

918
00:57:56,300 --> 00:57:57,620
这是某些东西，

919
00:57:57,620 --> 00:58:03,380
是一个标准的数据库分区方案，

920
00:58:04,120 --> 00:58:05,320
这很酷，

921
00:58:05,320 --> 00:58:06,910
因为如果你需要计算机加入，

922
00:58:07,440 --> 00:58:09,900
你不需要做很多通信，

923
00:58:09,900 --> 00:58:12,030
所以让我开始一张新的幻灯片，

924
00:58:12,030 --> 00:58:14,850
因为它有点难读。

925
00:58:14,850 --> 00:58:15,960
所以散列分区，

926
00:58:20,210 --> 00:58:21,590
所以，如果你有两个数据集，

927
00:58:22,460 --> 00:58:24,980
这是数据集 1 ，这是数据集 2 ，

928
00:58:25,220 --> 00:58:28,280
它们有键， K1 K2 ，

929
00:58:29,620 --> 00:58:31,540
它们有一套相同的键，

930
00:58:32,250 --> 00:58:35,100
你使用散列分区所做的，

931
00:58:35,190 --> 00:58:37,470
你将数据集分成多个分区，

932
00:58:37,500 --> 00:58:39,240
所以等等，

933
00:58:39,930 --> 00:58:42,570
你对键做散列，

934
00:58:44,830 --> 00:58:47,080
所以对 K1 散列，你对 K2 散列，

935
00:58:47,080 --> 00:58:49,270
这取决于分区的结果，

936
00:58:50,000 --> 00:58:53,960
具有相同散列的所有键

937
00:58:53,960 --> 00:58:55,070
都出现在同一位置，

938
00:58:55,070 --> 00:58:59,600
比如这是机器 1 ，机器 2 ，机器 3 ，

939
00:58:59,810 --> 00:59:03,560
所以你把散列 K1 放在这里，

940
00:59:03,920 --> 00:59:06,080
你对 K2 散列，

941
00:59:06,080 --> 00:59:08,450
可能在文件中的其他地方，

942
00:59:08,660 --> 00:59:09,890
你将它散列到这个分区，

943
00:59:10,130 --> 00:59:13,780
你对其他数据集执行相同的操作，

944
00:59:13,780 --> 00:59:15,010
这是数据集 1 ，

945
00:59:17,620 --> 00:59:18,730
这是数据集 2 ，

946
00:59:21,060 --> 00:59:22,260
比如 links 和 ranks ，

947
00:59:22,590 --> 00:59:24,780
接下来会发生的是，

948
00:59:24,930 --> 00:59:26,970
这个数据集中的所有记录，

949
00:59:26,970 --> 00:59:31,740
与其他数据集中的记录具有相同的键，

950
00:59:31,860 --> 00:59:35,340
这些键或记录会被放在同一台机器里，

951
00:59:35,340 --> 00:59:37,990
所以，你对这个分区，

952
00:59:37,990 --> 00:59:44,550
K1 也会在这里，同一台机器上，

953
00:59:44,550 --> 00:59:46,380
其他键也是一样的，

954
00:59:46,380 --> 00:59:48,450
因为你使用相同的散列函数，

955
00:59:48,450 --> 00:59:49,770
你有一套相同的键，

956
00:59:50,040 --> 00:59:52,530
所以，这允许你将数据集分区，

957
00:59:52,530 --> 00:59:53,730
以相同的方式，

958
00:59:53,760 --> 00:59:55,440
使用这种散列技巧。

959
00:59:56,100 --> 00:59:56,940
这很酷，

960
00:59:56,940 --> 01:00:00,600
因为现在你可以对两个数据集做 join ，

961
01:00:00,600 --> 01:00:02,790
例如，如果你需要 join 这两个数据集，

962
01:00:02,940 --> 01:00:04,800
你可以 join 分区，

963
01:00:06,420 --> 01:00:08,100
而且你不需要通信，

964
01:00:08,800 --> 01:00:12,670
这些机器中的每一台都不需要与任何其他机器通信，

965
01:00:12,700 --> 01:00:17,320
因为它知道它拥有另一个数据集拥有的所有键，

966
01:00:17,320 --> 01:00:18,580
它们都在同一台机器上。

967
01:00:20,260 --> 01:00:24,370
明白了，它是尝试排序，不是排序，

968
01:00:24,370 --> 01:00:27,430
就像把不同的东西放入同一台机器，

969
01:00:27,430 --> 01:00:29,170
这样它就不需要通信了。

970
01:00:32,070 --> 01:00:33,510
好的，非常感谢。

971
01:00:35,010 --> 01:00:37,890
这意味着散列函数必须确保，

972
01:00:38,310 --> 01:00:39,930
没有 links ，

973
01:00:40,230 --> 01:00:44,010
必须使用另一台机器上的计算？

974
01:00:44,910 --> 01:00:47,490
是的，因为它们使用相同的散列函数，

975
01:00:47,640 --> 01:00:48,720
而且它们有相同的键，

976
01:00:48,720 --> 01:00:49,500
这是会发生的。

977
01:00:54,100 --> 01:00:54,910
好的。

978
01:00:56,340 --> 01:00:58,050
我有个问题，

979
01:00:58,050 --> 01:01:00,900
我想回到我之前问的那个问题上。

980
01:01:01,020 --> 01:01:05,550
是的，很好。

981
01:01:06,000 --> 01:01:07,500
所以，让我打开。

982
01:01:07,530 --> 01:01:09,570
是的，我想我也打开论文。

983
01:01:09,780 --> 01:01:12,570
还有其他人有问题吗，

984
01:01:12,600 --> 01:01:14,520
因为这可能需要一点时间。

985
01:01:15,530 --> 01:01:16,790
是的，我有一个简短的问题，

986
01:01:16,790 --> 01:01:20,300
关于 FaRM 的容错能力，

987
01:01:20,480 --> 01:01:24,740
所以为了弄清楚到底发生了什么，

988
01:01:24,740 --> 01:01:29,420
所以，如果在决策点之前发生故障，

989
01:01:29,840 --> 01:01:32,660
然后整个事情就中止了，

990
01:01:32,690 --> 01:01:34,580
但它发生在决定点之后，

991
01:01:34,580 --> 01:01:37,820
然后在出现故障的计算机重新启动后，

992
01:01:37,820 --> 01:01:40,400
它们必须重新询问协调者，

993
01:01:40,400 --> 01:01:41,570
是否应该承诺。

994
01:01:42,340 --> 01:01:44,530
它们并不重新询问，

995
01:01:44,530 --> 01:01:46,810
这里发生的是，

996
01:01:46,810 --> 01:01:49,000
在失败之后，有一个恢复程序运行，

997
01:01:49,500 --> 01:01:53,790
恢复进程查看所有日志[]，

998
01:01:53,790 --> 01:01:57,360
然后恢复进程查看系统的状态，

999
01:01:57,690 --> 01:01:59,400
基于系统的状态，

1000
01:01:59,400 --> 01:02:00,990
并决定如何处理事务，

1001
01:02:01,260 --> 01:02:02,760
要么中止，要么提交，

1002
01:02:03,600 --> 01:02:07,590
这个协议的关键方面是，

1003
01:02:07,590 --> 01:02:09,660
在这一点上，为了确保，

1004
01:02:09,720 --> 01:02:15,020
事务协调器已经向应用程序报告，

1005
01:02:15,020 --> 01:02:17,510
这个事务已经成功提交，

1006
01:02:17,810 --> 01:02:18,950
必须是这样的，

1007
01:02:18,950 --> 01:02:22,550
系统中留下了足够多的证据，

1008
01:02:22,550 --> 01:02:24,050
所以在恢复过程中，

1009
01:02:24,050 --> 01:02:25,640
这个事务肯定是被提交的，

1010
01:02:26,780 --> 01:02:30,000
这就是我们的方案。

1011
01:02:30,700 --> 01:02:32,680
有足够证据的原因是，

1012
01:02:32,680 --> 01:02:35,170
因为有日志记录在这里，

1013
01:02:35,560 --> 01:02:38,560
这里有提交备份记录在这里，

1014
01:02:38,680 --> 01:02:40,690
这里有一个提交记录。

1015
01:02:43,140 --> 01:02:43,590
我明白了，

1016
01:02:43,590 --> 01:02:44,880
所以如果有什么事，

1017
01:02:44,880 --> 01:02:50,790
比如，如果在 primary 上发生故障，在 primary 提交之前。

1018
01:02:51,000 --> 01:02:51,540
是的。

1019
01:02:52,070 --> 01:02:53,150
那里发生了什么？

1020
01:02:53,300 --> 01:02:54,200
这很有趣，

1021
01:02:54,200 --> 01:02:56,090
所以有足够的备份记录，

1022
01:02:56,620 --> 01:02:58,090
来决定这个，

1023
01:02:58,090 --> 01:03:00,520
每个备份，每个分片已经提交，

1024
01:03:01,360 --> 01:03:04,030
所以，这是足够的信息，

1025
01:03:04,030 --> 01:03:05,200
让恢复过程说，

1026
01:03:05,200 --> 01:03:07,390
我要运行那个事务，

1027
01:03:07,630 --> 01:03:08,800
因为它可能已经提交了。

1028
01:03:10,630 --> 01:03:12,910
明白了，所以在这种情况下不需要 primary ，

1029
01:03:12,910 --> 01:03:15,580
可以使用备份，因为备份有。

1030
01:03:17,140 --> 01:03:17,860
是的，就是这样。

1031
01:03:20,030 --> 01:03:20,990
明白了，谢谢，

1032
01:03:21,350 --> 01:03:23,840
如果备份失败，会发生什么情况？

1033
01:03:24,620 --> 01:03:26,660
好的，如果其中一个备份失败，

1034
01:03:26,660 --> 01:03:29,510
这意味着提交记录仍在那里，

1035
01:03:30,100 --> 01:03:32,290
再一次，有足够的信息来决定，

1036
01:03:32,290 --> 01:03:33,910
这个事务需要提交，

1037
01:03:34,400 --> 01:03:37,640
有足够的备份来了解新的值，

1038
01:03:37,640 --> 01:03:40,880
或者还有日志条目包含，

1039
01:03:40,880 --> 01:03:42,290
所以如果 primary 开始，

1040
01:03:42,620 --> 01:03:43,880
它将有一个日志条目，

1041
01:03:43,940 --> 01:03:45,290
将有一个提交的条目，

1042
01:03:45,410 --> 01:03:48,230
加上备份完成事务。

1043
01:03:50,650 --> 01:03:51,220
谢谢。

1044
01:03:52,380 --> 01:03:53,970
哦，抱歉要跟进这件事，

1045
01:03:53,970 --> 01:03:57,630
你说如果 primary 失败了，

1046
01:03:57,630 --> 01:04:01,110
然后，你可以使用备份来完成操作，

1047
01:04:01,110 --> 01:04:02,160
如果它们的数量足够多，

1048
01:04:02,550 --> 01:04:05,400
所以我们需要选举新的 primary 吗？

1049
01:04:06,540 --> 01:04:09,870
我想这一切都发生在，

1050
01:04:09,930 --> 01:04:12,960
你可以将恢复过程看成是 primary ，

1051
01:04:13,350 --> 01:04:15,090
它完成了所有的事情。

1052
01:04:16,520 --> 01:04:19,490
哦，所以做恢复工作的就是 primary 。

1053
01:04:19,900 --> 01:04:21,550
是的。

1054
01:04:22,280 --> 01:04:24,470
好的，理解了，谢谢。

1055
01:04:24,560 --> 01:04:27,230
我不认为他们明确地选择 primary ，

1056
01:04:27,230 --> 01:04:28,640
只是继续并完成它。

1057
01:04:30,060 --> 01:04:32,130
什么是足够多的备份？

1058
01:04:32,490 --> 01:04:36,310
嗯，我们有 f+1 ，

1059
01:04:36,430 --> 01:04:40,120
所以这意味着，如果一个丢失了，

1060
01:04:40,920 --> 01:04:42,330
我们还是好的，

1061
01:04:42,360 --> 01:04:44,670
所以我们可以有 f+1 失败，

1062
01:04:45,060 --> 01:04:46,380
我们只能有 f 个故障，

1063
01:04:46,380 --> 01:04:48,570
在这个图中， f 是 1 ，

1064
01:04:51,100 --> 01:04:53,980
所以每个分片只剩一台机器。

1065
01:04:56,090 --> 01:04:58,100
好的，理解了，谢谢。

1066
01:04:58,640 --> 01:04:59,240
不用谢。

1067
01:05:02,440 --> 01:05:04,240
好了， Felipe ，只有我和你了。

1068
01:05:06,750 --> 01:05:10,200
好的，除非还有其他人问问题。

1069
01:05:14,710 --> 01:05:16,420
是的，我和你。

1070
01:05:16,420 --> 01:05:20,500
所以他们在第 6 页解释了。

1071
01:05:20,920 --> 01:05:22,420
好的，让我。

1072
01:05:23,590 --> 01:05:25,450
在表 3 下面。

1073
01:05:25,630 --> 01:05:26,200
好的。

1074
01:05:27,660 --> 01:05:31,770
有一段以 the most interesting question 开始，

1075
01:05:31,770 --> 01:05:34,140
它接着定义。

1076
01:05:34,890 --> 01:05:35,940
是的，我们发现它足够且有用，

1077
01:05:35,940 --> 01:05:37,650
将依赖分类两个类型，

1078
01:05:37,650 --> 01:05:40,200
窄依赖，父 RDD 的父分区

1079
01:05:40,200 --> 01:05:43,170
由最多一个子 RDD 使用，

1080
01:05:43,170 --> 01:05:43,860
所以这就是。

1081
01:05:44,070 --> 01:05:44,580
是的。

1082
01:05:44,820 --> 01:05:46,680
所以让我们画出这个，

1083
01:05:46,680 --> 01:05:51,840
这里我们有一个父分区。

1084
01:05:52,980 --> 01:05:53,400
是的。

1085
01:05:54,960 --> 01:05:56,580
假设这里有一个 map ，

1086
01:05:57,820 --> 01:05:59,620
这里我们有一个子分区。

1087
01:06:04,640 --> 01:06:05,090
好的?

1088
01:06:05,840 --> 01:06:06,410
好的。

1089
01:06:07,550 --> 01:06:09,890
好的，这是窄（依赖）的情况。

1090
01:06:12,600 --> 01:06:17,310
是的，但是我想，

1091
01:06:17,340 --> 01:06:21,380
我想的例子是，

1092
01:06:21,380 --> 01:06:31,420
每个父分区最多子的一个分区使用，

1093
01:06:31,950 --> 01:06:35,220
但是子，它没有说什么东西，

1094
01:06:35,220 --> 01:06:37,530
它说的，

1095
01:06:37,530 --> 01:06:41,610
它不一定意味着它是一对一的关系。

1096
01:06:41,640 --> 01:06:44,220
嗯，或多或少，

1097
01:06:44,220 --> 01:06:47,550
假设我们有一个宽（依赖），

1098
01:06:47,550 --> 01:06:53,250
这里我们有父分区 1 ，

1099
01:06:56,350 --> 01:06:59,140
这里，也许它有 n 个，

1100
01:06:59,140 --> 01:07:01,240
这是 2 ，这是 n ，

1101
01:07:01,870 --> 01:07:07,710
在宽（依赖）中，子分区。

1102
01:07:09,920 --> 01:07:13,370
好的，我想说的是，

1103
01:07:13,520 --> 01:07:17,030
我想根据论文中给出的定义，

1104
01:07:17,720 --> 01:07:20,480
这可能是一个窄分区，

1105
01:07:24,010 --> 01:07:26,800
事实上，我的意思是，如果你看一下，

1106
01:07:28,580 --> 01:07:32,690
比如 join 输入共同分区，比如你有。

1107
01:07:32,930 --> 01:07:35,930
是的，哈希分区，将宽依赖变成窄依赖。

1108
01:07:36,530 --> 01:07:42,230
是的，但你仍然有一个子分区，

1109
01:07:42,230 --> 01:07:49,360
是从几个父分区计算出来的。

1110
01:07:49,360 --> 01:07:52,570
明确提到这个，

1111
01:07:52,630 --> 01:07:54,160
我想这是唯一的例子。

1112
01:07:54,910 --> 01:07:57,130
是的，但是。

1113
01:07:57,430 --> 01:07:59,080
我觉得那句话打错了。

1114
01:08:02,250 --> 01:08:04,080
我的意思是，我不确定，

1115
01:08:04,080 --> 01:08:06,150
是的，我不确定是不是，

1116
01:08:06,450 --> 01:08:08,610
他们是什么意思，关于[]。

1117
01:08:09,240 --> 01:08:12,330
好的，我们知道我们的结论是，

1118
01:08:12,330 --> 01:08:14,470
这是两种情况，比如我有。

1119
01:08:14,470 --> 01:08:14,950
是的。

1120
01:08:14,980 --> 01:08:16,720
我想，而且没有其他情况，

1121
01:08:17,350 --> 01:08:21,310
我们可以运行每个操作，

1122
01:08:21,310 --> 01:08:23,380
然后我们可以看它是窄的还是宽的。

1123
01:08:23,910 --> 01:08:24,690
好的。

1124
01:08:25,200 --> 01:08:30,270
所以，一旦编程者定义这些操作，

1125
01:08:30,270 --> 01:08:33,300
表明它是宽分区还是窄的，

1126
01:08:33,600 --> 01:08:35,610
宽依赖还是窄依赖，

1127
01:08:36,360 --> 01:08:39,300
这就是图 3 所示的内容。

1128
01:08:39,750 --> 01:08:43,230
是的，我想说的是，

1129
01:08:43,230 --> 01:08:46,200
通常，就像我在论文中看到的，

1130
01:08:46,230 --> 01:08:49,590
比如，你的宽（依赖）的例子会是，

1131
01:08:49,590 --> 01:08:52,500
可能是一种窄依赖，

1132
01:08:52,500 --> 01:08:55,200
除非你有几个子分区，

1133
01:08:55,410 --> 01:08:57,390
而父分区是。

1134
01:08:57,660 --> 01:08:59,430
好的，所以总的来说，

1135
01:08:59,430 --> 01:09:00,780
好的，当然是这样的，

1136
01:09:00,930 --> 01:09:02,520
如果这里还有另一个子分区，

1137
01:09:02,550 --> 01:09:04,230
好的，也许这就是为什么我们想要，

1138
01:09:04,650 --> 01:09:06,000
所以让我们分开，

1139
01:09:06,060 --> 01:09:07,860
真实的图是这样的，

1140
01:09:08,330 --> 01:09:09,920
它有另一个子分区，

1141
01:09:10,070 --> 01:09:14,750
基本上，操作，转换是。

1142
01:09:17,210 --> 01:09:21,560
没错，是的，而且这肯定是窄的。

1143
01:09:21,920 --> 01:09:23,960
这个，在右边，这个是宽的。

1144
01:09:23,960 --> 01:09:25,280
抱歉，是宽的，是的。

1145
01:09:25,280 --> 01:09:29,480
这就是我的意思，这肯定宽的。

1146
01:09:29,480 --> 01:09:31,040
我想我画的另一个也是宽的，

1147
01:09:31,850 --> 01:09:33,380
比如，如果你执行 join ，

1148
01:09:33,380 --> 01:09:37,580
如果你做一个 collect 操作在最后，

1149
01:09:37,730 --> 01:09:38,570
它就是宽依赖。

1150
01:09:38,570 --> 01:09:40,120
好的，好的。

1151
01:09:40,120 --> 01:09:42,970
它没有说，它必须来自不同的 RDD ，

1152
01:09:42,970 --> 01:09:45,280
它只是说它必须来自不同的分区。

1153
01:09:45,580 --> 01:09:46,600
所以这是窄的，

1154
01:09:47,230 --> 01:09:49,900
所以我认为窄的只是一对一的情况。

1155
01:09:50,610 --> 01:09:51,420
好的。

1156
01:09:51,450 --> 01:09:54,210
窄的就是，窄的就是没有通信。

1157
01:09:55,870 --> 01:10:03,680
好的，好的，是的。

1158
01:10:07,660 --> 01:10:11,290
是的，我想我困惑的那个情况是，

1159
01:10:11,290 --> 01:10:15,280
比如多对一，

1160
01:10:15,310 --> 01:10:19,750
我想根据论文上的定义，

1161
01:10:19,750 --> 01:10:23,980
多对一的关系还是窄的。

1162
01:10:24,340 --> 01:10:26,920
不，我想他们的意思是。

1163
01:10:26,920 --> 01:10:30,760
是的，但严格来说，[]，

1164
01:10:30,760 --> 01:10:34,660
是的，我想也许你会看到的实现，

1165
01:10:35,020 --> 01:10:37,330
是的，你说的，它是宽的，

1166
01:10:37,710 --> 01:10:38,280
我就是，

1167
01:10:38,280 --> 01:10:39,300
我想如果你读到。

1168
01:10:39,300 --> 01:10:41,040
是的，你可能困惑。

1169
01:10:41,040 --> 01:10:41,970
论文实际上，

1170
01:10:41,970 --> 01:10:45,330
是的，你可能会对多对一的关系感到困惑，

1171
01:10:45,420 --> 01:10:48,300
但是一对多显然是宽的，

1172
01:10:49,000 --> 01:10:50,890
但是，好的，听起来不错。

1173
01:10:51,430 --> 01:10:51,970
好的。

1174
01:10:52,000 --> 01:10:57,570
是的，我认为这篇论文总体上容易理解。

1175
01:10:57,810 --> 01:10:58,470
好的。

1176
01:10:59,390 --> 01:11:00,260
好的，好的。

1177
01:11:00,500 --> 01:11:03,590
它比 FaRM 论文简单吗？

1178
01:11:03,590 --> 01:11:07,490
哦，是的，当然。

1179
01:11:07,550 --> 01:11:11,840
是的，我想它们是最[重]的两篇论文，

1180
01:11:11,840 --> 01:11:13,490
我们在这学期看到的。

1181
01:11:14,940 --> 01:11:15,780
好的，很好。

1182
01:11:15,780 --> 01:11:17,400
FaRM 和 Spanner ，

1183
01:11:17,430 --> 01:11:21,900
我认为剩下的要更（简单），

1184
01:11:21,900 --> 01:11:23,640
我要直截了当地说，

1185
01:11:24,060 --> 01:11:26,880
可能更少的[可移动部分]。

1186
01:11:27,710 --> 01:11:28,310
好的。

1187
01:11:29,980 --> 01:11:32,650
好的，太棒了，谢谢教授。

1188
01:11:32,770 --> 01:11:34,570
我能问最后一个问题吗，

1189
01:11:34,600 --> 01:11:36,970
我刚刚意识到，

1190
01:11:37,450 --> 01:11:41,020
是关于谈话的，你可以[]，

1191
01:11:41,490 --> 01:11:42,690
如果它是不同的分区，

1192
01:11:42,690 --> 01:11:46,520
但如果它，你说的如果它在。

1193
01:11:46,520 --> 01:11:48,680
是的，阶段，

1194
01:11:48,680 --> 01:11:52,040
这里有流并行，

1195
01:11:52,040 --> 01:11:53,840
或者流水线并行。

1196
01:11:54,530 --> 01:11:56,780
让我看看能不能找到一张图片，

1197
01:11:58,110 --> 01:11:58,950
这里有一张。

1198
01:12:04,840 --> 01:12:10,510
我得找到谱系图，不，不，

1199
01:12:11,260 --> 01:12:12,730
在这里，这是谱系图，

1200
01:12:12,760 --> 01:12:15,910
好的，也许这是一张图片我们可以修改。

1201
01:12:16,800 --> 01:12:17,640
你看到了吗？

1202
01:12:18,900 --> 01:12:19,590
是的。

1203
01:12:19,770 --> 01:12:24,210
好的，这是 collect 的谱系图，

1204
01:12:24,510 --> 01:12:27,900
所以这是一个阶段，

1205
01:12:30,820 --> 01:12:35,440
调度器运行一个阶段在每个 worker 或每个分区，

1206
01:12:35,890 --> 01:12:43,670
每个 worker 在分区上运行一个阶段，

1207
01:12:48,770 --> 01:12:50,570
所以所有这些分区，

1208
01:12:50,570 --> 01:12:54,140
所有这些阶段在不同的 worker 上并行运行，

1209
01:12:55,200 --> 01:12:58,290
然后在一个阶段内，也有并行，

1210
01:12:59,100 --> 01:13:03,480
因为每个 filter 都是流水线的，

1211
01:13:04,010 --> 01:13:05,930
这个的意思是，

1212
01:13:05,930 --> 01:13:08,660
你读取最前面的 n 个记录，

1213
01:13:09,450 --> 01:13:11,430
然后你应用 filter 操作，

1214
01:13:12,780 --> 01:13:19,320
然后产生 n 个记录，

1215
01:13:20,030 --> 01:13:24,860
然后下一个 filter 处理这 n 个记录，

1216
01:13:24,890 --> 01:13:26,960
当处理这 n 个记录时，

1217
01:13:27,200 --> 01:13:29,060
第一个 filter 读取下一个 n ，

1218
01:13:30,560 --> 01:13:33,560
产生它们，然后把它们传递下去，

1219
01:13:33,560 --> 01:13:35,960
然后产生一些记录，

1220
01:13:35,960 --> 01:13:37,820
再一次，它不停继续，

1221
01:13:38,270 --> 01:13:40,670
所以所有这些，

1222
01:13:40,670 --> 01:13:45,380
糟糕，所有这些转换都是流水线的，

1223
01:13:48,200 --> 01:13:50,030
所以它们几乎同时运行，

1224
01:13:50,030 --> 01:13:51,920
它们不是真正同时运行，

1225
01:13:51,920 --> 01:13:53,240
它们是以流水线方式运行的。

1226
01:13:54,440 --> 01:13:58,220
哦，我刚说了这是批次的事情，他们谈论。

1227
01:13:58,250 --> 01:14:01,130
是的，所以事情过去，分批进行，

1228
01:14:01,130 --> 01:14:04,280
管道的每个阶段都是批处理的。

1229
01:14:05,500 --> 01:14:07,450
好的，好的，说得很清楚，

1230
01:14:07,450 --> 01:14:08,500
是的，非常感谢，

1231
01:14:08,500 --> 01:14:11,320
这是一节有趣的课程，谢谢。

1232
01:14:11,350 --> 01:14:13,940
好的，不客气，很高兴你喜欢，

1233
01:14:14,650 --> 01:14:15,460
这是一个很酷的系统。

1234
01:14:23,780 --> 01:14:25,430
抱歉，抱歉，你现在能听到我说话吗？

1235
01:14:25,670 --> 01:14:30,710
是的，我疑惑你在。

1236
01:14:30,890 --> 01:14:32,540
没问题，我很抱歉，

1237
01:14:32,540 --> 01:14:34,070
抱歉，我在听，

1238
01:14:34,070 --> 01:14:37,940
我意识我们会很晚，

1239
01:14:37,940 --> 01:14:39,740
我会试着让这个问题变得非常简短，

1240
01:14:39,830 --> 01:14:42,290
我以前也用过 Spark 。

1241
01:14:43,310 --> 01:14:46,580
谢谢，非常感谢。

1242
01:14:47,360 --> 01:14:50,930
所以，是的，我真的很感谢这节课，

1243
01:14:50,930 --> 01:14:54,080
Spark 是我在未来的工作中会用到的东西，

1244
01:14:54,080 --> 01:14:55,730
所以我很感谢你教我这个，

1245
01:14:55,790 --> 01:14:57,470
只有一个。

1246
01:14:57,470 --> 01:15:01,550
也许我不确定这是否对你编写 Spark 程序有帮助。

1247
01:15:01,700 --> 01:15:06,830
不，我是说我当实习生的时候，不知道我在做什么，

1248
01:15:06,830 --> 01:15:10,670
但这给了我更多的背景信息。

1249
01:15:12,100 --> 01:15:15,550
所以我想我要问的 Spark 程序的问题是，

1250
01:15:15,550 --> 01:15:19,390
我对 Spark 作业的理解方式，

1251
01:15:19,420 --> 01:15:27,160
Spark 如何构造所有任务的有向无环图。

1252
01:15:27,760 --> 01:15:31,810
是的，这就是你所说的宽分区和窄分区。

1253
01:15:31,810 --> 01:15:35,800
我想它们被称为依赖，而不是分区。

1254
01:15:35,800 --> 01:15:41,190
哦，是的，好的，好的，好的，抱歉，

1255
01:15:41,190 --> 01:15:44,460
有了 RDD ，我想，

1256
01:15:45,010 --> 01:15:47,650
好的，这是不同的术语，

1257
01:15:48,660 --> 01:15:53,580
依赖是所有任务的有向无环图中的这些任务，

1258
01:15:53,580 --> 01:15:54,840
但是 RDD ，

1259
01:15:55,400 --> 01:16:00,650
比如，这个图中的每个任务通过 RDD 表示。

1260
01:16:01,370 --> 01:16:02,570
让我回去，

1261
01:16:02,990 --> 01:16:04,520
也许这些图片是对的。

1262
01:16:04,550 --> 01:16:07,820
哦，我很感谢你留在这里，

1263
01:16:07,820 --> 01:16:13,160
如果你一定要去，请告诉我。

1264
01:16:13,370 --> 01:16:14,600
不，不，没关系，我有更多的时间。

1265
01:16:14,750 --> 01:16:18,620
所以，好的，这是一个 RDD ，

1266
01:16:19,010 --> 01:16:21,350
让我画另一种颜色，

1267
01:16:21,350 --> 01:16:22,730
这样我们可以[]，

1268
01:16:22,910 --> 01:16:27,390
这是一个 RDD ， RDD 有一堆分区，

1269
01:16:28,420 --> 01:16:30,220
这是另一个 RDD 。

1270
01:16:33,230 --> 01:16:34,430
好的，是的。

1271
01:16:34,820 --> 01:16:37,820
这些箭头是，

1272
01:16:37,820 --> 01:16:39,860
这里是一样的故事，

1273
01:16:39,950 --> 01:16:42,170
让我完成这张图，

1274
01:16:42,170 --> 01:16:44,360
在这一边，有更多的分区，

1275
01:16:45,050 --> 01:16:51,230
这是 RDD ， RDD ， RDD ，

1276
01:16:51,230 --> 01:16:54,080
这些转换是在 RDD 之间的，

1277
01:16:54,860 --> 01:16:56,060
所以这些箭头，

1278
01:16:56,880 --> 01:16:58,950
让我选另一种颜色，

1279
01:16:58,980 --> 01:17:02,370
这些箭头是转换。

1280
01:17:04,010 --> 01:17:04,850
明白了，

1281
01:17:04,850 --> 01:17:09,980
这是 Spark 作业有向无环图的一部分，

1282
01:17:10,070 --> 01:17:13,730
每一个转换都会导致创建另一个 RDD ，

1283
01:17:14,090 --> 01:17:16,160
理解了，理解了。

1284
01:17:16,220 --> 01:17:17,540
好的，唯一的问题是，

1285
01:17:17,540 --> 01:17:21,520
有些箭头是宽的，有些是窄的，

1286
01:17:22,040 --> 01:17:24,950
从图中，你不能区分，

1287
01:17:25,370 --> 01:17:28,760
哪些是窄的或哪些是，

1288
01:17:28,760 --> 01:17:33,530
哪些变换是窄变换或宽变换。

1289
01:17:33,740 --> 01:17:37,970
你说的图是 Spark 程序展示给你的吗？

1290
01:17:38,520 --> 01:17:40,500
是的，这个谱系图，你不能。

1291
01:17:40,500 --> 01:17:41,910
明白了，好的，好的。

1292
01:17:42,150 --> 01:17:42,900
是的，这里，

1293
01:17:42,900 --> 01:17:46,860
所以看一下这张谱系图，

1294
01:17:46,860 --> 01:17:49,530
比如这个转换，那个转换，那个转换，

1295
01:17:49,530 --> 01:17:51,090
所有转换都是窄的，

1296
01:17:51,090 --> 01:17:52,230
因为这是单个箭头，

1297
01:17:52,440 --> 01:17:53,790
但这不是真的，

1298
01:17:53,790 --> 01:17:56,640
比如，最后一个必须是宽的，

1299
01:17:58,450 --> 01:18:00,040
因为它将从所有收集信息。

1300
01:18:00,040 --> 01:18:00,490
明白了。

1301
01:18:03,110 --> 01:18:05,720
好的，然后我想，

1302
01:18:05,720 --> 01:18:11,030
比如，你有没有关于资源的建议，

1303
01:18:11,030 --> 01:18:14,450
可以向我展示 Spark 如何解决，

1304
01:18:14,450 --> 01:18:19,220
如何构建有向无环图来完成所有这些任务。

1305
01:18:19,220 --> 01:18:23,960
是的，看看调度程序，仅此而已。

1306
01:18:23,960 --> 01:18:26,930
是的，我在论文上看到了，

1307
01:18:26,930 --> 01:18:30,950
我在尽我所能理解这篇论文，

1308
01:18:30,950 --> 01:18:33,290
但这很难，但是。

1309
01:18:33,680 --> 01:18:34,880
它总是很难读懂，

1310
01:18:35,180 --> 01:18:40,610
所以，我想我会先回到论文，[]论文，

1311
01:18:40,610 --> 01:18:42,410
我肯定有一个调度器。

1312
01:18:43,440 --> 01:18:44,220
明白了，

1313
01:18:44,280 --> 01:18:46,050
哦，好的，这将向我展示

1314
01:18:46,050 --> 01:18:48,240
Spark 是如何制作这个图的。

