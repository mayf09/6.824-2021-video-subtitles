1
00:00:00,060 --> 00:00:00,600
又起作用了。

2
00:00:00,810 --> 00:00:03,570
好的，今天的计划是关于 GFS ，

3
00:00:03,600 --> 00:00:05,880
我会分多个步骤来做。

4
00:00:06,330 --> 00:00:09,840
首先，我会从总体上谈一下存储，

5
00:00:09,840 --> 00:00:13,260
为什么它如此重要，

6
00:00:13,680 --> 00:00:15,540
以及为什么我们花很多时间

7
00:00:15,540 --> 00:00:17,130
在这堂课上讨论它。

8
00:00:17,930 --> 00:00:22,070
然后我将讨论一下，

9
00:00:22,640 --> 00:00:25,280
从 GFS 的角度，以及它的主要设计，

10
00:00:25,460 --> 00:00:27,560
我们重点关注一致性，

11
00:00:27,560 --> 00:00:30,530
它是这堂课的主要主题，

12
00:00:31,100 --> 00:00:32,750
作为一致性的一部分，

13
00:00:32,750 --> 00:00:34,730
我们很可能这样，

14
00:00:35,390 --> 00:00:37,040
希望还有时间进入分组会议室，

15
00:00:37,040 --> 00:00:41,290
讨论一下，分组会议关于课程，

16
00:00:41,290 --> 00:00:43,240
或者课程贴出的问题，

17
00:00:43,240 --> 00:00:49,060
我们将继续讨论一致性的问题。

18
00:00:50,920 --> 00:00:52,510
好的，所以，

19
00:00:53,100 --> 00:00:55,590
让我来总体上地讨论一下存储系统，

20
00:00:56,220 --> 00:01:01,530
以及为什么它们在 6.824 中占据重要地位，

21
00:01:02,280 --> 00:01:03,990
主要原因是，

22
00:01:04,020 --> 00:01:06,870
它是一个神奇的构建组件，

23
00:01:07,510 --> 00:01:11,800
用于容错系统。

24
00:01:13,840 --> 00:01:15,490
所以基本的想法是，

25
00:01:15,490 --> 00:01:21,610
如果你能建立一个持久的存储系统，

26
00:01:21,730 --> 00:01:24,730
然后你可以构建你的应用程序，

27
00:01:24,940 --> 00:01:28,720
应用程序无状态的，

28
00:01:31,680 --> 00:01:35,520
然后存储保存所有的持久状态。

29
00:01:39,660 --> 00:01:42,540
这极大地简化了应用程序的设计，

30
00:01:43,270 --> 00:01:48,490
因为应用程序没有任何持久的存储空间，

31
00:01:48,490 --> 00:01:50,140
它必须保持自己，

32
00:01:50,140 --> 00:01:52,720
事实上，这些都在存储系统，

33
00:01:53,020 --> 00:01:56,500
所以，你可以非常快速地启动新的应用程序，

34
00:01:56,500 --> 00:01:58,030
它崩溃并不重要，

35
00:01:58,030 --> 00:02:00,760
因为它只有软状态，没有任何硬状态，

36
00:02:00,970 --> 00:02:02,050
然后再重新启动，

37
00:02:02,050 --> 00:02:02,980
当你重新启动时，

38
00:02:02,980 --> 00:02:05,470
你就从分布式存储系统进入状态。

39
00:02:06,340 --> 00:02:09,070
你可以在任何网站上看到这个，

40
00:02:09,070 --> 00:02:10,570
基本上就是这样构建的，

41
00:02:10,720 --> 00:02:14,440
有一个存储后端，用来保持状态，

42
00:02:14,440 --> 00:02:16,480
然后是应用程序，

43
00:02:16,870 --> 00:02:20,380
参与应用程序计算的中间层，

44
00:02:20,380 --> 00:02:22,780
或者运行 Javascript Go 的程序，

45
00:02:22,960 --> 00:02:25,330
它的前端在，

46
00:02:25,330 --> 00:02:27,760
在互联网上的客户端。

47
00:02:28,280 --> 00:02:32,810
所以，存储像一个神奇的构建组件,

48
00:02:32,810 --> 00:02:33,920
我想这是一个原因，

49
00:02:33,920 --> 00:02:37,040
为什么我们会在这节课上反复看到这个。

50
00:02:37,700 --> 00:02:40,490
这意味着存储系统本身，

51
00:02:40,490 --> 00:02:42,170
当然必须具有高度的容错性，

52
00:02:42,380 --> 00:02:44,660
这是一件非常棘手的事情，

53
00:02:44,660 --> 00:02:48,290
这就是另一个方面，

54
00:02:48,290 --> 00:02:49,130
另一方面，

55
00:02:49,220 --> 00:02:50,960
它使应用程序的生命周期变得简单，

56
00:02:50,960 --> 00:02:54,860
但是设计容错存储系统并不容易。

57
00:02:55,710 --> 00:02:56,850
那么为什么这么难，

58
00:03:00,480 --> 00:03:05,100
可以归结为一个原因，

59
00:03:05,100 --> 00:03:07,200
驱动这些设计，

60
00:03:07,200 --> 00:03:09,330
我们通常希望获得高性能，

61
00:03:09,990 --> 00:03:12,330
当你考虑今天的存储系统，

62
00:03:12,450 --> 00:03:14,670
GFS 的主要目标是，

63
00:03:14,670 --> 00:03:17,160
支持 mapreduce 类型的应用程序，

64
00:03:17,160 --> 00:03:20,190
所以，它需要高性能。

65
00:03:20,580 --> 00:03:21,960
好的，那是什么意思，

66
00:03:21,990 --> 00:03:28,890
这意味着你必须跨服务器对数据分片，

67
00:03:30,660 --> 00:03:32,790
所以你不能使用一台服务器，

68
00:03:32,790 --> 00:03:33,840
你必须使用多台服务器，

69
00:03:34,260 --> 00:03:37,020
你想要从磁盘中读取的原因，

70
00:03:37,020 --> 00:03:40,290
通常特定的机器具有有限的吞吐量，

71
00:03:40,470 --> 00:03:41,520
如果你想读取更多，

72
00:03:41,520 --> 00:03:43,770
超过一个磁盘的容量，

73
00:03:43,770 --> 00:03:44,880
你必须使用多个磁盘，

74
00:03:44,880 --> 00:03:46,470
你必须使用多个网卡，

75
00:03:46,470 --> 00:03:50,580
你可以立即进入这种大规模系统，

76
00:03:50,580 --> 00:03:53,130
在 GFS 中，有数千台机器。

77
00:03:54,560 --> 00:03:55,850
但是如果你有多台服务器，

78
00:03:58,070 --> 00:03:59,060
有些会失败，

79
00:04:00,790 --> 00:04:01,930
你会遭遇失败，

80
00:04:02,500 --> 00:04:03,340
或者你可能，

81
00:04:03,340 --> 00:04:06,160
你会看到更多专有的不断的故障，

82
00:04:08,710 --> 00:04:13,060
假设电脑崩溃，一年一次，

83
00:04:13,180 --> 00:04:17,050
现在假设你有数千台机器，

84
00:04:17,050 --> 00:04:18,940
就像在 GFS 的论文中，

85
00:04:18,970 --> 00:04:20,440
比上千台机器更多，

86
00:04:20,440 --> 00:04:21,910
最少一千台机器，

87
00:04:22,320 --> 00:04:25,050
粗略地说，每天会看到多少次失败。

88
00:04:29,210 --> 00:04:30,440
大概 3 次。

89
00:04:30,680 --> 00:04:31,850
是的，大约 3 次，

90
00:04:31,850 --> 00:04:35,240
这意味着计算机的失败，

91
00:04:35,540 --> 00:04:37,820
像我在课程开头的笔记本电脑，

92
00:04:37,970 --> 00:04:41,120
是一个常见的场景，

93
00:04:41,240 --> 00:04:42,860
如果你上升到

94
00:04:42,860 --> 00:04:46,280
超过一千台，一万台机器，十万台机器，十万台机器，

95
00:04:46,460 --> 00:04:48,950
你使用这种数量的计算机运行应用程序，

96
00:04:49,130 --> 00:04:50,120
你会遇到失败，

97
00:04:50,120 --> 00:04:53,450
这意味着你需要一个容错的设计。

98
00:05:01,260 --> 00:05:03,210
为了获得容错能力，

99
00:05:03,210 --> 00:05:04,260
至少在这种情况下，

100
00:05:04,260 --> 00:05:06,480
存储系统采用的传统方法，

101
00:05:06,480 --> 00:05:07,710
我们将使用复制，

102
00:05:09,780 --> 00:05:11,790
复制数据到多个磁盘上，

103
00:05:12,060 --> 00:05:13,350
这样，当这个失败时，

104
00:05:13,350 --> 00:05:15,930
希望另一个磁盘有数据。

105
00:05:17,770 --> 00:05:20,020
但是如果你使用复制，

106
00:05:20,290 --> 00:05:22,510
数据位于多个位置，

107
00:05:23,060 --> 00:05:26,720
就会遇到数据不同步的挑战，

108
00:05:26,960 --> 00:05:30,770
你会陷入可能的不一致。

109
00:05:40,020 --> 00:05:42,390
为了避免这些不一致，

110
00:05:42,540 --> 00:05:44,940
如果你想要强一致性，

111
00:05:44,940 --> 00:05:47,790
你的复制系统的行为就像

112
00:05:47,790 --> 00:05:50,580
就像未复制系统的行为。

113
00:05:51,180 --> 00:05:55,290
然后，你将需要一些持久性协议，

114
00:05:57,600 --> 00:06:00,060
这可能需要发送一些消息，

115
00:06:00,060 --> 00:06:02,280
而且可能会降低性能，

116
00:06:05,870 --> 00:06:09,230
也许消息本身并不会带来很大的性能开销，

117
00:06:09,230 --> 00:06:10,730
但是我们会看到的[]知识，

118
00:06:10,910 --> 00:06:14,150
你可能必须读取或写入持久存储，

119
00:06:14,150 --> 00:06:15,320
作为协议的一部分，

120
00:06:15,650 --> 00:06:17,240
而且读取或写入存储

121
00:06:17,240 --> 00:06:19,220
往往是相当昂贵的。

122
00:06:19,740 --> 00:06:21,450
所以我们在这里看到了这个难题，

123
00:06:21,450 --> 00:06:23,340
我们想要高性能，

124
00:06:23,640 --> 00:06:24,960
我们想要容错，

125
00:06:24,960 --> 00:06:26,280
因为我们有很多服务器，

126
00:06:26,610 --> 00:06:29,130
我们希望在多台服务器上实现高性能，

127
00:06:29,130 --> 00:06:30,900
许多服务器意味着容错，

128
00:06:31,020 --> 00:06:34,920
这意味着应用程序不一致的情况，

129
00:06:34,950 --> 00:06:37,320
因为我们在多个地方都有数据，

130
00:06:37,320 --> 00:06:38,490
为了修复不一致，

131
00:06:38,490 --> 00:06:41,370
我们需要一个协议，可能会降低性能。

132
00:06:41,700 --> 00:06:44,130
所以，这是基本挑战，

133
00:06:44,130 --> 00:06:46,440
在设计这些分布式存储系统时，

134
00:06:46,440 --> 00:06:51,090
用户在一致性和性能之间苦苦挣扎，

135
00:06:51,150 --> 00:06:53,520
我们将在整个学期中看到这一点。

136
00:06:55,840 --> 00:06:58,090
所以，让我来讨论一下一致性，

137
00:07:02,400 --> 00:07:03,630
从很高的层面,

138
00:07:03,780 --> 00:07:06,570
我向你保证在这学期剩下的时间里，

139
00:07:06,570 --> 00:07:09,240
我们将会有更多的详细介绍。

140
00:07:09,750 --> 00:07:12,690
首先，让我们讨论一下理想的一致性，

141
00:07:13,260 --> 00:07:16,440
理想的一致性最简单的思考方式是，

142
00:07:16,440 --> 00:07:19,530
机器的行为就像一个单一系统一样，

143
00:07:28,770 --> 00:07:30,540
这也是我们想要的行为，

144
00:07:30,570 --> 00:07:34,410
有两件事产生想要的行为，

145
00:07:34,410 --> 00:07:40,890
或两种危险使得这种设计行为很难实现，

146
00:07:41,610 --> 00:07:44,580
或者至少需要一些思考，

147
00:07:44,910 --> 00:07:47,550
第一个是并发性，第二个是失败。

148
00:07:48,350 --> 00:07:50,450
让我从消费者并发性开始，

149
00:07:50,450 --> 00:07:55,280
因为即使你有一台具有多个客户端的计算机，

150
00:07:55,280 --> 00:07:57,200
你在一台计算机中的并发性，

151
00:07:57,320 --> 00:07:59,090
你也必须考虑一致性，

152
00:07:59,390 --> 00:08:01,310
这个原因是很明显的。

153
00:08:01,310 --> 00:08:04,520
假设我们有一台机器，一个磁盘，

154
00:08:04,790 --> 00:08:08,090
有两个请求来自不同的客户端，

155
00:08:08,490 --> 00:08:10,140
如果机器是多处理器机器，

156
00:08:10,140 --> 00:08:13,680
它们可能会在内部并行运行这些请求。

157
00:08:14,240 --> 00:08:17,120
所以，让我们稍微想一想，

158
00:08:17,120 --> 00:08:17,840
这是什么意思，

159
00:08:17,840 --> 00:08:21,200
所以，假设我们有客户端 1 ，

160
00:08:21,620 --> 00:08:27,380
它对键 x 写入 1 ，

161
00:08:28,190 --> 00:08:29,270
与此同时，

162
00:08:29,270 --> 00:08:32,570
也有一个请求对 x 写入，

163
00:08:32,570 --> 00:08:35,320
但写入的值是 2 。

164
00:08:35,320 --> 00:08:39,280
现在，如果你想具体说明或展示一致性是什么，

165
00:08:39,280 --> 00:08:42,070
我们需要一些规则，比如会发生什么，

166
00:08:42,460 --> 00:08:45,130
在这个规则中，通常从读者的角度表述，

167
00:08:45,160 --> 00:08:47,080
假设有另一个读取者进来，

168
00:08:47,980 --> 00:08:51,580
来自另一个客户端的另一个请求，并读取 x ，

169
00:08:53,460 --> 00:08:54,000
问题是，

170
00:08:54,000 --> 00:08:57,840
读者或客户端观察到的值是什么。

171
00:08:58,460 --> 00:09:00,830
看起来更复杂或更有趣，

172
00:09:00,830 --> 00:09:02,300
假设我们有四个客户端，

173
00:09:02,300 --> 00:09:05,600
我们将更清楚地提出一致性定义这一问题，

174
00:09:05,840 --> 00:09:07,520
它也读取 x ，

175
00:09:07,580 --> 00:09:11,090
在客户端 3 读到了 x 之后。

176
00:09:12,580 --> 00:09:13,870
所以现在我们有了一些状态，

177
00:09:13,870 --> 00:09:15,220
什么是期望的结果，

178
00:09:15,220 --> 00:09:16,390
什么是不正确的结果，

179
00:09:16,390 --> 00:09:19,030
这就是一致性的真正定义。

180
00:09:19,670 --> 00:09:23,030
那么，让我们来看第一种情况 C3 ，

181
00:09:23,030 --> 00:09:28,070
什么是一个合理的结果，

182
00:09:28,280 --> 00:09:31,010
对于 C3 的读取来说，什么是合理的结果，

183
00:09:31,580 --> 00:09:32,390
什么值，

184
00:09:33,660 --> 00:09:35,220
什么值会让你开心，

185
00:09:35,220 --> 00:09:37,020
或者让应用程序程序员开心。

186
00:09:38,850 --> 00:09:39,420
2.

187
00:09:39,960 --> 00:09:41,340
2 很合理吗？

188
00:09:42,100 --> 00:09:44,080
还有其他合理的值吗？

189
00:09:44,820 --> 00:09:45,390
1.

190
00:09:45,720 --> 00:09:46,980
是的， 1 是合理的，

191
00:09:47,280 --> 00:09:49,170
因为操作是同时进行的，

192
00:09:49,170 --> 00:09:50,970
所以也许我们不知道哪一个，

193
00:09:50,970 --> 00:09:53,640
我们并不想限制它们的具体顺序，

194
00:09:53,670 --> 00:09:55,230
所以我们说随便哪一个都可以，

195
00:09:55,740 --> 00:09:56,400
因为是并行运行的。

196
00:09:57,350 --> 00:09:59,450
有哪些值观是我们不想看到的，

197
00:10:00,660 --> 00:10:01,770
对于 C3 读取。

198
00:10:02,410 --> 00:10:03,100
7.

199
00:10:03,370 --> 00:10:04,960
是的， 7 ，任何其他的值，

200
00:10:04,990 --> 00:10:06,310
因为没人写过这些，

201
00:10:06,370 --> 00:10:07,450
所以这是不受欢迎的。

202
00:10:08,210 --> 00:10:10,460
好的，所以我们一致认为，

203
00:10:10,460 --> 00:10:13,580
c3 的合理结果可能是 1 或 2 。

204
00:10:14,240 --> 00:10:15,440
好的，那么 C4 呢？

205
00:10:17,520 --> 00:10:18,900
与 C3 相同。

206
00:10:19,580 --> 00:10:21,260
是吗，一样的吗？

207
00:10:23,270 --> 00:10:25,070
所以，假设 C3 返回 1 ，

208
00:10:25,620 --> 00:10:27,330
我们期望 C4 返回什么？

209
00:10:28,490 --> 00:10:29,960
C3看到的值。

210
00:10:30,230 --> 00:10:32,990
是的，因为它是在 C3 之后运行的，

211
00:10:32,990 --> 00:10:36,640
如果返回 1 ，我们希望这里是 1 ，

212
00:10:37,640 --> 00:10:39,980
如果返回 2 ，我们希望这里也是 2 。

213
00:10:41,800 --> 00:10:42,580
这能理解吗？

214
00:10:45,320 --> 00:10:49,700
好的，所以，这是一个很简短的介绍，

215
00:10:49,700 --> 00:10:52,730
说明我们如何定义一致性，

216
00:10:52,730 --> 00:10:55,010
通常我们使用 traces ，

217
00:10:55,010 --> 00:10:58,100
我们讨论特定[traces]的正确性，

218
00:10:58,100 --> 00:10:59,210
我们将看到更多这样的情况。

219
00:10:59,940 --> 00:11:03,900
当然，服务器可以强制这种并发性，

220
00:11:03,900 --> 00:11:05,070
例如使用锁，

221
00:11:05,070 --> 00:11:06,150
如果你已经这样做了，

222
00:11:06,300 --> 00:11:07,620
如果你做了 mapreduce ，

223
00:11:07,620 --> 00:11:09,930
任何你写的并发 Go 程序，

224
00:11:10,170 --> 00:11:14,670
那是强制一致性的标准技术，

225
00:11:14,730 --> 00:11:17,910
在并发存在的情况下使用锁。

226
00:11:20,720 --> 00:11:22,460
在分布式系统中，

227
00:11:22,460 --> 00:11:25,790
理想的一致性有两种风险，

228
00:11:25,790 --> 00:11:28,040
第二种风险是故障，

229
00:11:28,040 --> 00:11:29,510
所以一般是复制，

230
00:11:29,540 --> 00:11:31,490
如果我们有两台服务器，

231
00:11:31,790 --> 00:11:35,000
所以这是 S1 ，这是 S2 ，

232
00:11:36,440 --> 00:11:38,510
两个都有磁盘，

233
00:11:40,400 --> 00:11:44,360
我们有和之前一样的客户端， C1 和 C2 ，

234
00:11:44,360 --> 00:11:46,520
它们向 x 写入，

235
00:11:47,380 --> 00:11:52,810
只是为了说明什么样的复杂性，

236
00:11:52,810 --> 00:11:56,410
说明我们必须做些什么，

237
00:11:56,410 --> 00:12:01,240
让我们从最笨的复制方案开始。

238
00:12:01,240 --> 00:12:03,220
一个非常糟糕的复制方案，

239
00:12:11,240 --> 00:12:13,340
所以这个特别糟糕的复制方案，

240
00:12:13,340 --> 00:12:14,120
我们要做的是，

241
00:12:14,120 --> 00:12:16,040
比如，我们将允许客户端，

242
00:12:16,220 --> 00:12:18,740
当客户端想要更新或写入时，

243
00:12:19,040 --> 00:12:21,050
我们要告诉它，

244
00:12:21,050 --> 00:12:23,210
我们跟据的协议是，

245
00:12:23,210 --> 00:12:25,100
将客户端写入到两台服务器，

246
00:12:25,250 --> 00:12:26,420
无论什么，

247
00:12:26,450 --> 00:12:28,880
不用协调，只需写入到两者。

248
00:12:29,900 --> 00:12:33,320
我们有客户端 1 ，客户端 2 在运行，

249
00:12:33,560 --> 00:12:37,220
然后，客户端 2 可能会做同样的事情，

250
00:12:39,520 --> 00:12:43,900
然后，我们会问自己同样的问题，

251
00:12:43,900 --> 00:12:48,580
C3 实际读到的是什么，

252
00:12:48,730 --> 00:12:50,110
让我们假设读取，

253
00:12:50,110 --> 00:12:52,090
无论使用哪种方式，

254
00:12:52,970 --> 00:12:54,800
我们会从任何复制中读取，

255
00:12:54,800 --> 00:12:57,170
像我说的，这是一个非常糟糕的复制方案，

256
00:12:57,170 --> 00:12:58,670
没有任何限制。

257
00:13:00,080 --> 00:13:01,610
那么，可能的结果是什么？

258
00:13:02,650 --> 00:13:06,190
这个写入 1 ，这个写入 2 ，

259
00:13:06,670 --> 00:13:08,530
我们是 C3 ，

260
00:13:10,080 --> 00:13:11,820
C3 的可能结果是什么？

261
00:13:15,130 --> 00:13:16,300
还是 1 和 2 。

262
00:13:16,540 --> 00:13:18,880
是的， 1 和 2 ，这真的很糟糕。

263
00:13:19,910 --> 00:13:20,870
C4 怎么样，

264
00:13:22,500 --> 00:13:25,260
我们读取 x ，在 C3 读取 x 之后，

265
00:13:25,260 --> 00:13:28,200
像在上一个白板上一样。

266
00:13:28,610 --> 00:13:29,810
也是 1 和 2 。

267
00:13:30,630 --> 00:13:32,490
是的，也是 1 和 2 ，

268
00:13:33,030 --> 00:13:39,740
如果 C3 读取 1 ，但 C4 可能返回什么？

269
00:13:41,130 --> 00:13:42,030
1 或 2 。

270
00:13:42,150 --> 00:13:44,490
1 或 2 ，这是我们想要的吗？

271
00:13:45,750 --> 00:13:46,230
不是。

272
00:13:46,770 --> 00:13:47,970
不，我是说，

273
00:13:47,970 --> 00:13:50,010
对于应用程序编写者来说，

274
00:13:50,010 --> 00:13:51,270
很难读取这个，

275
00:13:53,260 --> 00:13:55,570
特别是 C3 和 C4 是一回事，

276
00:13:55,570 --> 00:13:58,090
你首先读取 1 ，没有任何修改，

277
00:13:58,090 --> 00:13:59,770
然后下一秒返回另一个值，

278
00:13:59,770 --> 00:14:00,610
这怎么可能，

279
00:14:01,170 --> 00:14:03,510
这使得程序员很难编写程序。

280
00:14:04,500 --> 00:14:06,660
所以原因当然是，

281
00:14:06,660 --> 00:14:08,760
这里显示的不一致性，

282
00:14:08,880 --> 00:14:10,800
因为我们没有协议，

283
00:14:11,100 --> 00:14:14,490
来协调客户端，读取者和写入者，

284
00:14:14,520 --> 00:14:16,470
所以我们需要某种形式的分布式系统，

285
00:14:16,470 --> 00:14:18,960
我们需要某种形式的协议来解决这些问题，

286
00:14:18,960 --> 00:14:21,300
并获得，

287
00:14:21,300 --> 00:14:23,370
确保我们获得所需的一致性。

288
00:14:24,840 --> 00:14:26,640
所以我们可以在这学期剩下的时间里看到，

289
00:14:26,640 --> 00:14:28,230
很多可能的协议，

290
00:14:28,230 --> 00:14:31,140
它们在容错和一致性方面有不同的权衡。

291
00:14:32,340 --> 00:14:32,970
好的?

292
00:14:33,960 --> 00:14:38,250
你应该有这样的想法，

293
00:14:38,550 --> 00:14:43,230
我们要用很多不同的案例研究，

294
00:14:43,380 --> 00:14:47,400
今天的案例研究是 GFS 。

295
00:14:54,970 --> 00:14:56,590
这是一个有趣的案例研究，

296
00:14:56,620 --> 00:14:59,050
为什么我们布置它，

297
00:14:59,050 --> 00:15:00,850
其中一个原因是有趣的案例研究，

298
00:15:00,850 --> 00:15:04,000
因为它提出了所有这些核心问题。

299
00:15:04,060 --> 00:15:07,720
GFS 设计旨在获得高性能，

300
00:15:10,240 --> 00:15:19,280
这意味着它使用了复制和容错，

301
00:15:21,730 --> 00:15:25,510
而且它很难保持一致性，

302
00:15:25,540 --> 00:15:27,250
所以这就是一些主题，

303
00:15:27,250 --> 00:15:29,830
我们将在整个学期中持续看到它，

304
00:15:29,830 --> 00:15:31,600
都会出现在这篇论文中。

305
00:15:32,960 --> 00:15:36,110
为什么是有趣的案例研究的另一个原因，

306
00:15:36,110 --> 00:15:37,010
因为它是一个成功的系统，

307
00:15:41,030 --> 00:15:44,450
Google 确实使用了 GFS ，

308
00:15:44,450 --> 00:15:46,850
现在，据我所知，

309
00:15:46,850 --> 00:15:49,310
有一个后继文件系统，名为 Colossus ，

310
00:15:49,310 --> 00:15:51,560
但它的灵感来自于 GFS ，

311
00:15:51,980 --> 00:15:57,620
还有其他类型的基于集群的文件系统，

312
00:15:57,620 --> 00:16:00,680
比如 mapreduce 类型使用的 HDFS ，

313
00:16:00,740 --> 00:16:03,530
也是从 GFS 的设计获取的灵感。

314
00:16:04,620 --> 00:16:08,400
有一件事其实很有趣，

315
00:16:08,400 --> 00:16:10,440
在写这篇论文的时候，

316
00:16:10,530 --> 00:16:14,100
在差不多 2000 年的时候，

317
00:16:14,100 --> 00:16:17,160
分布式文件系统是容易理解的主题，

318
00:16:17,220 --> 00:16:18,630
人们知道容错，

319
00:16:18,630 --> 00:16:20,070
他们知道复制，

320
00:16:20,070 --> 00:16:21,900
人们知道一致性，

321
00:16:21,930 --> 00:16:24,660
所有这些事情都很容易理解。

322
00:16:25,210 --> 00:16:29,020
然而，没有人构建出系统，

323
00:16:29,020 --> 00:16:31,660
在上千台计算机的规模上，

324
00:16:31,810 --> 00:16:36,250
这肯定会带来一些挑战，

325
00:16:36,430 --> 00:16:38,560
以前的系统不能解决的，

326
00:16:38,680 --> 00:16:42,490
而且设计也不完全规范，

327
00:16:43,150 --> 00:16:45,700
所以，我们正在看的设计，

328
00:16:45,700 --> 00:16:47,980
不是某种标准的设计，

329
00:16:47,980 --> 00:16:50,020
你会在当时的学术论文中看到，

330
00:16:50,920 --> 00:16:53,290
有两个方面是非标准的，

331
00:16:53,620 --> 00:16:56,650
[]我们会把更多的时间花在上面。

332
00:16:56,740 --> 00:16:59,350
一个是这里只有一个 master ，

333
00:16:59,350 --> 00:17:02,190
master 不是复制的，

334
00:17:02,220 --> 00:17:04,230
只有一台机器负责

335
00:17:04,230 --> 00:17:08,830
系统中几乎所有的协调，

336
00:17:08,830 --> 00:17:10,750
所以这是不寻常的，

337
00:17:10,870 --> 00:17:14,800
为什么构建文件系统容错系统，

338
00:17:14,800 --> 00:17:16,180
却包含单点故障，

339
00:17:16,660 --> 00:17:20,230
而不是当时学术文献中的人正在做的事情，

340
00:17:21,070 --> 00:17:23,620
第二件事是，

341
00:17:23,620 --> 00:17:26,200
它有不一致，

342
00:17:26,230 --> 00:17:28,240
它可能有不一致之处，

343
00:17:33,180 --> 00:17:37,080
同样地，在那个时期的文献上，

344
00:17:37,080 --> 00:17:39,360
人们非常努力地构建

345
00:17:39,360 --> 00:17:42,270
具有强一致性的分布式系统，

346
00:17:42,420 --> 00:17:44,250
而且没有异常情况，

347
00:17:44,250 --> 00:17:45,810
我们在上一个白板上看到的那样。

348
00:17:47,120 --> 00:17:53,030
好的，就像你所熟知的许多核心技术一样，

349
00:17:53,150 --> 00:17:56,720
你把它们放在一起的的方式是完全不同的。

350
00:17:58,150 --> 00:17:59,440
因此，这让它变得有趣，

351
00:17:59,560 --> 00:18:04,330
特别是这个系统实际运行的规模是令人印象深刻的。

352
00:18:05,120 --> 00:18:06,860
即使在今天也很常见，

353
00:18:06,860 --> 00:18:08,090
这个问题，

354
00:18:08,270 --> 00:18:15,590
在容错，复制性能和一致性之间的斗争，

355
00:18:15,590 --> 00:18:17,330
是一个标准问题，

356
00:18:17,330 --> 00:18:19,880
几乎是任何分布式存储系统重复出现问题，

357
00:18:19,880 --> 00:18:21,050
今天的人们构建的。

358
00:18:22,660 --> 00:18:23,650
它随着时间的推移而改变，

359
00:18:23,680 --> 00:18:24,970
比如 S3 有一段时间，

360
00:18:24,970 --> 00:18:27,250
它们真的有强一致性，

361
00:18:27,250 --> 00:18:29,200
随后，它的一致性变得更强了。

362
00:18:30,990 --> 00:18:35,100
好的，因为论文驱动，

363
00:18:35,340 --> 00:18:39,570
设计是由性能驱动的，

364
00:18:39,600 --> 00:18:44,300
我想暂时回到 mapreduce 论文上，

365
00:18:44,330 --> 00:18:47,240
这是一张 mapreduce 的图，

366
00:18:47,570 --> 00:18:51,110
考虑 GFS 的一种方式是，

367
00:18:51,200 --> 00:18:55,550
它是 mapreduce 的文件系统，

368
00:19:00,530 --> 00:19:01,610
所以，我们的目标是，

369
00:19:01,610 --> 00:19:04,580
运行多个 mapreduce 作业并获得高性能。

370
00:19:05,250 --> 00:19:07,200
我们知道这是从，

371
00:19:07,200 --> 00:19:09,150
我们已经可以从 mapreduce 的论文中看出，

372
00:19:09,150 --> 00:19:13,350
GFS 在性能方面令人印象深刻。

373
00:19:13,680 --> 00:19:17,940
所以如果你看这张图的这一边，

374
00:19:17,940 --> 00:19:19,950
这是从 mapreduce 论文中拿出来的，

375
00:19:20,160 --> 00:19:23,880
这是一个 mapreduce 作业的正常执行，

376
00:19:24,120 --> 00:19:27,690
它有三个部分，

377
00:19:27,690 --> 00:19:29,100
一个是第一部分的输入，

378
00:19:29,100 --> 00:19:30,810
比如，读取输入文件，

379
00:19:30,810 --> 00:19:33,450
从文件系统到 map 的输入，

380
00:19:33,450 --> 00:19:35,280
他们没怎么说这件事，

381
00:19:35,280 --> 00:19:37,980
但这些都是从 GFS 读写的，

382
00:19:39,320 --> 00:19:41,300
这是我们关心的内部的 shuffle ，

383
00:19:41,300 --> 00:19:42,590
然后在最后，

384
00:19:42,620 --> 00:19:46,340
reduce 作业将结果写回 GFS 。

385
00:19:47,200 --> 00:19:51,670
所以，部分性能，

386
00:19:51,670 --> 00:19:53,860
mapreduce 任务决定于,

387
00:19:53,860 --> 00:19:55,270
从哪里读取，

388
00:19:55,360 --> 00:20:00,220
mapper 可以从 GFS 文件系统中读取数据，

389
00:20:00,250 --> 00:20:02,590
无论我们同时运行多少 mapper ，

390
00:20:02,590 --> 00:20:06,520
一些来自不同作业的 mapper 可能会读取相同的文件。

391
00:20:07,150 --> 00:20:08,710
所以我们来看一下输入，

392
00:20:08,740 --> 00:20:12,100
比如这里的最上面的图，

393
00:20:12,280 --> 00:20:16,120
以兆字节/秒为单位的显示输入，

394
00:20:16,420 --> 00:20:17,980
mapper 的读取，

395
00:20:17,980 --> 00:20:21,040
[为一项工作共同工作]，

396
00:20:21,040 --> 00:20:22,480
可以从文件系统中读取。

397
00:20:23,240 --> 00:20:23,870
正如你所看到的，

398
00:20:23,870 --> 00:20:28,700
它通过超过每秒 10000 兆字节。

399
00:20:30,800 --> 00:20:32,480
你要问的第一个问题是，

400
00:20:32,480 --> 00:20:34,190
当然是一个令人印象深刻的数字，

401
00:20:38,180 --> 00:20:39,740
我们对这个数字印象深刻，

402
00:20:39,740 --> 00:20:43,230
考虑给我一个磁盘，我也可以做。

403
00:20:50,500 --> 00:20:51,340
有人吗？

404
00:20:51,820 --> 00:20:54,790
我想是的，因为它很老了，也许是的。

405
00:20:56,000 --> 00:21:01,910
好的，固态硬盘，读写速率是多少？

406
00:21:08,220 --> 00:21:09,300
好吧，让我告诉你，

407
00:21:09,300 --> 00:21:15,560
在论文发表的当时，一个磁盘的吞吐量大概是

408
00:21:15,560 --> 00:21:17,540
30 兆字节每秒，

409
00:21:17,540 --> 00:21:19,250
有时在每秒几十兆字节，

410
00:21:20,810 --> 00:21:21,920
所以这里我们看到，

411
00:21:21,950 --> 00:21:26,980
超过 10000 兆字节每秒，

412
00:21:26,980 --> 00:21:28,480
这是一个令人印象深刻的数字。

413
00:21:29,540 --> 00:21:30,860
你必须做些工作，

414
00:21:30,860 --> 00:21:32,150
正如你所看到的，

415
00:21:32,150 --> 00:21:34,520
GFS 设计允许这种吞吐量。

416
00:21:36,260 --> 00:21:38,690
当然，这项技术表明 GFS ，

417
00:21:38,690 --> 00:21:40,520
当然，这项技术更快，

418
00:21:40,700 --> 00:21:43,040
这里真正的目标是什么，

419
00:21:43,040 --> 00:21:44,480
我们有一千台机器，

420
00:21:44,690 --> 00:21:46,100
也许每个机器都有一个磁盘，

421
00:21:46,100 --> 00:21:48,200
每一个都读取每秒 30 兆字节，

422
00:21:48,260 --> 00:21:51,170
这是 1000 乘以 30 兆字节每秒才能[摆脱]它。

423
00:21:51,800 --> 00:21:52,400
好的?

424
00:21:53,410 --> 00:21:57,460
所以这个设计的驱动是，

425
00:21:57,460 --> 00:22:02,080
允许 mapper 从文件系统并行读取，

426
00:22:02,080 --> 00:22:03,880
[联合]的文件系统。

427
00:22:04,910 --> 00:22:05,480
好的?

428
00:22:06,850 --> 00:22:08,860
关于这个，让我再说一点，

429
00:22:08,860 --> 00:22:12,250
GFS 的关键属性是什么，

430
00:22:12,610 --> 00:22:17,670
一个大的数据集，

431
00:22:17,670 --> 00:22:19,860
我的意思是，

432
00:22:23,900 --> 00:22:27,380
你应该考虑的数据集就像 mapreduce 数据集，

433
00:22:27,380 --> 00:22:32,240
你将爬取整个万维网，

434
00:22:32,270 --> 00:22:34,340
存储在这个分布式文件系统中。

435
00:22:35,460 --> 00:22:37,140
必须要快，

436
00:22:37,140 --> 00:22:38,250
我们谈到了，

437
00:22:38,790 --> 00:22:41,820
他们获得高性能的方法是进行自动分片，

438
00:22:43,730 --> 00:22:45,620
分片文件到多个磁盘，

439
00:22:45,830 --> 00:22:48,890
允许多个客户端从这些磁盘并行读取。

440
00:22:49,600 --> 00:22:50,080
好的？

441
00:22:51,710 --> 00:22:52,700
它是全局的，

442
00:22:55,610 --> 00:22:57,710
这意味着它是共享的，

443
00:22:57,710 --> 00:23:02,690
所以应用看到相同的文件系统，

444
00:23:06,190 --> 00:23:07,000
这很方便，

445
00:23:07,000 --> 00:23:09,940
例如，如果你有多个 mapreduce 作业，

446
00:23:09,940 --> 00:23:12,850
对同一组文件进行操作，

447
00:23:13,090 --> 00:23:16,000
首先，它们可以读取所有相同的文件集，

448
00:23:16,000 --> 00:23:17,410
然后它们可以制作新文件，

449
00:23:17,410 --> 00:23:19,780
另一个 mapreduce 再次使用这些文件，

450
00:23:19,810 --> 00:23:23,440
所以，在应用程序之间进行大量共享非常方便，

451
00:23:23,440 --> 00:23:24,520
所以拥有它是非常方便的。

452
00:23:26,000 --> 00:23:27,920
当然， GFS 必须具有容错能力，

453
00:23:33,710 --> 00:23:35,210
它们很可能会失败，

454
00:23:35,210 --> 00:23:37,040
我们想要自动的，

455
00:23:37,990 --> 00:23:40,000
尽可能自动容错，

456
00:23:40,000 --> 00:23:42,040
你会发现 GFS 并不是完全自动的，

457
00:23:42,040 --> 00:23:45,370
但在提高容错能力方面做得相当好。

458
00:23:48,160 --> 00:23:52,120
好的，到目前为止，关于这一部分，有什么问题吗，

459
00:23:52,540 --> 00:23:55,030
对这个主题的宽泛介绍，

460
00:23:55,030 --> 00:23:59,020
关于 GFS 的几个介绍。

461
00:24:04,330 --> 00:24:04,900
好的。

462
00:24:05,420 --> 00:24:06,650
然后让我们来讨论一下设计。

463
00:24:13,940 --> 00:24:16,790
这里的设计，

464
00:24:16,790 --> 00:24:20,990
是从论文中图一看到的，

465
00:24:21,320 --> 00:24:23,360
有几件事我想指出，

466
00:24:23,360 --> 00:24:25,010
更详细地讨论一些细节。

467
00:24:25,480 --> 00:24:27,280
所以，首先，我们有一个应用程序，

468
00:24:27,280 --> 00:24:30,220
然后这个应用程序可能是 mapreduce 作业，

469
00:24:30,610 --> 00:24:34,150
包含多个 reduce 任务，多个 map 任务，

470
00:24:34,450 --> 00:24:36,460
它们与 GFS 关联，

471
00:24:36,460 --> 00:24:39,940
它不是 Linux 文件系统，

472
00:24:39,970 --> 00:24:41,410
这不是（普通的）文件系统，

473
00:24:41,410 --> 00:24:45,550
你用来编辑文件或编译，

474
00:24:45,580 --> 00:24:47,410
它是一个专门用于，

475
00:24:47,410 --> 00:24:52,420
这些大型计算的文件系统。

476
00:24:53,800 --> 00:24:54,910
正如我之前所说，

477
00:24:54,910 --> 00:24:58,240
我们的真正目标是实现一个令人印象深刻的数字，

478
00:24:58,240 --> 00:25:01,870
比如我们想要单个磁盘的兆字节数乘以机器数量，

479
00:25:01,870 --> 00:25:04,180
单个应用程序应该能够利用这个。

480
00:25:04,840 --> 00:25:08,680
所以他们安排的方式是有一个 master ，

481
00:25:08,950 --> 00:25:12,010
它负责东西在哪里，

482
00:25:12,190 --> 00:25:15,190
客户端只是周期性地与 master 交互，

483
00:25:15,190 --> 00:25:18,670
为了获得信息，

484
00:25:18,670 --> 00:25:20,710
例如，它会打开文件，

485
00:25:20,770 --> 00:25:25,660
打开调用将导致向 master 发送一条消息，

486
00:25:25,660 --> 00:25:28,570
master 将回复，

487
00:25:28,570 --> 00:25:30,790
表示所有指定的文件名，

488
00:25:30,850 --> 00:25:34,330
你需要的块在这里，

489
00:25:34,640 --> 00:25:36,260
好的，这些是你需要的块，

490
00:25:36,530 --> 00:25:39,140
并且有一个块句柄标识符，

491
00:25:39,140 --> 00:25:41,540
对应那个文件包含的块，

492
00:25:41,690 --> 00:25:45,080
这是块数据的服务器，

493
00:25:45,110 --> 00:25:49,460
你可以得到块句柄以及很多块位置。

494
00:25:50,620 --> 00:25:53,410
一个文件可能包含，

495
00:25:53,410 --> 00:25:55,060
如果你考虑一个大文件，

496
00:25:55,750 --> 00:25:57,460
它由许多块组成，

497
00:25:59,350 --> 00:26:06,580
块 0 、块 1 、块 2 、块 3 等等，

498
00:26:06,580 --> 00:26:09,610
任何块都是很大的， 64 兆字节，

499
00:26:12,060 --> 00:26:15,930
应用程序想要第二个 64 兆字节，

500
00:26:15,930 --> 00:26:18,630
它告诉 GFS ，

501
00:26:18,630 --> 00:26:21,990
我想读取第二块，

502
00:26:22,320 --> 00:26:24,450
这个特定的文件，

503
00:26:24,450 --> 00:26:28,800
GFS 将使用块 1 的句柄进行应答，

504
00:26:28,860 --> 00:26:32,470
以及保存块 1 的服务器。

505
00:26:33,910 --> 00:26:39,130
多个应用程序可能会要求从同一文件中获取块，

506
00:26:39,250 --> 00:26:41,650
它们都会得到，

507
00:26:42,310 --> 00:26:43,960
一个应用程序可能正在读取块 0 ，

508
00:26:43,960 --> 00:26:46,120
另一应用程序可能读取块 2 ，

509
00:26:46,150 --> 00:26:48,880
它们将得到不同的列表，对应这些块。

510
00:26:50,460 --> 00:26:53,640
一旦 GFS 客户端知道了块位置，

511
00:26:53,670 --> 00:26:56,280
就会直接与块服务器交互，

512
00:26:57,670 --> 00:27:04,270
以网络的速度读取数据，

513
00:27:04,270 --> 00:27:08,440
可能每个磁盘都位于特定的区块服务器后面，

514
00:27:08,440 --> 00:27:09,700
直接连接到应用程序。

515
00:27:10,480 --> 00:27:13,030
这里你可以看到，我们获得了重大胜利，

516
00:27:13,030 --> 00:27:14,500
因为我们能够读取，

517
00:27:14,500 --> 00:27:15,550
对于多个，

518
00:27:15,550 --> 00:27:19,570
多个客户端可以同时从多个磁盘读取，

519
00:27:19,840 --> 00:27:22,330
我们将获得巨大的性能，

520
00:27:22,540 --> 00:27:25,420
比如，这是一个运行的 map 任务，

521
00:27:25,750 --> 00:27:27,400
这是另一个正在运行的 map 任务，

522
00:27:27,400 --> 00:27:28,570
也是作为客户端，

523
00:27:28,870 --> 00:27:31,720
它们会和一组服务器交互，

524
00:27:31,720 --> 00:27:34,900
有一个完整的所有数据集的块的集合，

525
00:27:35,020 --> 00:27:36,820
它们会并行读取，

526
00:27:36,820 --> 00:27:38,800
从所有不同的块服务器，

527
00:27:39,200 --> 00:27:43,190
这会给我们一个很高的吞吐量数字。

528
00:27:45,090 --> 00:27:45,900
这能理解吗，

529
00:27:45,900 --> 00:27:47,670
这是总体方案。

530
00:27:52,590 --> 00:27:53,820
为了解释完整，

531
00:27:53,820 --> 00:27:56,940
块服务器不是别的，

532
00:27:56,940 --> 00:28:01,020
只是有磁盘的 Linux 计算机，

533
00:28:01,230 --> 00:28:03,240
实际上，是 64 兆字节的块，

534
00:28:03,330 --> 00:28:06,660
每个都作为一个 Linux 文件存储在 Linux 文件系统中。

535
00:28:07,710 --> 00:28:08,280
好的?

536
00:28:12,080 --> 00:28:14,360
好的，我想把不同的部分放大，

537
00:28:14,420 --> 00:28:15,920
我先从 master 开始，

538
00:28:15,920 --> 00:28:20,360
因为 master 跟这里的控制中心有关，

539
00:28:20,570 --> 00:28:24,230
所以，讨论一下 master 维护的状态。

540
00:28:29,340 --> 00:28:32,100
好的，首先，

541
00:28:32,130 --> 00:28:42,310
它有从文件名到块句柄数组的映射，

542
00:28:49,040 --> 00:28:50,240
正如你在论文上看到的，

543
00:28:50,240 --> 00:28:50,840
其中一个目标，

544
00:28:50,840 --> 00:28:54,140
是维护所有这些内存，

545
00:28:54,140 --> 00:28:56,870
大多数信息直接在内存中，

546
00:28:57,140 --> 00:29:00,770
所以 master 可以非常快速地响应客户端，

547
00:29:00,770 --> 00:29:02,840
而这么做的原因是因为，

548
00:29:03,020 --> 00:29:05,510
现在只有一个 master ，很多客户端，

549
00:29:05,600 --> 00:29:08,510
你希望尽可能高效地执行每个客户端操作，

550
00:29:08,510 --> 00:29:12,050
这样就可以将 master 扩展到合理数量的客户端，

551
00:29:13,940 --> 00:29:15,380
然后，对于每个块句柄，

552
00:29:19,120 --> 00:29:21,280
master 包含一些额外的数字，

553
00:29:21,310 --> 00:29:23,590
它维护一个版本号，

554
00:29:28,640 --> 00:29:33,590
和一个块服务器列表，

555
00:29:34,970 --> 00:29:38,000
里面有块的复制。

556
00:29:39,820 --> 00:29:41,050
正如我们稍后会看到的，

557
00:29:41,050 --> 00:29:43,450
其中一个名字叫做，

558
00:29:43,450 --> 00:29:45,160
其中一台服务器是主服务器，

559
00:29:46,000 --> 00:29:47,770
而其他的则是次要的，

560
00:29:50,260 --> 00:29:54,340
典型数量是块存储在 3 台服务器上，

561
00:29:54,640 --> 00:29:57,010
我们可以过一会儿再谈为什么是 3 .

562
00:29:58,010 --> 00:30:02,300
然后每个主服务器有一个释放时间，

563
00:30:02,300 --> 00:30:04,310
所以，也维持一个释放时间。

564
00:30:06,100 --> 00:30:09,970
然后还有两个大的存储组件，

565
00:30:09,970 --> 00:30:12,940
这些都是文件系统级别的东西，

566
00:30:12,940 --> 00:30:16,510
然后在实施方面，有一个日志，

567
00:30:17,370 --> 00:30:18,510
还有检查点.

568
00:30:23,620 --> 00:30:27,910
因为 master 是关键的控制中心，

569
00:30:27,940 --> 00:30:31,780
每当名称空间发生更改时，

570
00:30:31,780 --> 00:30:35,020
可能在 GFS 中创建新文件，

571
00:30:35,260 --> 00:30:39,430
或者将文件映射到块和改变，

572
00:30:39,430 --> 00:30:41,500
所有这些操作都会写入这个日志，

573
00:30:41,530 --> 00:30:44,350
而日志存放在稳定的存储里。

574
00:30:49,160 --> 00:30:51,200
基本的想法是，

575
00:30:51,200 --> 00:30:54,050
在回应客户端之前，

576
00:30:54,050 --> 00:30:58,130
改变使 master 首先写入稳定存储器，

577
00:30:58,620 --> 00:30:59,970
然后对客户端进行响应，

578
00:31:00,120 --> 00:31:03,750
所以，这意味着如果 master 出现故障或崩溃，

579
00:31:03,990 --> 00:31:05,280
然后又回来了，

580
00:31:05,280 --> 00:31:09,780
它可以通过重放日志来重建它的内部状态，

581
00:31:10,840 --> 00:31:14,320
通过在响应客户端之前首先将其写入存储器，

582
00:31:14,470 --> 00:31:16,360
客户端永远不会观察到奇怪的结果，

583
00:31:16,360 --> 00:31:19,330
你可以用另一种方式，

584
00:31:19,330 --> 00:31:20,320
但那会导致一个问题，

585
00:31:20,320 --> 00:31:22,870
因为客户端会认为文件已创建，

586
00:31:22,870 --> 00:31:25,450
服务器崩溃回复，然后文件就不存在了，

587
00:31:26,840 --> 00:31:30,080
所以，这是另一个一致性关键点。

588
00:31:31,440 --> 00:31:33,750
重放总是所有操作，

589
00:31:33,750 --> 00:31:36,360
从开始时间到日志当然是不想要的，

590
00:31:36,360 --> 00:31:38,010
这意味着如果 master 崩溃，

591
00:31:38,010 --> 00:31:40,830
我们只有一个，会停机很长一段时间，

592
00:31:41,100 --> 00:31:42,150
所以除此之外，

593
00:31:42,150 --> 00:31:45,210
它也会将检查点保存在稳定存储中，

594
00:31:47,250 --> 00:31:51,690
所以， master 会定期创建自己状态的检查点，

595
00:31:51,690 --> 00:31:54,900
和映射[]块句柄，

596
00:31:55,320 --> 00:31:58,710
并将其存储在稳定的存储上，

597
00:31:58,830 --> 00:32:01,500
然后它们只需要重放最后一段，

598
00:32:01,530 --> 00:32:04,740
日志中最后一个检查点之后的所有操作，

599
00:32:04,830 --> 00:32:06,420
所以，恢复是很快的。

600
00:32:08,220 --> 00:32:09,630
所以，还有另外几个有趣的问题，

601
00:32:09,630 --> 00:32:10,590
我们可以问自己，

602
00:32:10,590 --> 00:32:14,370
比如什么状态需要放在一个稳定的存储里，

603
00:32:14,370 --> 00:32:16,350
对于 master 的功能来说。

604
00:32:17,140 --> 00:32:18,640
所以第一个要问的问题是，

605
00:32:18,700 --> 00:32:23,770
这个从文件名到块句柄的映射需要吗，

606
00:32:23,770 --> 00:32:26,500
它需要稳定储存吗，

607
00:32:27,320 --> 00:32:28,790
或者它可以只存在于内存中。

608
00:32:37,770 --> 00:32:40,980
如果 master 崩溃，

609
00:32:41,130 --> 00:32:47,650
我想你可以从块服务器获得信息，

610
00:32:48,200 --> 00:32:51,390
所以也许只是在内存中。

611
00:32:52,340 --> 00:32:54,380
是的，这是问题的答案，

612
00:32:54,380 --> 00:32:55,250
其他人是怎么想的。

613
00:32:56,180 --> 00:32:58,340
所以它可以从日志中重建出来，

614
00:32:58,370 --> 00:33:00,380
所以当服务器崩溃时，

615
00:33:00,470 --> 00:33:03,470
只有日志需要存储在硬盘中，

616
00:33:03,710 --> 00:33:05,900
然后它可以从日志重新加载到主存中。

617
00:33:06,200 --> 00:33:07,880
是的，它肯定在日志中，

618
00:33:07,880 --> 00:33:08,840
所以我们同意，

619
00:33:08,840 --> 00:33:11,930
这个块句柄列表必须存储在稳定的存储中，

620
00:33:16,220 --> 00:33:17,510
否则，我们会丢失，

621
00:33:17,510 --> 00:33:18,800
比如我们创建一个文件，

622
00:33:18,830 --> 00:33:20,210
我们没有写入存储，

623
00:33:20,210 --> 00:33:21,530
我们就把文件丢了，

624
00:33:21,530 --> 00:33:25,760
所以，从文件名到块句柄的这种映射需要在稳定的存储中，

625
00:33:25,760 --> 00:33:30,290
那么从块句柄到块服务器列表需要吗，

626
00:33:32,220 --> 00:33:33,930
它需要[]吗？

627
00:33:35,580 --> 00:33:36,660
我想在论文中，

628
00:33:36,660 --> 00:33:41,100
他们说当 master 重新启动时，

629
00:33:41,340 --> 00:33:45,780
它要求服务器告诉 master ，

630
00:33:45,780 --> 00:33:48,570
它们拥有的块是什么。

631
00:33:48,810 --> 00:33:50,520
是的，所以这不是，

632
00:33:50,520 --> 00:33:55,600
这只是易失性状态，而不是稳定的存储。

633
00:33:56,080 --> 00:34:01,770
同样的，对于主要的和次要的，以及释放时间。

634
00:34:02,630 --> 00:34:03,710
那么版本号呢？

635
00:34:10,740 --> 00:34:14,910
master 是否需要将版本号记到稳定存储中？

636
00:34:16,410 --> 00:34:18,210
是的，因为它需要知道，

637
00:34:18,210 --> 00:34:23,190
其他服务器中的块是否是旧的。

638
00:34:23,780 --> 00:34:26,030
是的，完全正确，

639
00:34:26,030 --> 00:34:27,890
所以 master 必须记住版本号，

640
00:34:27,890 --> 00:34:31,580
因为如果它不这么做，

641
00:34:31,580 --> 00:34:33,350
整个系统崩溃了，

642
00:34:33,770 --> 00:34:35,450
然后块服务器又恢复了，

643
00:34:35,750 --> 00:34:39,590
可能块服务器包含最新的还没有出现的数据，

644
00:34:39,590 --> 00:34:42,230
是一个旧的版本号 14 ，

645
00:34:42,620 --> 00:34:44,480
然后， master 必须能够区分，

646
00:34:44,480 --> 00:34:49,790
版本是 14 的块服务器不是最新的块服务器，

647
00:34:50,620 --> 00:34:53,710
所以，它需要在磁盘上维护版本号，

648
00:34:53,710 --> 00:34:55,030
可以用来区分，

649
00:34:55,060 --> 00:34:58,960
哪个块服务器拥有最新信息，哪个没有。

650
00:35:00,010 --> 00:35:00,550
好的?

651
00:35:01,020 --> 00:35:02,430
我有一个问题，

652
00:35:03,600 --> 00:35:07,740
如果 master 失败了，

653
00:35:07,740 --> 00:35:09,120
然后它再次出现，

654
00:35:09,330 --> 00:35:12,540
无论如何，它都会连接到所有块服务器，

655
00:35:12,540 --> 00:35:17,560
它会找到最大的版本是什么。

656
00:35:18,220 --> 00:35:21,760
是的，有能力找出最新的，

657
00:35:21,760 --> 00:35:25,840
首先，它尝试与所有块服务器进行交互，

658
00:35:26,110 --> 00:35:27,460
一些块服务器可能已经关闭。

659
00:35:28,040 --> 00:35:28,670
好的。

660
00:35:29,120 --> 00:35:31,670
有可能就是那台块服务器，

661
00:35:31,670 --> 00:35:33,890
正好有最新版本。

662
00:35:34,220 --> 00:35:34,910
是的，好的。

663
00:35:35,390 --> 00:35:38,990
所以，你不能使用最大的寿命的块服务器，

664
00:35:39,480 --> 00:35:41,250
这是不正确的。

665
00:35:46,110 --> 00:35:47,400
对于这个，还有其他问题吗？

666
00:35:51,820 --> 00:35:54,490
好的，让我们来看看两种基本运算，

667
00:35:55,120 --> 00:35:57,280
真正做到一致性，

668
00:35:57,280 --> 00:35:59,710
当然，这是读取和写入，

669
00:35:59,950 --> 00:36:00,940
所以读取一个文件，

670
00:36:01,510 --> 00:36:02,950
然后我们讨论如何写入文件。

671
00:36:04,060 --> 00:36:06,790
从某种意义上说，读取文件很简单，

672
00:36:06,820 --> 00:36:09,340
我们谈到的客户端发送消息，

673
00:36:09,340 --> 00:36:15,150
使用文件名加上偏移量给 master ，

674
00:36:16,320 --> 00:36:20,650
询问请给我块服务器，

675
00:36:20,740 --> 00:36:29,110
以及在偏移量处保存数据的块句柄，

676
00:36:29,850 --> 00:36:32,010
所以找到块句柄，

677
00:36:32,730 --> 00:36:36,270
比如读取字节 0 ，

678
00:36:36,300 --> 00:36:42,010
很明显，这是列表上的第一个条目，

679
00:36:42,010 --> 00:36:45,390
从文件名到块句柄。

680
00:36:46,130 --> 00:36:52,360
所以， master 块句柄与 master 一起回复，

681
00:36:52,390 --> 00:36:55,270
用块句柄回复客户端，

682
00:36:57,440 --> 00:37:06,080
以及那个句柄的块服务器列表和版本号。

683
00:37:09,000 --> 00:37:11,670
所以客户端会收到一条消息，

684
00:37:11,670 --> 00:37:14,070
表示这是块 221 ，

685
00:37:14,400 --> 00:37:17,340
并且这是三台机器，

686
00:37:17,340 --> 00:37:19,560
这三台机器所有的 IP 地址，

687
00:37:20,140 --> 00:37:22,960
并且版本号比如是 10 。

688
00:37:26,400 --> 00:37:28,200
然后，客户端缓存这个列表，

689
00:37:34,820 --> 00:37:38,240
然后它向最近的服务器发送一条消息，

690
00:37:40,140 --> 00:37:46,290
从最近的服务器读取。

691
00:37:51,380 --> 00:37:55,700
那么为什么客户端缓存这些信息，

692
00:37:58,100 --> 00:37:59,240
我们稍后再看，

693
00:37:59,240 --> 00:38:00,590
那造成了一些麻烦。

694
00:38:01,400 --> 00:38:04,340
所以它在一段时间内不需要联系 master ，

695
00:38:04,340 --> 00:38:07,580
如果它想要再次读取或写入块。

696
00:38:08,780 --> 00:38:10,130
是的，这个为什么重要？

697
00:38:11,610 --> 00:38:15,270
为了减少流量，

698
00:38:15,450 --> 00:38:18,240
一般来说，会花费更少的时间，

699
00:38:18,240 --> 00:38:20,460
如果你与 master 的通信更少。

700
00:38:20,610 --> 00:38:23,640
是的，这是正确的，

701
00:38:23,640 --> 00:38:26,040
这种设计 master 是一台机器，

702
00:38:26,980 --> 00:38:28,030
作为一台机器，

703
00:38:28,030 --> 00:38:31,750
你只拥有有限的内存和有限的网络接口，

704
00:38:31,750 --> 00:38:34,150
你有太多的客户端交互，

705
00:38:34,150 --> 00:38:36,340
它就不能服务了，

706
00:38:36,340 --> 00:38:39,970
所以，客户端缓存对于减少这台机器上的负载很重要。

707
00:38:41,730 --> 00:38:44,010
好的，为什么要从最近的服务器上读取？

708
00:38:46,860 --> 00:38:48,300
最大限度地减少网络流量。

709
00:38:48,660 --> 00:38:49,920
是的，最大限度地减少网络流量，

710
00:38:49,920 --> 00:38:51,510
所以整个目标是，

711
00:38:51,510 --> 00:38:54,660
为了将尽可能多的数据传输到客户端，

712
00:38:54,660 --> 00:38:55,500
最高的吞吐量。

713
00:38:55,890 --> 00:38:59,070
这里面有两个问题，

714
00:38:59,070 --> 00:39:01,320
我们必须通过数据中心网络，

715
00:39:01,320 --> 00:39:04,320
一个可能有一些拓扑，

716
00:39:04,320 --> 00:39:07,530
也许[]像顶层链接拓扑，

717
00:39:07,980 --> 00:39:12,870
可能会增加到达另一边的延迟。

718
00:39:13,520 --> 00:39:15,800
好的，能够访问最近的一个是重要的，

719
00:39:15,800 --> 00:39:18,980
同样，为了最大限度地提高吞吐量，

720
00:39:18,980 --> 00:39:20,840
它联合一组客户端，

721
00:39:20,840 --> 00:39:22,010
你可以得到，

722
00:39:22,010 --> 00:39:25,220
当它们从许多块服务器并行读取时。

723
00:39:26,420 --> 00:39:26,990
好的?

724
00:39:28,110 --> 00:39:32,640
所以块服务器 S 检查版本号，

725
00:39:35,570 --> 00:39:37,190
如果版本号是正确的，

726
00:39:37,280 --> 00:39:38,570
然后发送数据。

727
00:39:42,570 --> 00:39:43,170
好的?

728
00:39:44,510 --> 00:39:46,190
为什么在那里检查版本号？

729
00:39:50,580 --> 00:39:52,530
检查它是不是太旧了。

730
00:39:52,770 --> 00:39:58,010
是的，我们尽最大努力避免读取过时的数据，

731
00:39:58,820 --> 00:40:00,140
我们马上就会看到，

732
00:40:00,140 --> 00:40:02,930
我们没有在[]方面做得完美，

733
00:40:02,930 --> 00:40:08,920
但是尽量减少客户端读取过时数据的情况。

734
00:40:09,500 --> 00:40:10,040
好的?

735
00:40:11,470 --> 00:40:13,780
这些读取直截了当。

736
00:40:15,450 --> 00:40:16,920
那么，让我们来看看写入。

737
00:40:20,690 --> 00:40:22,910
这是论文上的一张图片，

738
00:40:24,880 --> 00:40:26,860
所以我们假设客户端是，

739
00:40:26,860 --> 00:40:28,450
让我们来关注追加。

740
00:40:40,440 --> 00:40:43,710
他们认为，对他们来说，这是非常常见的操作，

741
00:40:43,710 --> 00:40:45,510
需要将记录追加到文件中，

742
00:40:45,720 --> 00:40:48,630
我们能知道为什么，

743
00:40:48,660 --> 00:40:52,470
基于你们从 mapreduce 中了解到的情况，

744
00:40:52,470 --> 00:40:54,540
你知道 Google 是有道理的，

745
00:40:54,540 --> 00:40:56,010
为什么追加如此重要。

746
00:41:01,830 --> 00:41:04,380
因为在做 mapreduce 时，很大程度上，

747
00:41:04,620 --> 00:41:06,660
你需要，

748
00:41:06,810 --> 00:41:11,070
当 map 函数发出信息时，

749
00:41:11,070 --> 00:41:13,350
它在很大程度上只是增加信息，

750
00:41:13,350 --> 00:41:15,960
而不是修改之前已经发出的信息。

751
00:41:16,020 --> 00:41:18,360
是的，也许 map 不是最好的例子，

752
00:41:18,360 --> 00:41:20,940
因为它写入本地文件而不是 GFS ，

753
00:41:20,940 --> 00:41:21,990
但是 reducer 是这样做的，

754
00:41:22,290 --> 00:41:24,630
同样的论点也适用于 reducer 。

755
00:41:25,630 --> 00:41:27,310
是的，所以他们在那里工作，

756
00:41:27,310 --> 00:41:30,280
写入消耗了大量的信息，

757
00:41:30,430 --> 00:41:32,680
很快地把记录附加到文件中，

758
00:41:32,680 --> 00:41:35,170
与计算结果一起。

759
00:41:35,470 --> 00:41:36,010
好的?

760
00:41:36,970 --> 00:41:39,670
好的，所以第一步我们有客户端，

761
00:41:40,180 --> 00:41:43,630
它与 master 交互，以确定在哪里写入，

762
00:41:44,520 --> 00:41:46,650
master 查看表，

763
00:41:46,650 --> 00:41:50,250
文件名到块句柄的表，

764
00:41:56,510 --> 00:41:58,460
找到块句柄，

765
00:41:58,490 --> 00:42:06,380
然后查看块句柄到服务器的表，

766
00:42:08,360 --> 00:42:10,040
找到对应的服务器列表，

767
00:42:10,190 --> 00:42:11,600
包含指定的东西，

768
00:42:12,170 --> 00:42:13,340
包含指定的块。

769
00:42:13,950 --> 00:42:15,210
好的，接下来会发生什么，

770
00:42:15,240 --> 00:42:16,890
所以有两种情况，

771
00:42:16,950 --> 00:42:19,260
当已经有 primary 时，

772
00:42:19,260 --> 00:42:20,910
第二种情况，第一种情况，

773
00:42:20,910 --> 00:42:22,950
两种情况是有 primary 或没有 primary 。

774
00:42:23,650 --> 00:42:25,360
假设这是很早的第一次，

775
00:42:25,360 --> 00:42:29,110
这个客户端为了这个块访问 master ，

776
00:42:29,290 --> 00:42:30,820
还没有其他人这样做过，

777
00:42:30,850 --> 00:42:31,840
所以还没有 primary ，

778
00:42:32,510 --> 00:42:35,120
在这种情况下，我们需要做的是，

779
00:42:35,850 --> 00:42:38,070
master 需要选出一个 primary ，

780
00:42:38,070 --> 00:42:38,790
它是怎么做的。

781
00:42:39,950 --> 00:42:44,690
我认为 master 可以选择任何可用的块服务器。

782
00:42:46,290 --> 00:42:46,950
是的，选出一个，

783
00:42:47,400 --> 00:42:50,550
所以选出一个是 primary 和其他的都是 secondary ，

784
00:42:50,880 --> 00:42:52,920
在这种情况下，还涉及到哪些步骤。

785
00:42:53,340 --> 00:42:59,160
是的，然后 master 给那个 primary 一个租约，

786
00:42:59,160 --> 00:43:03,240
那个租约有明确的过期时间。

787
00:43:03,660 --> 00:43:04,740
是的，还有什么，

788
00:43:04,740 --> 00:43:06,570
一条或多条其他关键信息。

789
00:43:10,150 --> 00:43:10,780
Even。

790
00:43:12,260 --> 00:43:14,000
增加版本号？

791
00:43:14,000 --> 00:43:18,710
是的，第一步是增加版本号，

792
00:43:19,970 --> 00:43:22,580
因为你要有一个新的 primary ，

793
00:43:22,580 --> 00:43:24,410
当你每次有新的 primary 时，

794
00:43:24,410 --> 00:43:24,680
或者无论你有新的 primary ，

795
00:43:24,680 --> 00:43:27,290
你需要考虑的是进入了一个新时期，

796
00:43:27,320 --> 00:43:30,740
在文件系统中或这个文件中，

797
00:43:30,740 --> 00:43:31,970
所以增加版本号，

798
00:43:32,180 --> 00:43:33,680
因为你有一个新的数据，

799
00:43:34,600 --> 00:43:37,240
所以， master 会增加版本号，

800
00:43:37,880 --> 00:43:43,730
它会给 primary 和 secondary 发送一个新的版本号，

801
00:43:43,760 --> 00:43:47,570
然后说，我们要开始一个新的，

802
00:43:47,570 --> 00:43:48,920
我们要开始一个新的改变，

803
00:43:48,950 --> 00:43:51,320
你需要形成一个复制组，

804
00:43:51,560 --> 00:43:54,110
你的复制组使用这个指定的版本号，

805
00:43:54,170 --> 00:43:56,710
比如版本号 12 。

806
00:43:57,350 --> 00:44:00,170
然后 primary 和 secondary 保存版本号，

807
00:44:00,170 --> 00:44:02,000
你需要怎么保存版本号，

808
00:44:07,210 --> 00:44:11,770
它们是存储在磁盘上还是内存上，或者。

809
00:44:16,160 --> 00:44:16,850
我不知道。

810
00:44:18,780 --> 00:44:21,810
有人知道吗，你怎么想的？

811
00:44:22,740 --> 00:44:23,880
好的，让我们放到内存里，

812
00:44:23,880 --> 00:44:25,200
假设存储在内存中，

813
00:44:25,200 --> 00:44:26,190
这是一个好的设计吗？

814
00:44:28,900 --> 00:44:29,590
不是。

815
00:44:30,720 --> 00:44:31,170
抱歉。

816
00:44:31,770 --> 00:44:32,400
你可以继续。

817
00:44:32,790 --> 00:44:34,200
我想不是，

818
00:44:34,200 --> 00:44:36,360
因为如果块服务器出现故障，

819
00:44:36,360 --> 00:44:37,860
然后它又回来了，

820
00:44:37,890 --> 00:44:40,700
它应该知道自己有什么版本。

821
00:44:41,240 --> 00:44:43,100
是的，因为否则你不能说服 primary ，

822
00:44:43,100 --> 00:44:44,300
你有最近一次的，

823
00:44:44,360 --> 00:44:46,880
primary ，抱歉， master 可能会很大，

824
00:44:46,910 --> 00:44:48,740
块服务器有最新的数据，

825
00:44:49,610 --> 00:44:50,990
所以它必须是这样，

826
00:44:51,020 --> 00:44:52,850
所以，版本号存储在磁盘上，

827
00:44:52,850 --> 00:44:57,480
包括块服务器和 master 。

828
00:44:58,340 --> 00:45:00,560
所以当 master 回来后，

829
00:45:00,560 --> 00:45:03,560
来自 primary 和 secondary 的确认，

830
00:45:03,560 --> 00:45:06,920
它们已经将版本号写入磁盘，

831
00:45:07,010 --> 00:45:10,220
primary 收到了租约，

832
00:45:10,340 --> 00:45:15,260
然后 master 也将它的版本号写入磁盘，

833
00:45:15,260 --> 00:45:16,610
然后对客户端作出响应。

834
00:45:18,050 --> 00:45:18,650
好的?

835
00:45:19,780 --> 00:45:21,130
所以，要返回到客户端，

836
00:45:21,250 --> 00:45:23,320
使用服务器列表作为响应，

837
00:45:23,500 --> 00:45:27,520
primary 加上 secondary 加上版本号。

838
00:45:29,350 --> 00:45:29,980
好的?

839
00:45:31,580 --> 00:45:33,260
然后下一步，

840
00:45:33,260 --> 00:45:34,760
同样，我们在这里看到，整个目标是，

841
00:45:34,760 --> 00:45:36,710
从网络中[输入]大量数据，

842
00:45:36,710 --> 00:45:39,710
客户端只是发送数据，

843
00:45:39,740 --> 00:45:43,190
想要写入到 primary 和 secondary 的，

844
00:45:44,000 --> 00:45:46,130
它的工作方式是一种有趣的方式，

845
00:45:46,130 --> 00:45:49,070
联系它知道的最近的 secondary ，

846
00:45:49,220 --> 00:45:50,360
在这个列表上，

847
00:45:50,630 --> 00:45:51,770
并将数据发送到那里，

848
00:45:52,520 --> 00:45:56,570
那个 secondary 将数据转移给列表中的第二个人，

849
00:45:56,570 --> 00:45:58,340
然后转给下一个服务器列表，

850
00:46:00,500 --> 00:46:01,310
通过这种方式，

851
00:46:01,310 --> 00:46:03,890
数据从客户端

852
00:46:03,890 --> 00:46:07,760
发送到管道，到所有副本，

853
00:46:07,910 --> 00:46:11,090
当 secondary 收到后，

854
00:46:11,090 --> 00:46:12,680
第一个 secondary 接收到一些数据，

855
00:46:12,680 --> 00:46:16,100
立即开始将数据推向管道。

856
00:46:16,760 --> 00:46:17,420
好的?

857
00:46:18,960 --> 00:46:20,010
这种设计的原因是，

858
00:46:20,010 --> 00:46:22,140
这种方式的网络接口，

859
00:46:22,140 --> 00:46:24,240
客户端走向[外面的世界]，

860
00:46:24,300 --> 00:46:28,020
使用全网络接口向管道推送数据，

861
00:46:29,000 --> 00:46:30,410
所以，这为我们提供了高吞吐量。

862
00:46:31,550 --> 00:46:32,090
好的?

863
00:46:34,650 --> 00:46:37,200
好的，如果这些都成功了，

864
00:46:37,230 --> 00:46:40,800
数据已经被推送到所有服务器，

865
00:46:40,920 --> 00:46:43,020
这些服务器还不会存储信息，

866
00:46:43,020 --> 00:46:45,240
它只是坐在一边，

867
00:46:45,240 --> 00:46:47,520
要在下一步中使用。

868
00:46:48,120 --> 00:46:48,900
所以下一步是，

869
00:46:48,900 --> 00:46:51,060
让客户端发送消息，

870
00:46:51,060 --> 00:46:55,450
比如一个追加消息到 primary ，

871
00:46:55,810 --> 00:46:57,340
在这一刻，

872
00:46:57,640 --> 00:47:00,610
primary 会检查版本号，

873
00:47:02,240 --> 00:47:04,670
它的版本号是否匹配，

874
00:47:04,670 --> 00:47:07,220
如果它不匹配，

875
00:47:07,220 --> 00:47:08,990
那么它们不会允许这样做，

876
00:47:09,540 --> 00:47:12,390
primary 检查这个租约是否有效，

877
00:47:13,290 --> 00:47:14,940
因为如果租约不再有效，

878
00:47:14,940 --> 00:47:17,940
它不能接受任何改变操作，

879
00:47:17,940 --> 00:47:19,590
因为如果租约无效，

880
00:47:19,590 --> 00:47:22,170
外面的世界可能会有另一个 primary ，

881
00:47:23,100 --> 00:47:25,080
所以它会检查租约，

882
00:47:25,610 --> 00:47:28,940
然后，如果版本号匹配，租约有效，

883
00:47:29,150 --> 00:47:31,280
然后会选择一个偏移量来写入。

884
00:47:34,190 --> 00:47:35,180
然后下一步是，

885
00:47:35,180 --> 00:47:37,670
我们写下刚刚进来的数据，

886
00:47:37,670 --> 00:47:40,940
这个记录到一个稳定存储，

887
00:47:40,970 --> 00:47:44,330
所以，在这一点上， primary 将其写入稳定存储，

888
00:47:44,940 --> 00:47:45,660
这个数据，

889
00:47:46,380 --> 00:47:48,480
然后将消息发送到 secondary ，

890
00:47:48,480 --> 00:47:50,160
表示请将数据写入。

891
00:47:51,480 --> 00:47:54,810
因为 primary 选择的偏移量，

892
00:47:54,810 --> 00:47:56,460
它告诉 secondary ，

893
00:47:56,460 --> 00:47:59,280
将记录写入文件的哪个位置，

894
00:48:00,310 --> 00:48:03,370
比如你选择的偏移量是 125 ，

895
00:48:03,370 --> 00:48:05,140
它会告诉 secondary ，

896
00:48:05,290 --> 00:48:10,360
将早些时候进来的数据写入到偏移量 125 处。

897
00:48:11,930 --> 00:48:13,700
然后，如果一切顺利，

898
00:48:13,700 --> 00:48:16,700
所有 secondary 和 primary

899
00:48:16,700 --> 00:48:19,160
都成功地将数据写入磁盘，

900
00:48:19,310 --> 00:48:21,080
然后它会对客户端做出响应，

901
00:48:21,080 --> 00:48:25,250
表示，好的，你追加已经成功了。

902
00:48:27,770 --> 00:48:31,520
存在一种方式，写入可能不成功，

903
00:48:31,520 --> 00:48:32,900
或可能不成功，

904
00:48:32,900 --> 00:48:35,480
比如， primary 已写入自己的磁盘，

905
00:48:35,690 --> 00:48:37,790
但它没能写入，

906
00:48:37,790 --> 00:48:40,310
它没能写入其中一个 secondary ，

907
00:48:40,310 --> 00:48:42,200
或许 secondary 崩溃了，

908
00:48:42,200 --> 00:48:45,020
或者可能 secondary 的网络不工作了，

909
00:48:46,060 --> 00:48:50,980
在这种情况下， primary 会向客户端返回错误，

910
00:48:51,010 --> 00:48:58,390
所以，如果一个 secondary 没有响应，就是错误的，

911
00:49:05,510 --> 00:49:09,230
在这种情况下，客户端库将执行的操作通常是重试，

912
00:49:09,470 --> 00:49:15,240
它将重新发布相同的追加，并再次尝试，

913
00:49:15,750 --> 00:49:17,880
希望在第二次的时候，

914
00:49:18,030 --> 00:49:20,790
这些数据能被通过，

915
00:49:21,690 --> 00:49:25,290
这就是他们所说的最少一次。

916
00:49:30,830 --> 00:49:34,460
如果重试， primary 会选取相同的偏移量吗？

917
00:49:36,630 --> 00:49:37,590
我不这样认为。

918
00:49:40,740 --> 00:49:41,550
不，它需要一个新的偏移量，

919
00:49:41,550 --> 00:49:45,360
写入新的指定偏移量，

920
00:49:45,750 --> 00:49:50,040
这意味着如果你查看磁盘，

921
00:49:50,040 --> 00:49:52,440
一个文件在三个副本上，

922
00:49:53,130 --> 00:49:55,680
primary S1 和 S2 ，

923
00:49:55,680 --> 00:49:56,550
可能是这种情况，

924
00:49:56,550 --> 00:50:00,440
你写入 S1 125 数据，

925
00:50:00,710 --> 00:50:02,840
我们成功可能 S2 12 ，

926
00:50:02,840 --> 00:50:07,520
但 S2 实际上并没有发生，没有数据，

927
00:50:08,110 --> 00:50:09,850
然后我们再试一次，

928
00:50:09,850 --> 00:50:11,830
我们可能读取相同的数据 x ，

929
00:50:11,830 --> 00:50:14,200
也许在三个副本上都成功了。

930
00:50:14,950 --> 00:50:15,850
所以你可以在这里看到，

931
00:50:15,850 --> 00:50:17,920
副本的记录是可以重复的。

932
00:50:20,960 --> 00:50:23,270
这在标准文件系统中可以发生吗，

933
00:50:23,270 --> 00:50:26,030
比如在你的笔记本或计算机上的 Linux 文件系统。

934
00:50:31,710 --> 00:50:32,370
不会。

935
00:50:33,210 --> 00:50:36,690
不，如果你的计算机做到这个，你会感到惊讶吗？

936
00:50:39,680 --> 00:50:40,160
我想是的，

937
00:50:40,160 --> 00:50:42,110
这不是标准文件写入的工作方式。

938
00:50:42,410 --> 00:50:48,450
是的，有这个特性会不方便，

939
00:50:48,450 --> 00:50:49,650
还是没什么关系？

940
00:50:53,140 --> 00:50:55,330
不方便。

941
00:50:55,330 --> 00:50:57,610
是的，这会是非常奇怪的，

942
00:50:57,640 --> 00:51:01,450
编译器产生结果到文件中，

943
00:51:01,780 --> 00:51:04,180
然后，某些数据块写入了两次，

944
00:51:04,180 --> 00:51:06,100
然后你不能再运行程序了，

945
00:51:06,130 --> 00:51:09,520
所有东西都变成了垃圾。

946
00:51:10,370 --> 00:51:11,750
所以这会很奇怪，

947
00:51:11,750 --> 00:51:12,830
就像你写了一封电子邮件，

948
00:51:12,830 --> 00:51:15,170
而电子邮件的正文出现了两次。

949
00:51:15,640 --> 00:51:19,540
所以，这不是典型的文件系统，

950
00:51:19,540 --> 00:51:21,400
所以是有点奇怪的，

951
00:51:21,970 --> 00:51:23,710
你知道理由是什么，

952
00:51:24,390 --> 00:51:26,970
为什么你认为这是个好主意。

953
00:51:29,800 --> 00:51:31,270
我不确定什么是好主意，

954
00:51:31,270 --> 00:51:35,170
但我搞不懂这对 mapreduce 是如何起作用的，

955
00:51:35,350 --> 00:51:38,620
如果你运行 word count ，并且这么做，

956
00:51:38,920 --> 00:51:41,200
一些文件，你会计数，

957
00:51:41,260 --> 00:51:44,710
比如单词 a ，它只出现一次，

958
00:51:44,710 --> 00:51:46,510
但你做了两次，

959
00:51:46,510 --> 00:51:47,740
因为有些事情失败了，

960
00:51:47,800 --> 00:51:49,900
现在你得到了 a,1 a,1 ，

961
00:51:50,110 --> 00:51:51,910
所以你的 a 计数会是错的。

962
00:51:52,370 --> 00:51:54,680
怎么回事，是的，我很困惑。

963
00:51:55,240 --> 00:51:58,120
是的，它们是怎么工作的，

964
00:51:58,120 --> 00:51:59,710
好像如果你什么都不做，

965
00:51:59,710 --> 00:52:01,810
那么这真的非常不方便，

966
00:52:02,140 --> 00:52:04,240
它返回到应用程序，

967
00:52:04,240 --> 00:52:05,680
将计算错误的结果。

968
00:52:07,230 --> 00:52:12,810
他们说使用校验和和唯一的 ID 来检查，

969
00:52:12,840 --> 00:52:19,070
每一条记录都只有一次。

970
00:52:20,080 --> 00:52:23,140
另外，当你做记录追加时，

971
00:52:23,140 --> 00:52:26,680
从 primary 返回给客户端的响应，

972
00:52:26,680 --> 00:52:29,980
为你提供文件的偏移量，

973
00:52:29,980 --> 00:52:31,720
你的数据实际写入的地方，

974
00:52:31,720 --> 00:52:35,500
而其余的部分则被认为是未定义的。

975
00:52:36,740 --> 00:52:38,570
是的，我认为这里的关键点是，

976
00:52:38,570 --> 00:52:41,960
应用程序不直接与文件系统交互，

977
00:52:41,960 --> 00:52:43,400
是与某些库交互，

978
00:52:43,400 --> 00:52:44,000
在那个库里，

979
00:52:44,000 --> 00:52:45,980
如果你写入追加记录，

980
00:52:46,340 --> 00:52:48,320
那个库在绑定一个 id 给它，

981
00:52:48,680 --> 00:52:52,130
同时也使用那个库读取哪些记录，

982
00:52:52,130 --> 00:52:54,380
所以，如果你看到具有相同 id 的记录，

983
00:52:54,380 --> 00:52:55,340
可以跳过第二个，

984
00:52:55,780 --> 00:52:58,030
因为你知道这显然是同一个。

985
00:52:58,940 --> 00:53:01,910
它们还有一个额外的东西，检查和，

986
00:53:01,910 --> 00:53:04,130
确保记录不会被篡改，

987
00:53:04,370 --> 00:53:09,920
也为了检测字节的变化，

988
00:53:09,920 --> 00:53:12,710
id 会帮助他们做出决定，

989
00:53:13,070 --> 00:53:15,110
允许库来决定，

990
00:53:15,110 --> 00:53:16,310
好的，这是相同的记录，

991
00:53:16,340 --> 00:53:17,930
我不会把它交给应用程序，

992
00:53:18,860 --> 00:53:20,450
或者应用程序不需要处理它。

993
00:53:21,520 --> 00:53:22,360
好的?

994
00:53:23,390 --> 00:53:24,860
我的问题是，

995
00:53:24,860 --> 00:53:27,500
除了重写每个副本，

996
00:53:27,500 --> 00:53:30,590
记住哪个副本失败不是更好吗，

997
00:53:31,070 --> 00:53:33,740
停止直到它可以被写入。

998
00:53:34,620 --> 00:53:36,540
是的，可能有很多不同的设计，

999
00:53:36,540 --> 00:53:40,410
当我们稍后再回来，

1000
00:53:40,410 --> 00:53:44,670
我认为他们这样做的一个原因是，

1001
00:53:44,670 --> 00:53:46,920
如果是暂时的失败，

1002
00:53:46,920 --> 00:53:49,080
比如网络断开或租约问题，

1003
00:53:49,080 --> 00:53:50,670
写入将会成功，它们可以继续，

1004
00:53:51,380 --> 00:53:53,510
并且不需要做任何重新配置，

1005
00:53:53,510 --> 00:53:55,100
什么都不用做，

1006
00:53:55,160 --> 00:53:58,410
写入可以继续下去，

1007
00:53:58,470 --> 00:54:00,630
所以，写入不是必须失败。

1008
00:54:02,630 --> 00:54:03,170
好的。

1009
00:54:03,820 --> 00:54:05,980
我有一个简短的问题，

1010
00:54:06,400 --> 00:54:11,170
所有这些服务器都是可信的，没有。

1011
00:54:11,200 --> 00:54:15,640
是的，当然，这是重要的一点，

1012
00:54:15,640 --> 00:54:17,440
这不像 Linux 文件系统，

1013
00:54:17,440 --> 00:54:20,350
有权限和访问控制写入

1014
00:54:20,350 --> 00:54:21,400
以及诸如此类的东西，

1015
00:54:22,180 --> 00:54:24,310
服务器是完全可信的，

1016
00:54:24,520 --> 00:54:26,590
客户端是可信的， master 是可信的，

1017
00:54:26,590 --> 00:54:28,390
Google 写的软件是可信的，

1018
00:54:28,390 --> 00:54:29,350
整个事情都是可信的，

1019
00:54:31,440 --> 00:54:33,360
这是完全内部的文件系统。

1020
00:54:34,220 --> 00:54:35,210
事实上，这很酷，

1021
00:54:35,210 --> 00:54:36,710
可能有点令人惊讶，

1022
00:54:36,710 --> 00:54:39,140
我们甚至不知道这个文件系统的这么多细节，

1023
00:54:39,170 --> 00:54:41,660
因为它只在 Google 内部使用，

1024
00:54:41,660 --> 00:54:43,010
其中一件很酷的事情是，

1025
00:54:43,010 --> 00:54:46,090
有一段时间，他们仍然在这样做，

1026
00:54:46,240 --> 00:54:47,830
他们撰写了论文，

1027
00:54:47,830 --> 00:54:49,840
并描述这些系统是如何工作的，

1028
00:54:49,870 --> 00:54:51,970
我们知道这个只有一个原因，

1029
00:54:52,450 --> 00:54:55,780
他们这样做是非常酷的。

1030
00:54:59,110 --> 00:54:59,650
好的。

1031
00:55:01,660 --> 00:55:04,990
好的，我们现在了解了读取是如何工作的，写入是如何工作的，

1032
00:55:04,990 --> 00:55:08,770
有一些有趣的行为，

1033
00:55:09,130 --> 00:55:11,350
我想更多地谈谈一致性，

1034
00:55:11,350 --> 00:55:12,670
这会归结为，

1035
00:55:13,030 --> 00:55:18,130
在你追加之后，读取会观察到什么，

1036
00:55:18,370 --> 00:55:22,270
家庭作业的问题会在这之后，

1037
00:55:22,270 --> 00:55:23,560
我现在想要做的是，

1038
00:55:23,560 --> 00:55:26,080
简短休息一下，比如五分钟，

1039
00:55:26,260 --> 00:55:30,220
所以你们可以讨论这个问题的答案，

1040
00:55:30,340 --> 00:55:31,270
然后回来，

1041
00:55:31,270 --> 00:55:33,760
更详细地讨论一下一致性。

1042
00:55:34,220 --> 00:55:34,850
好的?

1043
00:55:36,370 --> 00:55:42,070
我要让 Lily （设置 zoom ）。

1044
00:55:43,160 --> 00:55:45,210
好了，大家回来了。

1045
00:55:46,110 --> 00:55:48,120
大家能听到我吗，检查一下。

1046
00:55:48,570 --> 00:55:50,310
是的，教授，有一个问题，

1047
00:55:50,310 --> 00:55:53,490
你能够回到幻灯片，

1048
00:55:54,580 --> 00:55:56,950
当我们谈到写入时的幻灯片，

1049
00:55:56,980 --> 00:55:57,880
就像你提到的，

1050
00:55:58,560 --> 00:56:01,230
master 通过版本号响应客户端，

1051
00:56:02,780 --> 00:56:04,280
如果这是关键，

1052
00:56:04,280 --> 00:56:07,370
那有没有可能，

1053
00:56:08,120 --> 00:56:10,220
是否需要读取旧数据，

1054
00:56:10,220 --> 00:56:12,140
因为客户端具有版本号，

1055
00:56:12,140 --> 00:56:14,030
而块服务器没有版本号，

1056
00:56:14,330 --> 00:56:15,890
这样他们可以比较这些，

1057
00:56:16,070 --> 00:56:17,660
如果它们与客户端不匹配，

1058
00:56:17,660 --> 00:56:20,420
块服务器可以说，

1059
00:56:20,480 --> 00:56:21,890
我有一个旧数据，

1060
00:56:21,890 --> 00:56:24,410
所以你不应该读取这个。

1061
00:56:25,170 --> 00:56:26,190
好的，我们，

1062
00:56:26,250 --> 00:56:28,200
是的，让我们来看一下这个场景的更多细节。

1063
00:56:28,200 --> 00:56:29,700
让我来放大这个窗口。

1064
00:56:36,090 --> 00:56:37,440
好的，我们来谈谈，

1065
00:56:37,440 --> 00:56:39,120
我认为我们正在讨论的这个场景，

1066
00:56:39,450 --> 00:56:42,450
这会导致下面的问题，

1067
00:56:42,630 --> 00:56:44,730
我们有 primary ，我们 secondary ，

1068
00:56:44,730 --> 00:56:49,980
两个 secondary ， S1 S2 ，

1069
00:56:49,980 --> 00:56:51,720
我们在这边有个客户端，

1070
00:56:52,420 --> 00:56:54,460
我们有一个 primary ，

1071
00:56:55,450 --> 00:56:58,960
客户端收到返回的版本号，比如是 10 ，

1072
00:57:03,440 --> 00:57:09,020
随后，另一个 primary 将会，

1073
00:57:16,680 --> 00:57:19,350
好的，所以 S2 获得一些服务器，

1074
00:57:19,350 --> 00:57:21,600
然后在某个时候，

1075
00:57:22,920 --> 00:57:26,610
这个信息被缓存在（客户端），

1076
00:57:26,610 --> 00:57:32,490
也许一个 secondary 比如 S2 崩溃，

1077
00:57:32,900 --> 00:57:35,960
或者至少与网络断开，

1078
00:57:36,650 --> 00:57:39,800
所以 master 要做的是递增版本号，

1079
00:57:39,800 --> 00:57:43,430
转到 11 ，消息 11 ，

1080
00:57:44,160 --> 00:57:48,540
然后，另一个客户端可能会过来，开始写入，

1081
00:57:49,320 --> 00:57:54,870
所以，我们为该文件的 S1 和 S2 写入一个新值，

1082
00:57:54,870 --> 00:57:56,340
所以块现在已经更新了，

1083
00:57:56,340 --> 00:57:59,760
我们假设原始版本号为 10 ，

1084
00:57:59,760 --> 00:58:01,590
现在这里是 11 ，

1085
00:58:02,460 --> 00:58:03,930
但是情况是这样的，

1086
00:58:03,930 --> 00:58:07,590
即使 master primary secondary 不能访问 S2 ，

1087
00:58:07,590 --> 00:58:08,790
但是第二个客户端，

1088
00:58:09,030 --> 00:58:11,850
第一个客户端仍然与那个 secondary 交互，

1089
00:58:12,060 --> 00:58:14,340
它将读取到与之匹配的版本号，

1090
00:58:14,370 --> 00:58:15,510
它们都是 10 ，

1091
00:58:17,340 --> 00:58:21,990
它会发回 10 ，

1092
00:58:21,990 --> 00:58:24,840
所以，你有一种情况，写入已经完成，

1093
00:58:25,220 --> 00:58:26,990
并确认已经成功，

1094
00:58:27,260 --> 00:58:28,400
尽管如此，

1095
00:58:28,400 --> 00:58:30,980
还是有一个客户端会读取一个旧的值。

1096
00:58:31,680 --> 00:58:34,500
那么，为什么 11 不回到客户端呢？

1097
00:58:36,550 --> 00:58:38,590
第一个客户端，

1098
00:58:39,650 --> 00:58:42,620
原因是第一客户端将其缓存了更长的时间，

1099
00:58:43,280 --> 00:58:45,800
他们在协议中没有做到这个的内容。

1100
00:58:50,060 --> 00:58:51,860
当版本会更新，

1101
00:58:51,860 --> 00:58:57,320
当系统尝试将更新推送到 S2 时，

1102
00:58:57,320 --> 00:58:59,210
还是不能，或者。

1103
00:58:59,300 --> 00:59:01,100
版本号递增只是在，

1104
00:59:01,430 --> 00:59:03,320
版本号由 master 维护的，

1105
00:59:03,320 --> 00:59:06,350
它们只在选择新的 primary 时才会增加，

1106
00:59:12,910 --> 00:59:13,900
当你这样做的时候不会，

1107
00:59:13,900 --> 00:59:16,660
他们还提到了一个序列号，

1108
00:59:17,020 --> 00:59:18,460
但它与版本号不同，

1109
00:59:18,490 --> 00:59:20,590
它是你写入的顺序。

1110
00:59:22,670 --> 00:59:23,240
好的?

1111
00:59:23,920 --> 00:59:27,730
primary 如何知道它必须与哪个 secondary 进行检查，

1112
00:59:27,880 --> 00:59:30,640
在完成写入之前。

1113
00:59:31,360 --> 00:59:33,100
primary ， master 告诉它的，

1114
00:59:34,140 --> 00:59:36,900
master 告诉 primary 你需要更新 secondary 。

1115
00:59:39,720 --> 00:59:43,080
所以，当 master 向 primary 发出租约时，

1116
00:59:43,200 --> 00:59:46,710
如果当时有一个 secondary 出了故障，

1117
00:59:46,920 --> 00:59:48,990
master 是否认为这是一次失败，

1118
00:59:48,990 --> 00:59:52,860
或者它只是更新处于活动状态的服务器的版本号，

1119
00:59:52,860 --> 00:59:55,350
而它只是忽略另一个，

1120
00:59:55,350 --> 00:59:57,930
因为它无论如何都会有一个过时的版本号。

1121
00:59:58,410 --> 01:00:01,110
是的，论文有点[]，

1122
01:00:01,110 --> 01:00:06,420
恢复部分，重新配置是如何工作的，

1123
01:00:06,630 --> 01:00:08,040
但是我想，

1124
01:00:08,040 --> 01:00:12,300
primary 与 P1 S1 S2 之间有心跳，

1125
01:00:12,630 --> 01:00:15,150
在某个时刻， S2 挂掉了，

1126
01:00:15,420 --> 01:00:18,930
在这个时刻，它将指向，

1127
01:00:18,930 --> 01:00:21,240
primary 的租约可能会到期，

1128
01:00:21,660 --> 01:00:26,700
然后，它将创建一个新的 primary 和一个新的 S1 ，另一个 S ，

1129
01:00:26,700 --> 01:00:27,930
实际持有，

1130
01:00:27,930 --> 01:00:29,070
或者可能只是 S1 ，

1131
01:00:29,070 --> 01:00:32,670
因为没有额外的块服务器，

1132
01:00:32,850 --> 01:00:35,910
这形成了这个块的新的副本组。

1133
01:00:37,620 --> 01:00:40,860
此外，租约还没有到期。

1134
01:00:41,550 --> 01:00:44,310
好的， primary 不能指定，

1135
01:00:44,310 --> 01:00:45,990
好的，这里有一些有趣的案例，

1136
01:00:45,990 --> 01:00:46,440
我们看一下，

1137
01:00:46,560 --> 01:00:49,020
你们做的就是我想的，

1138
01:00:49,110 --> 01:00:50,670
在这篇论文的基础上，

1139
01:00:50,670 --> 01:00:53,580
你开始思考所有有问题的情况。

1140
01:00:53,990 --> 01:00:56,090
这正是你对一致性的看法，

1141
01:00:56,120 --> 01:00:57,740
当你开始考虑一致性时，

1142
01:00:57,740 --> 01:01:00,230
你需要考虑所有可能的失败，

1143
01:01:00,620 --> 01:01:04,070
并争论这些失败是否会导致不一致。

1144
01:01:04,700 --> 01:01:08,210
所以，有一件事，我们来谈谈这个情况，

1145
01:01:08,240 --> 01:01:10,760
我们有一个 master ，我们有一个 primary ，

1146
01:01:11,560 --> 01:01:16,690
我们假设 primary 和 master 断开连接，

1147
01:01:16,750 --> 01:01:18,880
让我以稍微不同的方式来画这幅图，

1148
01:01:21,170 --> 01:01:22,400
master 在中间，

1149
01:01:23,920 --> 01:01:29,060
我们这里有服务器， S1 S2 ，

1150
01:01:29,060 --> 01:01:30,500
假设 S2 是 primary ，

1151
01:01:32,310 --> 01:01:37,200
所以，你可能会与其他服务器交互，

1152
01:01:38,540 --> 01:01:43,160
也许 S1 是这个 primary 的一个 secondary 。

1153
01:01:43,930 --> 01:01:46,030
我们假设网络分裂，

1154
01:01:46,270 --> 01:01:49,390
所以 master 发送心跳消息，

1155
01:01:49,390 --> 01:01:50,560
没有得到响应，

1156
01:01:53,270 --> 01:01:55,640
什么时候 master 会指向新的 primary 。

1157
01:01:59,270 --> 01:02:01,610
当 S2 的租约到期？

1158
01:02:04,060 --> 01:02:08,740
是的，因为 primary 必须等待，

1159
01:02:08,740 --> 01:02:11,050
master 必须等待直到租约到期，

1160
01:02:11,610 --> 01:02:14,910
因为如果租约没有到期，

1161
01:02:15,090 --> 01:02:18,030
那么我们可能会同时有两个 primary ，

1162
01:02:18,800 --> 01:02:22,100
P1 和 P2 同时存在，

1163
01:02:22,100 --> 01:02:23,390
那会不会很糟糕？

1164
01:02:26,540 --> 01:02:28,880
是的，然后我想，

1165
01:02:30,180 --> 01:02:34,170
客户端不知道发送到哪里，

1166
01:02:34,170 --> 01:02:36,480
master 也不知道哪一个是 primary 。

1167
01:02:36,510 --> 01:02:39,750
大概有些客户端还在跟这个 primary 交互，

1168
01:02:40,410 --> 01:02:42,480
同时你也可能与这个 primary 交互，

1169
01:02:43,200 --> 01:02:44,670
同一块的 primary 。

1170
01:02:47,820 --> 01:02:49,860
我觉得东西会很奇怪，

1171
01:02:49,950 --> 01:02:51,990
一些写入操作会丢失，

1172
01:02:51,990 --> 01:02:53,910
那会是一团糟。

1173
01:02:54,630 --> 01:02:56,070
它不会是一个[原则]，

1174
01:02:56,070 --> 01:02:57,780
争论哪里，

1175
01:02:57,780 --> 01:03:00,900
所有写入的顺序，一次写入一个。

1176
01:03:03,900 --> 01:03:04,980
所以这是一个糟糕的情况，

1177
01:03:04,980 --> 01:03:06,480
这种情况是可以避免的，

1178
01:03:06,480 --> 01:03:10,200
比如脑裂，有时被称为脑裂，

1179
01:03:10,200 --> 01:03:12,510
那里你最终会得到一个有两个 master 的系统。

1180
01:03:12,980 --> 01:03:17,000
这里避免这个问题，因为使用了租约，

1181
01:03:17,990 --> 01:03:21,200
master 不会指定任何其他 primary ，

1182
01:03:21,200 --> 01:03:25,880
知道第一个 primary 的租约到期，

1183
01:03:25,880 --> 01:03:27,620
它知道即使 primary 是运行的，

1184
01:03:27,620 --> 01:03:28,910
但它无法达到，

1185
01:03:28,910 --> 01:03:30,530
但对其他客户端来说可能是合理的，

1186
01:03:30,590 --> 01:03:33,080
那个 primary 将不再接受任何写入消息，

1187
01:03:33,080 --> 01:03:34,400
因为租约已经到期了。

1188
01:03:40,210 --> 01:03:40,960
这能理解吗？

1189
01:03:43,400 --> 01:03:46,340
好的，在结束之前，让我再说一件事，

1190
01:03:46,580 --> 01:03:52,510
抱歉，因为我有一些技术问题，

1191
01:03:52,510 --> 01:03:54,490
但我想再说一个点，

1192
01:03:54,490 --> 01:03:58,390
这也是在分解会议室讨论中提出的，

1193
01:03:58,420 --> 01:04:00,370
那就是如何才能做得更好，

1194
01:04:00,940 --> 01:04:02,470
如何获得强一致性，

1195
01:04:06,070 --> 01:04:07,660
或者只是变得更强，

1196
01:04:07,690 --> 01:04:09,370
获得了相当强的一致性，

1197
01:04:09,370 --> 01:04:15,490
不是关于的问题。

1198
01:04:16,100 --> 01:04:17,990
所以有很多不同的方法来做，

1199
01:04:17,990 --> 01:04:24,980
事实上，我们将要看到的。

1200
01:04:25,740 --> 01:04:28,980
我认为这里经常出现的一个问题是，

1201
01:04:28,980 --> 01:04:32,730
除了获得 primary 然后报告，

1202
01:04:33,340 --> 01:04:35,020
以增量方式写入，

1203
01:04:35,020 --> 01:04:36,190
这可能不是个好主意，

1204
01:04:36,400 --> 01:04:37,870
所以你可能想要做的是，

1205
01:04:37,870 --> 01:04:43,900
更新所有 secondary primary 或者不更新，

1206
01:04:45,220 --> 01:04:47,320
但不是在这个设计中，

1207
01:04:47,320 --> 01:04:49,960
有些更新了，有些可能没有更新，

1208
01:04:49,960 --> 01:04:51,520
这对客户端是可见的。

1209
01:04:52,660 --> 01:04:56,710
所以有很多技术或协议

1210
01:04:56,710 --> 01:04:57,730
改变你可以做的，

1211
01:04:58,030 --> 01:04:59,320
会让它变得更好，

1212
01:04:59,320 --> 01:05:02,350
事实上，你将在实验 2 和 3 中看到，

1213
01:05:02,380 --> 01:05:05,590
你将构建的系统具有更强的属性，

1214
01:05:06,370 --> 01:05:11,080
处理并发的场景，从而实现一致性。

1215
01:05:11,690 --> 01:05:13,550
事实上，如果你看看 Google 自己，

1216
01:05:13,820 --> 01:05:15,860
我们之后会看到，

1217
01:05:16,040 --> 01:05:18,410
Google 建造了更多的存储系统，

1218
01:05:19,640 --> 01:05:21,830
其他一致性更强的存储系统，

1219
01:05:25,930 --> 01:05:29,170
并且针对不同的应用领域做了定制，

1220
01:05:29,410 --> 01:05:33,370
比如，在学期中看的 Spanner 论文，

1221
01:05:33,640 --> 01:05:37,540
它是具有更强大的一致性存储，

1222
01:05:37,540 --> 01:05:40,030
甚至支持事务。

1223
01:05:40,570 --> 01:05:43,150
但应用程序领域是完全不同的，

1224
01:05:43,180 --> 01:05:44,590
你可以在这里看到，

1225
01:05:44,590 --> 01:05:46,150
GFS 是量身定制的，

1226
01:05:46,150 --> 01:05:49,510
为了运行 mapreduce 作业。

1227
01:05:51,680 --> 01:05:55,430
好的，我希望这是一个关于一致性的有用的介绍，

1228
01:05:55,430 --> 01:05:57,650
开始思考这类问题，

1229
01:05:57,950 --> 01:06:00,290
因为它们会重复出现一系列问题，

1230
01:06:00,290 --> 01:06:02,090
将在本学期余下的时间里体现出来。

1231
01:06:03,760 --> 01:06:05,560
很抱歉，超出一些时间。

1232
01:06:07,740 --> 01:06:08,400
谢谢。

1233
01:06:08,400 --> 01:06:10,950
如果你们想问更多的问题，可以继续，

1234
01:06:10,950 --> 01:06:13,350
请随意提问，

1235
01:06:13,620 --> 01:06:15,300
如果你必须上另一节课，

1236
01:06:15,300 --> 01:06:16,920
请去上另一节课。

